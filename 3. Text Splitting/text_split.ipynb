{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDFloader = PyPDFLoader(\"2. DataIngestion/Machine LEarning.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDFDocs = PDFloader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 0}, page_content=''),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 1}, page_content='Machine\\tLearning\\tStep-by-Step\\tGuide\\tTo\\tImplementMachine\\tLearning\\tAlgorithms\\twith\\tPython\\t\\t\\t\\t\\t\\t\\t\\tAuthorRudolph\\tRussell'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 2}, page_content='©Copyright\\t2018\\t-\\tAll\\trights\\treserved.\\tIf\\tyou\\twould\\tlike\\tto\\tshare\\tthis\\tbook\\twith\\tanother\\tperson,\\tplease\\tpurchase\\tanadditional\\tcopy\\tfor\\teach\\trecipient.\\tThank\\tyou\\tfor\\trespecting\\tthe\\thard\\twork\\tofthis\\tauthor.\\tOtherwise,\\tthe\\ttransmission,\\tduplication\\tor\\treproduction\\tof\\tany\\tofthe\\tfollowing\\twork\\tincluding\\tspecific\\tinformation\\twill\\tbe\\tconsidered\\tan\\tillegalact\\tirrespective\\tof\\tif\\tit\\tis\\tdone\\telectronically\\tor\\tin\\tprint.\\tThis\\textends\\tto\\tcreatinga\\tsecondary\\tor\\ttertiary\\tcopy\\tof\\tthe\\twork\\tor\\ta\\trecorded\\tcopy\\tand\\tis\\tonly\\tallowedwith\\tan\\texpress\\twritten\\tconsent\\tfrom\\tthe\\tPublisher.\\tAll\\tadditional\\tright\\treserved.'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 3}, page_content='Table\\tof\\tContents\\tCHAPTER\\t1INTRODUCTION\\tTO\\tMACHINE\\tLEARNINGTheoryWhat\\tis\\tmachine\\tlearning?Why\\tmachine\\tlearning?When\\tshould\\tyou\\tuse\\tmachine\\tlearning?Types\\tof\\tSystems\\tof\\tMachine\\tLearningSupervised\\tand\\tunsupervised\\tlearningSupervised\\tLearningThe\\tmost\\timportant\\tsupervised\\talgorithmsUnsupervised\\tLearningThe\\tmost\\timportant\\tunsupervised\\talgorithmsReinforcement\\tLearningBatch\\tLearningOnline\\tLearningInstance\\tbased\\tlearningModel-based\\tlearningBad\\tand\\tInsufficient\\tQuantity\\tof\\tTraining\\tDataPoor-Quality\\tDataIrrelevant\\tFeaturesFeature\\tEngineeringTestingOverfitting\\tthe\\tDataSolutionsUnderfitting\\tthe\\tDataSolutionsEXERCISESSUMMARYREFERENCES\\tCHAPTER\\t2'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 4}, page_content='CLASSIFICATIONInstallationThe\\tMNISTMeasures\\tof\\tPerformanceConfusion\\tMatrixRecallRecall\\tTradeoffROCMulti-class\\tClassificationTraining\\ta\\tRandom\\tForest\\tClassifierError\\tAnalysisMulti-label\\tClassificationsMulti-output\\tClassificationEXERCISESREFERENCES\\tCHAPTER\\t3HOW\\tTO\\tTRAIN\\tA\\tMODELLinear\\tRegressionComputational\\tComplexityGradient\\tDescentBatch\\tGradient\\tDescentStochastic\\tGradient\\tDescentMini-Batch\\tGradient\\tDescentPolynomial\\tRegressionLearning\\tCurvesRegularized\\tLinear\\tModelsRidge\\tRegressionLasso\\tRegressionEXERCISESSUMMARYREFERENCES\\tChapter\\t4Different\\tmodels\\tcombinationsImplementing\\ta\\tsimple\\tmajority\\tclassiferCombining\\tdifferent\\talgorithms\\tfor\\tclassification\\twith\\tmajority\\tvoteQuestions'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 5}, page_content='CHAPTER\\t1INTRODUCTION\\tTO\\tMACHINE\\tLEARNING\\t'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 6}, page_content=\"TheoryIf\\tI\\task\\tyou\\tabout\\t“Machine\\tlearning,”\\tyou'll\\t\\tprobably\\t\\timagine\\ta\\trobot\\torsomething\\tlike\\tthe\\t\\tTerminator.\\tIn\\treality\\tt,\\tmachine\\tlearning\\tis\\tinvolved\\t\\tnotonly\\tin\\trobotics,\\tbut\\talso\\tin\\tmany\\tother\\tapplications.\\tYou\\tcan\\talso\\timaginesomething\\tlike\\ta\\tspam\\tfilter\\tas\\tbeing\\t\\tone\\tof\\tthe\\tfirst\\tapplications\\tin\\tmachinelearning,\\twhich\\t\\t\\thelps\\t\\timprove\\tthe\\tlives\\tof\\tmillions\\tof\\tpeople.\\tIn\\tthis\\tchapter,I'll\\tintroduce\\tyou\\twhat\\tmachine\\tlearning\\tis,\\tand\\thow\\tit\\tworks.\\t\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 7}, page_content='What\\tis\\tmachine\\tlearning?Machine\\tlearning\\tis\\tthe\\tpractice\\t\\tof\\tprogramming\\tcomputers\\tto\\tlearn\\tfrom\\tdata.In\\tthe\\tabove\\texample,\\tthe\\tprogram\\twill\\t\\teasily\\tbe\\table\\tto\\tdetermine\\tif\\t\\tgiven\\tareimportant\\tor\\tare\\t\\t“spam”.\\tIn\\tmachine\\tlearning,\\tdata\\treferred\\tto\\tas\\t\\tcalled\\ttrainingsets\\tor\\texamples.'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 8}, page_content=\"\\t\\tWhy\\tmachine\\tlearning?Let’s\\tassume\\tthat\\tyou'd\\tlike\\tto\\twrite\\tthe\\tfilter\\tprogram\\twithout\\tusing\\tmachinelearning\\tmethods.\\tIn\\tthis\\tcase,\\tyou\\twould\\thave\\tto\\tcarry\\tout\\tthe\\tfollowing\\tsteps:\\t∙\\tIn\\tthe\\tbeginning,\\tyou'd\\ttake\\ta\\tlook\\tat\\twhat\\tspam\\te-mails\\tlooks\\tlike.\\tYou\\tmight\\tselect\\tthem\\tfor\\tthe\\t\\twords\\tor\\tphrases\\tthey\\tuse,\\tlike\\t“debit\\tcard,”\\t“free,”\\tand\\tsoon,\\tand\\talso\\tfrom\\tpatterns\\tthat\\tare\\tused\\tin\\tthe\\tsender’s\\tname\\tor\\tin\\tthe\\tbody\\tofthe\\temail\\t∙\\tSecond,\\tyou'd\\twrite\\tan\\talgorithm\\tto\\tdetect\\tthe\\tpatterns\\tthat\\tyou've\\tseen,\\tandthen\\tthe\\tsoftware\\twould\\tflag\\temails\\tas\\tspam\\tif\\ta\\tcertain\\tnumber\\tof\\tthose\\tpatternsare\\tdetected.\\t\\t∙\\tFinally,\\tyou'd\\t\\ttest\\tthe\\tprogram,\\tand\\tthen\\tredo\\tthe\\tfirst\\ttwo\\tsteps\\tagain\\tuntil\\ttheresults\\tare\\tgood\\tenough.\\nBecause\\tthe\\tprogram\\tis\\tnot\\tsoftware,\\tit\\tcontains\\ta\\tvery\\tlong\\tlist\\tof\\trules\\tthat\\taredifficult\\tto\\t\\tmaintain.\\tBut\\tif\\tyou\\t\\tdeveloped\\tthe\\tsame\\tsoftware\\tusing\\tML,\\tyou'llbe\\table\\tto\\tmaintain\\tit\\tproperly.\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 9}, page_content='In\\taddition,\\tthe\\temail\\tsenders\\tcan\\t\\tchange\\ttheir\\te-mail\\ttemplates\\t\\tso\\tthat\\ta\\twordlike\\t“4U”\\tis\\tnow\\t\\t“for\\tyou,”\\tsince\\ttheir\\temails\\thave\\tbeen\\t\\tdetermined\\t\\tto\\tbespam.\\tThe\\tprogram\\tusing\\t\\ttraditional\\ttechniques\\twould\\tneed\\tto\\tbe\\tupdated,which\\tmeans\\tthat,\\t\\tif\\tthere\\twere\\tany\\tother\\tchanges,\\tyou\\twould\\tl\\tneed\\tto\\tupdateyour\\tcode\\tagain\\tand\\tagain\\tand\\tagain.On\\tthe\\tother\\thand,\\ta\\t\\tprogram\\tthat\\tuses\\tML\\ttechniques\\twill\\tautomatically\\tdetectthis\\tchange\\tby\\tusers,\\tand\\tit\\tstarts\\tto\\tflag\\tthem\\twithout\\tyou\\tmanually\\ttelling\\tit\\tto.\\nAlso,\\twe\\tcan\\tuse\\t,machine\\tlearning\\tto\\tsolve\\tproblems\\tthat\\tare\\tvery\\tcomplex\\tfornon-machine\\tlearning\\tsoftware.\\tFor\\texample,\\tspeech\\trecognition:\\twhen\\tyou\\tsay“one”\\tor\\t“two”,\\tthe\\tprogram\\tshould\\tbe\\table\\tto\\tdistinguish\\tthe\\tdifference.\\tSo,\\tfor'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 10}, page_content=\"this\\ttask,\\t\\tyou'll\\tneed\\tto\\tdevelop\\tan\\talgorithm\\tthat\\tmeasures\\tsound.In\\tthe\\tend,\\tmachine\\tlearning\\twill\\thelp\\tus\\tto\\tlearn,\\tand\\t\\tmachine-learningalgorithms\\tcan\\thelp\\tus\\tsee\\twhat\\twe\\thave\\tlearned.\\t\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 11}, page_content='When\\tshould\\tyou\\tuse\\tmachine\\tlearning?•\\tWhen\\tyou\\thave\\t\\ta\\tproblem\\tthat\\trequires\\tmany\\t\\tlong\\tlists\\tof\\trules\\tto\\tfind\\t\\tthesolution.\\tIn\\tthis\\tcase,\\tmachine-learning\\ttechniques\\tcan\\tsimplify\\tyour\\tcode\\tandimprove\\tperformance.•\\tVery\\tcomplex\\tproblems\\tfor\\twhich\\tthere\\tis\\tno\\tsolution\\twith\\ta\\ttraditionalapproach.•\\tNon-\\tstable\\tenvironments’:\\tmachine-learning\\tsoftware\\tcan\\tadapt\\tto\\tnew\\tdata.\\t'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 12}, page_content='Types\\tof\\tSystems\\tof\\tMachine\\tLearning\\tThere\\tare\\tdifferent\\ttypes\\tof\\tmachine-learning\\tsystems.\\tWe\\tcan\\tdivide\\tthem\\tintocategories,\\tdepending\\ton\\twhether\\t•\\tThey\\thave\\tbeen\\ttrained\\twith\\thumans\\t\\tor\\tnot-\\t\\t\\t\\t\\t\\t\\t\\tSupervised-\\t\\t\\t\\t\\t\\t\\t\\tUnsupervised-\\t\\t\\t\\t\\t\\t\\t\\tSemi-supervised-\\t\\t\\t\\t\\t\\t\\t\\tReinforcement\\tLearning•\\tIf\\tthey\\tcan\\tlearn\\tincrementally•\\tIf\\tthey\\twork\\tsimply\\tby\\tcomparing\\tnew\\tdata\\tpoints\\tto\\tfind\\t\\tdata\\tpoints,\\tor\\tcandetect\\tnew\\tpatterns\\tin\\tthe\\tdata\\t,and\\tthen\\twill\\tbuild\\ta\\tmodel.'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 13}, page_content=\"\\tSupervised\\tand\\tunsupervised\\tlearningWe\\tcan\\tclassify\\tmachine\\tlearning\\tsystems\\taccording\\tto\\tthe\\ttype\\tand\\tamount\\tofhuman\\tsupervision\\tduring\\tthe\\ttraining.\\t\\tYou\\tcan\\tfind\\tfour\\tmajor\\tcategories,\\taswe\\texplained\\tbefore.-\\t\\t\\t\\t\\t\\t\\t\\tSupervised\\tlearning-\\t\\t\\t\\t\\t\\t\\t\\tUnsupervised\\tlearning-\\t\\t\\t\\t\\t\\t\\t\\tSemi-supervised\\tlearning-\\t\\t\\t\\t\\t\\t\\t\\tReinforcement\\tlearning\\tSupervised\\tLearningIn\\tthis\\ttype\\tof\\tmachine-learning\\tsystem,\\tthe\\tdata\\tthat\\tyou\\tfeed\\tinto\\tthealgorithm,\\twith\\tthe\\tdesired\\tsolution,\\tare\\treferred\\tto\\tas\\t“labels.”\\n-\\t\\t\\t\\t\\t\\t\\t\\tSupervised\\tlearning\\tgroups\\ttogether\\ta\\ttasks\\tof\\tclassification.\\tThe\\taboveprogram\\tis\\ta\\tgood\\texample\\tof\\tthis\\tbecause\\tit's\\tbeen\\ttrained\\twith\\tmany\\temailsat\\tthe\\tsame\\ttime\\tas\\ttheir\\tclass.\\t\\tAnother\\texample\\tis\\tto\\tpredict\\ta\\tnumeric\\tvalue\\tlike\\tthe\\tprice\\tof\\ta\\tflat,\\tgiven\\ta\\tsetof\\tfeatures\\t(location,\\tnumber\\tof\\trooms,\\tfacilities)\\tcalled\\tpredictors;\\tthis\\ttype\\toftask\\tis\\tcalled\\tregression.\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 14}, page_content=\"You\\tshould\\tkeep\\tin\\tmind\\tthat\\tsome\\tregression\\talgorithms\\tcan\\tbe\\tused\\tforclassifications\\tas\\twell,\\tand\\tvice\\tversa.\\tThe\\tmost\\timportant\\tsupervised\\talgorithms-\\t\\t\\t\\t\\t\\t\\t\\tK-nears\\tneighbors-\\t\\t\\t\\t\\t\\t\\t\\tLinear\\tregression-\\t\\t\\t\\t\\t\\t\\t\\tNeural\\tnetworks-\\t\\t\\t\\t\\t\\t\\t\\tSupport\\tvector\\tmachines-\\t\\t\\t\\t\\t\\t\\t\\tLogistic\\tregression-\\t\\t\\t\\t\\t\\t\\t\\tDecision\\ttrees\\tand\\trandom\\tforestsUnsupervised\\tLearningIn\\tthis\\ttype\\tof\\tmachine-learning\\tsystem,\\tyou\\tcan\\tguess\\tthat\\tthe\\tdata\\tis\\tunlabeled.\\n\\tThe\\tmost\\timportant\\tunsupervised\\talgorithms-\\t\\t\\t\\t\\t\\t\\t\\tClustering:\\tk-means,\\thierarchical\\tcluster\\tanalysis-\\t\\t\\t\\t\\t\\t\\t\\tAssociation\\trule\\tlearning:\\tEclat,\\tapriori-\\t\\t\\t\\t\\t\\t\\t\\tVisualization\\tand\\tdimensionality\\treduction:\\tkernel\\tPCA,\\tt-distributed,PCAAs\\tan\\texample,\\tsuppose\\tyou've\\tgot\\t\\tmany\\tdata\\ton\\t\\tvisitor\\tUsing\\tof\\tone\\tof\\tour\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 15}, page_content=\"algorithms\\tfor\\tdetecting\\tgroups\\twith\\tsimilar\\tvisitors.\\tIt\\tmay\\tfind\\tthat\\t65%\\tofyour\\tvisitors\\tare\\tmales\\twho\\tlove\\twatching\\tmovies\\tin\\tthe\\tevening,\\twhile\\t30%\\twatch\\tplays\\tin\\tthe\\tevening;\\tin\\tthis\\tcase,\\tby\\tusing\\ta\\tclustering\\talgorithm,\\tit\\twilldivide\\tevery\\tgroup\\tinto\\tsmaller\\tsub-groups.\\nThere\\tare\\tsome\\tvery\\timportant\\talgorithms,\\tlike\\tvisualization\\talgorithms;\\ttheseare\\tunsupervised\\tlearning\\talgorithms.\\tYou'll\\tneed\\tto\\tgive\\tthem\\tmany\\tdata\\tandunlabeled\\tdata\\tas\\tan\\tinput,\\tand\\tthen\\tyou'll\\tget\\t2D\\tor\\t3D\\tvisualization\\tas\\tanoutput.\\nThe\\tgoal\\there\\tis\\tto\\tmake\\tthe\\toutput\\tas\\tsimple\\tas\\tpossible\\twithout\\tlosing\\tany\\tofthe\\tinformation.\\tTo\\thandle\\tthis\\tproblem.\\tit\\twill\\tcombine\\t\\t\\tseveral\\trelated\\tfeaturesinto\\t\\tone\\tfeature:\\tfor\\texample,\\tit\\twill\\tcmbn\\ta\\tcar’s\\tmake\\twith\\tits\\tmodel.\\tThis\\tiscalled\\tfeature\\textraction.\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 16}, page_content='Reinforcement\\tLearningReinforcement\\tlearning\\tis\\tanother\\ttype\\tof\\tmachine-learning\\tsystem.\\tAn\\tagent“AI\\tsystem”\\twill\\tobserve\\tthe\\tenvironment,\\tperform\\tgiven\\tactions,\\tand\\tthenreceive\\tt\\trewards\\tin\\treturn.\\tWith\\tthis\\ttype,\\tthe\\tagent\\tmust\\tlearn\\tby\\titself.\\tTiescalled\\ta\\tpolicy.\\nYou\\tcan\\tfind\\tthis\\ttype\\tof\\tlearning\\ttype\\tin\\tmany\\trobotics\\tapplications\\tthat\\tlearnhow\\tto\\twalk\\t'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 17}, page_content='Batch\\tLearningIn\\tthis\\tkind\\tof\\tmachine-learning\\tsystems,\\tthe\\tsystem\\tcan’t\\tlearn\\tincrementally:the\\tsystem\\tmust\\tobtain\\tall\\tthe\\tneeded\\tdata\\t.\\tThat\\tmeans\\tit\\twill\\trequire\\tmanyresources\\tand\\ta\\thuge\\tamount\\tof\\ttime,\\tso\\tit’s\\talways\\tdone\\toffline.\\tSo,\\tto\\tworkwith\\tthis\\ttype\\tof\\tlearning,\\tthe\\tfirst\\tthing\\tto\\tdo\\tis\\tto\\ttrain\\tthe\\tsystem,\\tand\\tthenlaunch\\tit\\twithout\\tany\\tlearning.\\t'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 18}, page_content='Online\\tLearningThis\\tkind\\tof\\tlearning\\tis\\tthe\\topposite\\tof\\tbatch\\tlearning.\\tI\\tmean\\tthat,\\there,\\tthesystem\\tcan\\tlearn\\tincrementally\\tby\\tproviding\\tthe\\tsystem\\twith\\tall\\tthe\\tavailabledata\\tas\\tinstances\\t(groups\\tor\\tindividually),\\tand\\tthen\\tthe\\tsystem\\tcan\\tlearn\\ton\\tthefly.\\nYou\\tcan\\tuse\\tthis\\ttype\\tof\\tsystem\\tfor\\tproblems\\tthat\\trequire\\tthe\\tcontinuous\\tflow\\tofdata,\\twhich\\talso\\tneeds\\tto\\tadapt\\tquickly\\tto\\tany\\tchanges.\\tAlso,\\tyou\\tcan\\tuse\\tthistype\\tof\\tsystem\\tto\\twork\\twith\\tvery\\tlarge\\tdata\\tsets,\\n\\tYou\\tshould\\tknow\\thow\\tfast\\tyour\\tsystem\\tcan\\tadapt\\tto\\tany\\tchanges\\tin\\tthe\\tdata’s“learning\\trate.”\\tIf\\tthe\\tspeed\\tis\\thigh,\\tmeans\\tthat\\tthe\\tsystem\\twill\\tlearn\\tquite,quickly,\\tbut\\tit\\talso\\twill\\tforget\\told\\tdata\\tquickly.'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 19}, page_content='\\tInstance\\tbased\\tlearningThis\\tis\\tthe\\tsimplest\\ttype\\tof\\tlearning\\tthat\\tyou\\tshould\\tlearn\\tby\\theart.\\t\\tBy\\tusingthis\\ttype\\tof\\tlearning\\tin\\tour\\temail\\tprogram,\\tit\\twill\\tflag\\tall\\tof\\tthe\\temails\\tthat\\twereflagged\\tby\\tusers.\\n.\\t\\t'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 20}, page_content='Model-based\\tlearningThere\\tis\\tanother\\ttype\\tof\\tlearning\\tin\\twhich\\tlearning\\tfrom\\texamples\\tallowsconstruction\\t\\tto\\tmake\\tpredictions\\n'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 21}, page_content=\"Bad\\tand\\tInsufficient\\tQuantity\\tof\\tTraining\\tDataMachine-learning\\tsystems\\tare\\tnot\\tlike\\tchildren,\\twho\\tcan\\tdistinguish\\tapples\\tandoranges\\tin\\tall\\tsorts\\tof\\tcolors\\tand\\tshapes,\\tbut\\tthey\\t\\trequire\\t\\tlot\\tof\\tdata\\tto\\tworkeffectively,\\twhether\\tyou're\\tworking\\twith\\tvery\\tsimple\\tprograms\\tand\\tproblems,\\t\\torcomplex\\tapplications\\tlike\\t\\timage\\tprocessing\\tand\\tspeech\\trecognition.\\tHere\\tis\\tanexample\\tof\\tthe\\tunreasonable\\teffectiveness\\tof\\tdata,\\tshowing\\tthe\\tMS\\tproject,which\\tincludes\\tsimple\\tdata\\tand\\tthe\\tcomplex\\tproblem\\tof\\tNLP.\\n\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 22}, page_content=\"Poor-Quality\\tDataIf\\tyou're\\tworking\\twith\\ttraining\\tdata\\tthat\\tis\\tfull\\tof\\terrors\\tand\\t\\toutliers,\\tthis\\t\\twillmake\\tit\\tvery\\thard\\tfor\\tthe\\tsystem\\tto\\tdetect\\tpatterns\\t,\\tso\\tit\\twon't\\twork\\tproperly.So,\\tif\\tyou\\twant\\tyour\\tprogram\\tto\\twork\\twell,\\tyou\\tmust\\tspend\\tmore\\ttime\\tcleaningup\\tyour\\ttraining\\tdata.\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 23}, page_content='\\tIrrelevant\\tFeaturesThe\\tsystem\\twill\\tonly\\tbe\\t\\table\\t\\tto\\tlearn\\tif\\tthe\\ttraining\\tdata\\tcontains\\tenoughfeatures\\tand\\tdata\\tthat\\taren’t\\ttoo\\tirrelevant.\\tThe\\tmost\\timportant\\tpart\\tof\\tany\\tMLproject\\tis\\tto\\tdevelop\\tgood\\tfeatures\\t“of\\tfeature\\tengineering”.\\tFeature\\tEngineeringThe\\tprocess\\tof\\tfeature\\tengineering\\tgoes\\tlike\\tthis:.\\tSelection\\tof\\tfeatures:\\tselecting\\tthe\\tmost\\tuseful\\tfeatures..\\tExtraction\\tof\\tfeatures:\\tcombining\\texisting\\tfeatures\\tto\\tprovide\\tmore\\tusefulfeatures..\\tCreation\\tof\\tnew\\tfeatures:\\tcreation\\tof\\tnew\\tfeatures,\\tbased\\ton\\tdata.\\t'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 24}, page_content=\"TestingIf\\tyou'd\\tlike\\tto\\tmake\\tsure\\tthat\\tyour\\tmodel\\tis\\tworking\\twell\\tand\\tthat\\tmodel\\tcangeneralize\\twith\\tnew\\tcases,\\tyou\\tcan\\ttry\\tout\\t\\tnew\\tcases\\twith\\tit\\tby\\tputting\\tthemodel\\tin\\tthe\\tenvironment\\tand\\tthen\\tmonitoring\\thow\\tit\\twill\\tperform.\\tThis\\tis\\tagood\\tmethod,\\tbut\\tif\\tyour\\tmodel\\tis\\tinadequate,\\tthe\\tuser\\twill\\tcomplain.\\tYou\\tshould\\tdivide\\tyour\\tdata\\tinto\\ttwo\\tsets,\\tone\\tset\\tfor\\ttraining\\tand\\tthe\\tsecondone\\tfor\\ttesting,\\tso\\tthat\\tyou\\tcan\\ttrain\\tyour\\tmodel\\tusing\\tthe\\tfirst\\tone\\tand\\ttest\\titusing\\tthe\\tsecond.\\tThe\\tgeneralization\\terror\\tis\\tthe\\trate\\tof\\terror\\tby\\tevaluation\\tofyour\\tmodel\\ton\\tthe\\ttest\\tset.\\tThe\\tvalue\\tyou\\tget\\twill\\ttell\\tyou\\tif\\tyour\\tmodel\\tis\\tgoodenough,\\tand\\tif\\tit\\twill\\twork\\tproperly.\\tIf\\tthe\\terror\\trate\\tis\\tlow,\\tthe\\tmodel\\tis\\tgood\\tand\\twill\\tperform\\tproperly.\\tIn\\tcontrast,if\\tyour\\trate\\tis\\thigh,\\tthis\\tmeans\\tyour\\tmodel\\twill\\tperform\\tbadly\\tand\\tnot\\tworkproperly.\\tMy\\tadvice\\tto\\tyou\\tis\\tto\\tuse\\t80%\\tof\\tthe\\tdata\\tfor\\ttraining\\tand\\t20%\\tfortesting\\tpurposes,\\tso\\tthat\\tit’s\\tvery\\tsimple\\tto\\ttest\\tor\\tevaluate\\ta\\tmodel.\\t\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 25}, page_content=\"Overfitting\\tthe\\tData\\tIf\\tyou're\\tin\\ta\\tforeign\\tcountry\\tand\\tsomeone\\tsteals\\tsomething\\tof\\tyours,\\tyou\\tmightsay\\tthat\\teveryone\\tis\\ta\\tthief.\\tThis\\tis\\tan\\tovergeneralization,\\tand,\\tin\\tmachinelearning,\\tis\\tcalled\\t“overfitting”.\\tThis\\tmeans\\tthat\\tmachines\\tdo\\tthe\\tsame\\tthing:they\\tcan\\tperform\\twell\\twhen\\tthey're\\tworking\\twith\\tthe\\ttraining\\tdata,\\tbut\\tthey\\tcan'tgeneralize\\tthem\\tproperly.\\t\\tFor\\texample,\\tin\\tthe\\tfollowing\\tfigure\\tyou'll\\tfind\\ta\\thighdegree\\tof\\tlife\\tsatisfaction\\tmodel\\tthat\\toverfits\\tthe\\tdata,\\tbut\\tit\\tworks\\twell\\twith\\tthetraining\\tdata.\\n\\tWhen\\tdoes\\tthis\\toccur?Overfitting\\toccurs\\twhen\\tthe\\tmodel\\tis\\tvery\\tcomplex\\tfor\\tthe\\tamount\\tof\\ttrainingdata\\tgiven.\\tSolutionsTo\\tsolve\\tthe\\toverfitting\\tproblem,\\tyou\\tshould\\tdo\\tthe\\tfollowing:-\\t\\t\\t\\t\\t\\t\\t\\tGather\\tmore\\tdata\\tfor\\t“training\\tdata”-\\t\\t\\t\\t\\t\\t\\t\\tReduce\\tthe\\tnoise\\tlevel-\\t\\t\\t\\t\\t\\t\\t\\tSelect\\tone\\twith\\tfewer\\tparameters\\t\\t\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 26}, page_content=\"Underfitting\\tthe\\tDataFrom\\tits\\tname,\\tunderfitting\\tis\\tthe\\topposite\\tof\\toverfitting,\\tand\\tyou'll\\tencounterthis\\twhen\\tthe\\tmodel\\tis\\tvery\\tsimple\\tto\\tlearn.\\tFor\\texample,\\tusing\\tthe\\texample\\tofquality\\tof\\tlife,\\treal\\tlife\\tis\\tmore\\tcomplex\\tthan\\tyour\\tmodel,\\tso\\tthe\\tpredictionswon't\\tyield\\tthe\\tsame,\\teven\\tin\\tthe\\ttraining\\texamples.\\nSolutionsTo\\tfix\\tthis\\tproblem:-\\t\\t\\t\\t\\t\\t\\t\\tSelect\\tthe\\tmost\\tpowerful\\tmodel,\\twhich\\thas\\tmany\\tparameters.\\t-\\t\\t\\t\\t\\t\\t\\t\\tFeed\\tthe\\tbest\\tfeatures\\tinto\\tyour\\talgorithm.\\tHere,\\tI'm\\treferring\\tto\\tfeatureengineering.-\\t\\t\\t\\t\\t\\t\\t\\tReduce\\tthe\\tconstraints\\ton\\tyour\\tmodel.\\t\\t\\t\\t\\t\\t\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 27}, page_content=\"EXERCISES\\tIn\\tthis\\tchapter,\\twe\\thave\\tcovered\\tmany\\tconcepts\\tof\\tmachine\\tlearning.\\tThefollowing\\tchapters\\twill\\tbe\\tvery\\tpractical,\\tand\\tyou'll\\twrite\\tcode,\\tbut\\tyou\\tshouldanswer\\tthe\\tfollowing\\tquestions\\tjust\\tto\\tmake\\tsure\\tyou're\\ton\\tthe\\tright\\ttrack.\\t\\t1.\\tDefine\\tmachine\\tlearning\\t\\t2.\\tDescribe\\tthe\\tfour\\ttypes\\tof\\tmachine-learning\\tsystems.\\t\\t\\t3.\\tWhat\\tis\\tthe\\tdifference\\tbetween\\tsupervised\\tand\\tunsupervised\\tlearning.\\t\\t4.\\tName\\tthe\\tunsupervised\\ttasks.\\t\\t\\t5.\\tWhy\\tare\\ttesting\\tand\\tvalidation\\timportant?\\t\\t6.\\tIn\\tone\\tsentence,\\tdescribe\\twhat\\tonline\\tlearning\\tis.\\t\\t\\t7.\\tWhat\\tis\\tthe\\tdifference\\tbetween\\tbatch\\tand\\toffline\\tlearning?\\t\\t8.\\tWhich\\ttype\\tof\\tmachine\\tlearning\\tsystem\\tshould\\tyou\\tuse\\tto\\tmake\\tarobot\\tlearn\\thow\\tto\\twalk?\\t\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 28}, page_content=\"SUMMARY\\tIn\\tthis\\tchapter,\\tyou've\\tlearned\\tmany\\tuseful\\tconcepts,\\tso\\tlet’s\\treview\\tsomeconcepts\\tthat\\tyou\\tmay\\tfeel\\ta\\tbit\\tlost\\twith.\\tMachine\\tlearning:\\tML\\trefers\\ttomaking\\tmachines\\twork\\tbetter\\tat\\tsome\\ttask,\\tusing\\tgiven\\tdata.\\t\\t.\\t\\tMachine\\tlearning\\tcomes\\tin\\tmany\\ttypes,\\tsuch\\tas\\tsupervised,\\tbatch,unsupervised,\\tand\\tonline\\tlearning.\\t\\t.\\tTo\\tperform\\tan\\tML\\tproject,\\tyou\\tneed\\tto\\tgather\\tdata\\tin\\ta\\ttraining\\tset,\\tand\\tthenfeed\\tthat\\tset\\tto\\ta\\tlearning\\talgorithm\\tto\\tget\\tan\\toutput,\\t“predictions”.\\t\\t\\t.\\t\\tIf\\tyou\\twant\\tto\\tget\\tthe\\tright\\toutput,\\tyour\\tsystem\\tshould\\tuse\\tclear\\tdata,\\twhich\\tisnot\\ttoo\\tsmall\\tand\\twhich\\tdoes\\tnot\\thave\\tirrelevant\\tfeatures.\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 29}, page_content='REFERENCES.http://static.googleusercontent.com/media/research.google.com/fr//pubs/archive/35179.pdf\\t'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 30}, page_content='CHAPTER\\t2CLASSIFICATION\\t'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 31}, page_content=\"InstallationYou'll\\tneed\\tto\\tinstall\\tPython,\\tMatplotlib\\tand\\tScikit-learn\\tfor\\tthis\\tchapter.\\tJust\\tgoto\\tthe\\treferences\\tsection\\tand\\tfollow\\tthe\\tsteps\\t\\tindicated.\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 32}, page_content='\\tThe\\tMNISTIn\\tthis\\tchapter,\\tyou\\'ll\\tgo\\tdeeper\\tinto\\tclassification\\tsystems,\\tand\\twork\\twith\\ttheMNIST\\tdata\\tset.\\tThis\\tis\\ta\\tset\\tof\\t70,000\\timages\\tof\\tdigits\\thandwritten\\tby\\tstudentsand\\temployees.\\tYou\\'ll\\tfind\\tthat\\teach\\timage\\thas\\ta\\tlabel\\tand\\ta\\tdigit\\tthat\\trepresentsit.\\t\\tThis\\tproject\\tis\\tlike\\tthe\\t“Hello,\\tworld”\\texample\\tof\\ttraditional\\tprogramming.So\\tevery\\tbeginner\\tto\\tmachine\\tlearning\\tshould\\tstart\\twith\\tthis\\tproject\\tto\\tlearnabout\\tthe\\tclassification\\talgorithm.\\tScikit-Learn\\thas\\tmany\\tfunctions,\\tincludingthe\\tMNIST.\\tLet’s\\ttake\\ta\\tlook\\tat\\tthe\\tcode:>>>\\tfrom\\tsklearn.data\\tsets\\timport\\tfetch_mldata>>>\\tmn=\\tfetch_mldata(\\'MNIST\\toriginal\\')>>>\\tmn{\\'COL_NAMES\\':\\t[\\'label\\',\\t\\'data\\'],\\'Description\\':\\t\\'mldata.org\\tdata\\tset:\\tmn-original\\',\\'data\\':\\tarray([[0,\\t0,\\t0,...,\\t0,\\t0,\\t0],[0,\\t0,\\t0,...,\\t0,\\t0,\\t0],[0,\\t0,\\t0,...,\\t0,\\t0,\\t0],...,[0,\\t0,\\t0,...,\\t0,\\t0,\\t0],[0,\\t0,\\t0,...,\\t0,\\t0,\\t0],[0,\\t0,\\t0,...,\\t0,\\t0,\\t0]],\\tdataType=uint8),\\'tar\\':\\tarray([\\t0.,\\t0.,\\t0.,...,\\t9.,\\t9.,\\t9.])}\\tde.\\tDescription\\tis\\ta\\tkey\\tthat\\tdescribes\\tthe\\tdata\\tset..\\tThe\\tdata\\tkey\\there\\tcontains\\tan\\tarray\\twith\\tjust\\tone\\trow\\tfor\\tinstance,\\tand\\tacolumn\\tfor\\tevery\\tfeature..\\tThis\\ttarget\\tkey\\tcontains\\tan\\tarray\\twith\\tlabels.Let’s\\twork\\twith\\tsome\\tof\\tthe\\tcode:>>>\\tX,\\ty\\t=\\tmn[\"data\"],\\tmn[\"tar\"]>>>\\tX.shape(70000,\\t784)>>>\\ty.shape(70000,).\\t7000\\there\\tmeans\\tthat\\tthere\\tare\\t70,000\\timages,\\tand\\tevery\\timage\\thas\\tmore\\tthan'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 33}, page_content='700\\tfeatures:\\t“784”.\\tBecause,\\tas\\tyou\\tcan\\tsee,\\t\\tevery\\timage\\tis\\t28\\tx\\t28\\tpixels,\\tyoucan\\timagine\\tthat\\tevery\\tpixel\\tis\\tone\\tfeature.\\tLet’s\\ttake\\tanother\\texample\\tfrom\\tthe\\tdata\\tset.\\t\\tYou\\'ll\\tonly\\tneed\\tto\\tgrab\\taninstance’s\\tfeature,\\tthen\\tmake\\tit\\t26\\tx\\t26\\tarrays,\\tand\\tthen\\tdisplay\\tthem\\tusing\\ttheimshow\\tfunction:%matplotlib\\tinlineimport\\tmatplotlibimport\\tmatplotlib.pyplot\\tas\\tpltyourDigit\\t=\\tX[36000]Your_image\\t=\\tyour_image.reshape(26,\\t26)plt.imshow(Your_image,\\tcmap\\t=\\tmatplotlib.cm.binary,interpolation=\"nearest\")plt.axis(\"off\")plt.show()As\\tyou\\tcan\\tsee\\tin\\tthe\\tfollowing\\timage,\\tit\\tlooks\\tlike\\tthe\\tnumber\\tfive,\\tand\\twe\\tcangive\\tthat\\ta\\tlabel\\tthat\\ttells\\tus\\tit’s\\tfive.\\n\\tIn\\tthe\\tfollowing\\tfigure,\\tyou\\tcan\\tsee\\tmore\\tcomplex\\tclassification\\ttasks\\tfrom\\ttheMNIST\\tdata\\tset.'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 34}, page_content=\"Also,\\tyou\\tshould\\tcreate\\ta\\ttest\\tset\\tand\\tmake\\tit\\tbefore\\tyour\\tdata\\tis\\tinspected.The\\tMNIST\\tdata\\tset\\tis\\tdivided\\tinto\\ttwo\\tsets,\\tone\\tfor\\ttraining\\tand\\tone\\tfor\\ttesting.x_tr,\\tx_tes,\\ty_tr,\\ty_te\\t=\\tx\\t[:60000],\\tx[60000:],\\ty[:60000],\\ty[60000:]Let’s\\tplay\\twith\\tyour\\ttraining\\tset\\tas\\tfollows\\tto\\tmake\\tthe\\tcross-validation\\tto\\tbesimilar\\t(without\\tany\\tmissing\\tof\\tany\\tdigit)Import\\tnumpy\\tas\\tnpmyData\\t=\\tnp.radom.permutaion(50000)x_tr,\\ty_tr\\t=\\tx_tr[myData],\\ty_tr[myData]\\tNow\\tit’s\\ttime\\tto\\tmake\\tit\\tsimple\\tenough,\\twe'll\\ttry\\tto\\tjust\\tidentify\\tone\\tdigit,\\te.g.the\\tnumber\\t6.\\tThis\\t“6-detector”\\twill\\tbe\\tan\\texample\\tof\\tthe\\tbinary\\tclassifier,\\ttodistinguish\\tbetween\\t6\\tand\\tnot\\t6,\\tso\\twe'll\\tcreate\\tthe\\tvectors\\tfor\\tthis\\ttask:Y_tr_6\\t=\\t(y_tr\\t\\t\\t==\\t6)\\t//\\tthis\\tmeans\\tit\\twill\\tbe\\ttrue\\tfor\\t6s,\\tand\\tfalse\\tfor\\tany\\tothernumberY_tes_6\\t=\\t(Y_tes\\t==\\t6)After\\tthat,\\twe\\tcan\\tchoose\\ta\\tclassifier\\tand\\ttrain\\tit.\\tBegin\\twith\\tthe\\t\\tSGD(Stochastic\\tGradient\\tDescent)\\tclassifier.The\\tScikit-Learn\\tclass\\thas\\tthe\\tadvantage\\tof\\thandling\\tvery\\tlarge\\tdata\\tsets.\\tIn\\tthisexample,\\tthe\\tSGD\\twill\\tdeal\\twith\\tinstances\\tseparately,\\tas\\tfollows.\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 35}, page_content='from\\tsklearn.linear_model\\timport\\tSGDClassifiermycl\\t=\\tSGDClassifier\\t(random_state\\t=\\t42)mycl.fit(x_tr,\\ty_tr_6)to\\tuse\\tit\\tto\\tdetect\\tthe\\t6>>>mycl.prdict([any_digit)]\\n'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 36}, page_content=\"Measures\\tof\\tPerformanceIf\\tyou\\twant\\tto\\tevaluate\\ta\\tclassifier,\\tthis\\twill\\tbe\\tmore\\tdifficult\\tthan\\ta\\tregressor,\\tsolet’s\\texplain\\thow\\tto\\tevaluate\\ta\\tclassifier.In\\tthis\\texample,\\twe'll\\tuse\\tacross-validation\\tto\\tevaluate\\tour\\tmodel.\\tfrom\\tsklearn.model_selection\\timport\\tStratifiedKFoldform\\tsklearn.base\\timport\\tclonesf\\t=\\tStratifiedKFold(n=2,\\tran_state\\t=\\t40)for\\ttrain_index,\\ttest_index\\tin\\tsf.split(x_tr,\\ty_tr_6):cl\\t=\\tclone(sgd_clf)x_tr_fd\\t=\\tx_tr[train_index]y_tr_fd\\t=\\t(y_tr_6[train_index])x_tes_fd\\t=\\tx_tr[test_index]y_tes_fd\\t=\\t(y_tr_6[test_index])cl.fit(x_tr_fd,\\ty_tr_fd)y_p\\t=\\tcl.predict(x_tes_fd)print(n_correct\\t/\\tlen(y_p)).\\tWe\\tuse\\tthe\\tStratifiedFold\\tclass\\tto\\tperform\\tstratified\\tsampling\\tthat\\tproducesfolds\\tthat\\tcontain\\ta\\tration\\tfor\\tevery\\tclass.\\tNext,\\tevery\\titeration\\tin\\tthe\\tcode\\twillcreate\\ta\\tclone\\tof\\tthe\\tclassifier\\tto\\tmake\\tpredictions\\ton\\tthe\\ttest\\tfold.\\tAnd\\tfinally,\\titwill\\tcount\\tthe\\tnumber\\tof\\tcorrect\\tpredictions\\tand\\ttheir\\tratio\\t.\\tNow\\twe'll\\tuse\\tthe\\tcross_val_score\\tfunction\\tto\\tevaluate\\tthe\\tSGDClassifier\\tbyK-fold\\tcross\\tvalidation.\\tThe\\tk\\tfold\\tcross\\tvalidation\\twill\\tdivide\\tthe\\ttraining\\tsetinto\\t3\\tfolds,\\tand\\tthen\\tit\\twill\\tmake\\tprediction\\tand\\tevaluation\\ton\\teach\\tfold.from\\tsklearn.model_selection\\timport\\tcross_val_scorecross_val_score(sgd_clf,\\tx_tr,\\ty_tr_6,\\tcv\\t=\\t3,\\tscoring\\t=\\t“accuracy”)\\tYou'll\\tget\\tthe\\tratio\\tof\\taccuracy\\tof\\t“correct\\tpredictions”\\ton\\tall\\tfolds.\\t\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 37}, page_content=\"Let’s\\tclassify\\tevery\\tclassifier\\tat\\tevery\\tsingle\\timage\\tin\\tthe\\tnot-6from\\tsklearn.base\\timport\\tBaseEstimatorclass\\tnever6Classifier(BaseEstimator):def\\tfit(self,\\tX,\\ty=None):\\t\\tpassdef\\tpredict(self,\\tx):return\\tnp.zeros((len(X),\\t1),\\tdtype=bool)Let’s\\texamine\\t\\tthe\\taccuracy\\tof\\tthis\\tmodel\\twith\\t\\tthe\\tfollowing\\tcode:>>>\\tnever_6_cl\\t=\\tNever6Classifier()>>>\\tcross_val_score(never_6_cl,\\tx_tr,\\ty_tr_6,\\tcv\\t=\\t3,\\tscoring\\t=\\t“accuracy”)Output:\\tarray\\t([“num”,\\t“num”,\\t“num”])For\\tthe\\toutput,\\tyou'll\\tget\\tno\\tless\\tthan\\t90%:\\tonly\\t10%\\tof\\tthe\\timages\\tare\\t6s,\\tso\\twecan\\t\\talways\\timagine\\tthat\\tan\\timage\\tis\\tnot\\ta\\t6.\\tWe'll\\tbe\\tright\\tabout\\t90%\\tof\\tthetime.Bear\\tin\\tmind\\tthat\\taccuracy\\tis\\tnot\\tthe\\tbest\\tperformance\\tmeasure\\tfor\\tclassifiers,\\tifyou're\\tworking\\twith\\tskewed\\tdata\\tsets.\\t\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 38}, page_content=\"Confusion\\tMatrixThere\\tis\\ta\\tbetter\\tmethod\\tto\\tevaluate\\tthe\\tperformance\\tof\\tyour\\tclassifier:\\ttheconfusion\\tmatrix.It’s\\teasy\\tto\\tmeasure\\tperformance\\twith\\tthe\\tconfusion\\tmatrix,\\tjust\\tby\\tcounting\\tthenumber\\tof\\ttimes\\tinstances\\tof\\tclass\\tX\\tare\\tclassified\\tas\\tclass\\tY,\\tfor\\texample.\\tToget\\tthe\\tnumber\\tof\\ttimes\\tof\\timage\\tclassifiers\\tof\\t6s\\twith\\t2s,\\tyou\\tshould\\tlook\\tin\\tthe6th\\trow\\tand\\t2nd\\tcolumn\\tof\\tthe\\tconfusion\\tmatrix.\\tLet’s\\tcalculate\\tthe\\tconfusion\\tmatrix\\tusing\\tthe\\tcross_val_predict\\t()\\tfunction.from\\tsklearn.model_selection\\timport\\tcross_Val_predicty_tr_pre\\t=\\tcross_val_predict\\t(sgd_cl,\\tx_tr,\\ty_tr_6,\\tcv\\t=\\t3)This\\tfunction,\\tlike\\tthe\\tcross_val_score()\\tfunction,\\tperforms\\tthe\\tk\\tfold\\tcross-validation,\\tand\\tit\\talso\\treturns\\tpredictions\\ton\\teach\\tfold.\\tIt\\talso\\treturns\\ta\\tcleanprediction\\tfor\\tevery\\tinstance\\tin\\tyour\\ttraining\\tset.\\tNow\\twe're\\tready\\tto\\tget\\tthe\\tmatrix\\tusing\\tthe\\tfollowing\\tcode.from\\tsklearn.metrics\\timport\\tconfusion_matrixconfusion_matrix\\t(y_tr_6,\\ty_tr_pred)You'll\\tget\\tan\\tarray\\tof\\t4\\tvalues\\t,“numbers”.Every\\trow\\trepresents\\ta\\tclass\\tin\\tthe\\tmatrix,\\tand\\tevery\\tcolumn\\trepresents\\tapredicted\\tclass.The\\tfirst\\trow\\tis\\tthe\\tnegative\\tone:\\tthat\\t\\t“contain\\tnon-6\\timages”.\\tYou\\tcan\\tlearn\\talot\\tfrom\\tthe\\tmatrix.But\\tthere\\tis\\talso\\ta\\tgood\\tone\\tthat's\\t,\\tinteresting\\tto\\twork\\twith\\tif\\tyou'd\\tlike\\tto\\tgetthe\\taccuracy\\tof\\tthe\\tpositive\\tpredictions,\\twhich\\tis\\tthe\\tprecision\\tof\\tthe\\tclassifierusing\\tthis\\tequation.Precision\\t=\\t(TP)/\\t(TP+FP)TP:\\tnumber\\tof\\ttrue\\tpositivesFP:\\tnumber\\tof\\tfalse\\tpositives\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 39}, page_content='Recall\\t=\\t(TP)\\t/(TP+FN)\\t“sensitivity”:\\t\\tit\\tmeasure\\tthe\\tratio\\tof\\tpositive\\tinstances.\\n\\t'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 40}, page_content='Recall>>>\\tfrom\\tsklearn.metrics\\timport\\tprecision_score,\\trecall_score>>>\\tprecision_score(y_tr_6,\\ty_pre)>>>recall_score(y_tr_6,\\ty_tr_pre)It’s\\tvery\\tcommon\\t\\tto\\tcombine\\tprecision\\tand\\trecall\\tinto\\tjust\\tone\\tmetric,\\twhich\\tisthe\\tF1\\tscore.F1\\tis\\tthe\\tmean\\tof\\tboth\\tprecision\\tand\\trecall.\\tWe\\tcan\\tcalculate\\tthe\\tF1\\tscore\\t\\twiththe\\tfollowing\\tequation:F1\\t=\\t2\\t/\\t((1/precision)\\t+\\t(1)/recall))\\t=\\t2\\t*\\t(precision\\t*\\trecall)\\t/\\t(precision\\t+recall)\\t=\\t(TP)\\t/\\t((TP)\\t+\\t(FN+FP)/2)To\\tcalculate\\tthe\\tF1\\tscore,\\tsimply\\tuse\\tthe\\tfollowing\\tfunction:>>>\\tfrom\\tsklearn.metrics\\timport\\tf1_score>>>f1_score\\t(y_tr_6,\\ty_pre)\\t\\n\\t\\t'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 41}, page_content=\"Recall\\tTradeoffTo\\tget\\tto\\tthis\\tpoint,\\tyou\\tshould\\ttake\\ta\\tlook\\tat\\tthe\\tSGDClassifier\\tand\\thow\\titmakes\\tdecisions\\tregarding\\tclassifications.\\tIt\\tcalculates\\tthe\\tscore\\tbased\\ton\\tthedecision\\tfunction,\\tand\\tthen\\tit\\tcompares\\tthe\\tscore\\twith\\tthe\\tthreshold.\\tIf\\tit’sgreater\\tthan\\tthis\\tscore,\\tit\\twill\\tassign\\tthe\\tinstance\\tto\\tthe\\t“positive\\tor\\tnegative”.classFor\\texample,\\tif\\tthe\\tdecision\\tthreshold\\tis\\tat\\tthe\\tcenter,\\tyou'll\\tfind\\t4\\ttrue\\t+\\ton\\ttheright\\tside\\tof\\tthe\\tthreshold,\\tand\\tonly\\tone\\tfalse.\\tSo\\tthe\\tprecision\\tratio\\twill\\tbe\\tonly80%.\\t\\nIn\\tScikit-Learn,\\tyou\\tcan't\\tset\\ta\\tthreshold\\tdirectly.\\tYou'll\\tneed\\tto\\taccess\\tthedecision\\tscores,\\twhich\\tuse\\tpredictions,\\tand\\tby\\t\\ty\\tcalling\\tthe\\tdecision\\tfunction,().>>>\\ty_sco\\t=\\tsgd_clf.decision_funciton([any\\tdigit])>>>\\ty_sco>>>\\tthreshold\\t=\\t0>>>y_any_digit_pre\\t=\\t(y_sco\\t>\\tthreshold)In\\tthis\\tcode,\\tthe\\tSGDClassifier\\tcontains\\ta\\tthreshold,\\t=\\t0,\\tto\\treturn\\tthe\\tsameresult\\tas\\tthe\\tthe\\tpredict\\t()\\tfunction.>>>\\tthreshold\\t=\\t20000>>>y_any_digit_pre\\t=\\t(y_sco\\t>\\tthreshold)>>>y_any_digit_pre\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 42}, page_content='This\\tcode\\twill\\tconfirm\\tthat,\\twhen\\tthe\\tthreshold\\tincreases,\\tthe\\trecall\\tdecreases.y_sco\\t=\\tcross_val_predict\\t(sgd_cl,\\tx_tr,\\ty_tr_6,\\tcv\\t=3,\\tmethod=”decisionfunction)It’s\\ttime\\tto\\tcalculate\\tall\\tpossible\\tprecision\\tand\\trecall\\tfor\\tthe\\tthreshold\\tby\\tcallingthe\\tprecision_recall_curve()functionfrom\\tsklearn.metrics\\timport\\tprecision_recall_curveprecisions,\\trecalls,\\tthreshold\\t=\\tprecision_recall_curve\\t(y_tr_6,\\ty_sco)and\\tnow\\tlet’s\\tplot\\tthe\\tprecision\\tand\\tthe\\trecall\\tusing\\tMatplotlibdef\\tplot_pre_re(pre,\\tre,\\tthr):plt.plot(thr,\\tpre[:-1],\\t“b—“,\\tlabel\\t=\\t“precision”)plt.plot(thr,\\tre[:1],\\t“g-“,\\tlabel=”Recall”)plt.xlabel(“Threshold”)plt.legend(loc=”left”)plt.ylim([0,1])plot_pre_re(pre,\\tre,\\tthr)plt.show\\n'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 43}, page_content=\"ROCROC\\tstands\\tfor\\treceiver\\toperating\\tcharacteristic\\tand\\tit's\\ta\\ttool\\tthat\\tused\\twithbinary\\tclassifiers.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tThis\\ttool\\tis\\tsimilar\\tto\\tthe\\trecall\\tcurve,\\tbut\\tit\\tdoesn’t\\tplot\\tthe\\tprecision\\tand\\trecall:it\\tplots\\tthe\\tpositive\\trateand\\tfalse\\trate.\\tYou'll\\twork\\talso\\twith\\tFPR,\\twhich\\tis\\tthe\\tratio\\tof\\tnegativesamples.\\t\\tYou\\tcan\\timagine\\tif\\tit's\\tlike\\t(1\\t–\\tnegative\\trate.\\tAnother\\tconcept\\tis\\ttheTNR\\tand\\tit's\\tthe\\tspecificity.\\tRecall\\t=\\t1\\t–\\tspecificity.Let’s\\tplay\\twith\\tthe\\tROC\\tCurve.\\tFirst,\\twe'll\\tneed\\tto\\tcalculate\\tthe\\tTPR\\tand\\ttheFPR,\\tjust\\tby\\tcalling\\tthe\\troc-curve\\t()\\tfunction,from\\tsklearn.metrics\\timport\\troc_curvefp,tp,\\tthers\\t=\\troc_curve\\t(y_tr_6,\\ty_sco)After\\tthat,\\tyou'll\\tplot\\tthe\\tFPR\\tand\\tTPR\\twith\\tMatplotlib\\taccording\\tto\\t\\tthefollowing\\tinstructions.def_roc_plot\\t(fp,\\ttp,\\tlabel=none):plt.plot(fp,\\ttp,\\tlinewidth=2,\\tlabel\\t=\\tlabel)plt.plot([0,1)],\\t[0,1],\\t“k--”)plt.axis([0,1,0,1])plt.xlabel(‘This\\tis\\tthe\\tfalse\\trate’)plt.ylabel(‘This\\tis\\tthe\\ttrue\\trate’)roc_plot\\t(fp,\\ttp)plt.show\\n\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 44}, page_content='\\t'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 45}, page_content=\"Multi-class\\tClassificationWe\\tuse\\tbinary\\tclassifiers\\tto\\tdistinguish\\tbetween\\tany\\ttwo\\tclasses,\\tbut\\twhat\\tifyou'd\\tlike\\tto\\tdistinguish\\tbetween\\tmore\\tthan\\ttwo?You\\tcan\\tuse\\tsomething\\tlike\\trandom\\tforest\\tclassifiers\\tor\\tBayes\\tclassifiers,\\twhichcan\\tcompare\\tbetween\\tmore\\tthan\\ttwo.\\tBut,\\ton\\tthe\\tother\\thand,\\tSVM\\t(the\\tSupportVector\\tMachine)\\tand\\tlinear\\tclassifiers\\tfunction\\tlike\\tbinary\\tclassifiers.If\\tyou'd\\tlike\\tto\\tdevelop\\ta\\tsystem\\tthat\\tclassifies\\timages\\tof\\tdigit\\tinto\\t12\\tclasses(from\\t0\\tto\\t11)\\tyou'll\\tneed\\tto\\ttrain\\t12\\tbinary\\tclassifiers,\\tand\\tmake\\tone\\tfor\\teveryclassifier\\t(such\\tas\\t4\\t–\\tdetector,\\t5-detector,\\t6-detector\\tand\\tso\\ton\\t),\\tand\\tthen\\tyou'llneed\\tto\\tget\\tthe\\tDS,\\tthe\\t“\\tdecision\\tscore,”\\tof\\tevery\\tclassifier\\tfor\\tthe\\timage.\\tThen,you'll\\tchoose\\tthe\\thighest\\tscore\\tclassifier.\\tWe\\tcall\\tthis\\tthe\\tOvA\\tstrategy:\\t“one-versus-all.”The\\tother\\tmethod\\tis\\tto\\ttrain\\ta\\tbinary\\tclassifier\\tfor\\teach\\tpair\\tof\\tdigits;\\tforexample,\\tone\\tfor\\t5s\\tand\\t6s\\tand\\tanother\\tone\\tfor\\t5s\\tand\\t7s.\\t—\\twe\\tcall\\tthis\\tmethodOvO,\\t“one-versus-one”\\t—\\tto\\tcount\\thow\\tmany\\tclassifiers\\tyou'll\\tneed,\\tbased\\tonthe\\tnumber\\tof\\tclasses\\tthat\\tuse\\tthe\\tfollowing\\tequation:\\t“N\\t=\\tnumber\\tof\\tclasses”.N\\t*\\t(N-1)/2.\\tIf\\tyou'd\\tlike\\tto\\tuse\\tthis\\ttechnique\\twith\\tthe\\tMNIST\\t10\\t*\\t(10-1)/2,the\\toutput\\twill\\tbe\\t45\\tclassifiers,\\t“binary\\tclassifiers”.In\\tScikit-Learn,\\tyou\\texecute\\tOvA\\t\\tautomatically\\twhen\\tyou\\tuse\\ta\\tbinaryclassification\\talgorithm.>>>\\tsgd_cl.fit(x_tr,\\ty_tr)>>>sgd_cl.Predict([any-digit])Additionally,\\tyou\\tcan\\tcall\\tthe\\tdecision_function\\t()\\tto\\treturn\\tthe\\tscores\\t“10\\tscoresfor\\tone\\tclass”>>>any_digit_scores\\t=\\tsgd_cl.decision_function([any_digit])>>>\\tany_digit_scoresArray([“num”,\\t“num”,\\t“num”,\\t“num”,\\t“num”,\\t“num”,\\t“num”,\\t“num”,\\t“num”,”num”]])\\t\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 46}, page_content=\"Training\\ta\\tRandom\\tForest\\tClassifier>>>\\tforest.clf.fit(x_tr,\\ty_tr)>>>\\tforest.clf.predict([any-digit])array([num])As\\tyou\\tcan\\tsee,\\t\\ttraining\\ta\\trandom\\tforest\\tclassifierwth\\tonly\\ttwo\\tlines\\tof\\tcode\\tisvery\\teasy.The\\tScikit-Learn\\tdidn’t\\texecute\\tany\\tOvA\\tor\\tOvO\\tfunctions\\tbecause\\tthis\\tkind\\tofalgorithm\\t—\\t\\t“random\\tforest\\tclassifiers”\\t—\\t\\tcan\\tautomatically\\twork\\tmultipleclasses.\\tIf\\tyou'd\\tlike\\tto\\ttake\\ta\\tlook\\tat\\tthe\\tlist\\tof\\tclassifier\\tpossibilities,\\tyou\\tcancall\\tthe\\tpredict_oroba\\t()\\tfunction.>>>\\tforest_cl.predict_proba([any_digit])array([[0.1,\\t0,\\t0,\\t0.1,\\t0,\\t0.8,\\t0,\\t0,\\t0]])The\\tclassifier\\tis\\tvery\\taccurate\\twith\\tits\\tprediction,\\tas\\tyou\\tcan\\tsee\\tin\\tthe\\toutput;there\\tis\\t0.8\\tat\\t\\tindex\\tnumber\\t5.Let’s\\tevaluate\\tthe\\tclassifier\\tusing\\tthe\\tcross_val_score()\\tfunction.>>>\\tcross_val_score(sgd_cl,\\tx_tr,\\ty_tr,\\tcv=3,\\tscoring\\t=\\t“accuracy”)array([0.84463177,\\t0.859668,\\t0.8662669])You'll\\tget\\t84%\\tmore\\t\\tn\\tthe\\tfolds.\\tWhen\\tusing\\ta\\trandom\\tclassifier,\\tyou'll\\tget,\\tinthis\\tcase,\\t10%\\tfor\\tthe\\taccuracy\\tscore.\\tKeep\\tin\\tmind\\tthat\\tthe\\thigher\\tthis\\tvalue\\tis,the\\tbetter.\\t\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 47}, page_content=\"Error\\tAnalysisFirst\\tof\\tall,\\twhen\\tdeveloping\\ta\\tmachine\\tlearning\\tproject:1.\\tDetermine\\tthe\\tproblem;2.\\tCollect\\tyour\\tdata;3.\\tWork\\ton\\tyour\\tdata\\tand\\texplore\\tit;4.\\tClean\\tthe\\tdata5.\\tWork\\twith\\tseveral\\tmodels\\tand\\tchoose\\tthe\\tbest\\tone;6.\\tCombine\\tyour\\tmodels\\tinto\\tthe\\tsolution;7.\\tShow\\tyour\\tsolution;8.\\tExecute\\tand\\ttest\\tyour\\tsystem.\\t\\tFirst,\\tyou\\tshould\\twork\\twith\\tthe\\tconfusion\\tmatrix\\tand\\tmake\\tpredictions\\tbythe\\tcross-val\\tfunction.\\tNext,\\tyou'll\\tcall\\tthe\\tconfusion\\tmatrix\\tfunction:\\t>>>\\ty_tr_pre\\t=\\tcross_val_prediciton(sgd_cl,\\tx_tr_scaled,\\ty_tr,\\tcv=3)>>>\\tcn_mx\\t\\t=\\tconfusion_matrix(y_tr,\\ty_tr_pre)>>>\\tcn_mx\\tarray([[5625,\\t2,\\t25,\\t8,\\t11,\\t44,\\t52,\\t12,\\t34,\\t6],[\\t2,\\t2415,\\t41,\\t22,\\t8,\\t45,\\t\\t10,\\t10,\\t9],[\\t52,\\t43,\\t7443,\\t104,\\t89,\\t26,\\t87,\\t60,\\t166,\\t13],[\\t47,\\t46,\\t141,\\t5342,\\t1,\\t231,\\t40,\\t50,\\t141,\\t92],[\\t19,\\t29,\\t41,\\t10,\\t5366,\\t9,\\t56,\\t37,\\t86,\\t189],[\\t73,\\t45,\\t36,\\t193,\\t64,\\t4582,\\t111,\\t30,\\t193,\\t94],[\\t29,\\t34,\\t44,\\t2,\\t42,\\t85,\\t5627,\\t10,\\t45,\\t0],[\\t25,\\t24,\\t74,\\t32,\\t54,\\t12,\\t6,\\t5787,\\t15,\\t236],[\\t52,\\t161,\\t73,\\t156,\\t10,\\t163,\\t61,\\t25,\\t5027,\\t123],[\\t50,\\t24,\\t32,\\t81,\\t170,\\t38,\\t5,\\t433,\\t80,\\t4250]])\\t\\t\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 48}, page_content=\"\\tPlt.matshow(cn_mx,\\tcmap=plt.cm.gray)Plt.show()\\n\\t\\tFirst,\\tyou\\tshould\\tdivide\\tevery\\tvalue\\tin\\tthe\\tmatrix\\tby\\tthe\\tnumber\\tof\\timages\\tin\\ttheclass,\\tand\\tthen\\tyou'll\\tcompare\\tthe\\terror\\trates.rw_sm\\t=\\tcn_mx.sum(axis=1,\\tkeepdims=True)nm_cn_mx\\t=\\tcn_mx\\t/\\trw_sumThe\\tnext\\tstep\\tis\\tto\\tmake\\tall\\tthe\\tzeros\\ton\\tthe\\tdiagonal,\\tand\\tthat\\twill\\tkeep\\ttheerrors\\tfrom\\toccurring.np.fill_diagonal\\t(nm_cn_mx,\\t0)plt.matshow(nm_cn_mx,\\tcmap=plt.cm.gray)plt.show()\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 49}, page_content='The\\terrors\\tare\\teasy\\tto\\tspot\\tin\\tthe\\tabove\\tschema.\\t\\tOne\\tthing\\tto\\tkeep\\tin\\tmind\\tisthat\\tthe\\trows\\trepresent\\tclasses\\tand\\tthe\\tcolumns\\trepresent\\tthe\\tpredicted\\tvalues.\\t\\t\\t'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 50}, page_content=\"Multi-label\\tClassifications\\tIn\\tthe\\tabove\\texamples,\\tevery\\tclass\\thas\\tjust\\tone\\tinstance.\\tBut\\twhat\\tif\\twe\\twant\\ttoassign\\tthe\\tinstances\\tto\\tmultiple\\tclasses\\t—\\t\\tface\\trecognition,\\tfor\\texample.Suppose\\tthat\\tyou'd\\tlike\\tto\\tfind\\tmore\\tthan\\tone\\tface\\tin\\tthe\\tsame\\tphoto.\\tThere\\twillbe\\tone\\tlabel\\tfor\\teach\\tface.\\tLet's\\tpractice\\twith\\ta\\tsimple\\texample.y_tr_big\\t=\\t(y_tr\\t>=\\t7)y_tr_odd\\t=\\t(y_tr\\t%2\\t==1)y_multi\\t=\\tnp.c\\t[y_tr_big,\\ty_tr_odd]kng_cl\\t=\\tKNeighborsClassifier()kng_cl.fit\\t(x_tr,\\ty_m,ulti)In\\tthese\\tinstructions,\\twe\\thave\\tcreated\\ta\\ty_mullti\\tarray\\tthat\\tcontains\\ttwo\\tlabelsfor\\tevery\\timage.And\\tthe\\tfirst\\tone\\tcontains\\tinformation\\ton\\twhether\\tthe\\tdigit\\tis\\t“big”\\t(8,9,.),\\tandthe\\tsecond\\tone\\tchecks\\tif\\tit's\\todd\\tor\\tnot.\\tNext,\\twe'll\\tmake\\ta\\tprediction\\tusing\\tthe\\tfollowing\\tset\\tof\\tinstructions.>>>kng_cl.predict([any-digit])Array([false,\\ttrue],\\tdataType=bool)\\tTrue\\there\\tmeans\\tthat\\tit's\\t\\todd\\tand\\tfalse,\\tthat\\tit's\\t\\tnot\\tbig.\\t\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 51}, page_content='Multi-output\\tClassification\\tAt\\tthis\\tpoint,\\twe\\tcan\\tcover\\tthe\\tfinal\\ttype\\tof\\tclassification\\ttask,\\twhich\\tis\\tthemulti-output\\tclassification.It’s\\tjust\\ta\\tgeneral\\tcase\\tof\\tmulti-label\\tclassification,\\tbut\\tevery\\tlabel\\twill\\thave\\tamulticlass.\\tIn\\tother\\twords,\\tit\\twill\\thave\\tmore\\tthan\\tone\\tvalue.Let’s\\tmake\\tit\\tclear\\twith\\tthis\\texample,\\tusing\\tthe\\tMNIST\\timages,\\tand\\taddingsome\\tnoise\\tto\\tthe\\timage\\twith\\tthe\\tNumPy\\tfunctions.\\tNo\\t=\\trnd.randint\\t(0,\\t101,\\t(len(x_tr),\\t785)))No\\t=\\trnd.randint(0,\\t101,\\t(len(x_tes),\\t785))x_tr_mo\\t=\\tx_tr\\t+\\tnox_tes_mo\\t=\\tx_tes\\t+\\tnoy_tr_mo\\t=\\tx_try_tes_mo\\t=\\tx_teskng_cl.fit(x_tr_mo,\\ty_tr_mo)cl_digit\\t=\\tkng_cl.predict(x_tes_mo[any-index]])plot_digit(cl_digit)\\n\\t'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 52}, page_content='EXERCISES\\t\\t1.\\tConstruct\\ta\\tclassifier\\tfor\\tthe\\tMNIST\\tdata\\tset\\t.\\tTry\\tto\\tget\\tmore\\tthan96%\\taccuracy\\ton\\tyour\\ttest\\tset.\\t\\t2.\\tWrite\\ta\\tmethod\\tto\\tshift\\tan\\timage\\tfrom\\tthe\\tMNIST\\t(right\\tor\\tleft)\\t\\tby\\t2pixels.\\t\\t3.\\tDevelop\\tyour\\town\\tanti-spam\\tprogram\\tor\\tclassifier.\\t\\t-\\t\\t\\t\\t\\t\\t\\t\\tDownload\\texamples\\tof\\tspam\\tfrom\\tGoogle.\\t-\\t\\t\\t\\t\\t\\t\\t\\tExtract\\tthe\\tdata\\tset.\\t\\t-\\t\\t\\t\\t\\t\\t\\t\\tDivide\\tthe\\tdata\\tset\\tinto\\ttraining\\tfor\\t\\ta\\ttest\\tset.\\t-\\t\\t\\t\\t\\t\\t\\t\\tWrite\\ta\\tprogram\\tto\\tconvert\\tevery\\temail\\tto\\ta\\tfeature\\tvector.\\t\\t-\\t\\t\\t\\t\\t\\t\\t\\tPlay\\twith\\t\\tthe\\tclassifiers,\\tand\\ttry\\tto\\tconstruct\\tthe\\tbest\\tone\\tpossible,\\twithhigh\\t\\tvalues\\tfor\\trecall\\tand\\tprecision.\\t'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 53}, page_content=\"SUMMARY\\tIn\\tthis\\tchapter,\\tyou've\\tlearned\\tuseful\\t\\tnew\\tconcepts\\tand\\timplemented\\tmanytypes\\tof\\tclassification\\talgorithms.\\tYou've\\talso\\tworked\\twith\\tnew\\tconcepts,\\tlike\\t:\\t\\t-\\t\\t\\t\\t\\t\\t\\t\\tROC:\\t\\tthe\\treceiver\\toperating\\tcharacteristic,\\tthe\\ttool\\tused\\twith\\tbinaryclassifiers.\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t-\\t\\t\\t\\t\\t\\t\\t\\tError\\tAnalysis:\\toptimizing\\tyour\\talgorithms.\\t\\t\\t-\\t\\tHow\\tto\\ttrain\\ta\\trandom\\tforest\\tclassifier\\tusing\\tthe\\tforest\\tfunction\\tin\\tScikit-Learn.\\t\\t\\t-\\t\\t\\t\\t\\t\\t\\t\\tUnderstanding\\tMulti-Output\\tClassification.\\t\\t\\t-\\t\\t\\t\\t\\t\\t\\t\\tUnderstanding\\tmulti-Label\\tclassifications.\\t\\t\\t\\t\\t\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 54}, page_content='REFERENCES\\t\\thttp://scikit-learn.org/stable/install.html\\thttps://www.python.org\\thttps://matplotlib.org/2.1.0/users/installing.html\\thttp://yann.lecun.com/exdb/mnist/\\t\\t\\t\\t\\t\\t\\t'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 55}, page_content=\"CHAPTER\\t3HOW\\tTO\\tTRAIN\\tA\\tMODELAfter\\tworking\\twith\\tmany\\tmachine\\tlearning\\tmodels\\tand\\ttraining\\talgorithms,which\\tseem\\tlike\\tunfathomable\\tblack\\tboxes.\\twe\\twere\\table\\tto\\toptimize\\taregression\\tsystem,\\thave\\talso\\tworked\\twith\\timage\\tclassifiers.\\tBut\\twe\\tdevelopedthese\\tsystems\\twithout\\tunderstanding\\twhat's\\ts\\tinside\\tand\\thow\\tthey\\twork,\\tso\\tnowwe\\tneed\\tto\\tgo\\tdeeper\\tso\\tthat\\twe\\tcan\\tgrasp\\thow\\tthey\\twork\\tand\\tunderstand\\tthedetails\\tof\\timplementation.Gaining\\ta\\tdeep\\tunderstanding\\tof\\tthese\\tdetails\\twill\\thelp\\tyou\\twith\\tthe\\tright\\tmodeland\\twith\\tchoosing\\tthe\\tbest\\ttraining\\talgorithm.\\tAlso,\\tit\\twill\\thelp\\tyou\\twithdebugging\\tand\\terror\\tanalysis.In\\tthis\\tchapter,\\twe'll\\twork\\twith\\tpolynomial\\tregression,\\twhich\\tis\\ta\\tcomplexmodel\\tthat\\tworks\\tfor\\tnonlinear\\tdata\\tsets.\\tIn\\taddition,\\twe'll\\tworking\\twith\\tseveralregularization\\ttechniques\\tthat\\treduce\\ttraining\\tthat\\tencourages\\toverfitting.\\t\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 56}, page_content=\"Linear\\tRegressionAs\\tan\\texample,\\twe'll\\ttake\\tl_S\\t=\\tθ0\\t+\\tθ1\\t×\\tGDP_per_cap.\\tThis\\tis\\ta\\tsimple\\tmodelfor\\ta\\tlinear\\tfunction\\tof\\tthe\\tinput\\tfeature\\t,“GPD_per_cap”.\\t(θ0\\tand\\tθ1)\\tare\\ttheparameters\\tof\\tthe\\tmodel,In\\tgeneral,\\tyou'll\\tuse\\t\\ta\\tlinear\\tmodel\\tto\\tmake\\ta\\tprediction\\tby\\tcalculating\\taweighted\\tsum\\tof\\tthe\\tinput\\tfeatures,\\tand\\talso\\ta\\tconstant\\t“bias,”\\tas\\tyou\\tcan\\tsee\\tinthe\\tfollowing\\tequation.\\n.\\tY\\tis\\tthe\\tvalue\\tof\\tthe\\tpredictor..\\tN\\trepresents\\tthe\\tfeatures.\\tX1\\tis\\tthe\\tvalue\\tof\\tthe\\tfeature..\\tΘj\\tis\\tthe\\tmodel\\tparameter\\tof\\tj\\ttheta.Also,\\twe\\tcan\\twrite\\tthe\\tequation\\tin\\tvectorized\\tform,\\tas\\tin\\tthe\\tfollowing\\texample:\\t\\n.\\tΘ\\tis\\tthe\\tvalue\\tthat\\tminimizes\\tthe\\tcost..\\tY\\tcontains\\tthe\\tvalues\\ty\\t(1)\\tto\\ty\\t(m).\\tLet’s\\twrite\\tsome\\tcode\\tto\\tpractice.Import\\tnumpy\\tas\\tnpV1_x\\t=\\t2\\t*\\tnp.random.rand\\t(100,\\t1)V2_y\\t=\\t4\\t+\\t3\\t*\\tV1_x\\t+\\tnp.random.randn\\t(100,\\t1)\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 57}, page_content=\"\\t\\n\\t\\tAfter\\tthat,\\twe'll\\tcalculate\\tΘ\\tvalue\\tusing\\tour\\tequation.\\tIt's\\ttime\\tto\\tuse\\tthe\\tinv()function\\tfrom\\tour\\tlinear\\talgebra\\tmodule\\tof\\tnumpy\\t(np.linalg)to\\tcalculate\\ttheinverse\\tof\\tany\\tmatrix,\\tand\\talso,\\tthe\\tdot()\\tfunction\\tfor\\tmultiply\\tour\\tmatrixValue1\\t=\\tnp.c_[np.ones((100,\\t1)),\\t\\tV1_x]myTheta\\t=\\tnp.linalg.inv(Value1.T.dot(Value1)).dot(Value1.T).dot(V2_y)>>>myTheta\\tArray([[num],\\t[num]])This\\tfunction\\tuses\\tthe\\tfollowing\\tequation\\t—\\t\\ty\\t=\\t4\\t+\\t3x\\t+\\tnoise\\t“Gaussian”\\t—\\tto\\tgenerate\\tour\\tdata.Now\\tlet’s\\tmake\\tour\\tpredictions.>>>V1_new\\t=\\tnp.array([[0],[2]])>>>V1_new_2\\t=\\tnp.c_[np.ones((2,1)),\\tV1_new]>>>V2_predicit\\t=\\tV1_new_2.dot(myTheta)>>>V2_predictArray([[\\t4.219424],\\t[9.74422282]])Now,\\tit’s\\ttime\\tto\\tplot\\tthe\\tmodel.\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 58}, page_content='Plt.plot(V1_new,\\tV2_predict,\\t“r-“)Plt.plot(V1_x,\\tV2_y,\\t“b.”)Plt.axis([0,2,0,15])Plt.show()\\n'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 59}, page_content=\"\\tComputational\\tComplexityWith\\tthe\\tnormal\\tformula,\\twe\\tcan\\tcompute\\tthe\\tinverse\\tof\\tM^T.\\tM\\t—\\t\\tthat\\tis,\\tan*n\\tmatrix\\t(n\\t=\\tthe\\tnumber\\tof\\tfeatures).\\tThe\\tcomplexity\\tof\\tthis\\tinversion\\tissomething\\tlike\\tO(n^2.5)\\tto\\tO(n^3.2),\\twhich\\tis\\tbased\\ton\\tthe\\timplementation.Actually,\\tif\\tyou\\tmake\\tthe\\tnumber\\tof\\tfeatures\\tlike\\ttwice,\\tyou'll\\tmake\\tthe\\ttimeof\\tthe\\tcomputation\\tattain\\tbetween\\t2^2.5\\tand\\t2^3.2.The\\tgreat\\tnews\\there\\tis\\tthat\\tthe\\tequation\\tis\\ta\\tlinear\\tequation.\\tThis\\tmeans\\tIt\\tcaneasily\\thandle\\thuge\\ttraining\\tsets\\tand\\tfit\\tthe\\tmemory\\tin.\\tAfter\\ttraining\\tyour\\tmodel,\\tthe\\tpredictions\\twill\\tbe\\tnot\\tslow,\\tand\\tthe\\tcomplexitywill\\tbe\\tsimple,\\tthanks\\tto\\tthe\\tlinear\\tmodel.\\tIt’s\\ttime\\tto\\tgo\\tdeeper\\tinto\\tthe\\tmethodsof\\ttraining\\ta\\t\\tlinear\\tregression\\tmodel,\\twhich\\tis\\talways\\tused\\twhen\\tthere\\tis\\ta\\tlargenumber\\tof\\tfeatures\\tand\\tinstances\\tin\\tthe\\tmemory.\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 60}, page_content=\"Gradient\\tDescentThis\\talgorithm\\tis\\ta\\tgeneral\\talgorithm\\tthat\\tis\\tused\\tfor\\toptimization\\tand\\tforproviding\\tthe\\toptimal\\tsolution\\tfor\\tvarious\\tproblems.\\tThe\\tidea\\tof\\tthis\\talgorithmis\\tto\\twork\\twith\\tthe\\tparameters\\tin\\tan\\titerative\\tway,\\tto\\tmake\\tthe\\tcost\\tfunction\\tassimple\\tas\\tpossible.The\\tgradient\\tdescent\\talgorithm\\tcalculates\\tthe\\tgradient\\tof\\tthe\\terror\\tusing\\ttheparameter\\ttheta,\\tand\\tit\\tworks\\twith\\tthe\\tmethod\\tof\\tdescending\\tgradient.\\tIf\\tthegradient\\tis\\tequal\\tto\\tzero,\\tyou'll\\treach\\tthe\\tminimum.\\t\\t\\n\\t\\tAlso,\\tyou\\tshould\\tkeep\\tin\\tthe\\tmind\\tthat\\tthe\\tsize\\tof\\tthe\\tsteps\\tis\\tvery\\timportant\\tforthis\\talgorithm,\\tbecause\\tif\\tit's\\tvery\\tsmall\\t–\\t\\t“meaning\\tthe\\trate\\tof\\tlearning”\\tis\\tslow–\\tit\\twill\\ttake\\ta\\tlong\\ttime\\tto\\tcover\\teverything\\tthat\\tit\\tneeds\\tto.\\t\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 61}, page_content=\"\\tBut\\twhen\\tthe\\trate\\tof\\tlearning\\tis\\thigh,\\tIt\\twill\\ttake\\tshort\\ttime\\tto\\tcover\\twhat’sneeded,\\tand\\tit\\twill\\tprovide\\tan\\toptimal\\tsolution.\\nAt\\tthe\\tend,\\tyou\\twon't\\talways\\tfind\\tthat\\tall\\tcost\\tfunctions\\tare\\teasy,\\tas\\tyou\\tcan\\tsee,but\\tyou'll\\talso\\tfind\\tirregular\\tfunctions\\tthat\\tmake\\tgetting\\tan\\toptimal\\tsolution\\tverydifficult.\\tThis\\tproblem\\toccurs\\twhen\\tthe\\tlocal\\tminimum\\tand\\tglobal\\tminimumlooks\\tlike\\tthey\\tdo\\tin\\tthe\\tfollowing\\tfigure.\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 62}, page_content=\"\\tIf\\tyou\\tassign\\tany\\tto\\tany\\ttwo\\tpoints\\ton\\tyour\\tcurve,\\tyou'll\\tfind\\tthat\\tthe\\tsegment\\tofthe\\tline\\twon't\\tjoin\\tthem\\ton\\tthe\\tsame\\tcurve.\\tThis\\tcost\\tfunction\\twill\\tlook\\t\\tlike\\tabowl,\\twhich\\twill\\toccur\\tif\\tthe\\tfeatures\\thave\\tmany\\tscales,\\tas\\tn\\tthe\\tfollowingimage\\n\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 63}, page_content=\"\\tBatch\\tGradient\\tDescentIf\\tyou'd\\tlike\\tto\\timplement\\tthis\\talgorithm,\\tyou\\tshould\\tfirst\\tcalculate\\tthe\\tgradientof\\tyour\\tcost\\tfunction\\tusing\\tthe\\ttheta\\tparameter.\\tIf\\tthe\\tvalue\\tof\\tthe\\tparametertheta\\thas\\tchanged,\\tyou’ll\\tneed\\tto\\tknow\\tthe\\tchanging\\trate\\tof\\tyour\\tcost\\tfunction.\\tWe\\tcan\\t\\t\\tcall\\tthis\\tchange\\tby\\ta\\tpartial\\tderivativeWe\\tcan\\tcalculate\\tthe\\tpartial\\tderivative\\tusing\\tthe\\tfollowing\\tequation:\\n\\tBut\\twe`ll\\talso\\tuse\\tthe\\tfollowing\\tequation\\tto\\tcalculate\\tthe\\tpartial\\tderivatives\\tandthe\\tgradient\\tvector\\ttogether.\\n\\t\\tLet’s\\timplement\\tthe\\talgorithm.Lr\\t=\\t1\\t#\\tLr\\tfor\\tlearning\\trateNum_it\\t=\\t1000\\t#\\tnumber\\tof\\titerationsL\\t=\\t100myTheta\\t=\\tnp.random.randn\\t(2,1)\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 64}, page_content=\"for\\tit\\tin\\trange(Num_it):gr\\t=\\t2/L\\t*\\tValue1.T.dot(Value1.dot(myTheta)\\t–\\tV2_y)myTheta\\t=\\tmyTheta\\t–\\tLr\\t*\\tgr>>>\\tmyThetaArray([[num],[num]])If\\tyou\\ttry\\tto\\tchange\\tthe\\tlearning\\trate\\tvalue,\\tyou'll\\tget\\tdifferent\\tshapes,\\tas\\tin\\tthefollowing\\tfigure.\\n\\t\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 65}, page_content=\"Stochastic\\tGradient\\tDescentYou'll\\tfind\\ta\\tproblem\\twhen\\tyou’re\\tusing\\tthe\\tbatch\\tgradient\\tdescent:\\tit\\tneeds\\ttouse\\tthe\\twhole\\ttraining\\tset\\tin\\torder\\tto\\tcalculate\\tthe\\tvalue\\tat\\teach\\tstep,\\tand\\tthatwill\\taffect\\tperformance\\t“speed”.But\\twhen\\tusing\\tthe\\tstochastic\\tgradient\\tdescent,\\tthe\\talgorithm\\twill\\trandomlychoose\\tan\\tinstance\\tfrom\\tyour\\ttraining\\tset\\tat\\teach\\tstep,\\tand\\tthen\\tit\\twill\\tcalculatethe\\tvalue.\\tIn\\tthis\\tway,\\tthe\\talgorithm\\twill\\tbe\\tfaster\\tthan\\tthe\\tbatch\\tgradientdescent,\\tsince\\tit\\tdoesn’t\\tneed\\tto\\tuse\\tthe\\twhole\\tset\\tto\\tcalculate\\tthe\\tvalue.\\tOn\\ttheother\\thand,\\tbecause\\tof\\tthe\\trandomness\\tof\\tthis\\tmethod,\\tit\\twill\\tbe\\tirregular\\twhencompared\\t\\tto\\tthe\\tbatch\\talgorithm.\\n\\tLet’s\\timplement\\tthe\\talgorithm.Nums\\t=\\t50L1,\\tL2\\t=\\t5,\\t50Def\\tlr_sc(s):\\t\\t\\t\\treturn\\tL1\\t/\\t(s\\t+\\tL2)myTheta\\t=\\tnp.random.randn(2,1)for\\tNum\\tin\\trange\\t(Nums):for\\tl\\tin\\trange\\t(f)\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 66}, page_content='myIndex\\t=\\tnp.random.randint(f)V1_Xi\\t=\\tValue1[myIndex:myIndex+1]V2_yi\\t=\\tV2_y[myIndex:myIndex+1]gr\\t=\\t2\\t*\\tV1_xi.T.dot(V1_xi.dot(myTheta)\\t–\\tV2_yi)Lr\\t=\\tlr_sc(Num\\t*\\tf\\t+\\ti)myTheta\\t=\\tmyTheta\\t–\\tLr\\t*\\tgr>>>\\tmyThetaArray\\t([[num],\\t[num]])\\n\\t'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 67}, page_content='\\tMini-Batch\\tGradient\\tDescentBecause\\tyou\\talready\\tknow\\tthe\\tbatch\\tand\\tthe\\tstochastic\\talgorithms,\\tthis\\tkind\\tofalgorithms\\tis\\tvery\\teasy\\tto\\tunderstand\\tand\\twork\\twith\\t.\\tAs\\tyou\\tknow,\\tbothalgorithms\\tcalculate\\tthe\\tvalue\\tof\\tthe\\tgradients,\\tbased\\ton\\tthe\\twhole\\ttraining\\tset\\torjust\\tone\\tinstance.\\tHowever,\\tthe\\tmini-batch\\tcalculates\\tits\\talgorithms\\tbased\\tonsmall\\tand\\trandom\\tsets,\\tand\\t\\tperforms\\tbetter\\tthan\\tthe\\tother\\ttwo\\talgorithms.\\t\\t\\n\\t'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 68}, page_content=\"Polynomial\\tRegressionWe’ll\\tuse\\tthis\\ttechnique\\twhen\\tworking\\twith\\tmore\\tcomplex\\tdata,\\tespecially,\\tinthe\\tcase\\tof\\t\\tlinear\\tand\\tnonlinear\\tdata.\\tAfter\\twe’ve\\tadded\\tthe\\tpowers\\tof\\teveryfeature,\\twe\\tcan\\ttrain\\tthe\\tmodel\\twith\\tnew\\tfeatures.\\tThis\\tis\\tknown\\tas\\tpolynomialregression.Now,\\tlet’s\\twrite\\tsome\\tcode.L\\t=\\t100V1\\t=\\t6*np.random.rand(L,\\t1)\\t–\\t3V2\\t=\\t0.5\\t*\\tV1**2\\t+\\tV1\\t+\\t2\\t+\\tnp.random.randn(L,\\t1)\\t\\t\\n\\t\\tAs\\tyou\\tcan\\tsee.\\tthe\\tstraight\\twill\\tnever\\trepresent\\tthe\\tdata\\tin\\tthe\\tmost\\tefficientway.\\tSo\\twe'll\\tuse\\tthe\\tpolynomial\\tmethod\\tto\\twork\\ton\\tthis\\tproblem.>>>from\\tsklearn.preprocession\\timport\\tPolynomialFeatures>>>P_F\\t=\\tPolynomialFeatures(degree\\t=\\t2,\\tinclude_bias=False)>>>V1_P\\t=\\tP_F.fit_transform(V1)\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 69}, page_content='>>>V1[0]Array([num])>>>V1_P[0]Now,\\tlet’s\\tmake\\tthis\\tfunction\\tproperly\\twith\\tour\\tdata,\\tand\\tchange\\tthe\\tstraightline.>>>\\tln_r\\t=\\tLinearRegression()>>>ln_r.fit(V1_P,\\tV2)>>>ln_r.intercept_,\\tln_r.coef\\n\\t\\t'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 70}, page_content='Learning\\tCurvesAssume\\tthat\\tyou’re\\twork\\twith\\tpolynomial\\tregression,\\t\\tand\\tyou\\twant\\tit\\tto\\tfit\\tthedata\\tbetter\\tthan\\twith\\tthe\\tlinear\\tone\\t.\\tIn\\tthe\\tfollowing\\timage,\\tyou’ll\\tfind\\ta\\t300-degree\\tmodel\\t.\\tWe\\tcan\\talso\\tcompare\\tthe\\tfinal\\tresult\\twith\\tthe\\tother\\tkind\\tof\\ttheregression:\\t“normal\\tlinear”.\\nIn\\tthe\\tabove\\tfigure,\\tyou\\tcan\\tsee\\tthe\\toverfitting\\tof\\tdata\\twhen\\tyou’re\\tusing\\tthepolynomial.\\tOn\\tthe\\tother\\thand,\\twith\\tlinear\\tone,\\tyou\\tcan\\tsee\\tthat\\tthe\\tdata\\tisobviously\\tbeing\\tunderfitted.'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 71}, page_content=\"Regularized\\tLinear\\tModelsWe\\thave\\tworked,\\tin\\tthe\\tfirst\\tand\\tsecond\\tchapters,\\ton\\thow\\tto\\treduce\\toverfittingby\\tregularizing\\tthe\\tmodel\\ta\\tlittle,\\tas\\tan\\texample,\\tif\\tyou'd\\tlike\\tto\\tregularize\\tapolynomial\\tmodel.\\tIn\\tthis\\tcase,\\tto\\tfix\\tthe\\tproblem,\\tyou\\tshould\\tdecrease\\tthenumber\\tof\\tdegrees.\\tRidge\\tRegressionThe\\tridge\\tregression\\tis\\tanother\\tversion\\tof\\tthe\\tlinear\\tregression,\\tbut,\\tafterregularizing\\tit\\tand\\tadding\\tweight\\tto\\tthe\\tcost\\tfunction,\\tthis\\tmakes\\tit\\tfit\\tthe\\tdata,and\\teven\\tmakes\\tthe\\tweight\\tof\\tthe\\tmodel\\tas\\tsimple\\tas\\tpossible.\\tHere\\tis\\tthe\\tcostfunction\\tof\\tthe\\tridge\\tregression:\\t\\n\\t\\tAs\\tan\\texample\\tof\\tridge\\tregression,\\tjust\\ttake\\ta\\tlook\\tat\\tthe\\tfollowing\\tfigures.\\n\\tLasso\\tRegression\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 72}, page_content='\\t“Lasso”\\tregression\\tstands\\tfor\\t“Least\\tAbsolute\\tShrinkage\\tand\\tSelectionOperator”\\tregression.\\tThis\\tis\\tanother\\ttype\\tof\\tthe\\tregularized\\tversion\\tof\\tlinearregression.\\tIt\\tlooks\\tlike\\tridge\\tregression,\\tbut\\twith\\ta\\tsmall\\tdifference\\tin\\tthe\\tequation,\\tas\\tinthe\\tfollowing\\tfigures\\tThe\\tcost\\tfunction\\tof\\tthe\\tlasso\\tregression:\\t\\n\\tAs\\tyou\\tcan\\tsee\\tin\\tthe\\tfollowing\\tfigure,\\tthe\\tlasso\\tregression\\tuses\\tsmaller\\tvaluesthan\\tthe\\tridge.\\t\\n'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 73}, page_content='EXERCISES\\t1.\\tIf\\tyou\\thave\\ta\\tset\\tthat\\tcontains\\ta\\thuge\\tnumber\\tof\\tfeatures\\t(millions\\tofthem),\\twhich\\tregression\\talgorithm\\tshould\\tyou\\tuse,\\tand\\twhy?\\t\\t\\t2.\\tIf\\tyou\\tuse\\tbatch\\tgradient\\tdescent\\tto\\tplot\\tthe\\terror\\tat\\teach\\tperiod,\\tandsuddenly\\tthe\\trate\\tof\\terrors\\tincreases,\\thow\\twould\\tyou\\tfix\\tthis\\tproblem?\\t\\t\\t3.\\tWhat\\tshould\\tyou\\tdo\\tif\\tyou\\tnotice\\tthat\\t\\terrors\\tbecome\\tlarger\\t\\twhen\\tyou’re\\tusing\\tthe\\tmini-batch\\tmethod?\\tWhy?4.\\tFrom\\tthese\\tpairs,\\twhich\\t\\tmethod\\tis\\tbetter?\\tWhy?\\t:\\t.\\t\\tRidge\\tregression\\tand\\tlinear\\tregression?\\t.\\t\\tLasso\\tregression\\tand\\tridge\\tregression?\\t\\t\\t5.\\tWrite\\tthe\\tbatch\\tGradient\\tdescent\\talgorithm.\\t'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 74}, page_content=\"SUMMARY\\tIn\\tthis\\tchapter,\\tyou've\\tlearned\\tnew\\tconcepts,\\tand\\thave\\tlearned\\thow\\tto\\ttrain\\tamodel\\tusing\\tdifferent\\ttypes\\tof\\talgorithms.\\tYou’ve\\talso\\tlearned\\twhen\\tto\\tuse\\teachalgorithm,\\tincluding\\tthe\\tfollowing:\\t\\t-\\t\\t\\t\\t\\t\\t\\t\\tBatch\\tgradient\\tdescent\\t-\\t\\t\\t\\t\\t\\t\\t\\tMini-batch\\tgradient\\tdescent\\t\\t-\\t\\t\\t\\t\\t\\t\\t\\tPolynomial\\tregression\\t\\t-\\t\\t\\t\\t\\t\\t\\t\\tRegularized\\tlinear\\tmodels\\t\\t\\t\\t\\t\\t\\t.\\tRidge\\tregression\\t\\t\\t\\t\\t\\t\\t\\t.\\tLasso\\tregressionIn\\taddition,\\tyou\\tnow\\tknow\\tthe\\tmeaning\\tof\\tcertain\\tterms:\\tlinear\\tregression,computational\\tcomplexity,\\tand\\tgradient\\tdescent.\\t\\t\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 75}, page_content='REFERENCES\\thttps://docs.scipy.org/doc/numpy-dev/user/quickstart.htmlhttp://scikit-learn.org/stable/auto_examples/linear_model/plot_polynomial_interpolation.html\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 76}, page_content='Chapter\\t4Different\\tmodels\\tcombinations\\t\\t\\n\\tTree\\tclassifers.The\\tnext\\timage\\twill\\tillustrate\\tthe\\tdefinition\\tof\\ta\\tgeneral\\ttarget\\tof\\tcollectingfunctions\\tthat\\tis\\tjust\\tto\\tmerge\\tdifferent\\tclassifers\\tinto\\ta\\tOne-classifer\\tthat\\thas\\tabetter\\tgeneralization\\tperformance\\tthan\\teach\\tindividual\\tclassifer\\talone.\\tAs\\tan\\texample,\\tassume\\tthat\\tyou\\tcollected\\tpredictions\\tfrom\\tmany\\texperts.Ensemble\\tmethods\\twould\\tallow\\tus\\tto\\tmerge\\tthese\\tpredictions\\tby\\tthe\\tlots\\tofexperts\\tto\\tget\\ta\\tprediction\\tthat\\tis\\tmore\\tproper\\tand\\trobust\\tthan\\tthe\\tpredictions\\tofeach\\tindividual\\texpert.\\tAs\\tyou\\tcan\\tsee\\tlater\\tin\\tthis\\tpart,\\tthere\\tare\\tmany\\tdifferentmethods\\tto\\tcreate\\tan\\tensemble\\tof\\tclassifers.\\tIn\\tthis\\tpart,\\twe\\twill\\tintroduce\\tabasic\\tperception\\tabout\\thow\\tensembles\\twork\\tand\\twhy\\tthey\\tare\\ttypicallyrecognized\\tfor\\tyielding\\ta\\tgood\\tgeneralization\\tperformance.In\\tthis\\tpart,\\twe\\twill\\twork\\twith\\tthe\\tmost\\tpopular\\tensemble\\tmethod\\tthat\\tuses\\tthe'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 77}, page_content='majority\\tvoting\\tprinciple.\\tMany\\tvoting\\tsimply\\tmeans\\tthat\\twe\\tchoose\\tthe\\tlabelthat\\thas\\tbeen\\tpredicted\\tby\\tthe\\tmajority\\tof\\tclassifers;\\tthat\\tis,\\treceived\\tmore\\tthan50\\tpercent\\tof\\tthe\\tvotes.\\tAs\\tan\\texample,\\tthe\\tterm\\there\\tis\\tlike\\tvote\\trefers\\tto\\tjustbinary\\tclass\\tsettings\\tonly.\\tHowever,\\tit\\tis\\tnot\\thard\\tto\\tgenerate\\tthe\\tmajority\\tvotingprinciple\\tto\\tmulti-class\\tsettings,\\twhich\\tis\\tcalled\\tplurality\\tvoting.\\tAfter\\tthat,\\twewill\\tchoose\\tthe\\tclass\\tlabel\\tthat\\treceived\\tthe\\tmost\\tvotes.\\tThe\\tfollowing\\tdiagramillustrates\\tthe\\tconcept\\tof\\tmajority\\tand\\tplurality\\tvoting\\tfor\\tan\\tensemble\\tof\\t10classifers\\twhere\\teach\\tunique\\tsymbol\\t(triangle,\\tsquare,\\tand\\tcircle)\\trepresents\\taunique\\tclass\\tlabel:Using\\tthe\\ttraining\\tset,\\twe\\tstart\\tby\\ttraining\\tm\\tdifferent\\tclassifers\\t(C\\tC\\t1,\\t,\\t…\\tm\\t).Based\\ton\\tthe\\tmethod,\\tthe\\tensemble\\tcan\\tbe\\tbuilt\\tfrom\\tmany\\tclassificationalgorithms;\\tfor\\texample,\\tdecision\\ttrees,\\tsupport\\tvector\\tmachines,\\tlogisticregression\\tclassifers,\\tand\\tso\\ton.\\tIn\\tfact,\\tyou\\tcan\\tuse\\tthe\\tsame\\tbase\\tclassificationalgorithm\\tfitting\\tdifferent\\tsubsets\\tof\\tthe\\ttraining\\tset.\\tAn\\texample\\tof\\tthis\\tmethodwould\\tbe\\tthe\\trandom\\tforest\\talgorithm,\\twhich\\tmerges\\tmany\\tdecision\\tensembleways\\tusing\\tmajority\\tvoting.'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 78}, page_content=\"To\\tpredict\\ta\\tclass\\tlabel\\tvia\\ta\\tsimple\\tmajority\\tor\\tplurality\\tvoting,\\twe\\tcombine\\tthepredicted\\tclass\\tlabels\\tof\\teach\\tindividual\\tclassifer\\tC\\tj\\tand\\tselect\\tthe\\tclass\\tlabel\\tyˆthat\\treceived\\tthe\\tmost\\tvotes:y\\tm\\tˆ\\t=\\tode{C\\tC\\t1\\t2\\t(\\t)\\tx\\tx\\t,\\t,\\t(\\t)\\t…,Cm\\t(\\t)\\tx\\t}For\\texample,\\tin\\ta\\tbinary\\tclassification\\ttask\\twhere\\tclass1\\t1\\t=\\t−\\tand\\tclass2\\t1\\t=\\t+,we\\tcan\\twrite\\tthe\\tmajority\\tvote\\tprediction.\\tTo\\tillustrate\\twhy\\tensemble\\tmethods\\tcan\\twork\\tbetter\\tthan\\tindividual\\tclassifiersalone,\\tlet's\\tapply\\tthe\\tsimple\\tconcepts\\tof\\tcombinatory.\\tFor\\tthe\\tfollowingexample,\\twe\\tmake\\tthe\\tassumption\\tthat\\tall\\tn\\tbase\\tclassifiers\\tfor\\ta\\tbinaryclassification\\ttask\\thave\\tan\\tequal\\terror\\trate,\\tε.\\tAdditionally,\\twe\\tassume\\tthat\\ttheclassifiers\\tare\\tindependent\\tand\\tthe\\terror\\trates\\tare\\tnot\\tcorrelated.\\tAs\\tyou\\tcan\\tsee,we\\tcan\\tsimply\\texplain\\tthe\\terror\\tstatistics\\tof\\tan\\tensemble\\tof\\tbase\\tclassifiers\\tas\\taprobability.\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 79}, page_content=\"Mass\\tfunction\\tof\\ta\\tbinomial\\tdistribution:Here,\\tn.\\tk\\tis\\tthe\\tbinomial\\tcoefficient\\tn\\tchoose\\tk.\\tAs\\tyou\\tcan\\tsee,\\tyou\\tcancalculate\\tthe\\tprobability\\tthat\\tthe\\tprediction\\tof\\tthe\\tensemble\\tis\\twrong.\\tNow,\\tlet'stake\\ta\\tlook\\tat\\ta\\tmore\\tconcrete\\texample\\tof\\t11\\tbase\\tclassifiers\\t(n\\t=11)\\twith\\tanerror\\trate\\tof\\t0.25\\t(ε\\t=\\t0.25):You\\tcan\\tnotice\\tthat\\tthe\\terror\\trate\\tof\\tthe\\tensemble\\t(0.034)\\tis\\tsmaller\\tthan\\ttheerror\\trate\\tof\\teach\\tindividual\\tclassifer\\t(0.25)\\tif\\tall\\tthe\\tassumptions\\tare\\tmet.\\tNotethat\\tin\\tthis\\tsimplified\\timage,\\ta\\t50-50\\tsplit\\tby\\tan\\teven\\tnumber\\tof\\tclassifiers\\tn\\tistreated\\tas\\tan\\terror,\\twhereas\\tthis\\tis\\tonly\\ttrue\\thalf\\tof\\tthe\\ttime.\\tTo\\tcompare\\tsuch\\tanidealistic\\tensemble\\tclassifer\\tto\\ta\\tbase\\tclassifer\\tover\\ta\\trange\\tof\\tdifferent\\tbaseerror\\trates,\\tlet's\\timplement\\tthe\\tprobability\\tmass\\tfunction\\tin\\tPython:>>>\\timport\\tmath>>>\\tdef\\tensemble_error(n_classifier,\\terror):...\\tq_start\\t=\\tmath.ceil(n_classifier\\t/\\t2.0)...\\tProbability\\t=\\t[comb(n_class,\\tq)\\t*...\\terror**q\\t*...\\t(1-error)**(n_classifier\\t-\\tq)...\\tfor\\tq\\tin\\trange(q_start,\\tl_classifier\\t+\\t2)]...\\treturn\\tsum(Probability)>>>\\tensemble_error(n_classifier=11,\\terror=0.25)0.034327507019042969Let’s\\twrite\\tsome\\tcode\\tto\\tcompute\\tthe\\trates\\tfor\\tthe\\tdifferent\\terrors\\tvisualize\\ttherelationship\\tbetween\\tensemble\\tand\\tbase\\terrors\\tin\\ta\\tline\\tgraph:>>>\\timport\\tnumpy\\tas\\tnp>>>\\terror_range\\t=\\tnp.arange(0.0,\\t1.01,\\t0.01)\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 80}, page_content=\">>>\\ten_error\\t=\\t[en_er(n_classifier=11,\\ter=er)...\\tfor\\ter\\tin\\ter_range]>>>\\timport\\tmatplotlib.pyplot\\tas\\tplt>>>\\tplt.plot(er_range,\\ten_error,...\\tlabel='Ensemble\\terror',...\\tlinewidth=2)>>>\\tplt.plot(er_range,\\ter_range,...\\tls='--',\\tlabel='B_\\ter',...\\tlinewidth=2)>>>\\tplt.xlabel('B_\\ter')>>>\\tplt.label('B/En_er')>>>\\tplt.legend(loc='upper\\tleft')>>>\\tplt.grid()>>>\\tplt.show()As\\twe\\tcan\\tsee\\tin\\tthe\\tresulting\\tplot,\\tthe\\terror\\tprobability\\tof\\tan\\tensemble\\tisalways\\tbetter\\tthan\\tthe\\terror\\tof\\tan\\tindividual\\tbase\\tclassifer\\tas\\tlong\\tas\\tthe\\tbaseclassifiers\\tperform\\tbetter\\tthan\\trandom\\tguessing\\t(ε\\t<\\t0.5\\t).\\tYou\\tshould\\tnotice\\tthatthe\\ty-axis\\tdepicts\\tthe\\tbase\\terror\\tas\\twell\\tas\\tthe\\tensemble\\terror\\t(continuous\\tline):\\t\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 81}, page_content=''),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 82}, page_content=\"Implementing\\ta\\tsimple\\tmajority\\tclassiferAs\\twe\\tsaw\\tin\\tthe\\tintroduction\\tto\\tmerge\\tlearning\\tin\\tthe\\tlast\\tsection,\\twe\\twill\\tworkwith\\ta\\twarm-up\\ttraining\\tand\\tthen\\tdevelop\\ta\\tsimple\\tclassifer\\tfor\\tmajority\\tvotingin\\tPython\\tprogramming.\\tAs\\tyou\\tcan\\tsee,\\tthe\\tnext\\talgorithm\\twill\\twork\\ton\\tmulti-class\\tsettings\\tvia\\tplurality\\tvoting;\\tyou\\twill\\tuse\\tthe\\tterm\\tmajority\\tvoting\\tforsimplicity\\tas\\tis\\talso\\toften\\tdone\\tin\\tliterature.In\\tthe\\tfollowing\\tprogram,\\twe\\twill\\tdevelop\\tand\\talso\\tcombine\\tdifferentclassification\\tprograms\\tassociated\\twith\\tindividual\\tweights\\tfor\\tconfidence.\\tOurgoal\\tis\\tto\\tbuild\\ta\\tstronger\\tmeta-classifer\\tthat\\tbalances\\tout\\tthe\\tindividualclassifiers'\\tweaknesses\\ton\\ta\\tparticular\\tdataset.\\tIn\\tmore\\tprecise\\tmathematicalterms,\\twe\\tcan\\twrite\\tthe\\tweighted\\tmajority\\tvote.\\tTo\\ttranslate\\tthe\\tconcept\\tof\\tthe\\tweighted\\tmajority\\tvote\\tinto\\tPython\\tcode,\\twe\\tcanuse\\tNumPy's\\tconvenient\\targmax\\tand\\tbincount\\tfunctions:>>>\\timport\\tnumpy\\tas\\tnp>>>\\tnp.argmax(np.bincount([0,\\t0,\\t1],...\\tweights=[0.2,\\t0.2,\\t0.6]))1Here,\\tpij\\tis\\tthe\\tpredicted\\tprobability\\tof\\tthe\\tjth\\tclassifer\\tfor\\tclass\\tlabel\\ti.\\tTocontinue\\twith\\tour\\tprevious\\texample,\\tlet's\\tassume\\tthat\\twe\\thave\\ta\\tbinaryclassification\\tproblem\\twith\\tclass\\tlabels\\ti\\t∈{\\t}\\t0,1\\tand\\tan\\tensemble\\tof\\tthreeclassifiers\\tC\\tj\\t(\\tj\\t∈{\\t}\\t1,2,3\\t).\\tLet's\\tassume\\tthat\\tthe\\tclassifer\\tC\\tj\\treturns\\tthefollowing\\tclass\\tmembership\\tprobabilities\\tfor\\ta\\tparticular\\tsample\\tx:C1\\t(\\t)\\tx\\t→\\t[\\t]\\t0.9,0.1\\t,\\tC2\\t(\\t)\\tx\\t→\\t[\\t]\\t0.8,0.2\\t,\\tC3\\t(\\t)\\tx\\t→\\t[\\t]\\t0.4,0.6To\\timplement\\tthe\\tweighted\\tmajority\\tvote\\tbased\\ton\\tclass\\tprobabilities,\\twe\\tcanagain\\tmake\\tuse\\tof\\tNumPy\\tusing\\tnumpy.average\\tand\\tnp.argmax:\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 83}, page_content='>>>\\tex\\t=\\tnp.array([[0.9,\\t0.1],...\\t[0.8,\\t0.2],...\\t[0.4,\\t0.6]])>>>\\tp\\t=\\tnp.average(ex,\\taxis=0,\\tweights=[0.2,\\t0.2,\\t0.6])>>>\\tparray([\\t0.58,\\t0.42])>>>\\tnp.argmax(p)0Putting\\teverything\\ttogether,\\tlet\\'s\\tnow\\timplement\\ta\\tMajorityVoteClassifier\\tinPython:from\\tsklearn.base\\timport\\tClassifierMixinfrom\\tsklearn.pre_processing\\timport\\tLabel_Enfrom\\tsklearn.ext\\timport\\tsixfrom\\tsklearn.ba\\timport\\tclonefrom\\tsklearn.pipeline\\timport\\t_name_estimatorsimport\\tnumpy\\tas\\tnpimport\\toperatorclass\\tMVClassifier(BaseEstimator,ClassifierMixin):\"\"\"\\tA\\tmajority\\tvote\\tensemble\\tclassifierParameters----------cl\\t:\\tarray-like,\\tshape\\t=\\t[n_classifiers]'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 84}, page_content='Different\\tclassifiers\\tfor\\tthe\\tensemble\\tvote:\\tstr,\\t{\\'cl_label\\',\\t\\'prob\\'}Default:\\t\\'cl_label\\'If\\t\\'cl_label\\'\\tthe\\tprediction\\tis\\tbased\\ton\\tthe\\targmax\\tof\\tclass\\tlabels.\\tElif\\t\\'prob\\',\\tthearg\\tof\\tthe\\ttotal\\tof\\tprobs\\tis\\tused\\tto\\tpredict\\tthe\\tclass\\tlabel\\t(recommended\\tforcalibrated\\tclassifiers).w\\t:\\tarr-like,\\ts\\t=\\t[n_cl]Optional,\\tdefault:\\tNoneIf\\ta\\tlist\\tof\\t`int`\\tor\\t`float`\\tvalues\\tare\\tprovided,\\tthe\\tclassifiers\\tare\\tweighted\\tby\\t\"\"\"def\\t__init__(s,\\tcl,v=\\'cl_label\\',\\tw=None):s.cl\\t=\\tcls.named_cl\\t=\\t{key:\\tvalue\\tforkey,\\tvalue\\tin_name_estimators(cl)}s.v\\t=\\tvs.w=\\twdef\\tfit_cl(s,\\tX,\\ty):\"\"\"\\tFit_cl.Parameters----------X\\t:\\t{array-like,\\tsparse\\tmatrix},s\\t=\\t[n_samples,\\tn_features]Matrix\\tof\\ttraining\\tsamples.'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 85}, page_content='y\\t:\\tarr_like,\\tsh\\t=\\t[n_samples]Vector\\tof\\ttarget\\tclass\\tlabels.Returns-------s\\t:\\tobject\"\"\"#\\tUse\\tLabelEncoder\\tto\\tensure\\tclass\\tlabels\\tstart#\\twith\\t0,\\twhich\\tis\\timportant\\tfor\\tnp.argmax#\\tcall\\tin\\ts.predicts.l_\\t=\\tLabelEncoder()s.l_.fit(y)s.cl_\\t=\\tself.lablenc_.classes_s.cl_\\t=\\t[]for\\tcl\\tin\\ts.cl:fit_cl\\t=\\tclone(cl).fit(X,s.la_.transform(y))s.cl_.append(fit_cl)return\\tsI\\tadded\\ta\\tlot\\tof\\tcomments\\tto\\tthe\\tcode\\tto\\tbetter\\tunderstand\\tthe\\tindividual\\tparts.However,\\tbefore\\twe\\timplement\\tthe\\tremaining\\tmethods,\\tlet\\'s\\ttake\\ta\\tquick\\tbreakand\\tdiscuss\\tsome\\tof\\tthe\\tcode\\tthat\\tmay\\tlook\\tconfusing\\tat\\tfirst.\\tWe\\tused\\ttheparent\\tclasses\\tBaseEstimator\\tand\\tClassifierMixin\\tto\\tget\\tsome\\tbase\\tfunctionalityfor\\tfree,\\tincluding\\tthe\\tmethods\\tget_params\\tand\\tset_params\\tto\\tset\\tand\\treturn\\ttheclassifer\\'s\\tparameters\\tas\\twell\\tas\\tthe\\tscore\\tmethod\\tto\\tcalculate\\tthe\\tprediction'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 86}, page_content='accuracy,\\trespectively.\\tAlso,\\tnote\\tthat\\twe\\timported\\tsix\\tto\\tmake\\ttheMajorityVoteClassifier\\tcompatible\\twith\\tPython\\t2.7.Next,\\twe\\twill\\tadd\\tthe\\tpredict\\tmethod\\tto\\tpredict\\tthe\\tclass\\tlabel\\tvia\\tmajority\\tvotebased\\ton\\tthe\\tclass\\tlabels\\tif\\twe\\tinitialize\\ta\\tnew\\tMajorityVoteClassifier\\tobjectwith\\tvote=\\'classlabel\\'.\\tAlternatively,\\twe\\twill\\tbe\\table\\tto\\tinitialize\\tthe\\tensembleclassifer\\twith\\tvote=\\'probability\\'\\tto\\tpredict\\tthe\\tclass\\tlabel\\tbased\\ton\\tthe\\tclassmembership\\tprobabilities.\\tFurthermore,\\twe\\twill\\talso\\tadd\\ta\\tpredict_proba\\tmethodto\\treturn\\tthe\\taverage\\tprobabilities,\\twhich\\tis\\tuseful\\tto\\tcompute\\tthe\\tReceiverOperator\\tCharacteristic\\tarea\\tunder\\tthe\\tcurve\\t(ROC\\tAUC).def\\tpre(s,\\tX):\"\"\"\\tPre\\tclass\\tlabels\\tfor\\tX.Parameters----------X\\t:\\t{arr-like,\\tspar\\tmat},Sh\\t=\\t[n_samples,\\tn_features]Matrix\\tof\\ttraining\\tsamples.Returns----------ma_v\\t:\\tarr-like,\\tsh\\t=\\t[n_samples]Predicted\\tclass\\tlabels.\"\"\"if\\tse.v\\t==\\t\\'probability\\':ma_v\\t=\\tnp.argmax(spredict_prob(X),axis=1)'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 87}, page_content='else:\\t#\\t\\'cl_label\\'\\tvpredictions\\t=\\tnp.asarr([cl.predict(X)for\\tcl\\tins.cl_]).Tma_v\\t=\\tnp.ap_al_ax(lambda\\tx:np.argmax(np.bincount(x,\\tweights=s.w)),axis=1,arr=predictions)ma_v\\t=\\ts.l_.inverse_transform(ma_v)return\\tma_vdef\\tpredict_proba(self,\\tX):\"\"\"\\tPrediction\\tfor\\tX.Parameters----------X\\t:\\t{arr-like,\\tsp\\tmat},sh\\t=\\t[n_samples,\\tn_features]Training\\tvectors,\\twhere\\tn_samples\\tis\\tthe\\tnumber\\tof\\tsamples\\tand\\tn_features\\tisthe\\tnumber\\tof\\tfeatures.Returns----------av_prob\\t:\\tarray-like,sh\\t=\\t[n_samples,\\tn_classes]'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 88}, page_content='Weighted\\taverage\\tprobability\\tfor\\teach\\tclass\\tper\\tsample.\"\"\"probs\\t=\\tnp.asarr([cl.predict_prob(X)for\\tcl\\tin\\ts.cl_])av_prob\\t=\\tnp.av(probs,axis=0,\\tweights=s.w)return\\tav_probdef\\tget_ps(self,\\tdeep=True):\"\"\"\\tGet\\tclassifier\\tparameter\\tnames\\tfor\\tGridSearch\"\"\"if\\tnot\\tdeep:return\\tsuper(MVC,self).get_ps(deep=False)else:ou\\t=\\ts.n_cl.copy()for\\tn,\\tstep\\tin\\\\six.iteritems(s.n_cl):for\\tk,\\tvalue\\tin\\tsix.iteritems(step.get_ps(deep=True)):ou[\\'%s__%s\\'\\t%\\t(n,\\tk)]\\t=\\tvaluereturn\\tou\\t\\t'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 89}, page_content=\"Combining\\tdifferent\\talgorithms\\tfor\\tclassification\\twith\\tmajority\\tvoteNow,\\tit\\tis\\tabout\\ttime\\tto\\tput\\tthe\\tMVC\\tthat\\twe\\timplemented\\tin\\tthe\\tprevioussection\\tinto\\taction.\\tYou\\tshould\\tfirst\\tprepare\\ta\\tdataset\\tthat\\tyou\\tcan\\ttest\\tit\\ton.Since\\twe\\tare\\talready\\tfamiliar\\twith\\ttechniques\\tto\\tload\\tdatasets\\tfrom\\tCSV\\tfiles,we\\twill\\ttake\\ta\\tshortcut\\tand\\tload\\tthe\\tIris\\tdataset\\tfrom\\tscikit-learn's\\tdatasetmodule.Furthermore,\\twe\\twill\\tonly\\tselect\\ttwo\\tfeatures,\\tsepal\\twidth\\tand\\tpetal\\tlength,\\ttomake\\tthe\\tclassification\\ttask\\tmore\\tchallenging.\\tAlthough\\tourMajorityVoteClassifier,\\tor\\tMVC,\\tgeneralizes\\tto\\tmulticlass\\tproblems,\\twe\\twillonly\\tclassify\\tflower\\tsamples\\tfrom\\tthe\\ttwo\\tclasses,\\tIr-Versicolor\\tand\\tIr-Virginica,to\\tcompute\\tthe\\tROC\\tAUC.\\tThe\\tcode\\tis\\tas\\tfollows:>>>\\timport\\tsklearn\\tas\\tsk>>>\\timport\\tsklearn.cross_validation\\tas\\tcv>>>\\tir\\t=\\tdatasets.load_ir()>>>\\tX,\\ty\\t=\\tir.data[50:,\\t[1,\\t2]],\\tir.target[50:]>>>\\tle\\t=\\tLabelEncoder()>>>\\ty\\t=\\tle.fit_transform(y)Next\\twe\\tsplit\\tthe\\tIris\\tsamples\\tinto\\t50\\tpercent\\ttraining\\tand\\t50\\tpercent\\ttest\\tdata:>>>\\tX_train,\\tX_test,\\ty_train,\\ty_test\\t=\\\\...\\ttrain_test_split(X,\\ty,...\\ttest_size=0.5,...\\trandom_state=1)Using\\tthe\\ttraining\\tdataset,\\twe\\tnow\\twill\\ttrain\\tthree\\tdifferent\\tclassifiers\\t—\\talogistic\\tregression\\tclassifier,\\ta\\tdecision\\ttree\\tclassifer,\\tand\\ta\\tk-nearest\\tneighborsclassifier\\t—\\tand\\tlook\\tat\\ttheir\\tindividual\\tperformances\\tvia\\ta\\t10\\tcross-validation\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 90}, page_content=\"on\\tthe\\ttraining\\tdataset\\tbefore\\twe\\tmerge\\tthem\\tinto\\tan\\tensemble\\tone:import\\tthe\\tfollowing\\tsklearn.cross_validationsklearn.linear_modelsklearn.tree\\tsklearn.pipelinePipelinenumpy\\tas\\tnp>>>\\tclf1\\t=\\tLogisticRegression(penalty='l2',...\\tC=0.001,...\\trandom_state=0)>>>\\tclf2\\t=\\tDTCl(max_depth=1,...\\tcriterion='entropy',...\\trandom_state=0)\\t>>>\\tcl\\t=\\tKNC(n_nb=1,...\\tp=2,...\\tmet='minsk')>>>\\tpipe1\\t=\\tPipeline([['sc',\\tStandardScaler()],...\\t['clf',\\tclf1]])>>>\\tpipe3\\t=\\tPipeline([['sc',\\tStandardScaler()],...\\t['clf',\\tclf3]])\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 91}, page_content='>>>\\tclf_labels\\t=\\t[\\'Logistic\\tRegression\\',\\t\\'Decision\\tTree\\',\\t\\'KNN\\']>>>\\tprint(\\'10-fold\\tcross\\tvalidation:\\\\n\\')>>>\\tfor\\tclf,\\tlabel\\tin\\tzip([pipe1,\\tclf2,\\tpipe3],\\tclf_labels):...\\tsc\\t=\\tcrossVSc(estimator=clf,>>>\\tX=X_train,>>>\\ty=y_train,>>>\\tcv=10,>>>\\tscoring=\\'roc_auc\\')>>>\\tprint(\"ROC\\tAUC:\\t%0.2f\\t(+/-\\t%0.2f)\\t[%s]\"...\\t%\\t(scores.mean(),\\tscores.std(),\\tlabel))The\\toutput\\tthat\\twe\\treceive,\\tas\\tshown\\tin\\tthe\\tfollowing\\tsnippet,\\tshows\\tthat\\tthepredictive\\tperformances\\tof\\tthe\\tindividual\\tclassifiers\\tare\\talmost\\tequal:10-fold\\tcross\\tvalidation:ROC\\tAUC:\\t0.92\\t(+/-\\t0.20)\\t[Logistic\\tRegression]ROC\\tAUC:\\t0.92\\t(+/-\\t0.15)\\t[Decision\\tTree]ROC\\tAUC:\\t0.93\\t(+/-\\t0.10)\\t[KNN]You\\tmay\\tbe\\twondering\\twhy\\twe\\ttrained\\tthe\\tlogistic\\tregression\\tand\\tk-nearestneighbors\\tclassifier\\tas\\tpart\\tof\\ta\\tpipeline.\\tThe\\tcause\\there\\tis\\tthat,\\tas\\twe\\tsaid,logistic\\tregression\\tand\\tk-nearest\\tneighbors\\talgorithms\\t(using\\tthe\\tEuclideandistance\\tmetric)\\tare\\tnot\\tscale-invariant\\tin\\tcontrast\\twith\\tdecision\\ttrees.\\tHowever,the\\tIr\\tadvantages\\tare\\tall\\tmeasured\\ton\\tthe\\tsame\\tscale;\\tit\\tis\\ta\\tgood\\thabit\\tto\\tworkwith\\tstandardized\\tfeatures.Now,\\tlet\\'s\\tmove\\ton\\tto\\tthe\\tmore\\texciting\\tpart\\tand\\tcombine\\tthe\\tindividualclassifiers\\tfor\\tmajority\\trule\\tvoting\\tin\\tour\\tM_V_C:'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 92}, page_content=\">>>\\tmv_cl\\t=\\tM_V_C(...\\tcl=[pipe1,\\tclf2,\\tpipe3])>>>\\tcl_labels\\t+=\\t['Majority\\tVoting']>>>\\tall_cl\\t=\\t[pipe1,\\tclf2,\\tpipe3,\\tmv_clf]>>>\\tfor\\tcl,\\tlabel\\tin\\tzip(all_clf,\\tclf_labels):...\\tsc\\t=\\tcross_val_score(est=cl,...\\tX=X_train,...\\ty=y_train,...\\tcv=10,...\\tscoring='roc_auc')...\\t%\\t(scores.mean(),\\tscores.std(),\\tlabel))R_AUC:\\t0.92\\t(+/-\\t0.20)\\t[Logistic\\tRegression]R_AUC:\\t0.92\\t(+/-\\t0.15)\\t[D_T]R_AUC:\\t0.93\\t(+/-\\t0.10)\\t[KNN]R_AUC:\\t0.97\\t(+/-\\t0.10)\\t[Majority\\tVoting]Additionally,\\tthe\\toutput\\tof\\tthe\\tMajorityVotingClassifier\\thas\\tsubstantiallyimproved\\tover\\tthe\\tindividual\\tclassifiers\\tin\\tthe\\t10-fold\\tcross-validationevaluation.ClassifierIn\\tthis\\tpart,\\tyou\\tare\\tgoing\\tto\\tcompute\\tthe\\tR_C\\tcurves\\tfrom\\tthe\\ttest\\tset\\tto\\tcheckif\\tthe\\tMV_Classifier\\tgeneralizes\\twell\\tto\\tunseen\\tdata.\\tWe\\tshould\\tremember\\tthatthe\\ttest\\tset\\twill\\tnot\\tbe\\tused\\tfor\\tmodel\\tselection;\\tthe\\tonly\\tgoal\\tis\\tto\\treport\\tanestimate\\tof\\tthe\\taccuracy\\tof\\ta\\tclassifer\\tsystem.\\tLet’s\\ttake\\ta\\tlook\\tat\\tImportmetrics.\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 93}, page_content=\"import\\troc_curve\\tfrom\\tsklearn.metrics\\timport\\tauccls\\t=\\t['black',\\t'orange',\\t'blue',\\t'green']ls\\t=\\t[':',\\t'--',\\t'-.',\\t'-']for\\tcl,\\tlabel,\\tcl,\\tl\\t\\\\...\\tin\\tzip(all_cl,\\tcl_labels,\\tcls,\\tls):...\\ty_pred\\t=\\tclf.fit(X_train,...\\ty_train).predict_proba(X_test)[:,\\t1]...\\tfpr,\\ttpr,\\tthresholds\\t=\\trc_curve(y_t=y_tes,...\\ty_sc=y_pr)...\\trc_auc\\t=\\tac(x=fpr,\\ty=tpr)...\\tplt.plot(fpr,\\ttpr,...\\tcolor=clr,...\\tlinestyle=ls,...\\tla='%s\\t(ac\\t=\\t%0.2f)'\\t%\\t(la,\\trc_ac))>>>\\tplt.lg(lc='lower\\tright')>>>\\tplt.plot([0,\\t1],\\t[0,\\t1],...\\tlinestyle='--',...\\tcolor='gray',...\\tlinewidth=2)>>>\\tplt.xlim([-0.1,\\t1.1])>>>\\tplt.ylim([-0.1,\\t1.1])>>>\\tplt.grid()\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 94}, page_content=\">>>\\tplt.xlb('False\\tPositive\\tRate')>>>\\tplt.ylb('True\\tPositive\\tRate')>>>\\tplt.show()As\\twe\\tcan\\tsee\\tin\\tthe\\tresulting\\tROC,\\tthe\\tensemble\\tclassifer\\talso\\tperforms\\twellon\\tthe\\ttest\\tset\\t(ROC\\tAUC\\t=\\t0.95),\\twhereas\\tthe\\tk-nearest\\tneighbors\\tclassiferseems\\tto\\tbe\\tover-fitting\\tthe\\ttraining\\tdata\\t(training\\tROC\\tAUC\\t=\\t0.93,\\ttest\\tROCAUC\\t=\\t0.86):\\nYou\\tonly\\tchoose\\ttwo\\tfeatures\\tfor\\tthe\\tclassification\\ttasks.\\tIt\\twill\\tbe\\tinteresting\\ttoshow\\twhat\\tthe\\tdecision\\tregion\\tof\\tthe\\tensemble\\tclassifer\\tactually\\tlooks\\tlike.Although\\tit\\tis\\tnot\\tnecessary\\tto\\tstandardize\\tthe\\ttraining\\tfeatures\\tprior\\tto\\tmodel\\ttofit\\tbecause\\tour\\tlogistic\\tregression\\tand\\tk-nearest\\tneighbors\\tpipelines\\twillautomatically\\ttake\\tcare\\tof\\tthis,\\tyou\\twill\\tmake\\tthe\\ttraining\\tset\\tso\\tthat\\tthe\\tdecisionregions\\tof\\tthe\\tdecision\\ttree\\twill\\tbe\\ton\\tthe\\tsame\\tscale\\tfor\\tvisual\\tpurposes.Let’s\\ttake\\ta\\tlook:>>>\\tsc\\t=\\tSS()X_tra_std\\t=\\tsc.fit_transform(X_train)From\\titertools\\timport\\tproductx_mi=\\tX_tra_std[:,\\t0].mi()\\t-\\t1\\tx_ma\\t=\\tX_tra_std[:,\\t0].ma()\\t+\\t1\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 95}, page_content=\"y_mi\\t=\\tX_tra_std[:,\\t1].mi()\\t-\\t1y_ma\\t=\\tX_tra_std[:,\\t1].ma()\\t+\\t1\\txx,\\tyy\\t=\\tnp.meshgrid(np.arange(x_min,\\tx_max,\\t0.1),...\\tnp.arange(y_mi,\\ty_ma,\\t0.1))\\tf,\\taxarr\\t=\\tplt.subplots(nrows=2,\\tncols=2,sharex='col',sharey='row',figze=(7,\\t5))for\\tix,\\tcl,\\ttt\\tin\\tzip(product([0,\\t1],\\t[0,\\t1]),all_cl,\\tcl_lb):...\\tcl.fit(X_tra_std,\\ty_tra)...\\tZ\\t=\\tclf.predict(np.c_[xx.ravel(),\\tyy.ravel()])...\\tZ\\t=\\tZ.resh(xx.shape)...\\taxarr[idx[0],\\tidx[1]].contou(_xx,\\t_yy,\\tZ,\\talph=0.3)...\\taxarr[idx[0],\\tidx[1]].scatter(X_tra_std[y_tra==0,\\t0],...\\tX_tra_std[y_tra==0,\\t1],...\\tc='blue',...\\tmark='^',...\\ts=50)...\\taxarr[idx[0],\\tidx[1]].scatt(X_tra_std[y_tra==1,\\t0],...\\tX_tra_std[y_tra==1,\\t1],...\\tc='red',\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 96}, page_content=\"...\\tmarker='o',...\\ts=50)...\\taxarr[idx[0],\\tidx[1]].set_title(tt)>>>\\tplt.text(-3.5,\\t-4.5,...\\tz='Sl\\twid\\t[standardized]',...\\tha='center',\\tva='center',\\tftsize=12)>>>\\tplt.text(-10.5,\\t4.5,...\\tz='P_length\\t[standardized]',...\\tha='center',\\tva='center',...\\tf_size=13,\\trotation=90)>>>\\tplt.show()\\tInterestingly,\\tbut\\talso\\tas\\texpected,\\tthe\\tdecision\\tregions\\tof\\tthe\\tensemble\\tclassifierseem\\tto\\tbe\\ta\\thybrid\\tof\\tthe\\tdecision\\tregions\\tfrom\\tthe\\tindividual\\tclassifiers.\\tAtfirst\\tglance,\\tthe\\tmajority\\tvote\\tdecision\\tboundary\\tlooks\\ta\\tlot\\tlike\\tthe\\tdecisionboundary\\tof\\tthe\\tk-nearest\\tneighbor\\tclassifier.\\tHowever,\\twe\\tcan\\tsee\\tthat\\tit\\tisorthogonal\\tto\\tthe\\ty\\taxis\\tfor\\tsepal\\twidth\\t≥1,\\tjust\\tlike\\tthe\\tdecision\\ttree\\tstump:\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 97}, page_content=\"Before\\tyou\\tlearn\\thow\\tto\\ttune\\tthe\\tindividual\\tclassifer\\tparameters\\tfor\\tensembleclassification,\\tlet's\\tcall\\tthe\\tget_ps\\tmethod\\tto\\tfind\\tan\\tessential\\tidea\\tof\\thow\\twe\\tcanaccess\\tthe\\tindividual\\tparameters\\tinside\\ta\\tGridSearch\\tobject:>>>\\tmv_clf.get_params(){'decisiontreeclassifier':\\tDecisionTreeClassifier(class_weight=None,criterion='entropy',\\tmax_depth=1,max_features=None,\\tmax_leaf_nodes=None,\\tmin_samples_leaf=1,min_samples_split=2,\\tmin_weight_fraction_leaf=0.0,random_state=0,\\tsplitter='best'),'decisiontreeclassifier__class_weight':\\tNone,'decisiontreeclassifier__criterion':\\t'entropy',\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 98}, page_content=\"[...]'decisiontreeclassifier__random_state':\\t0,'decisiontreeclassifier__splitter':\\t'best','pipeline-1':\\tPipeline(steps=[('sc',\\tStandardScaler(copy=True,\\twith_mean=True,\\twith_std=True)),\\t('clf',\\tLogisticRegression(C=0.001,\\tclass_weight=None,\\tdual=False,\\tfit_intercept=True,intercept_scaling=1,\\tmax_iter=100,\\tmulti_class='ovr',penalty='l2',\\trandom_state=0,\\tsolver='liblinear',tol=0.0001,verbose=0))]),'pipeline-1__clf':\\tLogisticRegression(C=0.001,\\tclass_weight=None,dual=False,\\tfit_intercept=True,intercept_scaling=1,\\tmax_iter=100,\\tmulti_class='ovr',penalty='l2',\\trandom_state=0,\\tsolver='liblinear',tol=0.0001,verbose=0),'pipeline-1__clf__C':\\t0.001,'pipeline-1__clf__class_weight':\\tNone,'pipeline-1__clf__dual':\\tFalse,[...]'pipeline-1__sc__with_std':\\tTrue,'pipeline-2':\\tPipeline(steps=[('sc',\\tStandardScaler(copy=True,\\twith_\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 99}, page_content=\"mean=True,\\twith_std=True)),\\t('clf',\\tKNeighborsClassifier(algorithm='auto',\\tleaf_size=30,\\tmetric='minkowski',metric_params=None,\\tn_neighbors=1,\\tp=2,w='uniform'))]),'p-2__cl”:\\tKNC(algorithm='auto',\\tleaf_size=30,\\tmet='miski',met_ps=None,\\tn_neighbors=1,\\tp=2,w='uniform'),'p-2__cl__algorithm':\\t'auto',[...]'p-2__sc__with_std':\\tT}Depending\\ton\\tthe\\tvalues\\treturned\\tby\\tthe\\tget_ps\\tmethod,\\tyou\\tnow\\tknow\\thow\\ttoaccess\\tthe\\tindividual\\tclassifier's\\tattributes.\\tLet’s\\twork\\twith\\tthe\\tinverseregularization\\tparameter\\tC\\tof\\tthe\\tlogistic\\tregression\\tclassifier\\tand\\tthe\\tdecisiontree\\tdepth\\tvia\\ta\\tgrid\\tsearch\\tfor\\tdemonstration\\tpurposes.\\tLet’s\\ttake\\ta\\tlook\\tat:>>>\\tfrom\\tsklearn.grid_search\\timport\\tGdSearchCV>>>\\tparams\\t=\\t{'dtreecl__max_depth':\\t[0.1,\\t.02],...\\t'p-1__clf__C':\\t[0.001,\\t0.1,\\t100.0]}>>>\\tgd\\t=\\tGdSearchCV(estimator=mv_cl,...\\tparam_grid=params,...\\tcv=10,...\\tscoring='roc_auc')>>>\\tgd.fit(X_tra,\\ty_tra)\"),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 100}, page_content='After\\tthe\\tgrid\\tsearch\\thas\\tcompleted,\\twe\\tcan\\tprint\\tthe\\tdifferent\\thyper\\tparametervalue\\tcombinations\\tand\\tthe\\taverage\\tR_C\\tAC\\tscores\\tcomputed\\tthrough\\t10-foldcross-validation.\\tThe\\tcode\\tis\\tas\\tfollows:>>>\\tfor\\tparams,\\tmean_sc,\\tscores\\tin\\tgrid.grid_sc_:...\\tprint(\"%0.3f+/-%0.2f\\t%r\"...\\t%\\t(mean_sc,\\tsc.std()\\t/\\t2,\\tparams))0.967+/-0.05\\t{\\'p-1__cl__C\\':\\t0.001,\\t\\'dtreeclassifier__ma_depth\\':\\t1}0.967+/-0.05\\t{\\'p-1__cl__C\\':\\t0.1,\\t\\'dtreeclassifier__ma_depth\\':\\t1}1.000+/-0.00\\t{\\'p-1__cl__C\\':\\t100.0,\\t\\'dtreeclassifier__ma_depth\\':\\t1}0.967+/-0.05\\t{\\'p-1__cl__C\\':\\t0.001,\\t\\'dtreeclassifier__ma_depth\\':\\t2}0.967+/-0.05\\t{\\'p-1__cl__C\\':\\t0.1,\\t\\'dtreeclassifier__ma_depth\\':\\t2}1.000+/-0.00\\t{\\'p-1__cl__C\\':\\t100.0,\\t\\'dtreeclassifier__ma_depth\\':\\t2}>>>\\tprint(\\'Best\\tparameters:\\t%s\\'\\t%\\tgd.best_ps_)Best\\tparameters:\\t{\\'p1__cl__C\\':\\t100.0,\\'dtreeclassifier__ma_depth\\':\\t1}>>>\\tprint(\\'Accuracy:\\t%.2f\\'\\t%\\tgd.best_sc_)Accuracy:\\t1.00'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 101}, page_content='\\t\\t\\t\\t\\t\\t\\t'),\n",
       " Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 102}, page_content='Questions\\t1.\\tExplain\\thow\\tto\\tcombine\\tdifferent\\tmodels\\tin\\tdetail.\\t\\t2.\\tWhat\\tare\\tthe\\tgoals\\tand\\tbenefits\\tof\\tcombining\\tmodels?')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PDFDocs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursively Text Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Splitted_PDFDocs = text_splitter.split_documents(PDFDocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 1}, page_content='Machine\\tLearning\\tStep-by-Step\\tGuide\\tTo\\tImplementMachine\\tLearning\\tAlgorithms\\twith\\tPython\\t\\t\\t\\t\\t\\t\\t\\tAuthorRudolph\\tRussell')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Splitted_PDFDocs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '2. DataIngestion/Machine LEarning.pdf', 'page': 2}, page_content='©Copyright\\t2018\\t-\\tAll\\trights\\treserved.\\tIf\\tyou\\twould\\tlike\\tto\\tshare\\tthis\\tbook\\twith\\tanother\\tperson,\\tplease\\tpurchase\\tanadditional\\tcopy\\tfor\\teach\\trecipient.\\tThank\\tyou\\tfor\\trespecting\\tthe\\thard\\twork\\tofthis\\tauthor.\\tOtherwise,\\tthe\\ttransmission,\\tduplication\\tor\\treproduction\\tof\\tany\\tofthe\\tfollowing\\twork\\tincluding\\tspecific\\tinformation\\twill\\tbe\\tconsidered\\tan\\tillegalact\\tirrespective\\tof\\tif\\tit\\tis\\tdone\\telectronically\\tor\\tin\\tprint.\\tThis\\textends\\tto\\tcreatinga\\tsecondary\\tor\\ttertiary\\tcopy\\tof\\tthe\\twork\\tor\\ta\\trecorded\\tcopy\\tand\\tis\\tonly\\tallowedwith\\tan\\texpress\\twritten\\tconsent\\tfrom\\tthe\\tPublisher.\\tAll\\tadditional\\tright\\treserved.')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Splitted_PDFDocs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader('2. DataIngestion/super_DS.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '2. DataIngestion/super_DS.txt'}, page_content='Show Notes: http://www.superdatascience.com/802 1\\nSDS PODCAST\\nEPISODE 802:\\nIN CASE YOU MISSED\\nIT IN JUNE 2024\\n    Show Notes: http://www.superdatascience.com/802 2\\nJon: 00:02 This is episode number 802, our In Case You Missed it in\\nJune episode.\\n    00:19 Welcome back to the Super Data Science Podcast. I\\'m\\nyour host, Jon Krohn. This is an In Case You Missed It\\nepisode that highlights the best parts of conversations we\\nhad on the show in the last month. This first clip you\\'ll\\nhear is from my interview with Dr. Jason Yosinski, one of\\nmy all-time favorite AI researchers. We had a great\\nconversation about making your AI and ML models\\nattractive to customers.\\n    00:40 In this clip, I got him to speak from his experience as\\nCEO of the climate technology startup he founded,\\nWindscape AI. This is a great case study if you\\'re\\nplanning to launch your own AI models commercially.\\n00:51 I\\'m sure that kind of engineering mindset is applicable to\\na lot of our listeners, and it seems like your approach is\\nworking. So EDP, a large Portuguese utility company,\\nrecently selected Windscape as one of nine startups for its\\nrenewable innovation program in Singapore to accelerate\\nthe global energy transition. What opportunities do you\\nsee emerging from Windscape AI\\'s participation in this\\nprogram?\\n    Jason: 01:16 Yeah. Well, thanks for mentioning that. We did apply for\\nthis program. We were selected. EDP is a huge utility. I\\nbelieve they\\'re the fourth-largest wind owner in the world.\\nSo they own tons and tons of turbines. They generate a\\nlot of wind energy. When I met with folks from EDP, I\\nfound them to be a very forward-looking organization.\\nSometimes you get a big company and they\\'re impossibly\\nslow or something, but these folks are really pushing the\\nboundaries, all the boundaries they can, which I thought\\nwas super cool.\\n    Show Notes: http://www.superdatascience.com/802 3\\n01:50 What we hope to get out of it and where that collaboration\\nmight go is to pilot our technology, start working with\\nthem, see how it works on their wind farms around the\\nworld. And then if it does work really well, hopefully we\\nroll out more broadly and we can also maybe use that as\\na demo for new potential customers.\\n    Jon: 02:08 Very cool. So it sounds like EDP is forward-looking. But\\nin general, do you counter resistance or hurdles as you\\ntry to come to energy utilities and say, \"Hey, you could be\\nusing AI like Windscape\\'s to be improving the efficiency of\\nyour systems.\" Do you encounter resistance or hurdles,\\nor is it relatively straightforward to convince people that\\nyou\\'re doing something valuable?\\n    Jason: 02:31 I wouldn\\'t say it\\'s straightforward. No. Convincing people\\nthat what you\\'re doing is valuable is maybe always hard. I\\nwould say saying the words AI or machine learning\\ndoesn\\'t immediately open all the doors. It can open some\\ndoors. Some of these companies realize that AI might be\\nrevolutionizing things that happen internally, and they\\'re\\nnot quite sure how yet, but maybe we should talk to these\\nrandos from Windscape and see what they think.\\n02:59 It does open some doors, but not all. Just as probably\\nwithin any industry, there are some organizations that\\nare very forward-looking and others early adopters of any\\ntechnology and others that are slower, that are later\\nadopters. They literally, some have told us, \"We don\\'t care\\nwhat you\\'re [inaudible 00:03:17], just show us when four\\nother companies are using it and then we\\'ll consider\\nusing it because how we work,\" which is potentially an\\nefficient choice from their perspective.\\n    03:27 There\\'s also small energy companies and large energy\\ncompanies, and there\\'s a spectrum there of how you sell\\nto these companies and how you get adoption and so on.\\nSo yeah, and convincing everyone, it can be hard. You\\nShow Notes: http://www.superdatascience.com/802 4\\nhave to convince people that your technology will work,\\nthat it won\\'t be a huge headache to adopt. The people in\\nthe field need to buy into it. It can\\'t ruin their workflow or\\nsomething. It has to be possible to actually integrate. So\\nsome of these systems run software that\\'s hard to work\\nwith and simply integrating can be difficult at times. So I\\ndon\\'t know, there\\'s a lot of factors probably as in any\\nindustry.\\n    Jon: 04:10 Yeah, it makes so much sense. And hopefully I\\'m not\\ngoing too deep here, and if I am asking a question that\\nwould give away some kind of IP, just feel free to not\\nanswer this. But it seems to me like in a situation like\\nyours, where you are providing software to hardware\\ncompanies, say the turbine manufacturers, you are not,\\nat least in the immediate term, planning on building, say\\nyour own turbines, your own wind farms.\\n    04:37 You are a software company. You need to be partnering\\nwith turbine manufacturers, with wind farm operators.\\nHow does that work? Are people... I guess maybe your\\nresponse is going to be similar, where there\\'s a range of\\nresponses where some turbine manufacturers are\\nrelatively early adopters. They see the potential. They say,\\n\"Wow, Jason\\'s done a lot of amazing research in the past.\\nHe seems like the kind of person we should be working\\nwith to accelerate our roadmap.\" And then other folks are\\njust like, \"Yeah, we\\'ve got our own team,\" or I don\\'t know.\\nHow does it look for you? Yeah.\\n    Jason: 05:09 What we started this whole endeavor, what we imagined\\nwould happen is we would first build products that we\\nwould sell to people that own the turbines. Why do they\\nwant them? Because our product would help them make\\nmore money starting next month. We help them make\\nmore money. They like our product, we roll out, they tell\\ntheir friends. We deploy to more and more farms, more\\nand more companies. As we start to increase our market\\nShow Notes: http://www.superdatascience.com/802 5\\npenetration in the industry, then much later, turbine\\nmanufacturers would notice and they would say, \"Hey,\\neveryone\\'s using these Windscape people. Maybe we\\nshould talk to them and consider integrating their thing\\noff the factory floor rather than an as aftermarket add-on\\non.\"\\n    05:48 That\\'s still the process we\\'re following, although we\\'ve\\nbeen surprised that some OEMs are interested in chatting\\nearly. I think they just want to have on their radar what\\'s\\ngoing on in the world. And if there\\'s any promising\\ntechnology, they want to be there first. So I guess we\\'re\\nalready having some of those conversations too.\\nJon: 06:05 And now, we move from offers that tech companies can\\nrefuse to regulations that startups have a duty to follow.\\nIn this clip with the systems engineering and AI\\nregulation guru, Dr. Gina Guillaume-Joseph, she lays out\\nthe evolving regulatory field for AI, which can be difficult\\nto navigate even if you\\'ve got the best of intentions.\\nSpecifically, Gina and I talk about the AI Bill of Rights,\\nthe NIST AI regulatory framework, and her work on the\\nMITRE ATLAS.\\n    06:32 Explain for us... You mentioned there, so there\\'s the NIST\\nAI risk management framework. So NIST is the National\\nInstitutes of Science and Technology, that may be familiar\\nas an acronym. The NIST thing is something for those of\\nus who have done any deep learning to kind of Hello\\nworld deep learning example involves this handwritten\\ndata set of digits. So it\\'s 60,000 handwritten digits done\\nby, if I remember correctly, US postal workers, as well as\\nelementary school students. And so it\\'s just each image is\\na different digit. So it\\'s some of them are zero, some are\\none, some are two, some are threes, all the way up to\\nnine. And this handwritten dataset was curated initially, I\\nguess in the \\'90s, maybe even in the \\'80s by NIST.\\nShow Notes: http://www.superdatascience.com/802 6\\n    07:24 And then Yann Le Cun, who\\'s one of the most famous AI\\nresearchers of all time, he modified with his research\\nteam at the time, I believe they were AT&T Bell Labs, they\\nmodified that NIST handwritten digit dataset to create the\\nMNIST, modified NIST, handwritten dataset. So I don\\'t\\nknow, it\\'s a bit of an aside, but that MNIST dataset is\\nprobably familiar to anyone who\\'s done any kind of deep\\nlearning at all. And so yeah, so that same organization,\\nNIST, has been around for a long time in the US I don\\'t\\nknow how many decades.\\n    07:58 But has been trying to set up frameworks for all different\\nkinds of industries in science and technology, and has\\nnow created this AI risk management framework, which\\nagain, I\\'ll have a link to that in the show notes alongside\\nthe AI Bill of Rights. A third framework, I guess, you can\\ncorrect me if I\\'m not using the right word there, that you\\nbrought up in your talk that also seems really helpful\\nhere is something called the MITRE ATLAS.\\n    08:26 So I\\'ve been trying to, as you\\'ve been speaking, dig up\\nwhat MITRE stands for, M-I-T-R-E. It doesn\\'t seem like it\\nstands for anything. Can you tell us a bit about MITRE\\nand the MITRE ATLAS and then maybe you can weave\\ntogether these three different things; the AI Bill of Rights,\\nthe NIST AI regulatory framework, as well as MITRE\\nATLAS. And tell us how we can integrate these three\\nframeworks together in order to have a good sense of how\\nto move forward with the AI systems that we built.\\nGina: 08:58 So MITRE is a not-for-profit organization. I worked for\\nthem for 10 years, and they support the federal\\ngovernment across all the federal government agencies to\\nhelp them solve some of the most pressing challenges. So\\nMITRE operates federally funded research and\\ndevelopment centers in support of the federal government\\nto solve problems for a safer world, essentially is what\\nMITRE does. And while at MITRE, I supported multiple\\nShow Notes: http://www.superdatascience.com/802 7\\nagencies; Department of Homeland Security, Social\\nSecurity Administration, Veterans Affairs, Department of\\nDefense, in some of the challenges that they were facing\\nat the time.\\n    09:45 Societal challenges to include when the economy was\\ndoing some downward slides and banks were failing, part\\nof some of the work that I did was at the FDIC, that was\\nwith Booz Allen. But MITRE was involved in other aspects\\nof that as well, to really understand the failures and to\\nfigure out the mitigation strategies to ensure that society\\ndidn\\'t feel those impacts as broadly and as strongly.\\n10:24 And MITRE created the ATLAS threat model introduction,\\nthreat model. It\\'s this comprehensive coverage of AIspecific adversary tactics techniques that includes realworld observation and reporting. It talks about\\naccessibility and usability of AI alignment with existing\\ncybersecurity frameworks in terms of from an AI\\nperspective. And that community engagement\\ncontribution and the educational resources and training.\\n10:58 So they\\'re developing a detailed taxonomy of tactics, of\\ntechniques, of procedures specific to AI systems that\\ncover the entire lifecycle from data collection to model\\ndevelopment and deployment and maintenance. Where\\nthey establish those mechanisms for continuously\\ngathering and updating threat intelligence based on realworld cybersecurity incidents involving AI so that the\\nknowledge base remains current and relevant. So that\\'s\\nwhat MITRE is doing it with their MITRE ATLAS\\nframework. And the framework integrates their existing\\nMITRE attack for enterprise framework that shows that\\nthey bring in that consistency and interoperability across\\ncybersecurity efforts as it pertains to AI systems. And\\nthat\\'s MITRE ATLAS threat model.\\nShow Notes: http://www.superdatascience.com/802 8\\nJon: 12:01 Terrifically useful context there from Gina. In my next\\nclip, Alex Andorra and I discuss Bayesian statistics,\\nnamely why being able to crunch larger and larger data\\nsets has helped us to use a powerful modeling technique\\nthat was originally devised centuries ago.\\n12:15 In addition to the podcast, also, I mentioned this at the\\noutset, I said that you\\'re co-founder and principal data\\nscientist of the popular Bayesian stats modeling platform,\\nPyMC. So like many things in data science, it\\'s uppercase\\nP, lowercase Y, for Python. What\\'s the MC? PyMC, one\\nword, M and the C are capitalized.\\nAlex: 12:38 So it\\'s very confusing because it stands for Python and\\nthen MC is Monte Carlo. So I understand, but why Monte\\nCarlo? It\\'s because it comes from Markov chain Monte\\nCarlo. So actually, it should be PyMCMC or PyMC\\nsquared, which is what I\\'m saying since the beginning.\\nBut anyways, yeah, it\\'s actually PyMC squared. So for\\nMarkov chain Monte Carlo and Markov chain Monte Carlo\\nis one of the main ways... All the algorithms now, new\\nones, but the blockbuster algorithm to run Bayesian\\nmodels is to use MCMC.\\nJon: 13:21 So in the same way that stochastic gradient descent is\\nlike the defacto standard for finding your model weights\\nin machine learning, Markov chain Monte Carlo is the\\nstandard way of doing it with the Bayesian network?\\nAlex: 13:36 Yeah. Yeah, yeah. And so now there are newer versions,\\nmore efficient versions. That\\'s basically the name of the\\ngame, making the algorithm more and more efficient. But\\nthe first algorithm dates back... I think it was actually\\ninvented during the project Manhattan. So during World\\nWar II.\\nJon: 13:57 Theme of the day.\\nShow Notes: http://www.superdatascience.com/802 9\\nAlex: 13:58 Yeah. And lots of physicists actually, statistical physics is\\na field that\\'s contributed a lot to MCMC. And so yeah,\\nphysicists who came to the field of statistics and trying to\\nmake the algorithms more efficient for their models. So\\nthey have contributed a lot. The field of physics has\\ncontributed a lot of big names and people to great leaps\\ninto the realm of more efficient algorithms. And so, I don\\'t\\nknow who your audience is, but that may sound boring.\\n14:37 Yeah, the algorithm, it\\'s like the workhorse, but it\\'s\\nextremely powerful. And that\\'s also one of the main\\nreasons why Bayesian statistics are increasing in\\npopularity lately, because I\\'m going to argue that it\\'s\\nalways been the best framework to do statistics, to do\\nscience. But it was hard to do with pen and paper\\nbecause the problem is that you have a huge, nasty\\nintegral on the numerator, on the denominator, sorry.\\nAnd this integral is not computable by pen and paper. So\\nfor a long, long time, Bayesian statistics combined two\\nfeatures like campaigns, PR campaigns. Bayesian\\nstatistics was relegated to the margins because it was just\\nsuper hard to do.\\n15:31 And so for other problems, other than very trivial ones, it\\nwas not very applicable. But now with the advent of\\npersonal computing, you have these incredible\\nalgorithms. So now most of the time, it\\'s HMC, Hamilton\\nand Monte Carlo. That\\'s what we use under the hood with\\nPyMC. But if you stand, if you use [inaudible 00:15:54] ,\\nit\\'s the same. And thanks to these algorithms, now we\\ncan make extremely powerful models because we can\\napproximate the [inaudible 00:16:03] distributions thanks\\nto, well, computer\\'s computing power. A computer is very\\ngood at computing. I think that\\'s why it\\'s called that.\\nJon: 16:15 Yes. And so that reminds me of deep learning. It\\'s a\\nsimilar kind of thing where the applications we have\\ntoday, like your ChatGPT or whatever your favorite large\\nShow Notes: http://www.superdatascience.com/802 10\\nlanguage model is, these amazing. Video generation like\\nSora, all of this is happening thanks to deep learning,\\nwhich is an approach we\\'ve had since the \\'50s. Certainly\\nnot as old as Bayesian statistics, but similarly, it has\\nbeen able to take off with much larger data sets and\\nmuch more compute.\\nAlex: 16:46 Yeah, yeah. Yeah, yeah, very good point. And I think\\nthat\\'s even more the point in deep learning for sure,\\nbecause Bayesian stats doesn\\'t need the scale, but the\\nway we\\'re doing deep learning for now, definitely need the\\nscale.\\nJon: 16:58 Yeah, yeah. Scale of data.\\nAlex: 17:00 Yeah, yeah, exactly. Yeah, sorry, yeah, the scale, because\\nour two scales, data and computing. Yeah. You\\'re right.\\nJon: 17:05 And for model parameters. So that has actually... I mean,\\ntying back to something you said near the beginning of\\nthis episode, is that actually one of the advantages of\\nBayesian statistics is that you can do it with very few\\ndata. Maybe fewer data than with a frequentist approach\\nor a machine learning approach, because you can bake in\\nyour prior assumptions. And those prior assumptions\\ngive some kind of structure, some kind of framework for\\nyour data to make an impact.\\nAlex: 17:32 Yeah. Yeah, completely.\\nJon: 17:34 And in keeping with the theme of returning to the past to\\nfind golden opportunities, I speak to Dr. Nathan Lambert\\nabout historical influences on contemporary\\nmethodologies. I also managed to sneak in a question\\nabout reinforcement learning from human feedback.\\nNathan is a research scientist for the Allen Institute for\\nAI, and previously built out the RLHF team at Hugging\\nFace. So there was no better person to ask about the lack\\nShow Notes: http://www.superdatascience.com/802 11\\nof robustness in RLHF and how that could impact the\\nfuture development and deployment of AI systems.\\n18:02 Another really cool thing that you\\'ve done related to RLHF\\nis you have traced it back to ancient philosophy and\\nmodern economics. So mentioning Aristotle and von\\nNeumann-Morganstern utility theorem, for example. I\\ndon\\'t really know what the VNM utility theorem is, but\\nhow do these historical foundations influence current\\nmethodologies and what can modern AI research learn\\nfrom these early theories?\\nNathan: 18:30 Yeah. So this is a fun paper with a few colleagues that I\\nstarted working with at Berkeley, and now we\\'re kind of\\nspread out. This is all based on the fact that RL is very\\ndeep field multidisciplinary history, where it goes way\\nback. And then the notion of preference is a very vague\\nthing in economics. And it\\'s like the von NeumannMorganstern theory is a foundational thing that\\nessentially it\\'s like you can express either all behaviors or\\nall goals as probability and expected value distributions,\\nwhich essentially lets you do expected value math over\\npreferences.\\n19:10 And then it led to a bunch of debates on whether or not\\npreferences actually exist and are tractable in any of\\nthese things, or if they\\'re actually measurable or not due\\nto the preference shift over time based on context. So\\nthese are the kinds of things that we take and it\\'s ask a\\nlot of questions on how this impacts the modern RLHF\\nprocess. It\\'s things like is the final model\\'s preferences,\\nwhich is like we\\'re mapping onto very human terms, is\\nthat actually based more on the the base model, which is\\nscraped from the internet than the human preferences\\nthat they get from somewhere like Scale AI.\\n19:46 So it\\'s like if it\\'s based more on the internet crawling than\\nthis million dollar dataset they\\'re getting from Scale AI,\\nShow Notes: http://www.superdatascience.com/802 12\\nit\\'s kind of confusing to the marketing where we\\'re saying\\nwe\\'re learning a preference model, but it might not\\nactually do that much. Is other things like OpenAI now\\nhas a ton of user data and it\\'s like what does the\\neconomics literature say about generating data for\\ntraining that comes from a user context or a professional\\ncontext where someone is paid to do it and they\\'re paid to\\nact in a certain way? And how does all of this mix? So it\\'s\\nreally just a super long list of questions of why we should\\nlook at other social sciences if we\\'re making grand claims\\nabout human preferences and all of these things.\\nJon: 20:26 Nice. Well, fascinating. Tons to dig into there for our\\nlisteners. Final topic that I planned related to RLHF, I\\'m\\nsure it\\'ll come up again organically in the conversation,\\nbut you\\'ve mentioned that RLHF is not even robust to\\nfine-tuning. And so removing the safety layer from models\\nlike GPT-4 and Llama 2 can break down the notion of\\nsafety. Can you elaborate on the implications of this\\nfragility for the future development and deployment of AI\\nsystems?\\nNathan: 20:59 Yeah, so this is a specific line of research. So there\\'s a few\\npapers that showed that if you take a model like Zephyr\\nor Tulu that we were mentioning, if they have safety in\\nthe dataset, if you then go and fine-tune it again on some\\ndifferent tasks, you\\'ll do some of the behaviors that are\\n\"ingrained\" in the model. I honestly think this is a little\\nbit more clickbaity than actually worrisome because it\\'s\\nreally not surprising given that if you just look at the\\namount of compute applied at fine-tuning, we pre-trained\\nthese models for trillions of tokens. And then we apply a\\ncouple billion tokens of compute at fine-tuning.\\n21:36 And it\\'s like we\\'re not changing the weights of the model\\nsubstantially. We\\'re doing a slight nudge, and it makes\\nsense that a slight nudge could be undone at the same\\nway. But if you were to take this to some of the bigger\\nShow Notes: http://www.superdatascience.com/802 13\\nlabs, what you hear is that safety is not just a single\\nartifact thing. Safety is much more about a complete\\nsystem than a model. So open weight models being\\nunsafe or unsafe, I don\\'t consider to be that big of a deal.\\nIt\\'s like if you were to apply them to a free endpoint that\\neveryone on the internet could talk to, then I don\\'t want\\nmy model saying good things about Hitler and all these\\nobvious things.\\n22:09 But if it\\'s a research artifact that you need to spin up\\nGPUs to use yourself, and it\\'s a little bit more... I\\'m more\\nopen to having these diversity of models exist. But if you\\nask [inaudible 00:22:22] or somebody, it\\'s like, \"What\\nhappens... How do you get safety into your model?\" And\\nit\\'s like, it\\'s not just RLHF. You need to have safety at the\\npre-training, any preference model you trained. And then\\nall of these models have a safety filter on the output. So\\nChatGPT, it reads all the text generated from the base\\nmodel, and then there\\'s a go, no go where it will rephrase\\nthe text if it gets a no-go signal, which is like their content\\nmoderation API.\\n22:45 So it\\'s kind of a double. It\\'s the type of thing where\\nresearchers need to market their work, but it\\'s not as big\\nof a detail as I think it is. It\\'s like, okay, I think it has\\ninteresting business downstream things with liability. So\\nit\\'s just like if you want to fine-tune a Llama model, you\\nnormally do that on your own hardware, but OpenAI has\\na fine-tuning API. And if they claim their model is safe,\\nbut any fine-tuning on their API that they then host\\nmakes it unsafe, that seems like more of a business\\nproblem. Which is like, oh, it\\'s a nice way that open\\necosystem might be better off because it breaks the\\nliability chain. But we\\'ll see this research continue to\\nevolve. It\\'s so early in all of these things for a year in.\\nJon: 23:31 All right. That\\'s it for today\\'s In Case You Missed It\\nepisode, to be sure not to miss any of our exciting\\nShow Notes: http://www.superdatascience.com/802 14\\nupcoming episodes. Be sure to subscribe to this podcast\\nif you haven\\'t already. But most importantly, I hope you\\'ll\\njust keep on listening. Until next time, keep on rocking it\\nout there. And I\\'m looking forward to enjoying another\\nround of Super Data Science Podcast with you very soon.')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "superDS = \"\"\n",
    "with open('2. DataIngestion/super_DS.txt') as f:\n",
    "    sd = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Show Notes: http://www.superdatascience.com/802 1\\nSDS PODCAST\\nEPISODE 802:\\nIN CASE YOU MISSED\\nIT IN JUNE 2024\\n    Show Notes: http://www.superdatascience.com/802 2\\nJon: 00:02 This is episode number 802, our In Case You Missed it in\\nJune episode.\\n    00:19 Welcome back to the Super Data Science Podcast. I\\'m\\nyour host, Jon Krohn. This is an In Case You Missed It\\nepisode that highlights the best parts of conversations we\\nhad on the show in the last month. This first clip you\\'ll\\nhear is from my interview with Dr. Jason Yosinski, one of\\nmy all-time favorite AI researchers. We had a great\\nconversation about making your AI and ML models\\nattractive to customers.\\n    00:40 In this clip, I got him to speak from his experience as\\nCEO of the climate technology startup he founded,\\nWindscape AI. This is a great case study if you\\'re\\nplanning to launch your own AI models commercially.\\n00:51 I\\'m sure that kind of engineering mindset is applicable to\\na lot of our listeners, and it seems like your approach is\\nworking. So EDP, a large Portuguese utility company,\\nrecently selected Windscape as one of nine startups for its\\nrenewable innovation program in Singapore to accelerate\\nthe global energy transition. What opportunities do you\\nsee emerging from Windscape AI\\'s participation in this\\nprogram?\\n    Jason: 01:16 Yeah. Well, thanks for mentioning that. We did apply for\\nthis program. We were selected. EDP is a huge utility. I\\nbelieve they\\'re the fourth-largest wind owner in the world.\\nSo they own tons and tons of turbines. They generate a\\nlot of wind energy. When I met with folks from EDP, I\\nfound them to be a very forward-looking organization.\\nSometimes you get a big company and they\\'re impossibly\\nslow or something, but these folks are really pushing the\\nboundaries, all the boundaries they can, which I thought\\nwas super cool.\\n    Show Notes: http://www.superdatascience.com/802 3\\n01:50 What we hope to get out of it and where that collaboration\\nmight go is to pilot our technology, start working with\\nthem, see how it works on their wind farms around the\\nworld. And then if it does work really well, hopefully we\\nroll out more broadly and we can also maybe use that as\\na demo for new potential customers.\\n    Jon: 02:08 Very cool. So it sounds like EDP is forward-looking. But\\nin general, do you counter resistance or hurdles as you\\ntry to come to energy utilities and say, \"Hey, you could be\\nusing AI like Windscape\\'s to be improving the efficiency of\\nyour systems.\" Do you encounter resistance or hurdles,\\nor is it relatively straightforward to convince people that\\nyou\\'re doing something valuable?\\n    Jason: 02:31 I wouldn\\'t say it\\'s straightforward. No. Convincing people\\nthat what you\\'re doing is valuable is maybe always hard. I\\nwould say saying the words AI or machine learning\\ndoesn\\'t immediately open all the doors. It can open some\\ndoors. Some of these companies realize that AI might be\\nrevolutionizing things that happen internally, and they\\'re\\nnot quite sure how yet, but maybe we should talk to these\\nrandos from Windscape and see what they think.\\n02:59 It does open some doors, but not all. Just as probably\\nwithin any industry, there are some organizations that\\nare very forward-looking and others early adopters of any\\ntechnology and others that are slower, that are later\\nadopters. They literally, some have told us, \"We don\\'t care\\nwhat you\\'re [inaudible 00:03:17], just show us when four\\nother companies are using it and then we\\'ll consider\\nusing it because how we work,\" which is potentially an\\nefficient choice from their perspective.\\n    03:27 There\\'s also small energy companies and large energy\\ncompanies, and there\\'s a spectrum there of how you sell\\nto these companies and how you get adoption and so on.\\nSo yeah, and convincing everyone, it can be hard. You\\nShow Notes: http://www.superdatascience.com/802 4\\nhave to convince people that your technology will work,\\nthat it won\\'t be a huge headache to adopt. The people in\\nthe field need to buy into it. It can\\'t ruin their workflow or\\nsomething. It has to be possible to actually integrate. So\\nsome of these systems run software that\\'s hard to work\\nwith and simply integrating can be difficult at times. So I\\ndon\\'t know, there\\'s a lot of factors probably as in any\\nindustry.\\n    Jon: 04:10 Yeah, it makes so much sense. And hopefully I\\'m not\\ngoing too deep here, and if I am asking a question that\\nwould give away some kind of IP, just feel free to not\\nanswer this. But it seems to me like in a situation like\\nyours, where you are providing software to hardware\\ncompanies, say the turbine manufacturers, you are not,\\nat least in the immediate term, planning on building, say\\nyour own turbines, your own wind farms.\\n    04:37 You are a software company. You need to be partnering\\nwith turbine manufacturers, with wind farm operators.\\nHow does that work? Are people... I guess maybe your\\nresponse is going to be similar, where there\\'s a range of\\nresponses where some turbine manufacturers are\\nrelatively early adopters. They see the potential. They say,\\n\"Wow, Jason\\'s done a lot of amazing research in the past.\\nHe seems like the kind of person we should be working\\nwith to accelerate our roadmap.\" And then other folks are\\njust like, \"Yeah, we\\'ve got our own team,\" or I don\\'t know.\\nHow does it look for you? Yeah.\\n    Jason: 05:09 What we started this whole endeavor, what we imagined\\nwould happen is we would first build products that we\\nwould sell to people that own the turbines. Why do they\\nwant them? Because our product would help them make\\nmore money starting next month. We help them make\\nmore money. They like our product, we roll out, they tell\\ntheir friends. We deploy to more and more farms, more\\nand more companies. As we start to increase our market\\nShow Notes: http://www.superdatascience.com/802 5\\npenetration in the industry, then much later, turbine\\nmanufacturers would notice and they would say, \"Hey,\\neveryone\\'s using these Windscape people. Maybe we\\nshould talk to them and consider integrating their thing\\noff the factory floor rather than an as aftermarket add-on\\non.\"\\n    05:48 That\\'s still the process we\\'re following, although we\\'ve\\nbeen surprised that some OEMs are interested in chatting\\nearly. I think they just want to have on their radar what\\'s\\ngoing on in the world. And if there\\'s any promising\\ntechnology, they want to be there first. So I guess we\\'re\\nalready having some of those conversations too.\\nJon: 06:05 And now, we move from offers that tech companies can\\nrefuse to regulations that startups have a duty to follow.\\nIn this clip with the systems engineering and AI\\nregulation guru, Dr. Gina Guillaume-Joseph, she lays out\\nthe evolving regulatory field for AI, which can be difficult\\nto navigate even if you\\'ve got the best of intentions.\\nSpecifically, Gina and I talk about the AI Bill of Rights,\\nthe NIST AI regulatory framework, and her work on the\\nMITRE ATLAS.\\n    06:32 Explain for us... You mentioned there, so there\\'s the NIST\\nAI risk management framework. So NIST is the National\\nInstitutes of Science and Technology, that may be familiar\\nas an acronym. The NIST thing is something for those of\\nus who have done any deep learning to kind of Hello\\nworld deep learning example involves this handwritten\\ndata set of digits. So it\\'s 60,000 handwritten digits done\\nby, if I remember correctly, US postal workers, as well as\\nelementary school students. And so it\\'s just each image is\\na different digit. So it\\'s some of them are zero, some are\\none, some are two, some are threes, all the way up to\\nnine. And this handwritten dataset was curated initially, I\\nguess in the \\'90s, maybe even in the \\'80s by NIST.\\nShow Notes: http://www.superdatascience.com/802 6\\n    07:24 And then Yann Le Cun, who\\'s one of the most famous AI\\nresearchers of all time, he modified with his research\\nteam at the time, I believe they were AT&T Bell Labs, they\\nmodified that NIST handwritten digit dataset to create the\\nMNIST, modified NIST, handwritten dataset. So I don\\'t\\nknow, it\\'s a bit of an aside, but that MNIST dataset is\\nprobably familiar to anyone who\\'s done any kind of deep\\nlearning at all. And so yeah, so that same organization,\\nNIST, has been around for a long time in the US I don\\'t\\nknow how many decades.\\n    07:58 But has been trying to set up frameworks for all different\\nkinds of industries in science and technology, and has\\nnow created this AI risk management framework, which\\nagain, I\\'ll have a link to that in the show notes alongside\\nthe AI Bill of Rights. A third framework, I guess, you can\\ncorrect me if I\\'m not using the right word there, that you\\nbrought up in your talk that also seems really helpful\\nhere is something called the MITRE ATLAS.\\n    08:26 So I\\'ve been trying to, as you\\'ve been speaking, dig up\\nwhat MITRE stands for, M-I-T-R-E. It doesn\\'t seem like it\\nstands for anything. Can you tell us a bit about MITRE\\nand the MITRE ATLAS and then maybe you can weave\\ntogether these three different things; the AI Bill of Rights,\\nthe NIST AI regulatory framework, as well as MITRE\\nATLAS. And tell us how we can integrate these three\\nframeworks together in order to have a good sense of how\\nto move forward with the AI systems that we built.\\nGina: 08:58 So MITRE is a not-for-profit organization. I worked for\\nthem for 10 years, and they support the federal\\ngovernment across all the federal government agencies to\\nhelp them solve some of the most pressing challenges. So\\nMITRE operates federally funded research and\\ndevelopment centers in support of the federal government\\nto solve problems for a safer world, essentially is what\\nMITRE does. And while at MITRE, I supported multiple\\nShow Notes: http://www.superdatascience.com/802 7\\nagencies; Department of Homeland Security, Social\\nSecurity Administration, Veterans Affairs, Department of\\nDefense, in some of the challenges that they were facing\\nat the time.\\n    09:45 Societal challenges to include when the economy was\\ndoing some downward slides and banks were failing, part\\nof some of the work that I did was at the FDIC, that was\\nwith Booz Allen. But MITRE was involved in other aspects\\nof that as well, to really understand the failures and to\\nfigure out the mitigation strategies to ensure that society\\ndidn\\'t feel those impacts as broadly and as strongly.\\n10:24 And MITRE created the ATLAS threat model introduction,\\nthreat model. It\\'s this comprehensive coverage of AIspecific adversary tactics techniques that includes realworld observation and reporting. It talks about\\naccessibility and usability of AI alignment with existing\\ncybersecurity frameworks in terms of from an AI\\nperspective. And that community engagement\\ncontribution and the educational resources and training.\\n10:58 So they\\'re developing a detailed taxonomy of tactics, of\\ntechniques, of procedures specific to AI systems that\\ncover the entire lifecycle from data collection to model\\ndevelopment and deployment and maintenance. Where\\nthey establish those mechanisms for continuously\\ngathering and updating threat intelligence based on realworld cybersecurity incidents involving AI so that the\\nknowledge base remains current and relevant. So that\\'s\\nwhat MITRE is doing it with their MITRE ATLAS\\nframework. And the framework integrates their existing\\nMITRE attack for enterprise framework that shows that\\nthey bring in that consistency and interoperability across\\ncybersecurity efforts as it pertains to AI systems. And\\nthat\\'s MITRE ATLAS threat model.\\nShow Notes: http://www.superdatascience.com/802 8\\nJon: 12:01 Terrifically useful context there from Gina. In my next\\nclip, Alex Andorra and I discuss Bayesian statistics,\\nnamely why being able to crunch larger and larger data\\nsets has helped us to use a powerful modeling technique\\nthat was originally devised centuries ago.\\n12:15 In addition to the podcast, also, I mentioned this at the\\noutset, I said that you\\'re co-founder and principal data\\nscientist of the popular Bayesian stats modeling platform,\\nPyMC. So like many things in data science, it\\'s uppercase\\nP, lowercase Y, for Python. What\\'s the MC? PyMC, one\\nword, M and the C are capitalized.\\nAlex: 12:38 So it\\'s very confusing because it stands for Python and\\nthen MC is Monte Carlo. So I understand, but why Monte\\nCarlo? It\\'s because it comes from Markov chain Monte\\nCarlo. So actually, it should be PyMCMC or PyMC\\nsquared, which is what I\\'m saying since the beginning.\\nBut anyways, yeah, it\\'s actually PyMC squared. So for\\nMarkov chain Monte Carlo and Markov chain Monte Carlo\\nis one of the main ways... All the algorithms now, new\\nones, but the blockbuster algorithm to run Bayesian\\nmodels is to use MCMC.\\nJon: 13:21 So in the same way that stochastic gradient descent is\\nlike the defacto standard for finding your model weights\\nin machine learning, Markov chain Monte Carlo is the\\nstandard way of doing it with the Bayesian network?\\nAlex: 13:36 Yeah. Yeah, yeah. And so now there are newer versions,\\nmore efficient versions. That\\'s basically the name of the\\ngame, making the algorithm more and more efficient. But\\nthe first algorithm dates back... I think it was actually\\ninvented during the project Manhattan. So during World\\nWar II.\\nJon: 13:57 Theme of the day.\\nShow Notes: http://www.superdatascience.com/802 9\\nAlex: 13:58 Yeah. And lots of physicists actually, statistical physics is\\na field that\\'s contributed a lot to MCMC. And so yeah,\\nphysicists who came to the field of statistics and trying to\\nmake the algorithms more efficient for their models. So\\nthey have contributed a lot. The field of physics has\\ncontributed a lot of big names and people to great leaps\\ninto the realm of more efficient algorithms. And so, I don\\'t\\nknow who your audience is, but that may sound boring.\\n14:37 Yeah, the algorithm, it\\'s like the workhorse, but it\\'s\\nextremely powerful. And that\\'s also one of the main\\nreasons why Bayesian statistics are increasing in\\npopularity lately, because I\\'m going to argue that it\\'s\\nalways been the best framework to do statistics, to do\\nscience. But it was hard to do with pen and paper\\nbecause the problem is that you have a huge, nasty\\nintegral on the numerator, on the denominator, sorry.\\nAnd this integral is not computable by pen and paper. So\\nfor a long, long time, Bayesian statistics combined two\\nfeatures like campaigns, PR campaigns. Bayesian\\nstatistics was relegated to the margins because it was just\\nsuper hard to do.\\n15:31 And so for other problems, other than very trivial ones, it\\nwas not very applicable. But now with the advent of\\npersonal computing, you have these incredible\\nalgorithms. So now most of the time, it\\'s HMC, Hamilton\\nand Monte Carlo. That\\'s what we use under the hood with\\nPyMC. But if you stand, if you use [inaudible 00:15:54] ,\\nit\\'s the same. And thanks to these algorithms, now we\\ncan make extremely powerful models because we can\\napproximate the [inaudible 00:16:03] distributions thanks\\nto, well, computer\\'s computing power. A computer is very\\ngood at computing. I think that\\'s why it\\'s called that.\\nJon: 16:15 Yes. And so that reminds me of deep learning. It\\'s a\\nsimilar kind of thing where the applications we have\\ntoday, like your ChatGPT or whatever your favorite large\\nShow Notes: http://www.superdatascience.com/802 10\\nlanguage model is, these amazing. Video generation like\\nSora, all of this is happening thanks to deep learning,\\nwhich is an approach we\\'ve had since the \\'50s. Certainly\\nnot as old as Bayesian statistics, but similarly, it has\\nbeen able to take off with much larger data sets and\\nmuch more compute.\\nAlex: 16:46 Yeah, yeah. Yeah, yeah, very good point. And I think\\nthat\\'s even more the point in deep learning for sure,\\nbecause Bayesian stats doesn\\'t need the scale, but the\\nway we\\'re doing deep learning for now, definitely need the\\nscale.\\nJon: 16:58 Yeah, yeah. Scale of data.\\nAlex: 17:00 Yeah, yeah, exactly. Yeah, sorry, yeah, the scale, because\\nour two scales, data and computing. Yeah. You\\'re right.\\nJon: 17:05 And for model parameters. So that has actually... I mean,\\ntying back to something you said near the beginning of\\nthis episode, is that actually one of the advantages of\\nBayesian statistics is that you can do it with very few\\ndata. Maybe fewer data than with a frequentist approach\\nor a machine learning approach, because you can bake in\\nyour prior assumptions. And those prior assumptions\\ngive some kind of structure, some kind of framework for\\nyour data to make an impact.\\nAlex: 17:32 Yeah. Yeah, completely.\\nJon: 17:34 And in keeping with the theme of returning to the past to\\nfind golden opportunities, I speak to Dr. Nathan Lambert\\nabout historical influences on contemporary\\nmethodologies. I also managed to sneak in a question\\nabout reinforcement learning from human feedback.\\nNathan is a research scientist for the Allen Institute for\\nAI, and previously built out the RLHF team at Hugging\\nFace. So there was no better person to ask about the lack\\nShow Notes: http://www.superdatascience.com/802 11\\nof robustness in RLHF and how that could impact the\\nfuture development and deployment of AI systems.\\n18:02 Another really cool thing that you\\'ve done related to RLHF\\nis you have traced it back to ancient philosophy and\\nmodern economics. So mentioning Aristotle and von\\nNeumann-Morganstern utility theorem, for example. I\\ndon\\'t really know what the VNM utility theorem is, but\\nhow do these historical foundations influence current\\nmethodologies and what can modern AI research learn\\nfrom these early theories?\\nNathan: 18:30 Yeah. So this is a fun paper with a few colleagues that I\\nstarted working with at Berkeley, and now we\\'re kind of\\nspread out. This is all based on the fact that RL is very\\ndeep field multidisciplinary history, where it goes way\\nback. And then the notion of preference is a very vague\\nthing in economics. And it\\'s like the von NeumannMorganstern theory is a foundational thing that\\nessentially it\\'s like you can express either all behaviors or\\nall goals as probability and expected value distributions,\\nwhich essentially lets you do expected value math over\\npreferences.\\n19:10 And then it led to a bunch of debates on whether or not\\npreferences actually exist and are tractable in any of\\nthese things, or if they\\'re actually measurable or not due\\nto the preference shift over time based on context. So\\nthese are the kinds of things that we take and it\\'s ask a\\nlot of questions on how this impacts the modern RLHF\\nprocess. It\\'s things like is the final model\\'s preferences,\\nwhich is like we\\'re mapping onto very human terms, is\\nthat actually based more on the the base model, which is\\nscraped from the internet than the human preferences\\nthat they get from somewhere like Scale AI.\\n19:46 So it\\'s like if it\\'s based more on the internet crawling than\\nthis million dollar dataset they\\'re getting from Scale AI,\\nShow Notes: http://www.superdatascience.com/802 12\\nit\\'s kind of confusing to the marketing where we\\'re saying\\nwe\\'re learning a preference model, but it might not\\nactually do that much. Is other things like OpenAI now\\nhas a ton of user data and it\\'s like what does the\\neconomics literature say about generating data for\\ntraining that comes from a user context or a professional\\ncontext where someone is paid to do it and they\\'re paid to\\nact in a certain way? And how does all of this mix? So it\\'s\\nreally just a super long list of questions of why we should\\nlook at other social sciences if we\\'re making grand claims\\nabout human preferences and all of these things.\\nJon: 20:26 Nice. Well, fascinating. Tons to dig into there for our\\nlisteners. Final topic that I planned related to RLHF, I\\'m\\nsure it\\'ll come up again organically in the conversation,\\nbut you\\'ve mentioned that RLHF is not even robust to\\nfine-tuning. And so removing the safety layer from models\\nlike GPT-4 and Llama 2 can break down the notion of\\nsafety. Can you elaborate on the implications of this\\nfragility for the future development and deployment of AI\\nsystems?\\nNathan: 20:59 Yeah, so this is a specific line of research. So there\\'s a few\\npapers that showed that if you take a model like Zephyr\\nor Tulu that we were mentioning, if they have safety in\\nthe dataset, if you then go and fine-tune it again on some\\ndifferent tasks, you\\'ll do some of the behaviors that are\\n\"ingrained\" in the model. I honestly think this is a little\\nbit more clickbaity than actually worrisome because it\\'s\\nreally not surprising given that if you just look at the\\namount of compute applied at fine-tuning, we pre-trained\\nthese models for trillions of tokens. And then we apply a\\ncouple billion tokens of compute at fine-tuning.\\n21:36 And it\\'s like we\\'re not changing the weights of the model\\nsubstantially. We\\'re doing a slight nudge, and it makes\\nsense that a slight nudge could be undone at the same\\nway. But if you were to take this to some of the bigger\\nShow Notes: http://www.superdatascience.com/802 13\\nlabs, what you hear is that safety is not just a single\\nartifact thing. Safety is much more about a complete\\nsystem than a model. So open weight models being\\nunsafe or unsafe, I don\\'t consider to be that big of a deal.\\nIt\\'s like if you were to apply them to a free endpoint that\\neveryone on the internet could talk to, then I don\\'t want\\nmy model saying good things about Hitler and all these\\nobvious things.\\n22:09 But if it\\'s a research artifact that you need to spin up\\nGPUs to use yourself, and it\\'s a little bit more... I\\'m more\\nopen to having these diversity of models exist. But if you\\nask [inaudible 00:22:22] or somebody, it\\'s like, \"What\\nhappens... How do you get safety into your model?\" And\\nit\\'s like, it\\'s not just RLHF. You need to have safety at the\\npre-training, any preference model you trained. And then\\nall of these models have a safety filter on the output. So\\nChatGPT, it reads all the text generated from the base\\nmodel, and then there\\'s a go, no go where it will rephrase\\nthe text if it gets a no-go signal, which is like their content\\nmoderation API.\\n22:45 So it\\'s kind of a double. It\\'s the type of thing where\\nresearchers need to market their work, but it\\'s not as big\\nof a detail as I think it is. It\\'s like, okay, I think it has\\ninteresting business downstream things with liability. So\\nit\\'s just like if you want to fine-tune a Llama model, you\\nnormally do that on your own hardware, but OpenAI has\\na fine-tuning API. And if they claim their model is safe,\\nbut any fine-tuning on their API that they then host\\nmakes it unsafe, that seems like more of a business\\nproblem. Which is like, oh, it\\'s a nice way that open\\necosystem might be better off because it breaks the\\nliability chain. But we\\'ll see this research continue to\\nevolve. It\\'s so early in all of these things for a year in.\\nJon: 23:31 All right. That\\'s it for today\\'s In Case You Missed It\\nepisode, to be sure not to miss any of our exciting\\nShow Notes: http://www.superdatascience.com/802 14\\nupcoming episodes. Be sure to subscribe to this podcast\\nif you haven\\'t already. But most importantly, I hope you\\'ll\\njust keep on listening. Until next time, keep on rocking it\\nout there. And I\\'m looking forward to enjoying another\\nround of Super Data Science Podcast with you very soon.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_spitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text_splitter.create_documents([sd])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Show Notes: http://www.superdatascience.com/802 1\n",
      "SDS PODCAST\n",
      "EPISODE 802:\n",
      "IN CASE YOU MISSED\n",
      "IT IN JUNE 2024\n",
      "    Show Notes: http://www.superdatascience.com/802 2\n",
      "Jon: 00:02 This is episode number 802, our In Case You Missed it in\n",
      "June episode.\n",
      "    00:19 Welcome back to the Super Data Science Podcast. I'm\n",
      "your host, Jon Krohn. This is an In Case You Missed It\n",
      "episode that highlights the best parts of conversations we\n",
      "had on the show in the last month. This first clip you'll\n",
      "hear is from my interview with Dr. Jason Yosinski, one of\n",
      "my all-time favorite AI researchers. We had a great\n",
      "conversation about making your AI and ML models\n",
      "attractive to customers.\n",
      "    00:40 In this clip, I got him to speak from his experience as\n",
      "CEO of the climate technology startup he founded,\n",
      "Windscape AI. This is a great case study if you're\n",
      "planning to launch your own AI models commercially.\n",
      "00:51 I'm sure that kind of engineering mindset is applicable to'\n"
     ]
    }
   ],
   "source": [
    "print(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Windscape AI. This is a great case study if you're\n",
      "planning to launch your own AI models commercially.\n",
      "00:51 I'm sure that kind of engineering mindset is applicable to\n",
      "a lot of our listeners, and it seems like your approach is\n",
      "working. So EDP, a large Portuguese utility company,\n",
      "recently selected Windscape as one of nine startups for its\n",
      "renewable innovation program in Singapore to accelerate\n",
      "the global energy transition. What opportunities do you\n",
      "see emerging from Windscape AI's participation in this\n",
      "program?\n",
      "    Jason: 01:16 Yeah. Well, thanks for mentioning that. We did apply for\n",
      "this program. We were selected. EDP is a huge utility. I\n",
      "believe they're the fourth-largest wind owner in the world.\n",
      "So they own tons and tons of turbines. They generate a\n",
      "lot of wind energy. When I met with folks from EDP, I\n",
      "found them to be a very forward-looking organization.\n",
      "Sometimes you get a big company and they're impossibly\n",
      "slow or something, but these folks are really pushing the'\n"
     ]
    }
   ],
   "source": [
    "print(text[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_spitter = CharacterTextSplitter(separator=\"\\n\\n\", chunk_size=100, chunk_overlap=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text_spitter.split_documents(text_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '2. DataIngestion/super_DS.txt'}, page_content='Show Notes: http://www.superdatascience.com/802 1\\nSDS PODCAST\\nEPISODE 802:\\nIN CASE YOU MISSED\\nIT IN JUNE 2024\\n    Show Notes: http://www.superdatascience.com/802 2\\nJon: 00:02 This is episode number 802, our In Case You Missed it in\\nJune episode.\\n    00:19 Welcome back to the Super Data Science Podcast. I\\'m\\nyour host, Jon Krohn. This is an In Case You Missed It\\nepisode that highlights the best parts of conversations we\\nhad on the show in the last month. This first clip you\\'ll\\nhear is from my interview with Dr. Jason Yosinski, one of\\nmy all-time favorite AI researchers. We had a great\\nconversation about making your AI and ML models\\nattractive to customers.\\n    00:40 In this clip, I got him to speak from his experience as\\nCEO of the climate technology startup he founded,\\nWindscape AI. This is a great case study if you\\'re\\nplanning to launch your own AI models commercially.\\n00:51 I\\'m sure that kind of engineering mindset is applicable to\\na lot of our listeners, and it seems like your approach is\\nworking. So EDP, a large Portuguese utility company,\\nrecently selected Windscape as one of nine startups for its\\nrenewable innovation program in Singapore to accelerate\\nthe global energy transition. What opportunities do you\\nsee emerging from Windscape AI\\'s participation in this\\nprogram?\\n    Jason: 01:16 Yeah. Well, thanks for mentioning that. We did apply for\\nthis program. We were selected. EDP is a huge utility. I\\nbelieve they\\'re the fourth-largest wind owner in the world.\\nSo they own tons and tons of turbines. They generate a\\nlot of wind energy. When I met with folks from EDP, I\\nfound them to be a very forward-looking organization.\\nSometimes you get a big company and they\\'re impossibly\\nslow or something, but these folks are really pushing the\\nboundaries, all the boundaries they can, which I thought\\nwas super cool.\\n    Show Notes: http://www.superdatascience.com/802 3\\n01:50 What we hope to get out of it and where that collaboration\\nmight go is to pilot our technology, start working with\\nthem, see how it works on their wind farms around the\\nworld. And then if it does work really well, hopefully we\\nroll out more broadly and we can also maybe use that as\\na demo for new potential customers.\\n    Jon: 02:08 Very cool. So it sounds like EDP is forward-looking. But\\nin general, do you counter resistance or hurdles as you\\ntry to come to energy utilities and say, \"Hey, you could be\\nusing AI like Windscape\\'s to be improving the efficiency of\\nyour systems.\" Do you encounter resistance or hurdles,\\nor is it relatively straightforward to convince people that\\nyou\\'re doing something valuable?\\n    Jason: 02:31 I wouldn\\'t say it\\'s straightforward. No. Convincing people\\nthat what you\\'re doing is valuable is maybe always hard. I\\nwould say saying the words AI or machine learning\\ndoesn\\'t immediately open all the doors. It can open some\\ndoors. Some of these companies realize that AI might be\\nrevolutionizing things that happen internally, and they\\'re\\nnot quite sure how yet, but maybe we should talk to these\\nrandos from Windscape and see what they think.\\n02:59 It does open some doors, but not all. Just as probably\\nwithin any industry, there are some organizations that\\nare very forward-looking and others early adopters of any\\ntechnology and others that are slower, that are later\\nadopters. They literally, some have told us, \"We don\\'t care\\nwhat you\\'re [inaudible 00:03:17], just show us when four\\nother companies are using it and then we\\'ll consider\\nusing it because how we work,\" which is potentially an\\nefficient choice from their perspective.\\n    03:27 There\\'s also small energy companies and large energy\\ncompanies, and there\\'s a spectrum there of how you sell\\nto these companies and how you get adoption and so on.\\nSo yeah, and convincing everyone, it can be hard. You\\nShow Notes: http://www.superdatascience.com/802 4\\nhave to convince people that your technology will work,\\nthat it won\\'t be a huge headache to adopt. The people in\\nthe field need to buy into it. It can\\'t ruin their workflow or\\nsomething. It has to be possible to actually integrate. So\\nsome of these systems run software that\\'s hard to work\\nwith and simply integrating can be difficult at times. So I\\ndon\\'t know, there\\'s a lot of factors probably as in any\\nindustry.\\n    Jon: 04:10 Yeah, it makes so much sense. And hopefully I\\'m not\\ngoing too deep here, and if I am asking a question that\\nwould give away some kind of IP, just feel free to not\\nanswer this. But it seems to me like in a situation like\\nyours, where you are providing software to hardware\\ncompanies, say the turbine manufacturers, you are not,\\nat least in the immediate term, planning on building, say\\nyour own turbines, your own wind farms.\\n    04:37 You are a software company. You need to be partnering\\nwith turbine manufacturers, with wind farm operators.\\nHow does that work? Are people... I guess maybe your\\nresponse is going to be similar, where there\\'s a range of\\nresponses where some turbine manufacturers are\\nrelatively early adopters. They see the potential. They say,\\n\"Wow, Jason\\'s done a lot of amazing research in the past.\\nHe seems like the kind of person we should be working\\nwith to accelerate our roadmap.\" And then other folks are\\njust like, \"Yeah, we\\'ve got our own team,\" or I don\\'t know.\\nHow does it look for you? Yeah.\\n    Jason: 05:09 What we started this whole endeavor, what we imagined\\nwould happen is we would first build products that we\\nwould sell to people that own the turbines. Why do they\\nwant them? Because our product would help them make\\nmore money starting next month. We help them make\\nmore money. They like our product, we roll out, they tell\\ntheir friends. We deploy to more and more farms, more\\nand more companies. As we start to increase our market\\nShow Notes: http://www.superdatascience.com/802 5\\npenetration in the industry, then much later, turbine\\nmanufacturers would notice and they would say, \"Hey,\\neveryone\\'s using these Windscape people. Maybe we\\nshould talk to them and consider integrating their thing\\noff the factory floor rather than an as aftermarket add-on\\non.\"\\n    05:48 That\\'s still the process we\\'re following, although we\\'ve\\nbeen surprised that some OEMs are interested in chatting\\nearly. I think they just want to have on their radar what\\'s\\ngoing on in the world. And if there\\'s any promising\\ntechnology, they want to be there first. So I guess we\\'re\\nalready having some of those conversations too.\\nJon: 06:05 And now, we move from offers that tech companies can\\nrefuse to regulations that startups have a duty to follow.\\nIn this clip with the systems engineering and AI\\nregulation guru, Dr. Gina Guillaume-Joseph, she lays out\\nthe evolving regulatory field for AI, which can be difficult\\nto navigate even if you\\'ve got the best of intentions.\\nSpecifically, Gina and I talk about the AI Bill of Rights,\\nthe NIST AI regulatory framework, and her work on the\\nMITRE ATLAS.\\n    06:32 Explain for us... You mentioned there, so there\\'s the NIST\\nAI risk management framework. So NIST is the National\\nInstitutes of Science and Technology, that may be familiar\\nas an acronym. The NIST thing is something for those of\\nus who have done any deep learning to kind of Hello\\nworld deep learning example involves this handwritten\\ndata set of digits. So it\\'s 60,000 handwritten digits done\\nby, if I remember correctly, US postal workers, as well as\\nelementary school students. And so it\\'s just each image is\\na different digit. So it\\'s some of them are zero, some are\\none, some are two, some are threes, all the way up to\\nnine. And this handwritten dataset was curated initially, I\\nguess in the \\'90s, maybe even in the \\'80s by NIST.\\nShow Notes: http://www.superdatascience.com/802 6\\n    07:24 And then Yann Le Cun, who\\'s one of the most famous AI\\nresearchers of all time, he modified with his research\\nteam at the time, I believe they were AT&T Bell Labs, they\\nmodified that NIST handwritten digit dataset to create the\\nMNIST, modified NIST, handwritten dataset. So I don\\'t\\nknow, it\\'s a bit of an aside, but that MNIST dataset is\\nprobably familiar to anyone who\\'s done any kind of deep\\nlearning at all. And so yeah, so that same organization,\\nNIST, has been around for a long time in the US I don\\'t\\nknow how many decades.\\n    07:58 But has been trying to set up frameworks for all different\\nkinds of industries in science and technology, and has\\nnow created this AI risk management framework, which\\nagain, I\\'ll have a link to that in the show notes alongside\\nthe AI Bill of Rights. A third framework, I guess, you can\\ncorrect me if I\\'m not using the right word there, that you\\nbrought up in your talk that also seems really helpful\\nhere is something called the MITRE ATLAS.\\n    08:26 So I\\'ve been trying to, as you\\'ve been speaking, dig up\\nwhat MITRE stands for, M-I-T-R-E. It doesn\\'t seem like it\\nstands for anything. Can you tell us a bit about MITRE\\nand the MITRE ATLAS and then maybe you can weave\\ntogether these three different things; the AI Bill of Rights,\\nthe NIST AI regulatory framework, as well as MITRE\\nATLAS. And tell us how we can integrate these three\\nframeworks together in order to have a good sense of how\\nto move forward with the AI systems that we built.\\nGina: 08:58 So MITRE is a not-for-profit organization. I worked for\\nthem for 10 years, and they support the federal\\ngovernment across all the federal government agencies to\\nhelp them solve some of the most pressing challenges. So\\nMITRE operates federally funded research and\\ndevelopment centers in support of the federal government\\nto solve problems for a safer world, essentially is what\\nMITRE does. And while at MITRE, I supported multiple\\nShow Notes: http://www.superdatascience.com/802 7\\nagencies; Department of Homeland Security, Social\\nSecurity Administration, Veterans Affairs, Department of\\nDefense, in some of the challenges that they were facing\\nat the time.\\n    09:45 Societal challenges to include when the economy was\\ndoing some downward slides and banks were failing, part\\nof some of the work that I did was at the FDIC, that was\\nwith Booz Allen. But MITRE was involved in other aspects\\nof that as well, to really understand the failures and to\\nfigure out the mitigation strategies to ensure that society\\ndidn\\'t feel those impacts as broadly and as strongly.\\n10:24 And MITRE created the ATLAS threat model introduction,\\nthreat model. It\\'s this comprehensive coverage of AIspecific adversary tactics techniques that includes realworld observation and reporting. It talks about\\naccessibility and usability of AI alignment with existing\\ncybersecurity frameworks in terms of from an AI\\nperspective. And that community engagement\\ncontribution and the educational resources and training.\\n10:58 So they\\'re developing a detailed taxonomy of tactics, of\\ntechniques, of procedures specific to AI systems that\\ncover the entire lifecycle from data collection to model\\ndevelopment and deployment and maintenance. Where\\nthey establish those mechanisms for continuously\\ngathering and updating threat intelligence based on realworld cybersecurity incidents involving AI so that the\\nknowledge base remains current and relevant. So that\\'s\\nwhat MITRE is doing it with their MITRE ATLAS\\nframework. And the framework integrates their existing\\nMITRE attack for enterprise framework that shows that\\nthey bring in that consistency and interoperability across\\ncybersecurity efforts as it pertains to AI systems. And\\nthat\\'s MITRE ATLAS threat model.\\nShow Notes: http://www.superdatascience.com/802 8\\nJon: 12:01 Terrifically useful context there from Gina. In my next\\nclip, Alex Andorra and I discuss Bayesian statistics,\\nnamely why being able to crunch larger and larger data\\nsets has helped us to use a powerful modeling technique\\nthat was originally devised centuries ago.\\n12:15 In addition to the podcast, also, I mentioned this at the\\noutset, I said that you\\'re co-founder and principal data\\nscientist of the popular Bayesian stats modeling platform,\\nPyMC. So like many things in data science, it\\'s uppercase\\nP, lowercase Y, for Python. What\\'s the MC? PyMC, one\\nword, M and the C are capitalized.\\nAlex: 12:38 So it\\'s very confusing because it stands for Python and\\nthen MC is Monte Carlo. So I understand, but why Monte\\nCarlo? It\\'s because it comes from Markov chain Monte\\nCarlo. So actually, it should be PyMCMC or PyMC\\nsquared, which is what I\\'m saying since the beginning.\\nBut anyways, yeah, it\\'s actually PyMC squared. So for\\nMarkov chain Monte Carlo and Markov chain Monte Carlo\\nis one of the main ways... All the algorithms now, new\\nones, but the blockbuster algorithm to run Bayesian\\nmodels is to use MCMC.\\nJon: 13:21 So in the same way that stochastic gradient descent is\\nlike the defacto standard for finding your model weights\\nin machine learning, Markov chain Monte Carlo is the\\nstandard way of doing it with the Bayesian network?\\nAlex: 13:36 Yeah. Yeah, yeah. And so now there are newer versions,\\nmore efficient versions. That\\'s basically the name of the\\ngame, making the algorithm more and more efficient. But\\nthe first algorithm dates back... I think it was actually\\ninvented during the project Manhattan. So during World\\nWar II.\\nJon: 13:57 Theme of the day.\\nShow Notes: http://www.superdatascience.com/802 9\\nAlex: 13:58 Yeah. And lots of physicists actually, statistical physics is\\na field that\\'s contributed a lot to MCMC. And so yeah,\\nphysicists who came to the field of statistics and trying to\\nmake the algorithms more efficient for their models. So\\nthey have contributed a lot. The field of physics has\\ncontributed a lot of big names and people to great leaps\\ninto the realm of more efficient algorithms. And so, I don\\'t\\nknow who your audience is, but that may sound boring.\\n14:37 Yeah, the algorithm, it\\'s like the workhorse, but it\\'s\\nextremely powerful. And that\\'s also one of the main\\nreasons why Bayesian statistics are increasing in\\npopularity lately, because I\\'m going to argue that it\\'s\\nalways been the best framework to do statistics, to do\\nscience. But it was hard to do with pen and paper\\nbecause the problem is that you have a huge, nasty\\nintegral on the numerator, on the denominator, sorry.\\nAnd this integral is not computable by pen and paper. So\\nfor a long, long time, Bayesian statistics combined two\\nfeatures like campaigns, PR campaigns. Bayesian\\nstatistics was relegated to the margins because it was just\\nsuper hard to do.\\n15:31 And so for other problems, other than very trivial ones, it\\nwas not very applicable. But now with the advent of\\npersonal computing, you have these incredible\\nalgorithms. So now most of the time, it\\'s HMC, Hamilton\\nand Monte Carlo. That\\'s what we use under the hood with\\nPyMC. But if you stand, if you use [inaudible 00:15:54] ,\\nit\\'s the same. And thanks to these algorithms, now we\\ncan make extremely powerful models because we can\\napproximate the [inaudible 00:16:03] distributions thanks\\nto, well, computer\\'s computing power. A computer is very\\ngood at computing. I think that\\'s why it\\'s called that.\\nJon: 16:15 Yes. And so that reminds me of deep learning. It\\'s a\\nsimilar kind of thing where the applications we have\\ntoday, like your ChatGPT or whatever your favorite large\\nShow Notes: http://www.superdatascience.com/802 10\\nlanguage model is, these amazing. Video generation like\\nSora, all of this is happening thanks to deep learning,\\nwhich is an approach we\\'ve had since the \\'50s. Certainly\\nnot as old as Bayesian statistics, but similarly, it has\\nbeen able to take off with much larger data sets and\\nmuch more compute.\\nAlex: 16:46 Yeah, yeah. Yeah, yeah, very good point. And I think\\nthat\\'s even more the point in deep learning for sure,\\nbecause Bayesian stats doesn\\'t need the scale, but the\\nway we\\'re doing deep learning for now, definitely need the\\nscale.\\nJon: 16:58 Yeah, yeah. Scale of data.\\nAlex: 17:00 Yeah, yeah, exactly. Yeah, sorry, yeah, the scale, because\\nour two scales, data and computing. Yeah. You\\'re right.\\nJon: 17:05 And for model parameters. So that has actually... I mean,\\ntying back to something you said near the beginning of\\nthis episode, is that actually one of the advantages of\\nBayesian statistics is that you can do it with very few\\ndata. Maybe fewer data than with a frequentist approach\\nor a machine learning approach, because you can bake in\\nyour prior assumptions. And those prior assumptions\\ngive some kind of structure, some kind of framework for\\nyour data to make an impact.\\nAlex: 17:32 Yeah. Yeah, completely.\\nJon: 17:34 And in keeping with the theme of returning to the past to\\nfind golden opportunities, I speak to Dr. Nathan Lambert\\nabout historical influences on contemporary\\nmethodologies. I also managed to sneak in a question\\nabout reinforcement learning from human feedback.\\nNathan is a research scientist for the Allen Institute for\\nAI, and previously built out the RLHF team at Hugging\\nFace. So there was no better person to ask about the lack\\nShow Notes: http://www.superdatascience.com/802 11\\nof robustness in RLHF and how that could impact the\\nfuture development and deployment of AI systems.\\n18:02 Another really cool thing that you\\'ve done related to RLHF\\nis you have traced it back to ancient philosophy and\\nmodern economics. So mentioning Aristotle and von\\nNeumann-Morganstern utility theorem, for example. I\\ndon\\'t really know what the VNM utility theorem is, but\\nhow do these historical foundations influence current\\nmethodologies and what can modern AI research learn\\nfrom these early theories?\\nNathan: 18:30 Yeah. So this is a fun paper with a few colleagues that I\\nstarted working with at Berkeley, and now we\\'re kind of\\nspread out. This is all based on the fact that RL is very\\ndeep field multidisciplinary history, where it goes way\\nback. And then the notion of preference is a very vague\\nthing in economics. And it\\'s like the von NeumannMorganstern theory is a foundational thing that\\nessentially it\\'s like you can express either all behaviors or\\nall goals as probability and expected value distributions,\\nwhich essentially lets you do expected value math over\\npreferences.\\n19:10 And then it led to a bunch of debates on whether or not\\npreferences actually exist and are tractable in any of\\nthese things, or if they\\'re actually measurable or not due\\nto the preference shift over time based on context. So\\nthese are the kinds of things that we take and it\\'s ask a\\nlot of questions on how this impacts the modern RLHF\\nprocess. It\\'s things like is the final model\\'s preferences,\\nwhich is like we\\'re mapping onto very human terms, is\\nthat actually based more on the the base model, which is\\nscraped from the internet than the human preferences\\nthat they get from somewhere like Scale AI.\\n19:46 So it\\'s like if it\\'s based more on the internet crawling than\\nthis million dollar dataset they\\'re getting from Scale AI,\\nShow Notes: http://www.superdatascience.com/802 12\\nit\\'s kind of confusing to the marketing where we\\'re saying\\nwe\\'re learning a preference model, but it might not\\nactually do that much. Is other things like OpenAI now\\nhas a ton of user data and it\\'s like what does the\\neconomics literature say about generating data for\\ntraining that comes from a user context or a professional\\ncontext where someone is paid to do it and they\\'re paid to\\nact in a certain way? And how does all of this mix? So it\\'s\\nreally just a super long list of questions of why we should\\nlook at other social sciences if we\\'re making grand claims\\nabout human preferences and all of these things.\\nJon: 20:26 Nice. Well, fascinating. Tons to dig into there for our\\nlisteners. Final topic that I planned related to RLHF, I\\'m\\nsure it\\'ll come up again organically in the conversation,\\nbut you\\'ve mentioned that RLHF is not even robust to\\nfine-tuning. And so removing the safety layer from models\\nlike GPT-4 and Llama 2 can break down the notion of\\nsafety. Can you elaborate on the implications of this\\nfragility for the future development and deployment of AI\\nsystems?\\nNathan: 20:59 Yeah, so this is a specific line of research. So there\\'s a few\\npapers that showed that if you take a model like Zephyr\\nor Tulu that we were mentioning, if they have safety in\\nthe dataset, if you then go and fine-tune it again on some\\ndifferent tasks, you\\'ll do some of the behaviors that are\\n\"ingrained\" in the model. I honestly think this is a little\\nbit more clickbaity than actually worrisome because it\\'s\\nreally not surprising given that if you just look at the\\namount of compute applied at fine-tuning, we pre-trained\\nthese models for trillions of tokens. And then we apply a\\ncouple billion tokens of compute at fine-tuning.\\n21:36 And it\\'s like we\\'re not changing the weights of the model\\nsubstantially. We\\'re doing a slight nudge, and it makes\\nsense that a slight nudge could be undone at the same\\nway. But if you were to take this to some of the bigger\\nShow Notes: http://www.superdatascience.com/802 13\\nlabs, what you hear is that safety is not just a single\\nartifact thing. Safety is much more about a complete\\nsystem than a model. So open weight models being\\nunsafe or unsafe, I don\\'t consider to be that big of a deal.\\nIt\\'s like if you were to apply them to a free endpoint that\\neveryone on the internet could talk to, then I don\\'t want\\nmy model saying good things about Hitler and all these\\nobvious things.\\n22:09 But if it\\'s a research artifact that you need to spin up\\nGPUs to use yourself, and it\\'s a little bit more... I\\'m more\\nopen to having these diversity of models exist. But if you\\nask [inaudible 00:22:22] or somebody, it\\'s like, \"What\\nhappens... How do you get safety into your model?\" And\\nit\\'s like, it\\'s not just RLHF. You need to have safety at the\\npre-training, any preference model you trained. And then\\nall of these models have a safety filter on the output. So\\nChatGPT, it reads all the text generated from the base\\nmodel, and then there\\'s a go, no go where it will rephrase\\nthe text if it gets a no-go signal, which is like their content\\nmoderation API.\\n22:45 So it\\'s kind of a double. It\\'s the type of thing where\\nresearchers need to market their work, but it\\'s not as big\\nof a detail as I think it is. It\\'s like, okay, I think it has\\ninteresting business downstream things with liability. So\\nit\\'s just like if you want to fine-tune a Llama model, you\\nnormally do that on your own hardware, but OpenAI has\\na fine-tuning API. And if they claim their model is safe,\\nbut any fine-tuning on their API that they then host\\nmakes it unsafe, that seems like more of a business\\nproblem. Which is like, oh, it\\'s a nice way that open\\necosystem might be better off because it breaks the\\nliability chain. But we\\'ll see this research continue to\\nevolve. It\\'s so early in all of these things for a year in.\\nJon: 23:31 All right. That\\'s it for today\\'s In Case You Missed It\\nepisode, to be sure not to miss any of our exciting\\nShow Notes: http://www.superdatascience.com/802 14\\nupcoming episodes. Be sure to subscribe to this podcast\\nif you haven\\'t already. But most importantly, I hope you\\'ll\\njust keep on listening. Until next time, keep on rocking it\\nout there. And I\\'m looking forward to enjoying another\\nround of Super Data Science Podcast with you very soon.')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Show Notes: http://www.superdatascience.com/802 1\n",
      "SDS PODCAST\n",
      "EPISODE 802:\n",
      "IN CASE YOU MISSED\n",
      "IT IN JUNE 2024\n",
      "    Show Notes: http://www.superdatascience.com/802 2\n",
      "Jon: 00:02 This is episode number 802, our In Case You Missed it in\n",
      "June episode.\n",
      "    00:19 Welcome back to the Super Data Science Podcast. I'm\n",
      "your host, Jon Krohn. This is an In Case You Missed It\n",
      "episode that highlights the best parts of conversations we\n",
      "had on the show in the last month. This first clip you'll\n",
      "hear is from my interview with Dr. Jason Yosinski, one of\n",
      "my all-time favorite AI researchers. We had a great\n",
      "conversation about making your AI and ML models\n",
      "attractive to customers.\n",
      "    00:40 In this clip, I got him to speak from his experience as\n",
      "CEO of the climate technology startup he founded,\n",
      "Windscape AI. This is a great case study if you're\n",
      "planning to launch your own AI models commercially.\n",
      "00:51 I'm sure that kind of engineering mindset is applicable to\n",
      "a lot of our listeners, and it seems like your approach is\n",
      "working. So EDP, a large Portuguese utility company,\n",
      "recently selected Windscape as one of nine startups for its\n",
      "renewable innovation program in Singapore to accelerate\n",
      "the global energy transition. What opportunities do you\n",
      "see emerging from Windscape AI's participation in this\n",
      "program?\n",
      "    Jason: 01:16 Yeah. Well, thanks for mentioning that. We did apply for\n",
      "this program. We were selected. EDP is a huge utility. I\n",
      "believe they're the fourth-largest wind owner in the world.\n",
      "So they own tons and tons of turbines. They generate a\n",
      "lot of wind energy. When I met with folks from EDP, I\n",
      "found them to be a very forward-looking organization.\n",
      "Sometimes you get a big company and they're impossibly\n",
      "slow or something, but these folks are really pushing the\n",
      "boundaries, all the boundaries they can, which I thought\n",
      "was super cool.\n",
      "    Show Notes: http://www.superdatascience.com/802 3\n",
      "01:50 What we hope to get out of it and where that collaboration\n",
      "might go is to pilot our technology, start working with\n",
      "them, see how it works on their wind farms around the\n",
      "world. And then if it does work really well, hopefully we\n",
      "roll out more broadly and we can also maybe use that as\n",
      "a demo for new potential customers.\n",
      "    Jon: 02:08 Very cool. So it sounds like EDP is forward-looking. But\n",
      "in general, do you counter resistance or hurdles as you\n",
      "try to come to energy utilities and say, \"Hey, you could be\n",
      "using AI like Windscape's to be improving the efficiency of\n",
      "your systems.\" Do you encounter resistance or hurdles,\n",
      "or is it relatively straightforward to convince people that\n",
      "you're doing something valuable?\n",
      "    Jason: 02:31 I wouldn't say it's straightforward. No. Convincing people\n",
      "that what you're doing is valuable is maybe always hard. I\n",
      "would say saying the words AI or machine learning\n",
      "doesn't immediately open all the doors. It can open some\n",
      "doors. Some of these companies realize that AI might be\n",
      "revolutionizing things that happen internally, and they're\n",
      "not quite sure how yet, but maybe we should talk to these\n",
      "randos from Windscape and see what they think.\n",
      "02:59 It does open some doors, but not all. Just as probably\n",
      "within any industry, there are some organizations that\n",
      "are very forward-looking and others early adopters of any\n",
      "technology and others that are slower, that are later\n",
      "adopters. They literally, some have told us, \"We don't care\n",
      "what you're [inaudible 00:03:17], just show us when four\n",
      "other companies are using it and then we'll consider\n",
      "using it because how we work,\" which is potentially an\n",
      "efficient choice from their perspective.\n",
      "    03:27 There's also small energy companies and large energy\n",
      "companies, and there's a spectrum there of how you sell\n",
      "to these companies and how you get adoption and so on.\n",
      "So yeah, and convincing everyone, it can be hard. You\n",
      "Show Notes: http://www.superdatascience.com/802 4\n",
      "have to convince people that your technology will work,\n",
      "that it won't be a huge headache to adopt. The people in\n",
      "the field need to buy into it. It can't ruin their workflow or\n",
      "something. It has to be possible to actually integrate. So\n",
      "some of these systems run software that's hard to work\n",
      "with and simply integrating can be difficult at times. So I\n",
      "don't know, there's a lot of factors probably as in any\n",
      "industry.\n",
      "    Jon: 04:10 Yeah, it makes so much sense. And hopefully I'm not\n",
      "going too deep here, and if I am asking a question that\n",
      "would give away some kind of IP, just feel free to not\n",
      "answer this. But it seems to me like in a situation like\n",
      "yours, where you are providing software to hardware\n",
      "companies, say the turbine manufacturers, you are not,\n",
      "at least in the immediate term, planning on building, say\n",
      "your own turbines, your own wind farms.\n",
      "    04:37 You are a software company. You need to be partnering\n",
      "with turbine manufacturers, with wind farm operators.\n",
      "How does that work? Are people... I guess maybe your\n",
      "response is going to be similar, where there's a range of\n",
      "responses where some turbine manufacturers are\n",
      "relatively early adopters. They see the potential. They say,\n",
      "\"Wow, Jason's done a lot of amazing research in the past.\n",
      "He seems like the kind of person we should be working\n",
      "with to accelerate our roadmap.\" And then other folks are\n",
      "just like, \"Yeah, we've got our own team,\" or I don't know.\n",
      "How does it look for you? Yeah.\n",
      "    Jason: 05:09 What we started this whole endeavor, what we imagined\n",
      "would happen is we would first build products that we\n",
      "would sell to people that own the turbines. Why do they\n",
      "want them? Because our product would help them make\n",
      "more money starting next month. We help them make\n",
      "more money. They like our product, we roll out, they tell\n",
      "their friends. We deploy to more and more farms, more\n",
      "and more companies. As we start to increase our market\n",
      "Show Notes: http://www.superdatascience.com/802 5\n",
      "penetration in the industry, then much later, turbine\n",
      "manufacturers would notice and they would say, \"Hey,\n",
      "everyone's using these Windscape people. Maybe we\n",
      "should talk to them and consider integrating their thing\n",
      "off the factory floor rather than an as aftermarket add-on\n",
      "on.\"\n",
      "    05:48 That's still the process we're following, although we've\n",
      "been surprised that some OEMs are interested in chatting\n",
      "early. I think they just want to have on their radar what's\n",
      "going on in the world. And if there's any promising\n",
      "technology, they want to be there first. So I guess we're\n",
      "already having some of those conversations too.\n",
      "Jon: 06:05 And now, we move from offers that tech companies can\n",
      "refuse to regulations that startups have a duty to follow.\n",
      "In this clip with the systems engineering and AI\n",
      "regulation guru, Dr. Gina Guillaume-Joseph, she lays out\n",
      "the evolving regulatory field for AI, which can be difficult\n",
      "to navigate even if you've got the best of intentions.\n",
      "Specifically, Gina and I talk about the AI Bill of Rights,\n",
      "the NIST AI regulatory framework, and her work on the\n",
      "MITRE ATLAS.\n",
      "    06:32 Explain for us... You mentioned there, so there's the NIST\n",
      "AI risk management framework. So NIST is the National\n",
      "Institutes of Science and Technology, that may be familiar\n",
      "as an acronym. The NIST thing is something for those of\n",
      "us who have done any deep learning to kind of Hello\n",
      "world deep learning example involves this handwritten\n",
      "data set of digits. So it's 60,000 handwritten digits done\n",
      "by, if I remember correctly, US postal workers, as well as\n",
      "elementary school students. And so it's just each image is\n",
      "a different digit. So it's some of them are zero, some are\n",
      "one, some are two, some are threes, all the way up to\n",
      "nine. And this handwritten dataset was curated initially, I\n",
      "guess in the '90s, maybe even in the '80s by NIST.\n",
      "Show Notes: http://www.superdatascience.com/802 6\n",
      "    07:24 And then Yann Le Cun, who's one of the most famous AI\n",
      "researchers of all time, he modified with his research\n",
      "team at the time, I believe they were AT&T Bell Labs, they\n",
      "modified that NIST handwritten digit dataset to create the\n",
      "MNIST, modified NIST, handwritten dataset. So I don't\n",
      "know, it's a bit of an aside, but that MNIST dataset is\n",
      "probably familiar to anyone who's done any kind of deep\n",
      "learning at all. And so yeah, so that same organization,\n",
      "NIST, has been around for a long time in the US I don't\n",
      "know how many decades.\n",
      "    07:58 But has been trying to set up frameworks for all different\n",
      "kinds of industries in science and technology, and has\n",
      "now created this AI risk management framework, which\n",
      "again, I'll have a link to that in the show notes alongside\n",
      "the AI Bill of Rights. A third framework, I guess, you can\n",
      "correct me if I'm not using the right word there, that you\n",
      "brought up in your talk that also seems really helpful\n",
      "here is something called the MITRE ATLAS.\n",
      "    08:26 So I've been trying to, as you've been speaking, dig up\n",
      "what MITRE stands for, M-I-T-R-E. It doesn't seem like it\n",
      "stands for anything. Can you tell us a bit about MITRE\n",
      "and the MITRE ATLAS and then maybe you can weave\n",
      "together these three different things; the AI Bill of Rights,\n",
      "the NIST AI regulatory framework, as well as MITRE\n",
      "ATLAS. And tell us how we can integrate these three\n",
      "frameworks together in order to have a good sense of how\n",
      "to move forward with the AI systems that we built.\n",
      "Gina: 08:58 So MITRE is a not-for-profit organization. I worked for\n",
      "them for 10 years, and they support the federal\n",
      "government across all the federal government agencies to\n",
      "help them solve some of the most pressing challenges. So\n",
      "MITRE operates federally funded research and\n",
      "development centers in support of the federal government\n",
      "to solve problems for a safer world, essentially is what\n",
      "MITRE does. And while at MITRE, I supported multiple\n",
      "Show Notes: http://www.superdatascience.com/802 7\n",
      "agencies; Department of Homeland Security, Social\n",
      "Security Administration, Veterans Affairs, Department of\n",
      "Defense, in some of the challenges that they were facing\n",
      "at the time.\n",
      "    09:45 Societal challenges to include when the economy was\n",
      "doing some downward slides and banks were failing, part\n",
      "of some of the work that I did was at the FDIC, that was\n",
      "with Booz Allen. But MITRE was involved in other aspects\n",
      "of that as well, to really understand the failures and to\n",
      "figure out the mitigation strategies to ensure that society\n",
      "didn't feel those impacts as broadly and as strongly.\n",
      "10:24 And MITRE created the ATLAS threat model introduction,\n",
      "threat model. It's this comprehensive coverage of AIspecific adversary tactics techniques that includes realworld observation and reporting. It talks about\n",
      "accessibility and usability of AI alignment with existing\n",
      "cybersecurity frameworks in terms of from an AI\n",
      "perspective. And that community engagement\n",
      "contribution and the educational resources and training.\n",
      "10:58 So they're developing a detailed taxonomy of tactics, of\n",
      "techniques, of procedures specific to AI systems that\n",
      "cover the entire lifecycle from data collection to model\n",
      "development and deployment and maintenance. Where\n",
      "they establish those mechanisms for continuously\n",
      "gathering and updating threat intelligence based on realworld cybersecurity incidents involving AI so that the\n",
      "knowledge base remains current and relevant. So that's\n",
      "what MITRE is doing it with their MITRE ATLAS\n",
      "framework. And the framework integrates their existing\n",
      "MITRE attack for enterprise framework that shows that\n",
      "they bring in that consistency and interoperability across\n",
      "cybersecurity efforts as it pertains to AI systems. And\n",
      "that's MITRE ATLAS threat model.\n",
      "Show Notes: http://www.superdatascience.com/802 8\n",
      "Jon: 12:01 Terrifically useful context there from Gina. In my next\n",
      "clip, Alex Andorra and I discuss Bayesian statistics,\n",
      "namely why being able to crunch larger and larger data\n",
      "sets has helped us to use a powerful modeling technique\n",
      "that was originally devised centuries ago.\n",
      "12:15 In addition to the podcast, also, I mentioned this at the\n",
      "outset, I said that you're co-founder and principal data\n",
      "scientist of the popular Bayesian stats modeling platform,\n",
      "PyMC. So like many things in data science, it's uppercase\n",
      "P, lowercase Y, for Python. What's the MC? PyMC, one\n",
      "word, M and the C are capitalized.\n",
      "Alex: 12:38 So it's very confusing because it stands for Python and\n",
      "then MC is Monte Carlo. So I understand, but why Monte\n",
      "Carlo? It's because it comes from Markov chain Monte\n",
      "Carlo. So actually, it should be PyMCMC or PyMC\n",
      "squared, which is what I'm saying since the beginning.\n",
      "But anyways, yeah, it's actually PyMC squared. So for\n",
      "Markov chain Monte Carlo and Markov chain Monte Carlo\n",
      "is one of the main ways... All the algorithms now, new\n",
      "ones, but the blockbuster algorithm to run Bayesian\n",
      "models is to use MCMC.\n",
      "Jon: 13:21 So in the same way that stochastic gradient descent is\n",
      "like the defacto standard for finding your model weights\n",
      "in machine learning, Markov chain Monte Carlo is the\n",
      "standard way of doing it with the Bayesian network?\n",
      "Alex: 13:36 Yeah. Yeah, yeah. And so now there are newer versions,\n",
      "more efficient versions. That's basically the name of the\n",
      "game, making the algorithm more and more efficient. But\n",
      "the first algorithm dates back... I think it was actually\n",
      "invented during the project Manhattan. So during World\n",
      "War II.\n",
      "Jon: 13:57 Theme of the day.\n",
      "Show Notes: http://www.superdatascience.com/802 9\n",
      "Alex: 13:58 Yeah. And lots of physicists actually, statistical physics is\n",
      "a field that's contributed a lot to MCMC. And so yeah,\n",
      "physicists who came to the field of statistics and trying to\n",
      "make the algorithms more efficient for their models. So\n",
      "they have contributed a lot. The field of physics has\n",
      "contributed a lot of big names and people to great leaps\n",
      "into the realm of more efficient algorithms. And so, I don't\n",
      "know who your audience is, but that may sound boring.\n",
      "14:37 Yeah, the algorithm, it's like the workhorse, but it's\n",
      "extremely powerful. And that's also one of the main\n",
      "reasons why Bayesian statistics are increasing in\n",
      "popularity lately, because I'm going to argue that it's\n",
      "always been the best framework to do statistics, to do\n",
      "science. But it was hard to do with pen and paper\n",
      "because the problem is that you have a huge, nasty\n",
      "integral on the numerator, on the denominator, sorry.\n",
      "And this integral is not computable by pen and paper. So\n",
      "for a long, long time, Bayesian statistics combined two\n",
      "features like campaigns, PR campaigns. Bayesian\n",
      "statistics was relegated to the margins because it was just\n",
      "super hard to do.\n",
      "15:31 And so for other problems, other than very trivial ones, it\n",
      "was not very applicable. But now with the advent of\n",
      "personal computing, you have these incredible\n",
      "algorithms. So now most of the time, it's HMC, Hamilton\n",
      "and Monte Carlo. That's what we use under the hood with\n",
      "PyMC. But if you stand, if you use [inaudible 00:15:54] ,\n",
      "it's the same. And thanks to these algorithms, now we\n",
      "can make extremely powerful models because we can\n",
      "approximate the [inaudible 00:16:03] distributions thanks\n",
      "to, well, computer's computing power. A computer is very\n",
      "good at computing. I think that's why it's called that.\n",
      "Jon: 16:15 Yes. And so that reminds me of deep learning. It's a\n",
      "similar kind of thing where the applications we have\n",
      "today, like your ChatGPT or whatever your favorite large\n",
      "Show Notes: http://www.superdatascience.com/802 10\n",
      "language model is, these amazing. Video generation like\n",
      "Sora, all of this is happening thanks to deep learning,\n",
      "which is an approach we've had since the '50s. Certainly\n",
      "not as old as Bayesian statistics, but similarly, it has\n",
      "been able to take off with much larger data sets and\n",
      "much more compute.\n",
      "Alex: 16:46 Yeah, yeah. Yeah, yeah, very good point. And I think\n",
      "that's even more the point in deep learning for sure,\n",
      "because Bayesian stats doesn't need the scale, but the\n",
      "way we're doing deep learning for now, definitely need the\n",
      "scale.\n",
      "Jon: 16:58 Yeah, yeah. Scale of data.\n",
      "Alex: 17:00 Yeah, yeah, exactly. Yeah, sorry, yeah, the scale, because\n",
      "our two scales, data and computing. Yeah. You're right.\n",
      "Jon: 17:05 And for model parameters. So that has actually... I mean,\n",
      "tying back to something you said near the beginning of\n",
      "this episode, is that actually one of the advantages of\n",
      "Bayesian statistics is that you can do it with very few\n",
      "data. Maybe fewer data than with a frequentist approach\n",
      "or a machine learning approach, because you can bake in\n",
      "your prior assumptions. And those prior assumptions\n",
      "give some kind of structure, some kind of framework for\n",
      "your data to make an impact.\n",
      "Alex: 17:32 Yeah. Yeah, completely.\n",
      "Jon: 17:34 And in keeping with the theme of returning to the past to\n",
      "find golden opportunities, I speak to Dr. Nathan Lambert\n",
      "about historical influences on contemporary\n",
      "methodologies. I also managed to sneak in a question\n",
      "about reinforcement learning from human feedback.\n",
      "Nathan is a research scientist for the Allen Institute for\n",
      "AI, and previously built out the RLHF team at Hugging\n",
      "Face. So there was no better person to ask about the lack\n",
      "Show Notes: http://www.superdatascience.com/802 11\n",
      "of robustness in RLHF and how that could impact the\n",
      "future development and deployment of AI systems.\n",
      "18:02 Another really cool thing that you've done related to RLHF\n",
      "is you have traced it back to ancient philosophy and\n",
      "modern economics. So mentioning Aristotle and von\n",
      "Neumann-Morganstern utility theorem, for example. I\n",
      "don't really know what the VNM utility theorem is, but\n",
      "how do these historical foundations influence current\n",
      "methodologies and what can modern AI research learn\n",
      "from these early theories?\n",
      "Nathan: 18:30 Yeah. So this is a fun paper with a few colleagues that I\n",
      "started working with at Berkeley, and now we're kind of\n",
      "spread out. This is all based on the fact that RL is very\n",
      "deep field multidisciplinary history, where it goes way\n",
      "back. And then the notion of preference is a very vague\n",
      "thing in economics. And it's like the von NeumannMorganstern theory is a foundational thing that\n",
      "essentially it's like you can express either all behaviors or\n",
      "all goals as probability and expected value distributions,\n",
      "which essentially lets you do expected value math over\n",
      "preferences.\n",
      "19:10 And then it led to a bunch of debates on whether or not\n",
      "preferences actually exist and are tractable in any of\n",
      "these things, or if they're actually measurable or not due\n",
      "to the preference shift over time based on context. So\n",
      "these are the kinds of things that we take and it's ask a\n",
      "lot of questions on how this impacts the modern RLHF\n",
      "process. It's things like is the final model's preferences,\n",
      "which is like we're mapping onto very human terms, is\n",
      "that actually based more on the the base model, which is\n",
      "scraped from the internet than the human preferences\n",
      "that they get from somewhere like Scale AI.\n",
      "19:46 So it's like if it's based more on the internet crawling than\n",
      "this million dollar dataset they're getting from Scale AI,\n",
      "Show Notes: http://www.superdatascience.com/802 12\n",
      "it's kind of confusing to the marketing where we're saying\n",
      "we're learning a preference model, but it might not\n",
      "actually do that much. Is other things like OpenAI now\n",
      "has a ton of user data and it's like what does the\n",
      "economics literature say about generating data for\n",
      "training that comes from a user context or a professional\n",
      "context where someone is paid to do it and they're paid to\n",
      "act in a certain way? And how does all of this mix? So it's\n",
      "really just a super long list of questions of why we should\n",
      "look at other social sciences if we're making grand claims\n",
      "about human preferences and all of these things.\n",
      "Jon: 20:26 Nice. Well, fascinating. Tons to dig into there for our\n",
      "listeners. Final topic that I planned related to RLHF, I'm\n",
      "sure it'll come up again organically in the conversation,\n",
      "but you've mentioned that RLHF is not even robust to\n",
      "fine-tuning. And so removing the safety layer from models\n",
      "like GPT-4 and Llama 2 can break down the notion of\n",
      "safety. Can you elaborate on the implications of this\n",
      "fragility for the future development and deployment of AI\n",
      "systems?\n",
      "Nathan: 20:59 Yeah, so this is a specific line of research. So there's a few\n",
      "papers that showed that if you take a model like Zephyr\n",
      "or Tulu that we were mentioning, if they have safety in\n",
      "the dataset, if you then go and fine-tune it again on some\n",
      "different tasks, you'll do some of the behaviors that are\n",
      "\"ingrained\" in the model. I honestly think this is a little\n",
      "bit more clickbaity than actually worrisome because it's\n",
      "really not surprising given that if you just look at the\n",
      "amount of compute applied at fine-tuning, we pre-trained\n",
      "these models for trillions of tokens. And then we apply a\n",
      "couple billion tokens of compute at fine-tuning.\n",
      "21:36 And it's like we're not changing the weights of the model\n",
      "substantially. We're doing a slight nudge, and it makes\n",
      "sense that a slight nudge could be undone at the same\n",
      "way. But if you were to take this to some of the bigger\n",
      "Show Notes: http://www.superdatascience.com/802 13\n",
      "labs, what you hear is that safety is not just a single\n",
      "artifact thing. Safety is much more about a complete\n",
      "system than a model. So open weight models being\n",
      "unsafe or unsafe, I don't consider to be that big of a deal.\n",
      "It's like if you were to apply them to a free endpoint that\n",
      "everyone on the internet could talk to, then I don't want\n",
      "my model saying good things about Hitler and all these\n",
      "obvious things.\n",
      "22:09 But if it's a research artifact that you need to spin up\n",
      "GPUs to use yourself, and it's a little bit more... I'm more\n",
      "open to having these diversity of models exist. But if you\n",
      "ask [inaudible 00:22:22] or somebody, it's like, \"What\n",
      "happens... How do you get safety into your model?\" And\n",
      "it's like, it's not just RLHF. You need to have safety at the\n",
      "pre-training, any preference model you trained. And then\n",
      "all of these models have a safety filter on the output. So\n",
      "ChatGPT, it reads all the text generated from the base\n",
      "model, and then there's a go, no go where it will rephrase\n",
      "the text if it gets a no-go signal, which is like their content\n",
      "moderation API.\n",
      "22:45 So it's kind of a double. It's the type of thing where\n",
      "researchers need to market their work, but it's not as big\n",
      "of a detail as I think it is. It's like, okay, I think it has\n",
      "interesting business downstream things with liability. So\n",
      "it's just like if you want to fine-tune a Llama model, you\n",
      "normally do that on your own hardware, but OpenAI has\n",
      "a fine-tuning API. And if they claim their model is safe,\n",
      "but any fine-tuning on their API that they then host\n",
      "makes it unsafe, that seems like more of a business\n",
      "problem. Which is like, oh, it's a nice way that open\n",
      "ecosystem might be better off because it breaks the\n",
      "liability chain. But we'll see this research continue to\n",
      "evolve. It's so early in all of these things for a year in.\n",
      "Jon: 23:31 All right. That's it for today's In Case You Missed It\n",
      "episode, to be sure not to miss any of our exciting\n",
      "Show Notes: http://www.superdatascience.com/802 14\n",
      "upcoming episodes. Be sure to subscribe to this podcast\n",
      "if you haven't already. But most importantly, I hope you'll\n",
      "just keep on listening. Until next time, keep on rocking it\n",
      "out there. And I'm looking forward to enjoying another\n",
      "round of Super Data Science Podcast with you very soon.' metadata={'source': '2. DataIngestion/super_DS.txt'}\n"
     ]
    }
   ],
   "source": [
    "print(text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTMLHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import HTMLHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_string = \"\"\"<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    " \n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\"\n",
    "          content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>ChatBot</title>\n",
    "    <link rel=\"stylesheet\" href=\"style.css\">\n",
    "</head>\n",
    " \n",
    "<body>\n",
    "    <div class=\"chatBot\">\n",
    "        <header>\n",
    "            <h2>ChatBot</h2>\n",
    "            <span alt=\"Close\"\n",
    "                  id=\"cross\"\n",
    "                  onclick=\"cancel()\">X</span>\n",
    "        </header>\n",
    "        <ul class=\"chatbox\">\n",
    "            <li class=\"chat-incoming chat\">\n",
    "                <p>Hey! How can I assist you today?</p>\n",
    "            </li>\n",
    "        </ul>\n",
    "        <div class=\"chat-input\">\n",
    "            <textarea rows=\"0\" cols=\"17\"\n",
    "                      placeholder=\"Enter a message...\"></textarea>\n",
    "            <button id=\"sendBTN\">Send</button>\n",
    "        </div>\n",
    "    </div>\n",
    "    <script src=\"script.js\" defer></script>\n",
    "</body>\n",
    " \n",
    "</html>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"p\", \"Paragraph\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='ChatBot X'),\n",
       " Document(metadata={'Header 2': 'ChatBot'}, page_content='Hey! How can I assist you today?  \\nSend')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_splitter.split_text(html_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://plato.stanford.edu/entries/goedel/\"\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\"),\n",
    "    (\"h4\", \"Header 4\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Stanford Encyclopedia of Philosophy  \\nMenu  \\nBrowse About Support SEP  \\nTable of Contents What's New Random Entry Chronological Archives  \\nEditorial Information About the SEP Editorial Board How to Cite the SEP Special Characters Advanced Tools Contact  \\nSupport the SEP PDFs for SEP Friends Make a Donation SEPIA for Libraries  \\nEntry Navigation  \\nEntry Contents Bibliography Academic Tools Friends PDF Preview Author and Citation Info Back to Top  \\nKurt Gödel\"),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel'}, page_content='First published Tue Feb 13, 2007; substantive revision Fri Dec 11, 2015  \\nKurt Friedrich Gödel (b. 1906, d. 1978) was one of the principal founders of the modern, metamathematical era in mathematical logic. He is widely known for his Incompleteness Theorems, which are among the handful of landmark theorems in twentieth century mathematics, but his work touched every field of mathematical logic, if it was not in most cases their original stimulus. In his philosophical work Gödel formulated and defended mathematical Platonism, the view that mathematics is a descriptive science, or alternatively the view that the concept of mathematical truth is objective. On the basis of that viewpoint he laid the foundation for the program of conceptual analysis within set theory (see below). He adhered to Hilbert’s “original rationalistic conception” in mathematics (as he called it);[1] and he was prophetic in anticipating and emphasizing the importance of large cardinals in set theory before their importance became clear.  \\n1. Biographical Sketch 2. Gödel’s Mathematical Work 3. Gödel’s Philosophical Views Bibliography Academic Tools Other Internet Resources Related Entries  \\n2.1 The Completeness Theorem 2.2 The Incompleteness Theorems 2.3 Speed-up Theorems 2.4 Gödel’s Work in Set theory 2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic Supplement Document: Gödel’s Documents  \\n2.1.1 Introduction 2.1.2 Proof of the Completeness Theorem 2.1.3 An Important Consequence of the Completeness Theorem  \\n2.2.1 The First Incompleteness Theorem 2.2.2 The proof of the First Incompleteness Theorem 2.2.3 The Second Incompleteness Theorem Supplementary Document: Did the Incompleteness Theorems Refute Hilbert’s Program?  \\n2.4.1 The consistency of the Continuum Hypothesis and the Axiom of Choice 2.4.2 Gödel’s Proof of the Consistency of the Continuum Hypothesis and the Axiom of Choice with the Axioms of Zermelo-Fraenkel Set Theory 2.4.3 Consequences of Consistency 2.4.4 Gödel’s view of the Axiom of Constructibility  \\n2.5.1 Intuitionistic Propositional Logic is not Finitely-Valued 2.5.2 Classical Arithmetic is Interpretable in Heyting Arithmetic 2.5.3 Intuitionistic Propositional Logic is Interpretable in S4 2.5.4 Heyting Arithmetic is Interpretable into Computable Functionals of Finite Type.  \\n3.1 Gödel’s Rationalism 3.2 Gödel’s Realism Supplementary Document: Gödel’s Turn to Phenomenology Supplementary Document: A Philosophical Argument About the Content of Mathematics  \\nPrimary Sources Secondary Sources  \\nGödel’s Writings The Collected Papers of Kurt Gödel Selected Works of Kurt Gödel  \\n1. Biographical Sketch 2. Gödel’s Mathematical Work 2.1 The Completeness Theorem 2.1.1 Introduction 2.1.2 Proof of the Completeness Theorem 2.1.3 An Important Consequence of the Completeness Theorem 2.2 The Incompleteness Theorems 2.2.1 The First Incompleteness Theorem 2.2.2 The proof of the First Incompleteness Theorem 2.2.3 The Second Incompleteness Theorem 2.3 Speed-up Theorems 2.4 Gödel’s Work in Set theory 2.4.1 The consistency of the Continuum Hypothesis and the Axiom of Choice 2.4.2 Gödel’s Proof of the Consistency of the Continuum Hypothesis and the Axiom of Choice with the Axioms of Zermelo-Fraenkel Set Theory 2.4.3 Consequences of Consistency 2.4.4 Gödel’s view of the Axiom of Constructibility 2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic 2.5.1 Intuitionistic Propositional Logic is not Finitely-Valued 2.5.2 Classical Arithmetic is Interpretable in Heyting Arithmetic 2.5.3 Intuitionistic Propositional Logic is Interpretable in S4 2.5.4 Heyting Arithmetic is Interpretable into Computable Functionals of Finite Type. 3. Gödel’s Philosophical Views 3.1 Gödel’s Rationalism 3.2 Gödel’s Realism'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': '1. Biographical Sketch'}, page_content='Kurt Gödel was born on April 28, 1906 in what was then the Austro-Hungarian city of Brünn, and what is now Brno in the Czech Republic.  \\nGödel’s father Rudolf August was a businessman, and his mother Marianne was a well-educated and cultured woman to whom Gödel remained close throughout his life, as witnessed by the long and wide-ranging correspondence between them. The family was well off, and Gödel’s childhood was an uneventful one, with one important exception; namely, from about the age of four Gödel suffered frequent episodes of poor health, and the health problems he suffered then as well as others of various kinds were to plague him his entire life.  \\nHealth problems notwithstanding, Gödel proved to be an exemplary student at primary school and later the Gymnasium, excelling especially in mathematics, languages and religion. Upon his graduation from the Gymnasium in Brno in 1924 Gödel enrolled in the University of Vienna, attending lectures on physics, his initial field of interest, lectures on philosophy given by Heinrich Gomperz, and lectures on mathematics. Gödel took a number of physics courses during his undergraduate years, as witnessed by his university transcript; this is notable in view of Gödel’s subsequent contributions to relativity in 1947. Philipp Furtwängler, cousin of the great German conductor Wilhelm Furtwängler, was one of his mathematics professors, and indeed Furtwängler’s course on class field theory almost tempted Gödel to pursue his studies in that area. Gödel learned his logic from Rudolph Carnap and from Hans Hahn, eventually graduating under Hahn with a Dr.phil. in mathematics in 1929. The main theorem of his dissertation was the completeness theorem for first order logic (Gödel 1929).[2]  \\nGödel’s university years also marked the beginning of his attendance at meetings of the Vienna Circle, a group around Moritz Schlick that quickly became known as “logical positivists,” a term coined by Feigl and Blumberg in their 1931 “Logical positivism: A new movement in European philosophy” (Feigl and Blumberg 1931). Though Gödel was not himself a logical positivist, those discussions were a crucial formative influence.  \\nThe 1930s were a prodigious decade for Gödel. After publishing his 1929 dissertation in 1930, he published his groundbreaking incompleteness theorems in 1931, on the basis of which he was granted his Habilitation in 1932 and a Privatdozentur at the University of Vienna in 1933.  \\nAmong his mathematical achievements at the decade’s close is the proof of the consistency of both the Axiom of Choice and Cantor’s Continuum Hypothesis with the Zermelo-Fraenkel axioms for set theory, obtained in 1935 and 1937, respectively. Gödel also published a number of significant papers on modal and intuitionistic logic and arithmetic during this period, principal among which is his “On intuitionistic arithmetic and number theory,” (Gödel 1933e), in which he showed that classical first order arithmetic is interpretable in Heyting arithmetic by a simple translation. Other publications of the 1930s include those on the decision problem for the predicate calculus, on the length of proofs, and on differential and projective geometry.  \\nBy the end of the decade both Gödel’s advisor Hans Hahn and Moritz Schlick had died (the latter was assassinated by an ex-student), two events which led to a personal crisis for Gödel. Also, his appointment at the University, that of Privatdozentur, was cancelled, being replaced by the position “Dozentur neuer Ordnung,” granted to candidates only after they had passed a racial test.[3] Gödel’s three trips the United States during that decade triggered an investigation. (See Sigmund 2006.) Finally, Gödel was found fit for military service by the Nazi government in 1939.  \\nAll of these events were decisive in influencing his decision to leave Austria in 1940, when he and his wife Adele emigrated to the United States. This long and difficult episode in their life is recounted by John Dawson in his biography of Gödel called “Logical Dilemmas,” (Dawson 1997) as well as by Solomon Feferman in “Gödel’s Life and Work,” (Feferman 1986) to both of which the reader is referred.  \\nUpon arrival Gödel took up an appointment as an ordinary member at the Institute for Advanced Study; he would become a permanent member of the Institute in 1946 and would be granted his professorship in 1953. (Gödel and his wife were granted American citizenship in April 1948.) He would remain at the Institute until his retirement in 1976. The Gödels never returned to Europe.  \\nGödel’s early years at the Institute were notable for his close friendship with his daily walking partner Albert Einstein, as well as for his turn to philosophy of mathematics, a field on which Gödel began to concentrate almost exclusively from about 1943. The initial period of his subsequent lifelong involvement with philosophy was a fruitful one (in terms of publications): in 1944 he published his first philosophical paper, entitled “On Russell’s Mathematical Logic” (Gödel 1944), and in 1947 he published his second, entitled “What is Cantor’s Continuum Hypothesis?” (Gödel 1947). In 1949 he published his third, entitled “A Remark on the Relationship between Relativity Theory and Idealistic Philosophy.” (Gödel 1949a). The latter paper coincided with results on rotating universes in relativity he had obtained in 1949, which were first published in an article entitled: “An Example of a New Type of Cosmological Solutions of Einstein’s Field Equations of Gravitation.” (Gödel 1949).  \\nAmong Gödel’s other significant philosophical works of the 1940s must be counted his 1941 lecture entitled “In What Sense is Intuitionistic Logic Constructive?” (Gödel *1941) in which the notion: “computable function of finite type” is introduced. A paper based on the ideas in the lecture entitled “Über eine bisher noch nicht benützte Erweiterung des finiten Standpunktes,” was published only in 1958, and the interpretation of Heyting arithmetic into the quantifier free calculus T in it became known as the “Dialectica Interpretation,” after the journal in which the article was published (Gödel 1958). (For the revision of it from 1972, see Gödel 1995.) Finally the decade saw the beginning of Gödel’s intensive study of Leibniz, which, Gödel reports, occupied the period from 1943 to 1946.[4]  \\nThe 1950s saw a deepening of Gödel’s involvement with philosophy: In 1951 Gödel delivered a philosophical lecture at Brown University, usually referred to as the Gibbs Lecture, entitled “Some Basic Theorems on the Foundations of Mathematics and Their Philosophical Implications” (Gödel *1951). From 1953 to 1959 Gödel worked on a submission to the Schilpp volume on Rudolf Carnap entitled “Is Mathematics a Syntax of Language?” (Gödel *1953/9-III, Gödel *1953/9-V). Gödel published neither of these two important manuscripts in his lifetime, although both would appear on two lists which were found in the Gödel Nachlass, entitled “Was ich publizieren könnte.” (In English: “What I could publish.” Both manuscripts eventually appeared in Gödel 1995.) By the decade’s close Gödel developed a serious interest in phenomenology.[5]  \\nGödel’s final years are notable for his circulation of two manuscripts: “Some considerations leading to the probable conclusion that the true power of the continuum is ℵ2,” (Gödel *1970a, *1970b) his attempt to derive the value of the continuum from the so-called scale axioms of Hausdorff, and his “Ontologischer Beweis,” (Gödel *1970) which he entrusted to Dana Scott in 1970 (though it appears to have been written earlier). Taken together, the two manuscripts are the fitting last words of someone who, in a fifty year involvement with mathematics and philosophy, pursued, or more precisely, sought the grounds for pursuing those two subjects under the single heading: “strenge Wissenschaft”—a turn of mind that had been in place from Gödel’s start in 1929, when at the age of twenty-three he opened his doctoral thesis with some philosophical remarks.  \\nGödel died in Princeton on January 14, 1978 at the age of 71. His death certificate records the cause of death as “starvation and inanition, due to personality disorder.” His wife Adele survived him by three years.  \\nFor further biographical material, see Gödel 1987, Kleene 1987, Kreisel 1980, Taussky-Todd 1987 and Yourgrau 2005.'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work'}, page_content='Below is an examination of some of Gödel’s main contributions in logic and set theory. This treatment of Gödel’s technical work is not exhaustive, omitting discussion of Gödel’s work in physics and his work on the decision problem. These will be treated in the sequel to this entry.  \\nFor a complete chronology of Gödel’s work the reader is referred to that compiled by John Dawson in volume I of Gödel’s Collected Works (Gödel 1986, p. 37).'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem', 'Header 4': '2.1.1 Introduction'}, page_content='The completeness question for the first order predicate calculus was stated precisely and in print for the first time in 1928 by Hilbert and Ackermann in their text Grundzüge der theoretischen Logik (Hilbert and Ackermann 1928), a text with which Gödel would have been quite familiar.[6]  \\nThe question Hilbert and Ackermann pose is whether a certain explicitly given axiom system for the first order predicate calculus “…is complete in the sense that from it all logical formulas that are correct for each domain of individuals can be derived…” (van Heijenoort 1967, p. 48).'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem', 'Header 4': '2.1.2 Proof of the Completeness Theorem'}, page_content='We give an outline of Gödel’s own proof in his doctoral thesis (Gödel 1929). An essential difference with earlier efforts (discussed below and elsewhere, e.g. in Zach 1999), is that Gödel defines meticulously all the relevant basic concepts.  \\nA “logical expression” in Gödel’s terminology is a well-formed first order formula without identity. An expression is “refutable” if its negation is provable, “valid” if it is true in every interpretation and “satisfiable” if it is true in some interpretation. The Completeness Theorem is stated as follows:  \\nTheorem 1. Every valid logical expression is provable. Equivalently, every logical expression is either satisfiable or refutable.  \\nGödel’s proof calculus is that of Hilbert and Ackermann’s text. An expression is in normal form if all the quantifiers occur at the beginning. The degree of an expression or formula is the number of alternating blocks of quantifiers at the beginning of the formula, assumed to begin with universal quantifiers. Gödel shows that if the completeness theorem holds for formulas of degree k it must hold for formulas of degree k + 1. Thus the question of completeness reduces to formulas of degree 1. That is, it is to be shown that any normal formula (Q)φ of degree 1 is either satisfiable or refutable, where “(Q)” stands for a (non-empty) block of universal quantifiers followed by a (possibly empty) block of existential ones.  \\nGödel defines a book-keeping device, a well-ordering of all tuples of variables arising from a need to satisfy φ as dictated by (Q). For example, if (Q)φ is ∀x0∃x1ψ(x0, x1), we list the quantifier-free formulas ψ(xn, xn+1). (Or more precisely, finite conjunctions of these in increasing length. See below.) Then in any domain consisting of the values of the different xn, in which each ψ(xn, xn+1) is true, the sentence (Q)φ is clearly true. A crucial lemma claims the provability, for each k, of the formula (Q)φ → (Qk)φk, where the quantifier free formula φk asserts the truth of ψ for all tuples up to the kth tuple of variables arising from (Q), and (Qk)φk is the existential closure of φk. (See the example below where the definition of the φk′s is given.) This lemma is the main step missing from the various earlier attempts at the proof due to Löwenheim and Skolem, and, in the context of the completeness theorem for first order logic, renders the connection between syntax and semantics completely explicit.  \\nLet us consider an example of how a particular formula would be found to be either satisfiable or its negation provable, following Gödel’s method: Consider φ = ∀x0∃x1ψ(x0, x1), where ψ(x0, x1) is quantifier-free. We show that this is either refutable or satisfiable. We make the following definitions:  \\nφ0 is the expression ψ(x0, x1) φ1 is the expression ψ(x0, x1) ∧ ψ(x1, x2) … φn is the expression ψ(x0, x1) ∧ …∧ ψ(xn, xn+1).  \\nThe crucial lemma, referred to above, shows that from φ we can derive for each n, ∃x0…∃xn+1φn.  \\nCase 1: For some n, φn is not satisfiable. Then, Gödel argued, using the already known completeness theorem for propositional logic,[7] that ¬φn is provable, and hence so is ∀x0,…, xn+1¬φn. Thus ¬∃x0…∃xn+1φn is provable and therefore the ¬φ is provable, i.e., φ is refutable in the Hilbert-Ackermann system. (Some partial results about propositional logic in addition to those already mentioned include the semantic completeness of the propositional calculus due to Post (1921), as well as a more general completeness theorem for the same due to Bernays in 1918; the latter appears in Bernays’ unpublished Habilitationsschrift of 1918; see also Bernays 1926.)  \\nCase 2: Each φn is satisfiable. There are only finitely many possible models with universe {x0,…, xn+1}. Gödel orders them as a tree by defining a model M to be below a model M′ if M is a submodel of M′. In this way we obtain a tree which is finitely branching but infinite. By König’s Lemma there is an infinite branch B. (In the proof, Gödel explicitly constructs the branch given by König’s Lemma rather than citing it by name.) The union of the models on B forms a model M with universe {x0, x1,…}. Since M satisfies each φn, the original formula φ holds in M. So φ is satisfiable and we are done.  \\nNote that the model, in the satisfiability case of Gödel’s proof, is always countable. Thus this proof of the Completeness Theorem gives also the Löweheim-Skolem Theorem (see below). Gödel extends the result to countably many formulas and to the case of first order logic with identity. He also proves the independence of the axioms.  \\nIn 1930 Gödel published the paper based on his thesis (Gödel 1930) notable also for the inclusion of the compactness theorem, which is only implicitly stated in the thesis. The theorem as stated by Gödel in Gödel 1930 is as follows: a countably infinite set of quantificational formulas is satisfiable if and only if every finite subset of those formulas is satisfiable. Gödel uses compactness to derive a generalization of the completeness theorem.  \\nThe Compactness Theorem was extended to the case of uncountable vocabularies by Maltsev in 1936 (see Mal’cev 1971), from which the Upward Löwenheim-Skolem theorem immediately follows. The Compactness Theorem would become one of the main tools in the then fledgling subject of model theory.'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.1 The Completeness Theorem', 'Header 4': '2.1.3 An Important Consequence of the Completeness Theorem'}, page_content='A theory is said to be categorical if it has only one model up to isomorphism; it is λ-categorical if it has only one model of cardinality λ, up to isomorphism. One of the main consequences of the completeness theorem is that categoricity fails for Peano arithmetic and for Zermelo-Fraenkel set theory.  \\nIn detail, regarding the first order Peano axioms (henceforth PA), the existence of non-standard models of them actually follows from completeness together with compactness. One constructs these models, which contain infinitely large integers, as follows: add a new constant symbol c to the language of arithmetic. Extend PA to a new theory PA* by adding to it the infinite collection of axioms: {c > 0, c > 1, …}, where, e.g., 3 is S(S(S(0))). PA* is finitely consistent (i.e., every finite subset of PA* is consistent) hence consistent, hence by the Completeness Theorem it has a model.  \\nThis simple fact about models of Peano arithmetic was not pointed out by Gödel in any of the publications connected with the Completeness Theorem from that time, and it seems not to have been noticed by the general logic community until much later. Skolem’s definable ultrapower construction from 1933 (see Skolem 1933) gives a direct construction of a non-standard model of True Arithmetic (which extends Peano arithmetic, being the set of arithmetic sentences true in the natural numbers). But Skolem never mentions the fact that the existence of such models follows from the completeness and compactness theorems. Gödel in his review (1934c) of Skolem’s paper also does not mention this fact, rather observing that the failure of categoricity for arithmetic follows from the incompleteness theorem.  \\nAs for set theory, the failure of categoricity was already taken note of by Skolem in 1923, because it follows from the Löwenheim-Skolem Theorem (which Skolem arrived at that year; see Skolem 1923, based on Löwenheim 1915 and Skolem 1920): any first order theory in a countable language that has a model has a countable model.  \\nSkolem’s observation that categoricity fails for set theory because it has countable models is now known as the Skolem paradox.[8]The observation is strongly emphasized in Skolem’s paper, which is accordingly entitled ‘An Observation on the Axiomatic Foundations of Set Theory’ As he wrote in the conclusion of it, he had not pointed out the relativity in set theory already in 1915 because:  \\n… first, I have in the meantime been occupied with other problems; second, I believed that it was so clear that axiomatization in terms of sets was not a satisfactory ultimate foundation of mathematics that mathematicians would, for the most part, not be very much concerned with it. But in recent times I have seen to my surprise that so many mathematicians think that these axioms of set theory provide the ideal foundation for mathematics; therefore it seemed to me that the time had come to publish a critique. (English translation taken from van Heijenoort 1967, p. 300.)  \\nAs an aside, in the proof of the Löwenheim-Skolem theorem, specifically that part of the theorem in which one constructs a model for a satisfiable sentence, Löwenheim and Skolem’s tree construction was more or less the same as appears in Gödel’s thesis. In a 1967 letter to Hao Wang, Gödel takes note of the fact that his completeness proof had almost been obtained by Skolem in 1923. Though van Heijenoort and Dreben (Dreben and van Heijenoort 1986) remark that “Throughout much of the 1920s it was not semantic completeness but the decision problem for quantificational validity, a problem originating from the work of Schröder and Löwenheim, that was the dominant concern in studying quantification theory” (examples of such results would include the decision procedure for the first order monadic predicate calculus due to Behmann, (Behmann 1922)), according to Gödel, the reasons that Skolem did not obtain the complete proof are different and philosophically important, having to do with the then dominant bias against semantics and against infinitary methods:  \\nThe Completeness Theorem, mathematically, is indeed an almost trivial consequence of Skolem 1923. However, the fact is that, at that time, nobody (including Skolem himself) drew this conclusion neither from Skolem 1923 nor, as I did, from similar considerations of his own …This blindness (or prejudice, or whatever you may call it) of logicians is indeed surprising. But I think the explanation is not hard to find. It lies in the widespread lack, at that time, of the required epistemological attitude toward metamathematics and toward non-finitary reasoning. (Gödel 2003b).  \\nThe matter of Skolem’s contribution to the Completeness Theorem has been extensively discussed in van Atten and Kennedy 2009, as well as in van Atten 2005.'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems'}, page_content='Gödel mentioned the possibility of the unsolvability of a question about the reals already in his 1929 thesis, in arguing against the formalist principle of Hilbert’s, that consistency is a criterion for existence. In fact, giving a finitary proof of the consistency of analysis was a key desideratum of what was then known as the Hilbert program, along with proving its completeness. Accordingly it was Gödel’s turn to these questions, especially the first, which led him to the two incompleteness theorems. (For a discussion of the Hilbert Program the reader is referred to the standard references: Sieg 1990, 1988, 1999; Mancosu 1998, Zach 2003, Tait 1981 and Tait 2002.)  \\nThe First Incompleteness Theorem provides a counterexample to completeness by exhibiting an arithmetic statement which is neither provable nor refutable in Peano arithmetic, though true in the standard model. The Second Incompleteness Theorem shows that the consistency of arithmetic cannot be proved in arithmetic itself. Thus Gödel’s theorems demonstrated the infeasibility of the Hilbert program, if it is to be characterized by those particular desiderata, consistency and completeness.  \\nAs an aside, von Neumann understood the two theorems this way, even before Gödel did. In fact von Neumann went much further in taking the view that they showed the infeasibility of classical mathematics altogether. As he wrote to Carnap in June of 1931:  \\nThus today I am of the opinion that 1. Gödel has shown the unrealizability of Hilbert’s program. 2. There is no more reason to reject intuitionism (if one disregards the aesthetic issue, which in practice will also for me be the decisive factor). Therefore I consider the state of the foundational discussion in Königsberg to be outdated, for Gödel’s fundamental discoveries have brought the question to a completely different level.[9]  \\nAnd the previous fall von Neumann had written to Gödel in even stronger terms:  \\nThus, I think that your result has solved negatively the foundational question: there is no rigorous justification for classical mathematics. (Gödel 2003b, p. 339)  \\nIt would take Gödel himself a few years to see that those aspects of the Hilbert Program had been decisively refuted by his results (Mancosu 2004).'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems', 'Header 4': '2.2.1 The First Incompleteness Theorem'}, page_content='In his Logical Journey (Wang 1996) Hao Wang published the full text of material Gödel had written (at Wang’s request) about his discovery of the incompleteness theorems. This material had formed the basis of Wang’s “Some Facts about Kurt Gödel,” and was read and approved by Gödel:  \\nIn the summer of 1930 I began to study the consistency problem of classical analysis. It is mysterious why Hilbert wanted to prove directly the consistency of analysis by finitary methods. I saw two distinguishable problems: to prove the consistency of number theory by finitary number theory and to prove the consistency of analysis by number theory … Since the domain of finitary number theory was not well-defined, I began by tackling the second half… I represented real numbers by predicates in number theory… and found that I had to use the concept of truth (for number theory) to verify the axioms of analysis. By an enumeration of symbols, sentences and proofs within the given system, I quickly discovered that the concept of arithmetic truth cannot be defined in arithmetic. If it were possible to define truth in the system itself, we would have something like the liar paradox, showing the system to be inconsistent… Note that this argument can be formalized to show the existence of undecidable propositions without giving any individual instances. (If there were no undecidable propositions, all (and only) true propositions would be provable within the system. But then we would have a contradiction.)… In contrast to truth, provability in a given formal system is an explicit combinatorial property of certain sentences of the system, which is formally specifiable by suitable elementary means…  \\nWe see that Gödel first tried to reduce the consistency problem for analysis to that of arithmetic. This seemed to require a truth definition for arithmetic, which in turn led to paradoxes, such as the Liar paradox (“This sentence is false”) and Berry’s paradox (“The least number not defined by an expression consisting of just fourteen English words”). Gödel then noticed that such paradoxes would not necessarily arise if truth were replaced by provability. But this means that arithmetic truth and arithmetic provability are not co-extensive — whence the First Incompleteness Theorem.  \\nThis account of Gödel’s discovery was told to Hao Wang very much after the fact; but in Gödel’s contemporary correspondence with Bernays and Zermelo, essentially the same description of his path to the theorems is given. (See Gödel 2003a and Gödel 2003b respectively.) From those accounts we see that the undefinability of truth in arithmetic, a result credited to Tarski, was likely obtained in some form by Gödel by 1931. But he neither publicized nor published the result; the biases logicians had expressed at the time concerning the notion of truth, biases which came vehemently to the fore when Tarski announced his results on the undefinability of truth in formal systems 1935, may have served as a deterrent to Gödel’s publication of that theorem.'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems', 'Header 4': '2.2.2 The proof of the First Incompleteness Theorem'}, page_content='We now describe the proof of the two theorems, formulating Gödel’s results in Peano arithmetic. Gödel himself used a system related to that defined in Principia Mathematica, but containing Peano arithmetic. In our presentation of the First and Second Incompleteness Theorems we refer to Peano arithmetic as P, following Gödel’s notation.  \\nBefore proceeding to the details of the formal proof, we define the notion of ω-consistency used by Gödel in the First Incompleteness Theorem: P is ω-consistent if P ⊢ ¬φ(n) for all n implies P ⊬ ∃xφ(x). Naturally this implies consistency and follows from the assumption that the natural numbers satisfy the axioms of Peano arithmetic.  \\nOne of the main technical tools used in the proof is Gödel numbering, a mechanism which assigns natural numbers to terms and formulas of our formal theory P. There are different ways of doing this. The most common is based on the unique representation of natural numbers as products of powers of primes. Each symbol s of number theory is assigned a positive natural number #(s) in a fixed but arbitrary way, e.g.  \\n#(0) = 1 #(=) = 5 #(¬) = 9 #(1) = 2 #(\\u2009(\\u2009) = 6 #(∀) = 10 #(+) = 3 #(\\u2009)\\u2009) = 7 #(vi) = 11 + i #(×) = 4 #(∧) = 8 \\xa0  \\nThe natural number corresponding to a sequence w = < w0,…, wk > of symbols is  \\n⌈w⌉ = 2#(w0) · 3#(w1) · … · pk#(wk),  \\nwhere pk is the k+1st prime. It is called its Gödel number and denoted by ⌈w⌉. In this way we can assign Gödel numbers to formulas, sequences of formulas (once a method for distinguishing when one formula ends and another begins has been adopted), and most notably, proofs.  \\nAn essential point here is that when a formula is construed as a natural number, then the numeral corresponding to that natural number can occur as the argument of a formula, thus enabling the syntax to “refer” to itself, so to speak (i.e., when a numeral is substituted into a formula the Gödel number of which the numeral represents). This will eventually allow Gödel to formalize the Liar paradox (with “provability” in place of “truth”) by substituting into the formula which says, ‘the formula, whose code is x, is unprovable,’ its own natural number code (or more precisely the corresponding numeral).  \\nAnother concept required to carry out the formalization is the concept of numeralwise expressibility of number theoretic predicates. A number-theoretic formula φ(n1, …, nk) is numeralwise expressible in P if for each tuple of natural numbers (n1, …, nk):  \\nN ⊨ φ(n1, …, nk) ⇒ P ⊢ φ(n1, …, nk) N ⊨ ¬φ(n1, …, nk) ⇒ P ⊢ ¬φ(n1, …, nk)  \\nwhere n is the formal term which denotes the natural number n. (In P, this is S(S(…S(0)…), where n is the number of iterations of the successor function applied to the constant symbol 0.) One of the principal goals is to numeralwise express the predicate  \\nPrf(x, y): ‘the sequence with Gödel number x is a proof of the sentence with Gödel number y.’  \\nReaching this goal involves defining forty-five relations, each defined in terms of the preceding ones. These relations are all primitive recursive.[10] Relations needed are, among others, those which assert of a natural number that it codes a sequence, or a formula, or an axiom, or that it is the code, denoted by Sb(ru1…unZ(x1)…Z(xn)), of a formula obtained from a formula with code r by substituting for its free variable ui the xi th numeral for i = 1, …, n. The forty-fifth primitive recursive relation defined is Prf(x, y), and the forty-sixth is  \\nProv(y): ‘the sentence with Gödel number y is provable in P’  \\nwhich without being primitive recursive, is however obtained from Prf(x, y) by existentially quantifying x. (Prov(y) satisfies only the ‘positive’ part of numeralwise expressibility, and not the negative part; but the negative part is not needed.)  \\nIn Theorem V of his paper, Gödel proves that any number theoretic predicate which is primitive recursive is numeralwise expressible in P. Thus since Prf(x, y) and substitution are primitive recursive, these are decided by P when closed terms are substituted for the free variables x and y. This is the heart of the matter as we will see. Another key point about numeralwise expressibility is that although we informally interpret, for example, Prov(Sb(ru1…unZ(x1)…Z(xn))), by: ‘the formula with Gödel number r is provable if the Gödel number for the xi th numeral is substituted in place of the i th variable,’ neither the formal statement within the theory P nor anything we prove about it appeals to such meanings. On the contrary Prov(Sb(ru1…unZ(x1)…Z(xn))), is a meaningless string of logical and arithmetical symbols. As Gödel puts it in his introduction to his theorem V, ‘The fact that can be formulated vaguely by saying that every recursive relation is definable in the system P (if the usual meaning is given to the formulas of this system) is expressed in precise language, without reference to any interpretation of the formulas of P, by the following Theorem (V) (Gödel 1986, p. 171, italics Gödel’s).  \\nGödel in his incompleteness theorems uses a method given in what is called nowadays Gödel’s Fixed Point Theorem. Although Gödel constructs a fixed point in the course of proving the incompleteness theorem, he does not state the fixed point theorem explicitly. The fixed point theorem is as follows:  \\nTheorem 2 (Gödel’s Fixed Point Theorem) If φ(v0) is a formula of number theory, then there is a sentence ψ such that P ⊢ ψ ↔ φ(⌈ψ⌉), where ⌈ψ⌉ is the formal term corresponding to the natural number code of ⌈ψ⌉.  \\nProof: Let σ(x,y,z) be a formula that numeralwise expresses the number theoretic predicate ‘y is the Gödel number of the formula obtained by replacing the variable v0 in the formula whose Gödel number is x by the term z’. Let θ(v0) be the formula ∃v1(φ(v1) ∧ σ(v0, v1, v0)). Let k = ⌈θ(v0)⌉ and ψ = θ(k). Now directly by the construction P ⊢ ψ ↔ φ(⌈ψ⌉).  \\nA sentence is refutable from a theory if its negation is provable. The First Incompleteness Theorem as Gödel stated it is as follows:  \\nTheorem 3 (Gödel’s First Incompleteness Theorem) If P is ω-consistent, then there is a sentence which is neither provable nor refutable from P.  \\nProof: By judicious coding of syntax referred to above, write a formula Prf(x,y)[11] of number theory, representable in P, so that  \\nn codes a proof of φ ⇒ P ⊢ Prf(n, ⌈φ⌉).  \\nand  \\nn does not code a proof of φ ⇒ P ⊢ ¬Prf(n, ⌈φ⌉).  \\nLet Prov(y) denote the formula ∃x Prf(x,y)[12]. By Theorem 2 there is a sentence φ with the property  \\nP ⊢ (φ ↔ ¬Prov(⌈φ⌉)).  \\nThus φ says ‘I am not provable.’ We now observe, if P ⊢ φ, then by (1) there is n such that P ⊢ Prf(n, ⌈φ⌉), hence P ⊢ Prov(⌈φ⌉), hence, by (3) P ⊢ ¬φ, so P is inconsistent. Thus  \\nP ⊬ φ  \\nFurthermore, by (4) and (2), we have P ⊢ ¬Prf(n, ⌈φ⌉) for all natural numbers n. By ω-consistency P ⊬ ∃x Prf(x, ⌈φ⌉). Thus (3) gives P ⊬ ¬φ. We have shown that if P is ω-consistent, then φ is independent of P.  \\nOn concluding the proof of the first theorem, Gödel remarks, “we can readily see that the proof just given is constructive; that is … proved in an intuitionistically unobjectionable manner…” (Gödel 1986, p. 177). This is because, as he points out, all the existential statements are based on his theorem V (giving the numeralwise expressibility of primitive recursive relations), which is intuitionistically unobjectionable.'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.2 The Incompleteness Theorems', 'Header 4': '2.2.3 The Second Incompleteness Theorem'}, page_content='The Second Incompleteness Theorem establishes the unprovability, in number theory, of the consistency of number theory. First we have to write down a number-theoretic formula that expresses the consistency of the axioms. This is surprisingly simple. We just let Con(P) be the sentence ¬Prov(⌈0 = 1⌉).  \\nTheorem 4 (Gödel’s Second Incompleteness Theorem) If P is consistent, then Con(P) is not provable from P.  \\nProof: Let φ be as in (3). The reasoning used to infer ‘if P ⊢ φ, then P ⊢ 0 ≠ 1‘ does not go beyond elementary number theory, and can therefore, albeit with a lot of effort (see below), be formalized in P. This yields: P ⊢ (Prov(⌈φ⌉) → ¬Con(P)), and thus by (3), P ⊢ (Con(P) → φ). Since P ⊬ φ, we must have P ⊬ Con(P).  \\nThe above proof (sketch) of the Second Incompleteness Theorem is deceptively simple as it avoids the formalization. A rigorous proof would have to establish the proof of ‘if P ⊢ φ, then P ⊢ 0 ≠ 1’ in P.  \\nIt is noteworthy that ω-consistency is not needed in the proof of Gödel’s Second Incompleteness Theorem. Also note that neither is ¬Con(P) provable, by the consistency of P and the fact, now known as Löb’s theorem, that P ⊢ Prov(⌈φ⌉) implies P ⊢ φ.  \\nThe assumption of ω-consistency in the First Incompleteness Theorem was eliminated by Rosser in 1936, and replaced by the weaker notion of consistency. Rosser’s generalization involves applying the fixed point theorem to the formula R(x): ‘for all z: either z is not the Gödel number of a proof of the formula with Gödel number x or there is a proof shorter than z of the negation of (the formula with Gödel number) x’ (see Rosser 1936).  \\nWith regard to the Second Incompleteness Theorem, the argument relies in part on formalizing the proof of the First Incompleteness Theorem as we saw. This step is omitted in Gödel 1931. He planned to include the step in what would have been a second part II (see footnote 48a of Gödel 1931). But instead of writing it he turned to the continuum problem.[13] (Part II was to elaborate on other points too: the ‘true reason for incompleteness,’ and the applicability of the two theorems to other systems.) He perhaps did not feel compelled to attend to what looked like an exercise in formalization, relying instead on the informal argument to convince (in which it succeeded). However this step turned out to be somewhat non-trivial. As Kleene puts it in his introduction to Gödel 1931, of the informal presentation, “Certainly the idea of the argument for Theorem XI (consistency) was very convincing; but it turned out that the execution of the details required somewhat more work and care than had been anticipated.” (See pp. 126–141 of Gödel 1986.) Eventually a complete proof of the Second Theorem was given by Hilbert and Bernays in some seventy pages in their Hilbert and Bernays 1939. A much more compact treatment of the theorem was given by Löb in his Löb 1956, and subsequently Feferman, in his 1960 “Arithmetization of Metamathematics in a General Setting” (Feferman 1960/1961), gave a succinct and completely general treatment of both the First and Second Theorems. But see the supplementary document:  \\nDid the Incompleteness Theorems Refute Hilbert’s Program?  \\nFor more detailed discussion, see the entry on Gödel’s incompleteness theorems.'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.3 Speed-up Theorems'}, page_content='Gödel’s 1936 ‘Speed-up’ theorem, published in an abstract “On the length of proofs”, Gödel 1936 says that while some sentences of arithmetic are true but unprovable, there are other sentences which are provable, but even the shortest proof is longer than any bound given in advance as a recursive function of the sentence. More exactly:  \\nTheorem 5. Given any recursive function f there are provable sentences φ of arithmetic such that the shortest proof is greater than f(⌈φ⌉) in length.  \\nThe proof we will outline is sensitive to the particular concept we use for the length of a proof. Another possibility, and the one that Gödel has in mind, is the number of formulas in the proof. Buss (see below) proves the theorem in either case, so both cases are resolved.  \\nProof: Let f be total recursive function. By Gödel’s Fixed Point theorem there is a formula φ(n) stating ‘φ(n) has no proof in PA shorter than f(n)’. This is tenable if the length is measured by number of symbols, because we only need to search through finitely many proofs shorter than f(n). Note that φ(n) is true for all n, for if φ(n) were false, then there would be a short proof of φ(n), and hence by soundness φ(n) would be true, a contradiction: φ(n) would both true and false. This can be formalized in PA and thus we get the result that for each n the sentence φ(n) is provable in PA. Since φ(n) is true for all n, it cannot have a proof in PA which is shorter than f(n).  \\nThe Speed-up Theorem is the result of contemplating and elaborating the proof of the incompleteness theorem. It applies the fixed-point technique to the concept of unprovability by a short proof, as opposed to the original idea of applying the fixed-point theorem to mere unprovability. The proof has very much the same flavor as the proof of the incompleteness theorem. Interestingly, it dates from the same year as the construction, due to Rosser, that eliminates the use of ω-consistency in the first Incompleteness Theorem; like the Speed-up Theorem of Gödel, Rosser’s construction exploits the issue of short and long proofs. Gödel never submitted a proof for the Speed-up Theorem. Over the years several related proofs were published, but the first full proof of Gödel’s original result was given only in 1994 by Sam Buss in his ‘On Gödel’s theorems on lengths of proofs I: Number of lines and speedups for arithmetic.’ (Buss 1994). Buss also gives a second proof of the theorem which avoids self-reference, following a technique due to Statman. Gödel measures the length of proofs by the number of formulas; but there are also other possibilities, such as the number of symbols in the proof. The case of the Speed-up Theorem where the length of proof is measured by the number of symbols was proved by Mostowski in 1952 (Mostowski 1982). For proofs of similar results see Ehrenfeucht and Mycieleski 1971, and Parikh 1971. Though both measures may be equally natural candidates for measuring the length of a proof, proving the theorem for length measured by the number of symbols avoids a technical complication introduced by the other measure: there are only finitely many proofs with a given number of symbols, whereas there are infinitely many proofs with a given number of formulas.  \\nGödel states the Speed-up Theorem differently from the above. Let Sn be the system of logic of the n-th order, the variables of the first level being thought of as ranging over natural numbers. In this setting, variables of the second level range over sets of natural numbers and so on. Gödel’s formulation is:  \\nTheorem 6. Let n be a natural number > 0. If f is a computable function, then there are infinitely many formulas A, provable in Sn, such that if k is the length of the shortest proof of A in Sn and l is the length of the shortest proof of A in Sn+1, then k > f(l).  \\nProof sketch: The idea is the following: Let φ(x) be a formula, like above, for which φ(m) does not have a short proof in Sn for any m. Suppose we have a higher type system Sn+1 in which we can prove ∀xφ(x). This proof is of constant length. Thus each φ(m) is derivable from this universal statement by one application of the logical rule ∀xφ(x) → φ(t). Thus φ(m) has in that system for all m a short proof.  \\nWhat kind of stronger system can we have in which ∀xφ(x) is provable? We may consider second order logic in which we can define a predicate N(x) for the set of natural numbers and furthermore can prove of a new predicate symbol Tr(x) that it satisfies the inductive clauses of the truth definition of first order formulas of arithmetic, relativized to N. Then the stronger system can prove that provable first order sentences of arithmetic satisfy the predicate Tr . By the above argument, we can prove in the stronger system that ∀xφ(x) satisfies Tr. Then by adding a few lines we can prove each φ(n) satisfies Tr. Because of the nature of φ(n), this implies the stronger system has a (short) proof of φ(n). An alternative system is Peano’s axioms PA in an extended language where we have a new predicate symbol Tr and axioms stating that the predicate Tr codes the satisfaction relation for all sentences of the vocabulary not containing Tr.'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory', 'Header 4': '2.4.1 The consistency of the Continuum Hypothesis and the Axiom of Choice'}, page_content='Gödel’s proof of the consistency of the continuum hypothesis with the axioms of Zermelo-Fraenkel set theory is a tour de force and arguably the greatest achievement of his mathematical life. This is because aside from the arithmetization, virtually all of the technical machinery used in the proof had to be invented ab initio.  \\nThe Continuum Hypothesis (henceforth CH) was formulated by Georg Cantor, and was the first problem on Hilbert’s list of twenty-three unsolved problems as given in his famous address to the International Mathematical Congress in Paris in 1900. The problem as stated by Hilbert is as follows: Let A be an infinite set of real numbers. Then A is either countable, or has cardinality 2ℵ0, i.e., A is in one-to-one correspondence either with the set of natural numbers or with the set of all real numbers (otherwise known as the continuum). Another way to state the continuum hypothesis is that (the first uncountably infinite cardinal) ℵ1 = 2ℵ0.  \\nAs early as 1922 Skolem speculated that the CH was independent of the axioms for set theory given by Zermelo in 1908. Nevertheless Hilbert published a (false) proof of the CH in Hilbert 1926. In 1937 Gödel proved its consistency with the axioms of ZF set theory. (Henceforth we use the standard abbreviations for Zermelo-Fraenkel set theory, ZF, and Zermelo-Fraenkel set theory with the Axiom of Choice, ZFC.) The consistency of the negation of the CH was shown by Paul Cohen in 1961 (see Cohen 1963) and hence together with Gödel’s result one infers that the CH is independent of ZF (and ZFC).  \\nCohen invented an important new technique called forcing in the course of proving his result; this technique is at present the main method used to construct models of set theory. Forcing led to a revival of formalism among set theorists, the plurality of models being an indication of the “essential variability in set theory,” (Dehornoy 2004) and away from the notion that there is an intended model of set theory—a perspective Gödel advocated since at least 1947, if not earlier.[14] Recently there have been signs that the CH may again be coming to be regarded as a problem to be solved mathematically (with the help of course of some new evident axioms extending ZF). (See for example Woodin 2001a, 2002, 2001b, and Foreman 1998.) If any of the proposed solutions gain acceptance, this would confirm Gödel’s view that the CH would eventually be decided by finding an evident extension of the ZF axioms for set theory. The program associated with this view is called “Gödel’s Large Cardinal Program.”'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory', 'Header 4': '2.4.2 Gödel’s Proof of the Consistency of the Continuum Hypothesis and the Axiom of Choice with the Axioms of Zermelo-Fraenkel Set Theory'}, page_content='The continuum problem is shown to be consistent with ZF by finding an enumeration of the reals which is indexed by the countable ordinals, a strategy which had been recognized as a promising one already by Hilbert.[15] The problem, and the intuition behind the proof, is to build a “small” model, one in which the absolute minimum number of reals is allowed, while at the same time the model is large enough to be closed under all the operations the ZF axioms assert to exist.  \\nGödel’s is a relative consistency proof, obtained by constructing a so-called “inner model” for ZF together with the CH. An inner model is a subcollection M of the collection V of all sets (see below) which satisfies the axioms of ZF when only sets in M are considered. Gödel’s inner model is called the inner model of constructible sets (see below) and is denoted by L. Whatever is true in an inner model is consistent with ZF for the same reason that any theory with a model is consistent. An artifact of the construction is that the Axiom of Choice (henceforth AC) is satisfied in Gödel’s inner model and hence the consistency of the AC with ZF was established by Gödel. Later on it was shown by Sierpinski that the AC is actually a consequence of the Generalized Continuum Hypothesis or the GCH, which states that for each κ, 2κ = κ+ (see Sierpinski 1947).  \\nGödel published two versions of these theorems, in 1939 and in 1940, entitled “Consistency Proof for the Generalized Continuum Hypothesis,” and “The Consistency of the Axiom of Choice and of the Generalized Continuum Hypothesis with the Axioms of Set Theory,” respectively. Though completely definitive, the 1939 version is lacking in a great many details, most notably the arguments showing that if L is built inside L itself, the same L results; that is to say, the so-called absoluteness arguments are missing. Also missing are the details of the proofs that the ZF axioms hold in L. Unlike the case of the Second Incompleteness Theorem, however, Gödel subsequently gave a completely detailed proof of the two theorems in the 1940 monograph. (The 1940 proof differs substantially from the first version. For details about the two proofs and the difference between them the reader is referred to Solovay 1990 and Kanamori 2006.)  \\nWe now sketch the proof of the consistency of CH and of AC with ZFC, using modern terminology. Some preliminary concepts before sketching the proof: We first define the stratified set theoretic universe, denoted V. (V is also known as the cumulative hierarchy.) It is obtained by iteration of the power set operation (℘) beginning with the null set:  \\nV0 = ∅, Vα+1 = ℘(Vα), Vγ = ∪β<γ Vβ,  \\nwhere α, β are any ordinals, γ is a limit ordinal and ℘(x) denotes the power set of x. Finally  \\nV = ∪α∈Ord Vα,  \\nwhere Ord denotes the class of all ordinals.  \\nThe constructible hierarchy L is likewise defined by recursion on ordinals. But whereas the full power set operation is iterated to obtain the cumulative hierarchy, the levels of the constructible hierarchy are defined strictly predicatively, that is by including at the next level only those sets which are first order definable using parameters from the previous level. More exactly, let Def(A) denote the set of all subsets of A definable in the structure < A, ∈ > by first order formulas with parameters in A. (For more on definability see the entry on model theory in this encyclopedia.)  \\nWith this notation the constructible hierarchy is defined by induction over the ordinals as follows:  \\nL0 = ∅, Lα+1 = Def(Lα), Lγ = ∪α<γ Lα, L = ∪α∈Ord Lα,  \\nA set x is said to be constructible if x ∈ L. The axiom which states that all sets are constructible is denoted V = L and is called the Axiom of Constructibility. Note that L is a proper class and not a set; although as we will see, each Lα is a set, and the predicate “x is constructible” is actually a definable term of the language.  \\nOur next task is to show that L is a model of ZF. A set or a class is transitive if elements of it are also subsets. By a meticulous transfinite induction, Lα can be shown to be transitive for each α; and therefore so is L itself. This fact, together with the observation that some elementary closure properties hold in L [16] is enough to show that L is a model of ZF. (Indeed, as it turns out, L is the minimal transitive model of the ZF axioms containing all the ordinals, and is therefore in this sense canonical.)  \\nIn detail, proving that the ZF axioms, apart from the comprehension axiom, are true in L, amounts to showing that, roughly speaking, any set with a property P that a ZF axiom asserts to exist, can be seen to exist in L by considering the relativization PL of the property P to L. (A property P is relativized to an inner model M by replacing every quantifier ∃xφ by ∃x(x ∈ M ∧ φ) and every quantifier ∀xφ by ∀x(x ∈ M→ φ).) As for the comprehension axiom, verifying it requires showing that the set asserted to exist is constructed at a particular successor level Lα + 1. Proving this requires an important principle of set theory which in modern terminology is called the Levy (or ZF) Reflection Principle. This principle says that any statement in the language of ZF which is true in V is already true on some level of any continuously increasing hierarchy such as L. (For the history of this principle, see Kanamori 2006.) The Levy Reflection Principle gives the level α at which the elements of the set are all constructed. Gödel did not actually have the Levy Reflection Principle but used the argument behind the proof of the principle.  \\nOnce it is established that L is a model of ZF, one can now prove that both the CH and the AC hold in L. To this end, one first shows that the definition of L is absolute for L, where absoluteness is defined as follows: given a class M, a predicate P(x) is said to be absolute for M if and only if for all x ∈ M, P(x) ↔ PM(x).  \\nProving that the predicate “x is constructible” is absolute requires formalizing the notion of definability, which in turn requires formalizing the notion of satisfaction. This is because the predicate “x is constructible” says of a set, that for some ordinal α, and for some formula φ with parameters in Lα, x = {y ∈ Lα | Lα ⊨ φ(y)}. This part of the proof is tedious but unproblematic.  \\nOnce the absoluteness of L is established, it follows that ZF satisfies the axiom of constructibility if it is relativized to L; that is, ZF ⊢ (V=L)L. In particular, the axiom V = L is consistent if ZF is.  \\nWe now give the idea of the proof of CH and AC in ZF + V = L. (For a detailed exposition of the proof, the reader is referred to the standard sources. See for example Devlin’s chapter on constructibility in Barwise 1977; see also Kunen 1983, and Jech 2003.)  \\nAs concerns the CH, the idea behind the proof of it in L is simply the following: Gödel showed that assuming V = L, every real number occurs on some countable level of the L-hierarchy. Since every countable level is itself countable (after all, there are only countably many possible defining formulas), and there are ω1 countable levels, there must be only ω1 real numbers.  \\nThe difficulty here, if not of the whole proof altogether, lies in showing that every real is constructed already on a countable level of the L-hierarchy. To show this Gödel argued as follows: Suppose A is a real number thought of as a set of natural numbers. By a combination of the Levy Reflection principle and the Löwenheim-Skolem Theorem there is a countable submodel < M, ∈ > of < L, ∈ > satisfying a sufficiently large finite part of the ZF axioms + V = L, such that A belongs to M. By a simple procedure < M, ∈ > can be converted into a transitive model < N, ∈ >. This procedure, used by Gödel already in 1937, was explicitly isolated by Mostowski (Mostowski 1949). The resulting model is referred to as the Mostowski Collapse.  \\nLet us pause to discuss this important technique. Suppose < M, E> is a well-founded model of the axiom of extensionality. It is a consequence of the well-foundedness of the binary predicate E on M, and of the principle of transfinite recursion, that the equation π(x) = {π(y)\\u2009|\\u2009y ∈ M ∧ yEx} defines a unique function on M. The range N of π is transitive, for if π(a) ∈ N and y ∈ π(a), then y = π(b) for some b ∈ M with bEa, whence π(b) ∈ N. The fact that π is an isomorphism between < M, E> and < N, ∈ > can be proved by transfinite induction on elements on M, based again on the well-foundedness of E. The well-foundedness of < M, E> is in practice often the consequence of < M, E> being a submodel of some < Vα, ε >.  \\nWe now return to the proof of the CH in L. We used the Mostowski Collapse to construct the transitive set N. As it turns out, the real number A is still an element of < N, ∈ > . By basic properties of L, < N, ∈ > must be < Lα , ∈ > for some α . Since N is countable, α is countable too. (It can be shown that |Lα| = |α| + ℵ0.) Thus A is constructible on a countable level, which was to have been shown.  \\nAs for the AC, Gödel exhibits a definable well-ordering, that is, a formula of set theory which defines, in L, a well-ordering of all of L. The formula is tedious to write down but the idea is a simple one: A set x precedes a set y in the well-ordering if and only if either x occurs in the L-hierarchy on an earlier level Lα than y, or else they occur on the same level but x is defined by a shorter formula than y, or else they are defined by the same formula but the parameters in the definition of x occur in L earlier than the parameters of y. This well-ordering of L shows that the AC holds in L.  \\nThis concludes the proof of the consistency of AC and the CH in L.  \\nWe note that Gödel proved more in his 1939 and 1940 than what was shown here, namely he proved the Generalized Continuum Hypothesis in L and hence that its consistency with ZF.'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory', 'Header 4': '2.4.3 Consequences of Consistency'}, page_content='As noted above, it was suggested already in the 1920s that the CH might be independent of ZF or ZFC. After first conjecturing that the Axiom of Constructibility might be “absolutely consistent,” meaning not falsifiable by any further extension of models of ZF + V = L,[17] in his 1947 “What is Cantor’s Continuum Hypothesis?” Gödel conjectured that the CH would be shown to be independent. The main consequence of Gödel’s result, then, as far as the problem of proving the independence of the CH is concerned, was that it pointed mathematicians in the direction of adding non-constructible sets to a model of set theory in order to establish the consistency of the negation of the CH. In 1961 Dana Scott proved that the failure of the Axiom of Constructibility follows from the existence of a measurable cardinal, contrary to a conjecture Gödel had made in 1940. (See Scott 1961. A cardinal κ is said to be measurable if there is a non-principal κ-complete ultrafilter in the power-set Boolean algebra of κ.) In 1963, as noted, Paul Cohen proved the consistency of the negation of the CH by adding non-constructible sets to an inner model.  \\nWhat other open questions of set theory could be solved by Gödel’s method? Gödel himself noted some consequences. They are related to so called projective sets of real numbers and finite sequences of real numbers. The simplest projective sets are the closed sets, also called Π10-sets. A set is Σ1n+1 if it is the projection of a Π1n-subset of the real plane. A set is Δ1n+1 if it and its complement are Σ1n+1. Gödel observed that there is both a non-Lebesgue measurable Δ12-set and an uncountable Π11-set without a perfect subset in L. (A set of reals is perfect if it is closed, non-empty, and has no isolated points. Such sets have the size of the continuum.) Gödel gave a sketch of the proof in the 1951 second printing of Gödel 1940.  \\nIt has turned out subsequently that the axiom V = L gives a virtually complete extension of ZFC. This means that, apart from sentences arising from Gödel’s incompleteness theorems, essentially all set-theoretical questions can be decided by means of the axioms V = L. This is not to imply that such results are in any way trivial. Indeed, it has turned out that L is quite a complicated structure, despite its relatively simple description. As for settling open set-theoretical questions in L, the main step was the emergence of Jensen’s fine structure theory of L (Jensen 1972). Recalling that the successor step Lα +1 in the definition of the constructible hierarchy adds to L all subsets of Lα definable by first order formulas φ over (Lα, ∈), fine structure theory, roughly speaking, ramifies the step from Lα to Lα+1 into smaller steps according to the complexity of the defining formula φ. Jensen established by means of his fine structure a strengthening, denoted by ◊, of CH, that he used to construct a Souslin tree in L, and a combinatorial principle □ that he used to show that the Souslin Hypothesis is consistent with CH.'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.4 Gödel’s Work in Set theory', 'Header 4': '2.4.4 Gödel’s view of the Axiom of Constructibility'}, page_content='If he did not think this way from the outset, Gödel soon came to adopt the view that the Axiom of Constructibility was implausible. As he remarked at the end of his 1947 “What is Cantor’s Continuum Hypothesis?”  \\n…it is very suspicious that, as against the numerous plausible propositions which imply the negation of the continuum hypothesis, not one plausible proposition is known which would imply the continuum hypothesis. (Gödel 1990, p. 186)  \\nGödel was compelled to this view of L by the Leibnizian[18] idea that, rather than the universe being “small,” that is, one with the minimum number of sets, it is more natural to think of the set theoretic universe as being as large as possible.[19]This idea would be reflected in his interest in maximality principles, i.e., principles which are meant to capture the intuitive idea that the universe of set theory is maximal in the sense that nothing can be added; and in his conviction that maximality principles would eventually settle statements like the CH. As Gödel put it in a letter to Ulam in the late 1950s, about a maximality principle of von Neumann:  \\nThe great interest which this axiom has lies in the fact that it is a maximality principle, somewhat similar to Hilbert’s axiom of completeness in geometry. For, roughly speaking, it says that any set which does not, in a certain well defined way, imply an inconsistency exists. Its being a maximum principle also explains the fact that this axiom implies the axiom of choice. I believe that the basic problems of set theory, such as Cantor’s continuum problem, will be solved satisfactorily only with the help of stronger axioms of this kind, which in a sense are opposite or complimentary to the constructivistic interpretation of mathematics. (Ulam 1958, as quoted in Gödel 1990, p. 168; original emphasis. Note that this is different from the very similar passage Gödel 2003b, p.295.)  \\nTwenty years earlier, in 1938, Gödel had written seemingly differently about the Axiom of Constructibility:  \\nThe proposition A (i.e., V = L) added as a new axiom seems to give a natural completion of the axioms of set theory, in so far as it determines the vague notion of an arbitrary infinite set in a definite way. (Gödel 1986, p.27)  \\nGödel may have meant by “natural completion” here “the correct completion,” or he may have meant to say no more than that the Axiom of Constructibility determines the notion of set in a definite way. In any case he used the term “natural” differently in a conversation with Wang on constructibility in 1972 (Wang 1996, p. 144):  \\nGödel talked more about the relation between axioms of infinity and the constructible universe…(he observed that) preliminary concepts such as that of constructible sets are necessary to arrive at the natural concept, such as that of set.  \\nThis is reminiscent of a remark of Hugh Woodin, that studying forcing leads to a better understanding of V — the general principle being that studying the models of a theory is not only useful to understand the theory itself, but useful to obtain a better picture of V (Woodin 1988).  \\nFor more on Gödel’s program and on Gödel’s program relative to the CH the reader is referred e.g., to Steel forthcoming and Feferman et al. 2000. For more on Gödel’s result, its history , and its significance the reader is referred to Floyd/Kanamori 2006 and Kennedy 2006.'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic'}, page_content='Gödel’s interest in intuitionism was deep and long-lasting. Although he himself did not subscribe to that view, he made a number of important contributions to intuitionistic logic. Perhaps the importance he placed on the concept of evidence (see below) led to his close consideration of it.  \\nWe discuss Gödel’s results on intuitionistic logic in their chronological order.'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic', 'Header 4': '2.5.1 Intuitionistic Propositional Logic is not Finitely-Valued'}, page_content='Both many-valued logic, introduced by Łukasiewicz in the twenties (Łukasiewicz 1970) and intuitionistic logic, formalized by Heyting in 1930, fail to satisfy the law of excluded middle. It was therefore natural to ask whether intuitionistic logic can be presented as a many-valued logic, and indeed a number of logicians in the 1920s had suggested just that. In his 1932 Gödel gave a simple argument which shows that intuitionistic propositional logic cannot be thought of as a finitely-valued logic. Precisely, Gödel proved two theorems:  \\nTheorem 7. There is no realization with finitely many elements (truth values) for which the formulas provable in H, and only those, are satisfied (that is, yield designated values for an arbitrary assignment).  \\n(H is intuitionistic propositional logic, after Heyting.)  \\nTheorem 8. Infinitely many systems lie between H and the system A of the ordinary propositional calculus, that is, there is a monotonically decreasing sequence of systems all of which include H as a subset and are included in A as subsets.  \\nIn his proof he considered for each natural number n > 0 the sentence  \\nFn = ∨1 ≤ i < j ≤ n pi ≡ pj.  \\nHe observed that in an n-valued logic the sentences Fm, for m > n, should be derivable. However, Gödel showed, Fn is not derivable from Heyting’s axioms for any n.  \\nSubsequently Jaśkowski (Jaśkowski 1936) showed that intuitionistic propositional logic can be given a many-valued semantics in terms of infinitely many truth-values. For further discussion of many-valued logics, see for example the entry on many-valued logic in this encyclopedia as well as van Stigt’s article on intuitionistic logic in Mancosu 1998.'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic', 'Header 4': '2.5.2 Classical Arithmetic is Interpretable in Heyting Arithmetic'}, page_content='We now consider Gödel 1933e, in which Gödel showed, in effect, that intuitionistic or Heyting arithmetic is only apparently weaker than classical first-order arithmetic. This is because the latter can be interpreted within the former by means of a simple translation, and thus to be convinced of the consistency of classical arithmetic, it is enough to be convinced of the consistency of Heyting arithmetic. Heyting arithmetic is defined to be the same as classical arithmetic, except that the underlying predicate logic is given by intuitionistic axioms and rules of inference (see below).  \\nThis result extends the same assertion for the propositional case. Let H denote the intuitionistic propositional logic, and A denote its classical counterpart (as above). Inductively define:  \\nA′ ≡ ¬¬A (A atomic) (¬A)′ ≡ ¬A′ (A → B)′ ≡ ¬(A′ ∧ ¬B′) (A ∨ B)′ ≡ ¬(¬A′ ∧ ¬B′) (A ∧ B)′ ≡ A′ ∧ B′  \\nThen,  \\nTheorem 9. Let F be a propositional formula. Then H ⊢ F if and only if A ⊢ F′,  \\nThe theorem follows easily from the result of Glivenko (1929) that ¬F follows from H if and only if ¬F follows from A, for any propositional formula F.  \\nGödel’s so-called double negation interpretation extends Theorem 9 to a reduction of classical first order logic to intuitionistic predicate logic. The translation in this case can be taken to map A′ to A for atomic A. Moreover, we let ∀xA(x)′ = ∀xA′(x) :  \\nTheorem 10. Suppose A is a first order formula. If A is provable in classical first order logic, then A′ is provable in intuitionistic first order logic.  \\nThe above result had been obtained independently by Gentzen (with Bernays), but upon hearing of Gödel’s result Gentzen withdrew his paper from publication. It had also been anticipated by Kolmogorov in his 1925 “On the Principle of the Excluded Middle,” (English translation van Heijenoort 1967) but that paper was largely unknown to logicians who were outside of Kolmogorov’s circle.  \\nBernays has written (see Bernays’ entry on David Hilbert in Edwards 1967) that this result of Gödel’s drew the attention of the Hilbert school to two observations: first, that intuitionistic logic goes beyond finitism, and secondly, that finitist systems may not be the only acceptable ones from the foundational point of view.  \\nThe following theorem for the case of arithmetic follows from Theorem 10:  \\nTheorem 11. Suppose A is a first order formula of arithmetic. If A is provable in classical Peano arithmetic, then A′ is provable in intuitionistic first order arithmetic.  \\nFor a list of the axioms and rules of intuitionistic first order logic see Gödel 1958, reprinted with detailed introductory note by A.S. Troelstra in Gödel 1990. See also Troelstra 1973, and Troelstra’s “Aspects of constructive mathematics” in Barwise 1977. For a detailed proof of the above theorem the reader is referred also to the latter.'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic', 'Header 4': '2.5.3 Intuitionistic Propositional Logic is Interpretable in S4'}, page_content='This result of Gödel’s (Gödel 1933f), which marks the beginning of provability logic, makes exact the difference between the concept of “provability in a specified formal system” and that of “provability by any correct means.”  \\nGödel had already noted this difference in the introduction to his 1929 thesis. The context was the following: Gödel entertains there the possibility that his proof of the Completeness Theorem might be circular, since the law of excluded middle was used to prove it. This is because while the Completeness Theorem asserts ‘a kind of decidability,’ namely every quantificational formula is either provable or a counterexample to it can be given, ‘the principle of the excluded middle seems to express nothing other than the decidability of every problem’:  \\n… what is affirmed (by the law of excluded middle) is the solvability not at all through specified means but only through all means that are in any way imaginable … [20]  \\nGödel considers intuitionistic propositional logic (henceforth IPL); he also considers a second system, classical propositional logic enriched by an operator “B”, where the intended meaning of “B” is “provable.” The axiom system now known as S4 (for a list of these axioms see for example the entry on modal logic in this encyclopedia) is added to the standard axioms for classical propositional logic together with a new rule of proof: from A, BA may be inferred. Let us call this second system G. Gödel’s theorem states that IPL is interpretable in G via the following translation:  \\n¬p ≡ ~Bp p ⊃ q ≡ Bp → Bq p ∨ q ≡ Bp ∨ Bq p ∧ q ≡ Bp ∧ Bq  \\nThat is,  \\nTheorem 12. Let A be a formula of IPL, and let A′ be its translation. Then IPL ⊢ A implies G ⊢ A′.  \\nGödel conjectures that the converse implication must be true, and indeed this was shown in McKinsey and Tarski 1948.  \\nThe difference between the two notions of provability: “provable in a given formal system S” and provability by any correct means — manifests itself as a consequence of Gödel’s Second Incompleteness Theorem, as follows. Let S contain Peano arithmetic, and let the operator B be interpreted as “provable in S”. If the axioms of S4 were valid for this interpretations of B, then from B(0 ≠ 1) → (0 ≠ 1), the sentence ¬B(0 ≠ 1) would be provable, contradicting the Second Incompleteness Theorem.  \\nFor further discussion of Gödel’s theorem, its antecedents and its extensions, as well as its philosophical significance, the reader is referred to A.S Troelstra’s introduction to 1933f.'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': '2. Gödel’s Mathematical Work', 'Header 3': '2.5 Gödel’s Work in Intuitionistic Logic and Arithmetic', 'Header 4': '2.5.4 Heyting Arithmetic is Interpretable into Computable Functionals of Finite Type.'}, page_content='Gödel’s so-called Dialectica intepretation (Gödel 1958) delivers a relative consistency proof and justification for Heyting arithmetic by means of a concrete interpretation involving a system T of computable functionals of finite type. Taken together with his 1933e, which reduces classical first order arithmetic to Heyting arithmetic, a justification in these terms is also obtained for classical first order arithmetic.  \\nGödel’s inductive definition of the notion “function of finite type” is as follows: (Gödel 1990, p. 245).  \\nThe functionals of type 0 are the natural numbers. If t0,…, tk are types and we have already defined what functionals of types t0,…,tk are, then (t0,…, tk) is a type and a functional of that type assigns to every k-tuple of functionals of respective types t1,…, tk, a functional of type t0.  \\nGödel considers the quantifier free theory of these functionals of finite type, denoted by T. T has the following features: the language of T contains variables of each type, constants for distinguished types, and a ternary predicate =σ for equality for type σ. Equality between terms of the same type is decidable. The non-logical axioms and rules for T include the classical arithmetic axioms for 0 and successor, and the induction rule:  \\n(F(0) ∧ (F(x0) → F(S(x0)))) → F(x0)  \\nfor quantifier-free formulas F(x0). As Gödel remarks (Gödel 1990, p. 247), the axioms for T are essentially those of primitive recursive arithmetic, except that the variables can be of any finite type.  \\nGödel’s translation associates with every formula F(x) of the language of Peano arithmetic a formula F′(x) = ∃y∀zA(y, z, x) of the language of the theory T, where A is quantifier free and the (boldface) bound variables are finite sequences of variables thought to range over functionals of a finite type determined by the type of the variable. Intuitively, y is a concrete analogue of the abstract notion of a construction constituting the meaning of F.  \\nGödel’s theorem is as follows:  \\nTheorem 13. Suppose F′ = ∃y∀zA(y, z, x). If F is provable in intuitionistic first order arithmetic, then there are computable functionals Q of finite type such that A(Q(x), z, x) is provable in T.  \\nThe proof is by induction on the structure of the proof of F in intuitionistic first order arithmetic. (For a treatment of the proof in detail, the reader is referred to Troelstra 1986.)  \\nThe importance of the theorem for foundations cannot be overstated.[21] A discussion of its generalizations, of ensuing work on functional interpretations stimulated by the theorem due to Kreisel, Tait, Howard, Feferman and others; its foundational and philosophical significance; and finally its relation particularly to the earlier, informal, proof interpretation, so-called, given by Heyting-Kolmogorov, will not be attempted here. Accordingly the reader is referred to the large literature on the subject, e.g., the abovementioned Troelstra 1986, Tait 1967, Feferman 1993 and Avigad & Feferman 1998. For interesting recent developments, e.g., in the area of relating Gödel’s Dialectica interpretation and Kreisel’s modified realizability, see Oliva 2006. See also van Oosten 2008.  \\nA remark concerning the philosophical context in which Gödel presented his translation, namely finitism. The question addressed in the introduction to the paper is what abstract notions must be added to finitary mathematics in order to obtain a consistency proof for arithmetic. Equivalently: what does the finitary view presuppose, which must be given up in the light of the Second Incompleteness Theorem, if the consistency proof is to be obtained:  \\nIn any case Bernays’ remark teaches us to distinguish two components of the finitary attitude; namely, first, the constructive element, which consists in our being allowed to speak of mathematical objects only insofar as we can exhibit them or actually produce them by means of a construction; second, the specifically finitistic element, which makes the further demand that the objects about which we make statements, with which the constructions are carried out and which we obtain by means of these constructions, are ‘intuitive’, that is, are in the last analysis spatiotemporal arrangements of elements whose characteristics other than their identity or nonidentity are irrelevant.… It is the second requirement that must be dropped. This fact has hitherto been taken into account by our adjoining to finitary mathematics parts of intuitionistic logic and the theory of ordinals. In what follows we shall show that, for the consistency proof of number theory, we can use, instead, the notion of computable function of finite type on the natural numbers and certain rather elementary principles of construction for such functions. (Gödel 1990, p.245).  \\nAside from its technical contribution, then, Gödel’s 1958/72 is one of Gödel’s most important philosophical works; notable for its analysis of the nature of finitary mathematics, as well as its analysis of the notions of “intuitive,” as in “intuitive knowledge,” and that of abstract versus concrete evidence.  \\nIn the next section, we turn to Gödel’s philosophical views. But interested readers may wish to read a brief discussion about Gödel’s Nachlass, important source of philosophical material by Gödel:  \\nSupplement Document: Gödel’s Documents'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': '3. Gödel’s Philosophical Views'}, page_content='Gödel’s philosophical views can be broadly characterized by two points of focus, or, in modern parlance, commitments. These are: realism, namely the belief that mathematics is a descriptive science in the way that the empirical sciences are. The second commitment is to a form of Leibnizian rationalism in philosophy; and in fact Gödel’s principal philosophical influences, in this regard particularly but also many others, were Leibniz, Kant and Husserl. (For further discussion of how these philosophers influenced Gödel, see van Atten and Kennedy 2003.)  \\nThe terms “Gödel’s realism” and “Gödel’s rationalism” must be prefaced with a disclaimer: there is no single view one could associate with each of these terms. Gödel’s realism underwent a complex development over time, in both the nature of its ontological claims as well as in Gödel’s level of commitment to those claims. Similarly Gödel’s rationalism underwent a complex development over time, from a tentative version of it at the beginning, to what was adjudged to be a fairly strong version of it in the 1950s. Around 1959 and for some time afterward Gödel fused his rationalistic program of developing exact philosophy with the phenomenological method as developed by Husserl.  \\nWe examine these two strains of Gödel’s thinking below:'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': '3. Gödel’s Philosophical Views', 'Header 3': '3.1 Gödel’s Rationalism'}, page_content='Gödel’s rationalism has its roots in the Leibnizian thought that the world, not that which we immanently experience but that which itself gives rise to immanent experience, is perfect and beautiful, and therefore rational and ordered. Gödel’s justification of this belief rests partly on an inductive generalization from the perfection and beauty of mathematics:  \\nRationalism is connected with Platonism because it is directed to the conceptual aspect rather than toward the (real) world. One uses inductive evidence…Mathematics has a form of perfection…We may expect that the conceptual world is perfect, and, furthermore, that objective reality is beautiful, good, and perfect. (Wang 1996, 9.4.18)  \\nOur total reality and total experience are beautiful and meaningful—this is also a Leibnizian thought. We should judge reality by the little which we truly know of it. Since that part which conceptually we know fully turns out to be so beautiful, the real world of which we know so little should also be beautiful. (9.4.20)  \\nAlthough the roots of Gödel’s belief in rationalism are metaphysical in nature, his long-standing aspirations in that domain had always been practical ones. Namely, to develop exact methods in philosophy; to transform it into an exact science, or strenge Wissenschaft, to use Husserl’s term.  \\nWhat this means in practice is taking the strictest view possible of what constitutes the dialectical grounds for the acceptance of an assertion; put another way, a level of rigor is aspired to in philosophical arguments approaching that which is found in mathematical proofs. A formulation of the view—one which is somewhat phenomenologically colored (see below)—can be found in a document in the Gödel Nachlass. This is a fourteen item list Gödel drew up in about 1960, entitled “My Philosophical Viewpoint.” Two items on the list are relevant here:  \\nThere are systematic methods for the solution of all problems (also art, etc.).  \\nThere is a scientific (exact) philosophy and theology, which deals with concepts of the highest abstractness; and this is also most highly fruitful for science.  \\n(The list was transcribed by Cheryl Dawson and was published in Wang 1996, p. 316.)  \\nGödel’s earlier conception of rationalism refers to mathematical rigor and includes the concept of having a genuine proof, and is therefore in some sense a more radical one than that to which he would later subscribe. One can see it at work at the end of the Gibbs lecture, after a sequence of arguments in favor of realism are given:  \\nOf course I do not claim that the foregoing considerations amount to a real proof of this view about the nature of mathematics. The most I could assert would be to have disproved the nominalistic view, which considers mathematics to consist solely in syntactical conventions and their consequences. Moreover, I have adduced some strong arguments against the more general view that mathematics is our own creation. There are, however, other alternatives to Platonism, in particular psychologism and Aristotelian realism. In order to establish Platonic realism, these theories would have to be disproved one after the other, and then it would have to be shown that they exhaust all possibilities. I am not in a position to do this now; however I would like to give some indications along these lines. (Gödel 1995, p. 321–2).  \\n(For a penetrating analysis of this passage see Tait 2001.) Such an analysis must be based on conceptual analysis:  \\nI am under the impression that after sufficient clarification of the concepts in question it will be possible to conduct these discussions with mathematical rigour and that the result will then be…that the Platonistic view is the only one tenable. (Gödel 1995, p. 322).  \\nAlong with the methodological component, as can be seen from the items on Gödel’s list, there was also an “optimistic” component to Gödel’s rationalism: once the appropriate methods have been developed, philosophical problems such as, for example, those in ethics (e.g., item 9 on the list is: “Formal rights comprise a real science.”) can be decisively solved. As for mathematical assertions, such as the Continuum Hypothesis in set theory, once conceptual analysis has been carried out in the right way, that is, once the basic concepts, such as that of “set,” have been completely clarified, the Continuum Hypothesis should be able to be decided.  \\nAlthough at the time of the Gibbs lecture the analogy in Gödel’s mind between philosophical and mathematical reasoning may have been a very close one, Gödel’s view at other periods was that the envisaged methods will not be mathematical in nature. What was wanted was a general, informal science of conceptual analysis.  \\nPhilosophy is more general than science. Already the theory of concepts is more general than mathematics…True philosophy is precise but not specialized.  \\nPerhaps the reason why no progress is made in mathematics (and there are so many unsolved problems), is that one confines oneself to the ext[ensional]—thence also the feeling of disappointment in the case of many theories, e.g., propositional logic and formalisation altogether. (Wang 1996, 9.3.20, 9.3.21)[22]  \\n(See notebook Max IV, p. 198 (Gödel Nachlaß, Firestone Library, Princeton, item 030090). Transcription Cheryl Dawson; translation from the German ours; amendment ours. Gödel’s dating of Max IV indicates that it is from May 1941 to April 1942. See also Gödel’s letter to Bernays, Gödel 2003a, p. 283.)  \\nAn important source for understanding Gödel’s advance toward a general theory of concepts are Gödel’s remarks on conceptual analysis published by Hao Wang in Logical Journey. In remark 8.6.10 for example, Gödel expresses the belief that extensionality fails for concepts, contrary to what he said in his 1944 “Russell’s Mathematical Logic,” a remark which he now wishes to retract:  \\nI do not (no longer) believe that generally sameness of range is sufficient to exclude the distinctness of two concepts.  \\nIn some of Gödel’s later discussions another component of conceptual analysis emerges, namely the project of finding the so-called primitive terms or concepts, and their relations. These are roughly terms or concepts which comprise a theoretical “starting point,” on the basis of their meaning being completely definite and clear. For example, the concept of “the application of a concept to another concept” is a primitive term, along with “force”. (Wang 1996, 9.1.29).  \\nHe spoke to Wang about the general project in 1972:  \\nPhenomenology is not the only approach. Another approach is to find a list of the main categories (e.g., causation, substance, action) and their interrelations, which, however, are to be arrived at phenomenologically. The task must be done in the right manner. (Wang 1996, 5.3.7).  \\nGödel spoke with Sue Toledo between 1972 and 1975 about the project of finding primitive terms, as well as other aspects of phenomenology. See Toledo 2011. We discuss Gödel’s involvement with phenomenology further in the supplementary document Gödel’s Turn to Phenomenology.  \\nThe judgement levied upon Gödel’s rationalism by contemporary philosophers was a harsh one. (See for example Gödel 1995, pp. 303–4). Nevertheless Gödel himself remained optimistic. As he commented to Wang:  \\nIt is not appropriate to say that philosophy as rigorous science is not realizable in the foreseeable future. Time is not the main factor; it can happen anytime when the right idea appears. (Wang 1996, 4.3.14).  \\nGödel concluded his 1944 on a similarly optimistic note.'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': '3. Gödel’s Philosophical Views', 'Header 3': '3.2 Gödel’s Realism'}, page_content='Gödel’s realist views were formulated mostly in the context of the foundations of mathematics and set theory.  \\nWe referred above the list “What I believe,” thought to have been written in 1960 or thereabouts. Out of 14 items, only two refer to realism, remarks 10 and 12:  \\nMaterialism is false.  \\nConcepts have an objective existence.  \\nGödel published his views on realism for the first time in his 1944. The following is one of his most quoted passages on the subject:  \\nClasses and concepts may, however, also be conceived as real objects, namely classes as “pluralities of things,” or as structures consisting of a plurality of things and concepts as the properties and relations of things existing independently of our definitions and constructions.  \\nIt seems to me that the assumption of such objects is quite as legitimate as the assumption of physical bodies and there is quite as much reason to believe in their existence. They are in the same sense necessary to obtain a satisfactory system of mathematics as physical bodies are necessary for a satisfactory theory of our sense perceptions and in both cases it is impossible to interpret the propositions one wants to assert about these entities as propositions about the “data,” i.e., in the latter case the actually occurring sense perceptions.  \\nGödel’s reference to the impossibility of interpreting empirical laws, or more precisely, instantiations of them—the statements “one wants to assert,”—as statements about sense perceptions, is likely an endorsement of the (then) contemporary critique of phenomenalism. The critique was based on the observation that sense data are so inextricably bound up with the conditions under which they are experienced, that no correspondence between statements about those and the statements “we want to assert” can be given (see Chisholm 1948 for example). More generally Gödel was against verificationism, namely the idea that the meaning of a statement is its mode of verification.  \\nThe analogical point in the first part of the passage was amplified by Gödel in the draft manuscript “Is Mathematics a Syntax of Language?”:  \\nIt is arbitrary to consider “This is red” an immediate datum, but not so to consider the proposition expressing modus ponens or complete induction (or perhaps some simpler propositions from which the latter follows). (Gödel 1995, p. 359)  \\nSome writers have interpreted Gödel in this and similar passages pragmatically, attributing to him the view that because empirical statements are paradigmatic of successful reference, reference in the case of abstract concepts should be modelled causally. (See Maddy 1990.) Interpreting reference to abstract objects this way, it is argued, addresses the main difficulty associated with realism, the problem how we can come to have knowledge of abstract objects. Others have argued that Gödel had no paradigm case in mind; that for him both the empirical and the abstract case are either equally problematic, or equally unproblematic. (See Tait 1986.) The latter view is referred to as epistemological parity in van Atten and Kennedy 2003. (See also Kennedy and van Atten 2004.)  \\nIn his 1947 “What is Cantor’s Continuum Problem?”, Gödel expounds the view that in the case of meaningful propositions of mathematics, there is always a fact of the matter to be decided in a yes or no fashion. This is a direct consequence of realism, for if there exists a domain of mathematical objects or concepts, then any meaningful proposition concerning them must be either true or false.[23] The Continuum Hypothesis is Gödel’s example of a meaningful question. The concept “how many” leads “unambiguously” to a definite meaning of the hypothesis, and therefore it should be decidable—at least in principle. Most strikingly Gödel does not leave the matter there but goes on to offer a practical strategy for determining the value of the continuum, as well as the truth value of other axioms extending ZFC. Specifically, he offers two criteria for their decidability: the first involves conceptual analysis and is associated with Gödel’s rationalistic program. (See the above section on Gödel’s rationalism.) Secondly one must keep an eye on the so-called success of the axiom, as a check or indicator of which direction to look to for the solution of its truth. For example, Gödel notes in the paper that none of the consequences of the Axiom of Constructibility are very plausible. It is, then, likely false. See Maddy 2011 and Koellner 2014 for discussion of intrinsic vs extrinsic justifications for new axioms of set theory.  \\nFor further discussion of Gödel’s philosophical views see the supplementary documents:  \\nGödel’s Turn to Phenomenology  \\nand  \\nA Philosophical Argument About the Content of Mathematics'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel'}, page_content='Bibliography Primary Sources Gödel’s Writings The Collected Papers of Kurt Gödel Selected Works of Kurt Gödel [1929] “I”, Dissertation, University of Vienna. Reprinted in Gödel 1986, pp. 60–101. [1930] “Die Vollständigkeit der Axiome des logischen Funktionenkalküls”, Monatshefte für Mathematik und Physik, 37: 349–360. Reprinted in Gödel 1986, pp. 102–123. [1931] “Über formal unentscheidbare Sätze der Principia Mathematica und verwandter Systeme, I”, Monatshefte für Mathematik und Physik, 38: 173–198. Reprinted in Gödel 1986, pp. 144–195. [1932] “Zum intuitionistischen Aussagenkalkül”, Anzeiger der Akademie der Wissenschaften in Wien, 69: 65–66. Reprinted in Gödel 1986, pp. 222–225. [1933e] “Zur intuitionistischen Arithmetik und Zahlentheorie”, Ergebnisse eines mathematischen Kolloquiums, 4: 34–38. Reprinted in Gödel 1986, pp. 286–295. [1933f] “Eine Interpretation des intuitionistischen Aussagenkalküls”, Ergebnisse eines mathematischen Kolloquiums 4, 39–40. Reprinted in Gödel 1986, pp. 300–301. [1933i] “Zum Entscheidungsproblem des logischen Functionenkalküls”, Monatshefte für Mathematik und Physik, 40: 433–443. Reprinted in Gödel 1986, pp. 306–326. [*1933o] “The present situation in the foundations of mathematics”, manuscript. Printed in Gödel 1995, pp. 45–53. [1934c] Review of Skolem (1933). Zentralblatt für Mathematik und ihre Grenzgebiete, 7: 193–194. Reprinted in Gödel 1986, pp. 379–380. [1936a] “Über die Länge von Beweisen”, Ergebnisse eines mathematischen Kolloquiums, 7: 23–24. Reprinted in Gödel 1986, pp. 395–399. [1939a] “Consistency proof for the generalized continuum hypothesis”, Proceedings of the National Academy of Sciences, U.S.A., 25: 220–224. Reprinted in Gödel 1990, pp. 28–32. [1940] “The Consistency of the Continuum Hypothesis”, Annals of Mathematics Studies, Volume 3, Princeton: Princeton University Press. Reprinted in Gödel 1990, pp. 33–101. [*1941] “In what sense is intuitionistic logic constructive?”, lecture manuscript. Printed in Gödel 1995, pp. 189–200. [1944] “Russell’s mathematical logic”, The Philosophy of Bertrand Russell (Library of Living Philosophers), P. Schilpp (ed.), New York: Tudor, 1951, pp. 123–153. Reprinted in Gödel 1990, pp. 119–141. [*1946/9-B2] “Some observations about the relationship between theory of relativity and Kantian philosophy”, manuscript. Printed in Gödel 1995, pp. 230–246. [*1946/9-C1] “Some observations about the relationship between theory of relativity and Kantian philosophy”, manuscript. Printed in Gödel 1995, pp. 247–259. [1947] “What is Cantor’s continuum problem?”, Amer. Math. Monthly, 54: 515–525. Reprinted in Gödel 1990, pp. 176–187. [1949a] “A remark on the relationship between relativity theory and idealistic philosophy”, Albert Einstein: Philosopher-Scientist (Library of Living Philosophers), P. Schilpp (ed.), La Salle, IL: Open Court, 1949, pp. 555–562. Reprinted in Gödel 1990, pp. 202–207. [1949] “An Example of a New Type of Cosmological Solutions of Einstein’s Field Equations of Gravitation,” Reviews of Modern Physics, 21: 447–450. Reprinted in Gödel 1990, pp. 190–198. [*1951] “Some basic theorems on the foundations of mathematics and their implications”, lecture manuscript. Printed in Gödel 1995, pp. 304–323. [*1953/9-III] “Is mathematics a syntax of language?”, lecture manuscript. Printed in Gödel 1995, pp. 334–356. [*1953/9-V] “Is mathematics a syntax of language?,” lecture manuscript. Printed in Gödel 1995, pp. 356–362. [1958] “Über eine bisher noch nicht benützte Erweiterung des finiten Standpunktes”, Dialectica, 12: 280–287. Reprinted in Gödel 1990, pp. 240–251. [*1961/?] “The modern development of the foundations of mathematics in light of philosophy”, manuscript. Printed in Gödel 1995, pp. 374–387. [1964] “What is Cantor’s continuum problem?”, revised version of Gödel 1947, in Benacerraf, P. and Putnam, H. (eds.), 1983, Philosophy of mathematics: selected readings (2nd ed.), Cambridge: Cambridge University Press. Reprinted in Gödel 1990, pp. 254–270. [*1970] “Ontological proof”, manuscript. Printed in Gödel 1995, pp. 403–404. [*1970a] “Some considerations leading to the probable conclusion that the true power of the continuum is ℵ2”, manuscript. Printed in Gödel 1995, pp. 420–422. [*1970b] “A proof of Cantor’s continuum hypothesis from a highly plausible axioms about orders of growth”, manuscript. Printed in Gödel 1995, pp. 422–423. Secondary Sources'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': 'Bibliography', 'Header 3': 'Primary Sources', 'Header 4': 'Gödel’s Writings'}, page_content='The Gödel Nachlass is located at Firestone Library of Princeton University with the exception of Gödel’s preprint collection, which is housed at the library of the Institute for Advanced Study. The Nachlass itself is the property of the Institute but a microfilm copy of it may be purchased from Brill. All of Gödel’s published work, together with a large number of the unpublished material from the Nachlass, together with a selection of Gödel’s correspondence is published in Kurt Gödel, Collected Works, Volumes I-V.'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': 'Bibliography', 'Header 3': 'Primary Sources', 'Header 4': 'The Collected Papers of Kurt Gödel'}, page_content='1986, Collected Works. I: Publications 1929–1936. S. Feferman, S. Kleene, G. Moore, R. Solovay, and J. van Heijenoort (eds.), Oxford: Oxford University Press. 1990, Collected Works. II: Publications 1938–1974. S. Feferman, J. Dawson, S. Kleene, G. Moore, R. Solovay, and J. van Heijenoort (eds.), Oxford: Oxford University Press. 1995, Collected Works. III: Unpublished essays and lectures. S. Feferman, J. Dawson, S. Kleene, G. Moore, R. Solovay, and J. van Heijenoort (eds.), Oxford: Oxford University Press. 2003a, Collected Works. IV: Correspondence A-G. S. Feferman, J. Dawson, S. Kleene, G. Moore, R. Solovay, and J. van Heijenoort (eds.), Oxford: Oxford University Press. 2003b, Collected Works. V: Correspondence H-Z. S. Feferman, J. Dawson, S. Kleene, G. Moore, R. Solovay, and J. van Heijenoort (eds.), Oxford: Oxford University Press.'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': 'Bibliography', 'Header 3': 'Secondary Sources'}, page_content='Avigad, J. and S. Feferman, 1998, “Gödel’s Functional (‘Dialectica’) Interpretation”, in Handbook of Proof Theory (Studies in Logic and the Foundations of Mathematics, Volume 137), Samuel Buss (ed.), Amsterdam: North-Holland, pp. 337-405. Awodey, S. and A. W. Carus, 2010, “Gödel and Carnap”, in Kurt Gödel: Essays for his Centennial, Solomon Feferman, Charles Parsons & Stephen G. Simpson (eds.), Cambridge: Cambridge University Press. Baaz, M., and C. Papadimitriou, D.Scott, H. Putnam, and C. Harper (eds.), 2011, Kurt Gödel and the Foundations of Mathematics: Horizons of Truth, Cambridge: Cambridge University Press. Badesa, C., and P. Mancosu, and R. Zach, 2009, “The Development of Mathematical Logic from Russell to Tarski, 1900–1935”, in Leila Haaparanta (ed.), The History of Modern Logic. New York and Oxford: Oxford University Press:318–470.. Barwise, Jon (ed.), 1977, Handbook of Mathematical Logic (Studies in Logic and the Foundations of Mathematics, Volume 90), Amsterdam: North-Holland Publishing Co. Behmann, Heinrich, 1922, “Beiträge, Algebra, Logik, insbesodere zum Entscheidungsproblem”, Mathematische Annalen, 86: 419–432. Benacerraf, P. and H. Putnam (eds.), 1983, Philosophy of Mathematics: Selected Readings, Cambridge: Cambridge University Press, 2nd edition. Bernays, Paul, 1926, “Axiomatische Untersuchung des Aussagen-Kalkuls der ‘Principia Mathematica’”, Mathematisches Zeitschrift, 25(1): 305–320. Bezboruah, A., and J.C. Sheperdson, 1976, “Gödel’s second incompleteness theorem for \\\\(Q\\\\)”, Journal of Symbolic Logic, 41 (2): 503–512. Bolzano, Bernard, 1969, Wissenschaftslehre, Sections 349–391, in Bernard Bolzano — Gesamtausgabe, Reihe I/Band 13, edited and with an introduction by Jan Berg, Stuttgart-Bad Cannstatt: Frommann Holzboog. Burgess, John, 2009, “”Intuitions of Three Kinds in Gödel’s Views on the Continuum“”, in Interpreting GödelKennedy, J. (ed.) Cambridge: Cambridge University Press, 2014. Buss, Samuel R., 1994, “On Gödel’s Theorems on Lengths of Proofs. I. Number of Lines and Speedup for Arithmetics”, Journal of Symbolic Logic, 59(3): 737–756. Chisholm, R., 1948, “The Problem of Empiricism”, The Journal of Philosophy, 45: 512–7. Cohen, Paul, 1963, “The Independence of the Continuum Hypothesis”, Proceedings of the National Academy of Sciences of the U.S.A., 50: 1143–1148. Crocco, G., 2003, “Gödel, Carnap and the Fregean Heritage”, History and Philosophy of Logic, 27: 171–191. –––, 2006, “Gödel on Concepts”, Synthese, 137(1,2): 21–41. Dawson, Jr., John W., 1997, Logical dilemmas: The Life and Work of Kurt Gödel, Wellesley, MA: A. K. Peters, Ltd. Dehornoy, Patrick, 2004, “Progrès récents sur l’hypothèse du continu (d’après Woodin)”, Astérisque, 294: viii, 147–172. Detlefsen, Michael, 1986, Hilbert’s Program: An essay on mathematical instrumentalism, Dordrecht: D. Reidel. –––, 2001, “What Does Gödel’s Second theorem Say?”, Philosophia Mathemathica, 9(1): 37–71. –––, 2014, “Completeness and the Ends of Axiomatization”, in Interpreting Gödel, Kennedy, J. (ed.) Cambridge: Cambridge University Press, 2014. Dreben, B. and J. van Heijenoort, 1986, “Introductory Note to 1929, 1930 and 1930a”, in Gödel 1986, pp. 44–59. Edwards, Paul (ed.), 1967, The Encyclopedia of Philosophy, New York: MacMillan. Ehrenfeucht, A. and J. Mycielski, 1971, “Abbreviating Proofs by Adding New Axioms”, Bulletin of the American Mathematical Society, 77: 366–367. Feferman, Solomon, 1960/1961, “Arithmetization of Metamathematics in a General Setting”, Fundamenta Mathematicae, 49: 35–92. –––, 1993, “Gödel’s Dialectica Interpretation and Its Two-way Stretch”, in Computational Logic and Proof Theory (Lecture Notes in Computer Science, Volume 713), G. Gottlob, A. Leitsch, and D. Mundici (eds.), Berlin: Springer, pp. 23–40. –––, 1986, “Gödel’s Life and Work”, in Gödel 1986, pp. 1–34. –––, 1988, “Hilbert’s Program Relativized: Proof-Theoretical and Foundational Reductions”, Journal of Symbolic Logic, 53: 364–384. –––, 1996, “Proof Theory”, in The Encyclopedia of Philosophy Supplement, D. Borchrt (ed.), New York: MacMillan, pp. 466–469. Feferman, S., and H. Friedman, P. Maddy, and J. Steel, 2000, “Does Mathematics Need New Axioms?”, Bulletin of Symbolic Logic, 6(4): 401–446. Feferman, S., C. Parsons, and S. Simpson (eds.), 2010, Kurt Gödel: Essays for his Centennial (Lecture Notes in Logic, 33), Cambridge: Cambridge University Press. Feigl, H. and A. Blumberg, 1931, “Logical Positivism. A New Movement in European Philosophy”, Journal of Philosophy, 28: 281–296. Floyd, J. and A. Kanamori, 2006, “How Gödel Transformed Set Theory”, Notices of the American Mathematical Society, 53(4): 419–427. Folina, Janet, 2014, “Gödel on How to Have your Mathematics and Know it Too”, in Interpreting Gödel, Kennedy, J. (ed.) Cambridge: Cambridge University Press, 2014. Føllesdal, Dagfinn, 1995, “Gödel and Husserl”, in From Dedekind to Gödel (Synthese Library, Volume 251), J. Hintikka (ed.), Dordrecht, Boston: Kluwer, pp. 427–446. Foreman, Matthew, 1998, “Generic Large Cardinals: New Axioms for Mathematics?”, in Documenta Mathematica, Extra Volume, Proceedings of the International Congress of Mathematicians, II, pp. 11–21 [available online (in compressed Postscript)]. Franks, Curtis, 2009, “The Autonomy of Mathematical Knowledge: Hilbert’s Program Revisited”, Cambridge: Cambridge University Press. –––, 2011, “Stanley Tennenbaum’s Socrates”, in Set Theory, Arithmetic and Foundations of Mathematics: Theorems, Philosophies, Kennedy, J. and Kossak, R., (eds.), Lecture Notes in Logic, 36, Cambridge: Cambridge University Press, 2011. –––, 2014, “Logical Completeness, Form and Content: An Archaeology”, in Interpreting Gödel, Kennedy, J. (ed.) Cambridge: Cambridge University Press, 2014. Gaifman, H., 2000, “What Godel’s Incompleteness Result Does and Does Not Show”, Journal of Philosophy, 97 (8): 462–471. Garson, James, 2003, “Modal Logic”, in The Stanford Encyclopedia of Philosophy, Fall 2003 Edition, Edward N. Zalta (ed.), URL = <https://plato.stanford.edu/archives/fall2003/entries/logic-modal/>. Glivenko, V., 1929, “Sur quelques points de la logique de m. Brouwer.”, Académie Royale de Belgique, Bulletin de la Classe des Sciences, 15: 183–188. Gottwald, Siegfried, 2004, “Many-valued Logic”, in The Stanford Encyclopedia of Philosophy, Winter 2004 Edition, Edward N. Zalta (ed.), URL = <https://plato.stanford.edu/archives/win2004/entries/logic-manyvalued/>. Gödel, Rudolf, 1983, “History of the Gödel Family”, Susan Simonsin (trans.), in Weingartner and Schmetterer 1987, pp. 11–27. Hauser, Kai, 2006, “Gödel’s Program Revisited, Part 1: the Turn to Phenomenology”, Bulletin of Symbolic Logic, 12 (4): 529–590. Heyting, Arendt, 1930, “Die formalen Regeln der intuitionistischen Logik”, Sitzungsberichte der Preussischen Akademie der Wissenschaften, physikalisch-mathematische Klasse, II, pp. 42–56. Hilbert, David, 1926, “Über das Unendliche”, Mathematische Annalen, 95: 161–190. Hilbert, D. and W. Ackermann, 1928, Grundzüge der theoretischen Logik, Berlin: Springer-Verlag. Hilbert, D. and P. Bernays, 1934, Grundlagen der Mathematik, Volume 1, Berlin: Springer-Verlag. –––, 1939, Grundlagen der Mathematik, Volume II, Berlin: Springer-Verlag. Hodges, Wilfrid, 2005, “Model Theory”, in The Stanford Encyclopedia of Philosophy, Fall 2005 Edition, Edward N. Zalta (ed.), URL = <https://plato.stanford.edu/archives/fall2005/entries/model-theory/>. Husserl, Edmund, 1911, “Philosophie als strenge Wissenschaft”, Logos, 1: 289–341. Jaśkowski, Stanisław, 1936, “Investigations into the System of Intuitionist Logic”, Studia Logica, 34(2) (1975): 117–120. (Translated by S. McCall from the French “Rechereches sur le système de la logique intuitioniste” in Actes du Congrés International de Philosophie Scientifique, Volume VI, Hermann, Paris, 1936, pp. 58–61.) Jech, Thomas, 2003, Set theory, (Springer Monographs in Mathematics), Berlin: Springer-Verlag. 3rd millennium edition, revised and expanded. Jensen, R. Björn, 1972, “The Fine Structure of the Constructible Hierarchy” (with a section by Jack Silver), Annals of Mathematical Logic, 4: 229–308; Erratum, 4 (1972): 443. Kanamori, Aki, 1996, “The Mathematical Development of Set theory from Cantor to Cohen.” Bulletin of Symbolic Logic, 2(1): 1–71. –––, 2006, “Levy and Set Theory”, Annals of Pure and Applied Logic, 140(3): 233–252. Kennedy, Juliette, 2006, “Incompleteness — A Book Review,” Notices of the American Mathematical Societ, 53(4): 448–455. –––, 2011, “Gödel’s Thesis: An Appreciation” in Kurt Gödel and the Foundations of Mathematics: Horizons of Truth, M. Baaz, C. Papadimitriou, D. Scott, H. Putnam, and C. Harper (eds.), Cambridge: Cambridge University Press 95–110. –––, 2013, “On Formalism Freeness: Implementing Gödel’s 1946 Princeton Bicentennial Lecture”, Bulletin of Symbolic Logic, 19(3): 351–393. –––, 2014, “Gödel’s 1946 Princeton Bicentennial Lecture: An Appreciation”, in Interpreting Gödel: Critical Essays, Cambridge: Cambridge University Press. Kennedy, Juliette (ed.), 2014, Interpreting Gödel: Critical Essays, Cambridge: Cambridge University Press. Kennedy, J. and van Atten, M., 2003, “On the Philosophical Development of Kurt Gödel”, Bulletin of Symbolic Logic, 9(4): 425–476. Reprinted in Kurt Gödel: Essays for his Centennial, Solomon Feferman, Charles Parsons and Stephen G. Simpson (eds.), Cambridge: Cambridge University Press. –––, 2004, “Gödel’s Modernism: On Set-theoretic Incompleteness”, Graduate Faculty Philosophy Journal, 25(2): 289–349. (See the Erratum in Graduate Faculty Philosophy Journal, 26(1) (2005), page facing contents.) –––, 2009, “Gödel’s Modernism: On Set-theoretic Incompleteness, Revisited”, in Logicism, Intuitionism and Formalism: What has become of them?, S. Linström, E. Palmgren, K. Segerberg, and V. Stoltenberg-Hansen (eds.), Berlin: Springer: 303–356. –––, 2009, “Gödel’s Logic”, in D. Gabbay and J. Woods (eds.), The Handbook of the History of Logic: Logic from Russell to Gödel, Volume 5, Amsterdam: Elsevier: 449–509. Kleene, S. C., 1987, “Gödel’s Impression on Students of Logic in the 1930s”, in Weingartner and Schmetterer 1987, pp. 49–64. Koellner, Peter, 2014, “Large Cardinals and Determinacy”, The Stanford Encyclopedia of Philosophy (Spring Edition), Edward N. Zalta (ed.), URL = <https://plato.stanford.edu/archives/spr2014/entries/large-cardinals-determinacy/>. Kreisel, Georg, 1980, “Kurt Gödel, 28 April 1906 – 14 January 1978”, Biographical Memoirs of Fellows of the Royal Society, 26: 148–224. Corrigenda, 27 (1981): 697; further corrigenda, 28 (1982): 697. –––, 1988, “Review of Kurt Gödel: Collected works, Volume I”, Notre Dame Journal of Formal Logic, 29(1): 160–181. –––, 1990, “Review of Kurt Gödel: Collected Works, Volume II”, Notre Dame Journal of Formal Logic, 31(4): 602–641. –––, 1998, “Second Thoughts Around Some of Gödel’s Writings: A Non-academic Option”, Synthese, 114(1): 99–160. Kripke, Saul, 2009, “The collapse of the Hilbert program: why a system cannot prove its own 1-consistency”, Bulletin of Symbolic Logic, 15 (2): 229–231. Kunen, Kenneth, 1983, Set Theory: An Introduction to Independence Proofs, (Studies in Logic and the Foundations of Mathematics, Volume 102), Amsterdam: North-Holland Publishing Co. Reprint of the 1980 original. Löb, M. H., 1956, “Formal Systems of Constructive Mathematics”, Journal of Symbolic Logic, 21: 63–75. Löwenheim, L., 1915, “Über Möglichkeiten im Relativkalkül”, Mathematische Annalen, 76(4): 447–470. Łukasiewicz, Jan, 1970, Selected works, (Studies in Logic and the Foundations of Mathematics), L. Borkowski (ed.), Amsterdam: North-Holland Publishing Co. Maddy, Penelope, 1990, Realism in Mathematics, New York: Clarendon Press. Maddy, Penelope, 2011, Defending the Axioms, Oxford: Oxford University Press. Mal’cev, Anatoli Ivanovic, 1971, The Metamathematics of Algebraic Systems. Collected Papers: 1936–1967 (Studies in Logic and the Foundations of Mathematics, Volume 66), translated, edited, and provided with supplementary notes by Benjamin Franklin Wells, III, Amsterdam: North-Holland Publishing Co. Mancosu, Paolo, 1998, From Brouwer to Hilbert. The Debate on the Foundations of Mathematics in the 1920s, Oxford: Oxford University Press. –––, 2004, “Review of Kurt Gödel, Collected Works, Volumes IV and V”, Notre Dame Journal of Formal Logic, 45: 109–125. Martin, D.A., 2005, “Gödel’s Conceptual Realism”, Bulletin of Symbolic Logic, 11: 207–224. McKinsey, J. C. C. and A. Tarski, 1948, “Some Theorems About the Sentential Calculi of Lewis and Heyting”, Journal of Symbolic Logic, 13: 1–15. Mostowski, Andrzej, 1949, “An Undecidable Arithmetical Statement”, Fundamenta Mathematicae, 36: 143–164. –––, 1982, Sentences Undecidable in Formalized Arithmetic: An Exposition of the Theory of Kurt Gödel, Westport, CT: Greenwood Press. Reprint of the 1952 original. Oliva, Paulo, 2006, “Unifying Functional Interpretations”, Notre Dame Journal of Formal Logic, 47(2): 263–290. Parikh, Rohit, 1971, “Existence and Feasibility in Arithmetic”, Journal of Symbolic Logic, 36: 494–508. Parsons, Charles, 1995a, “Platonism and Mathematical Intuition in Kurt Gödel’s Thought”, Bulletin of Symbolic Logic, 1(1): 44–74. –––, 1995b, “Quine and Gödel on Analyticity”, in On Quine: New Essays, Cambridge: Cambridge University Press, pp. 297–313. –––, 2000, “Reason and Intuition”, Synthese, 125(3): 299–315. –––, 2002, “Realism and the Debate on Impredicativity, 1917–1944”, in Reflections on the Foundations of Mathematics: Essays in Honor of Solomon Feferman, (Lecture Notes in Logic, Volume 15), W. Sieg, R. Sommer, and C. Talcott (eds.), Urbana, IL: Association of Symbolic Logic, pp. 372–389. –––, 2010, “Gödel and Philosophical Idealism”Philosophia Mathematica, 18 (2): 166–192. –––, 2014, “Analyticity for Realists”, in Interpreting Gödel, Kennedy, J. (ed.) Cambridge: Cambridge University Press, 2014. Poonen, Bjorn, 2014, “Undecidable Problems: A Sampler”, in Interpreting Gödel: Critical Essays, Cambridge: Cambridge University Press. Post, Emil L., 1921, “Introduction to a General Theory of Elementary Propositions”, American Journal of Mathematics, 43(3): 163–185. Pudlák, Pavel, 1996, “On the lengths of proofs of consistency: a survey of results”, Annals of the Kurt Gödel Society, 2: 65-86. Raatikainen, P., 2005, “On the Philosophical Relevance of Gödel’s Incompleteness Theorems”, Revue Internationale de Philosophie, 59 (4): 513–534. Rogers, Jr., Hartley, 1967, Theory of Recursive Functions and Effective Computability, New York: McGraw-Hill Book Co. Rosser, J.B., 1936, “Extensions of Some Theorems of Gödel and Church”, Journal of Symbolic Logic, 1(3): 87–91. Scott, Dana, 1961, “Measurable Cardinals and Constructible Sets”, Bulleint de l’Academie Polonaise des Sciences (Série des Science, Mathématiques, Astronomiques et Physiques), 9: 521–524. Shelah, Saharon, 2014, “Reflecting on Logical Dreams”, in Interpreting Gödel: Critical Essays, Cambridge: Cambridge University Press. Sieg, Wilfried, 1988, “Hilbert’s Program Sixty Years Later”, Journal of Symbolic Logic, 53(2): 338–348. –––, 1990, “Relative Consistency and Accessible Domains”, Synthese, 84(2): 259–297. –––, 1999, “Hilbert’s Programs: 1917–1922”, Bulletin of Symbolic Logic, 5(1): 1–44. –––, 2006, “Gödel on Computability”, Philosophia Mathematica, 14: 189–207. Sierpinski, Wacław, 1947, “L’hypothèse généralisée du continu et l’axiome du choix”, Fundamenta Mathematicae, 34: 1–5. Sigmund, Karl, 2006, “Pictures at an Exhibition”, Notices of the American Mathematical Society, 53(4): 428–432. Skolem, Thoralf, 1920, “Logisch-kombinatorische Untersuchungen über die Erfüllbarkeit oder Beweisbarkeit mathematischer Sätze nebst einem Theoreme über dichte Mengen”, Skrifter utgit av Videnskappsselskapet i Kristiania, I. Matematisk-naturvidenskabelig klasse, Number 4, pp. 1–36. Reprinted in Skolem 1970, pp. 103–136. –––, 1923, “Einige Bemerkungen zur axiomatischen Begründung der Mengenlehre”, Matematikerkongressen i Helsingfors den 4–7 Juli 1922, Den femte skandinaviska matematikerkongressen, Redogörelse, Helsinki, pp. 217–232. Reprinted in Skolem 1970, pp. 137–152. –––, 1933, “Über die Unmöglichkeit einer vollständigen Charakterisierung der Zahlenreihe mittels eines endlichen Axiomensystems”, Norsk Matematisk forenings skrifter, 10: 73–82. –––, 1970, Selected Works in Logic, Jens Erik Fenstad (ed.), Oslo: Universitetsforlaget. Smith, David Woodruff, 2005, “Phenomenology”, in The Stanford Encyclopedia of Philosophy (Winter Edition), Edward N. Zalta (ed.), URL = <https://plato.stanford.edu/archives/win2005/entries/phenomenology/>. Solovay, Robert, 1990, “Introductory Note to 1938, 1939, 1939a, 1940”, in Gödel 1990, pp. 1–25. Steel, John, 2000, “Mathematics Needs New Axioms”, Bulletin of Symbolic Logic, 6(4): 422–433. Steel, John, 2014, “Gödel’s Program”, in Interpreting Gödel, Kennedy, J. (ed.) Cambridge: Cambridge University Press, 2014. Tait, William, 1967, “Intensional Interpretations of Functionals of Finite Type I,” Journal of Symbolic Logic, 32(2): 198–212. –––, 1981, “Finitism”, Journal of Philosophy, 78: 524–556. Reprinted in Tait 2005, pp. 21–42. –––, 1986, “Truth and Proof: The Platonism of Mathematics”, Synthese, 69(3): 341–370. Reprinted in Tait 2005, pp. 61–88. –––, 2001, “Gödel’s Unpublished Papers on Foundations of Mathematics”, Philosophia Mathematica, 9(1): 87–126. Reprinted in Tait 2005, pp. 276–313. –––, 2002, “Remarks on Finitism”, in Reflections on the Foundations of Mathematics: Essays in Honor of Solomon Feferman (Lecture Notes in Logic, Volume 15), W. Sieg, R. Sommer, and C. Talcott (eds.), Urbana, IL: Association of Symbolic Logic, pp. 410–419. Reprinted in Tait 2005, pp. 43–53. –––, 2005, The Provenance of Pure Reason: Essays in the Philosophy of Mathematics and its History (Logic and Computation in Philosophy), New York: Oxford University Press. –––, 2006, “Gödel’s correspondence on proof theory and constructive mathematics”Philosophia Mathematica, 14 (1): 76–111. –––, 2006, “Gödel’s interpretation of intuitionism”,Philosophia Mathematica, 14 (2): 208–228. Taussky-Todd, Olga, 1983, “Remembrances of Kurt Gödel”, in Weingartner and Schmetterer 1987, pp. 29–41. Tieszen, Richard, 1992, “Kurt Gödel and Phenomenology”, Philosophy of Science, 59(2): 176–194. –––, 2002, “Gödel and the Intuition of Concepts”, Synthese, 133 (3): 363–391. –––, 2005, Phenomenology, Logic and the Philosophy of Mathematics, Cambridge: Cambridge University Press. –––, 2011, After Gödel: Platonism and Rationalism in Mathematics and Logic, Oxford: Oxford University Press. Toledo, Sue, 2011, “Sue Toledo’s Notes of her Conversations with Kurt Gödel in 1972-5”, in Set Theory, Arithmetic and Foundations of Mathematics: Theorems, Philosophies (Lecture Notes in Logic, 36), Kennedy, J. and Kossak, R., (eds.), Cambridge: Cambridge University Press, forthcoming. Tragesser, Robert, 1977, Phenomenology and Logic, Ithaca: Cornell University Press. –––, 1984, Husserl and Realism in Logic and Mathematics, (Series: Modern European Philosophy), Cambridge: Cambridge University Press. –––, 1989, “Sense Perceptual Intuition, Mathematical Existence, and Logical Imagination”, Philosphia Mathematica, 4(2): 154–194. Troelstra, A. S., 1986, “Note to 1958 and 1972”, in Gödel 1990, pp. 217–241. Troelstra, A. S. (ed.), 1973, Metamathematical Investigation of Intuitionistic Arithmetic and Analysis, (Lecture Notes in Mathematics, Volume 344), Berlin: Springer-Verlag. Turing, A. M., 1937, “On Computable Numbers, with an Application to the Entscheidungsproblem”, Proceedings of the London Mathematical Society (Series 2), 42: 230–265. van Atten, Mark, 2005, “On Gödel’s Awareness of Skolem’s Helsinki Lecture”, History and Philosophy of Logic, 26(4): 321–326. –––, 2006, “Two Draft Letters from Gödel on Self-knowledge of Reason”, Philosophia Mathematica, 14(2): 255–261. –––, 2015, “Essays on Gödel’s Reception of Leibniz, Husserl and Brouwer”, Springer. van Heijenoort, J. (ed.), 1967, From Frege to Gödel: A sourcebook in mathematical logic, 1879–1931, Cambridge, MA: Harvard University Press. van Oosten, Jaap, 2008, Realizability: An Introduction to its Categorical Side (Studies in Logic and Foundations of Mathematics: Volume 152), Amsterdam: Elsevier. von Neumann, John, 2005, John von Neumann: Selected Letters (History of Mathematics, Volume 27), foreword by P. Lax, introduction by Marina von Neumann Whitman, preface and introductory comments by Miklós Rédei (ed.), Providence, RI: American Mathematical Society. Väänänen, Jouko, 2014, “Multiverse Set Theory and Absolutely Undecidable Propositions”, in Interpreting Gödel, J. Kennedy (ed.), Cambridge: Cambridge University Press, 2014. Wang, Hao, 1957, “The Axiomatization of Arithmetic”, Journal of Symbolic Logic, 22: 145–158. –––, 1973, From Mathematics to Philosophy, London: Routledge. –––, 1981, “Some Facts about Kurt Gödel”, Journal of Symbolic Logic, 46(3): 653–659. –––, 1987, Reflections on Kurt Gödel, Cambridge, MA: MIT Press. –––, 1993, Popular Lectures on Mathematical Logic, New York: Dover Publications Inc., 2nd edition. –––, 1996, A Logical Lourney: From Gödel to Philosophy (Representation and Mind), Cambridge, MA: MIT Press. Weingartner, P., and L. Schmetterer (eds.), 1987, Gödel Remembered: Salzburg 10–12 July 1983, (History of Logic, Number 4), Naples: Bibliopolis. Wilkie, Alex, and J.B. Paris, 1987, “On the scheme of induction for bounded arithmetic formulas”, 35: 261–302. Woodin, W. Hugh, 1988, “Supercompact Cardinals, Sets of Reals, and Weakly Homogeneous Trees”, Proceedings of the National Academy of Sciences of the U.S.A., 85(18): 6587–6591. –––, 2001a, “The Continuum Hypothesis. I”, Notices of the American Mathematical Society, 48(6): 567–576. –––, 2001b, “The Continuum Hypothesis. II”, Notices of the American Mathematical Society, 48(7): 681–690. –––, 2002, “Correction: ‘The Continuum Hypothesis. II’”, Notices of the American Mathematical Society, 49(1): 46. Yourgrau, Palle, 2005, A World Without Time. The Forgotten Legacy of Gödel and Einstein, New York: Basic Books. Zach, Richard, 1999, “Completeness Before Post: Bernays, Hilbert, and the Development of Propositional Logic”, Bulletin of Symbolic Logic, 5(3): 331–366. –––, 2003, “Hilbert’s Program”, in The Stanford Encyclopedia of Philosophy (Fall Edition), Edward N. Zalta (ed.), URL = <https://plato.stanford.edu/archives/fall2003/entries/hilbert-program/>.'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel'}, page_content='Academic Tools'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': 'Academic Tools'}, page_content='How to cite this entry. Preview the PDF version of this entry at the Friends of the SEP Society. Look up topics and thinkers related to this entry at the Internet Philosophy Ontology Project (InPhO). Enhanced bibliography for this entry at PhilPapers, with links to its database.'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel'}, page_content='Other Internet Resources'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': 'Other Internet Resources'}, page_content='Avigad, Jeremy, “Gödel and the metamathematical tradition”, manuscript in PDF available online. Koellner, Peter, “Truth in Mathematics:The question of Pluralism”, manuscript in PDF available online. The Bernays Project.'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel'}, page_content='Related Entries'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 2': 'Related Entries'}, page_content='Gödel, Kurt: incompleteness theorems | Hilbert, David: program in the foundations of mathematics | Husserl, Edmund | Leibniz, Gottfried Wilhelm | mathematics, philosophy of: intuitionism | mathematics, philosophy of: Platonism | model theory | model theory: first-order | phenomenology | realism | set theory | set theory: continuum hypothesis | set theory: large cardinals and determinacy'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel'}, page_content='Acknowledgments'),\n",
       " Document(metadata={'Header 1': 'Kurt Gödel', 'Header 3': 'Acknowledgments'}, page_content='This entry was very much improved by discussion and correspondence with the following: Aki Kanamori, who made helpful corrections and comments to section 2.4; Jouko Väänänen, whose expertise in all areas of mathematical logic the author benefited from in a great many invaluable discussions regarding the material in section 2; my sub-editor Richard Zach, whose many important and helpful suggestions led to a vast improvement of this entry, and an anonymous referee for helpful comments and corrections. The author is grateful to the NWO for their support during the last period of the writing of this entry, to the Institute for Advanced Study for their hospitality during the writing of this entry, and to Marcia Tucker of the IAS and the Rare Books and Special Collections department of Firestone Library for all of their assistance over the years .'),\n",
       " Document(page_content='Copyright © 2015 by Juliette Kennedy <juliette.kennedy@helsinki.fi>  \\nOpen access to the SEP is made possible by a world-wide funding initiative. The Encyclopedia Now Needs Your Support Please Read How You Can Help Keep the Encyclopedia Free  \\nBrowse'),\n",
       " Document(metadata={'Header 4': 'Browse'}, page_content=\"Table of Contents What's New Random Entry Chronological Archives\"),\n",
       " Document(page_content='About'),\n",
       " Document(metadata={'Header 4': 'About'}, page_content='Editorial Information About the SEP Editorial Board How to Cite the SEP Special Characters Advanced Tools Accessibility Contact'),\n",
       " Document(page_content='Support SEP'),\n",
       " Document(metadata={'Header 4': 'Support SEP'}, page_content='Support the SEP PDFs for SEP Friends Make a Donation SEPIA for Libraries'),\n",
       " Document(page_content='Mirror Sites'),\n",
       " Document(metadata={'Header 4': 'Mirror Sites'}, page_content='View this site from another server:'),\n",
       " Document(page_content='USA (Main Site) Philosophy, Stanford University  \\nInfo about mirror sites  \\nThe Stanford Encyclopedia of Philosophy is copyright © 2023 by The Metaphysics Research Lab, Department of Philosophy, Stanford University  \\nLibrary of Congress Catalog Data: ISSN 1095-5054')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_splitter.split_text_from_url(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive JSON SPlitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = requests.get(\"https://api.smith.langchain.com/openapi.json\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveJsonSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_splitter = RecursiveJsonSplitter(max_chunk_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_chunks = json_splitter.split_json(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'openapi': '3.1.0',\n",
       "  'info': {'title': 'LangSmith', 'version': '0.1.0'},\n",
       "  'paths': {'/api/v1/sessions/{session_id}': {'get': {'tags': ['tracer-sessions'],\n",
       "     'summary': 'Read Tracer Session',\n",
       "     'description': 'Get a specific session.'}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}': {'get': {'operationId': 'read_tracer_session_api_v1_sessions__session_id__get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}': {'get': {'parameters': [{'name': 'session_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'}},\n",
       "      {'name': 'include_stats',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': False,\n",
       "        'title': 'Include Stats'}},\n",
       "      {'name': 'accept',\n",
       "       'in': 'header',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Accept'}}]}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TracerSession'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}': {'patch': {'tags': ['tracer-sessions'],\n",
       "     'summary': 'Update Tracer Session',\n",
       "     'description': 'Create a new session.',\n",
       "     'operationId': 'update_tracer_session_api_v1_sessions__session_id__patch'}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}': {'patch': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'session_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Session Id'}}]}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TracerSessionUpdate'}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TracerSessionWithoutVirtualFields'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}': {'delete': {'tags': ['tracer-sessions'],\n",
       "     'summary': 'Delete Tracer Session',\n",
       "     'description': 'Delete a specific session.',\n",
       "     'operationId': 'delete_tracer_session_api_v1_sessions__session_id__delete'}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}': {'delete': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'session_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Session Id'}}]}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions': {'get': {'tags': ['tracer-sessions'],\n",
       "     'summary': 'Read Tracer Sessions',\n",
       "     'description': 'Get all sessions.',\n",
       "     'operationId': 'read_tracer_sessions_api_v1_sessions_get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/sessions': {'get': {'parameters': [{'name': 'reference_free',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "        'title': 'Reference Free'}},\n",
       "      {'name': 'reference_dataset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Reference Dataset'}},\n",
       "      {'name': 'id',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Id'}},\n",
       "      {'name': 'name',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Name'}},\n",
       "      {'name': 'name_contains',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Name Contains'}},\n",
       "      {'name': 'dataset_version',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Dataset Version'}},\n",
       "      {'name': 'sort_by',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'allOf': [{'$ref': '#/components/schemas/SessionSortableColumns'}],\n",
       "        'default': 'start_time',\n",
       "        'title': 'Sort By'}},\n",
       "      {'name': 'sort_by_desc',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': True,\n",
       "        'title': 'Sort By Desc'}},\n",
       "      {'name': 'sort_by_feedback_key',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Sort By Feedback Key'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 100,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'facets',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean', 'default': False, 'title': 'Facets'}},\n",
       "      {'name': 'accept',\n",
       "       'in': 'header',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Accept'}}]}}}},\n",
       " {'paths': {'/api/v1/sessions': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/TracerSession'},\n",
       "          'title': 'Response Read Tracer Sessions Api V1 Sessions Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions': {'post': {'tags': ['tracer-sessions'],\n",
       "     'summary': 'Create Tracer Session',\n",
       "     'description': 'Create a new session.',\n",
       "     'operationId': 'create_tracer_session_api_v1_sessions_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/sessions': {'post': {'parameters': [{'name': 'upsert',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': False,\n",
       "        'title': 'Upsert'}}]}}}},\n",
       " {'paths': {'/api/v1/sessions': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TracerSessionCreate'}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TracerSessionWithoutVirtualFields'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions': {'delete': {'tags': ['tracer-sessions'],\n",
       "     'summary': 'Delete Tracer Sessions',\n",
       "     'description': 'Delete a specific session.',\n",
       "     'operationId': 'delete_tracer_sessions_api_v1_sessions_delete',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/sessions': {'delete': {'parameters': [{'name': 'session_ids',\n",
       "       'in': 'query',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'array',\n",
       "        'items': {'type': 'string', 'format': 'uuid'},\n",
       "        'title': 'Session Ids'}}]}}}},\n",
       " {'paths': {'/api/v1/sessions': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}},\n",
       "      '422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/metadata': {'get': {'tags': ['tracer-sessions'],\n",
       "     'summary': 'Read Tracer Sessions Runs Metadata',\n",
       "     'description': 'Given a session, a number K, and (optionally) a list of metadata keys, return the top K values for each key.'}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/metadata': {'get': {'operationId': 'read_tracer_sessions_runs_metadata_api_v1_sessions__session_id__metadata_get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/metadata': {'get': {'parameters': [{'name': 'session_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'}},\n",
       "      {'name': 'metadata_keys',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array', 'items': {'type': 'string'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Metadata Keys'}},\n",
       "      {'name': 'start_time',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Start Time'}},\n",
       "      {'name': 'k',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 1,\n",
       "        'default': 10,\n",
       "        'title': 'K'}}]}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/metadata': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RootModel_Dict_str__list_str___'}}}}}}}}},\n",
       " {'paths': {'/api/v1/sessions/{session_id}/metadata': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs': {'get': {'tags': ['orgs'],\n",
       "     'summary': 'List Organizations',\n",
       "     'description': 'Get all orgs visible to this auth',\n",
       "     'operationId': 'list_organizations_api_v1_orgs_get'}}}},\n",
       " {'paths': {'/api/v1/orgs': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/OrganizationPGSchemaSlim'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response List Organizations Api V1 Orgs Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs': {'get': {'security': [{'Bearer Auth': []}]}},\n",
       "   '/api/v1/orgs/current/setup': {'post': {'tags': ['orgs'],\n",
       "     'summary': 'Create Customers And Get Stripe Setup Intent',\n",
       "     'operationId': 'create_customers_and_get_stripe_setup_intent_api_v1_orgs_current_setup_post'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/setup': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/StripeSetupIntentResponse'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current': {'get': {'tags': ['orgs'],\n",
       "     'summary': 'Get Organization Info',\n",
       "     'operationId': 'get_organization_info_api_v1_orgs_current_get'}}}},\n",
       " {'paths': {'/api/v1/orgs/current': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Organization'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/info': {'get': {'tags': ['orgs'],\n",
       "     'summary': 'Get Current Organization Info',\n",
       "     'operationId': 'get_current_organization_info_api_v1_orgs_current_info_get'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/info': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/OrganizationInfo'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/billing': {'get': {'tags': ['orgs'],\n",
       "     'summary': 'Get Organization Billing Info',\n",
       "     'operationId': 'get_organization_billing_info_api_v1_orgs_current_billing_get'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/billing': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/OrganizationBillingInfo'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/dashboard': {'get': {'tags': ['orgs'],\n",
       "     'summary': 'Get Dashboard',\n",
       "     'operationId': 'get_dashboard_api_v1_orgs_current_dashboard_get',\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/dashboard': {'get': {'parameters': [{'name': 'type',\n",
       "       'in': 'query',\n",
       "       'required': True,\n",
       "       'schema': {'$ref': '#/components/schemas/OrganizationDashboardType'}},\n",
       "      {'name': 'color_scheme',\n",
       "       'in': 'query',\n",
       "       'required': True,\n",
       "       'schema': {'anyOf': [{'$ref': '#/components/schemas/OrganizationDashboardColorScheme'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Color Scheme'}}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/dashboard': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/OrganizationDashboardSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/dashboard': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/payment-method': {'post': {'tags': ['orgs'],\n",
       "     'summary': 'On Payment Method Created',\n",
       "     'operationId': 'on_payment_method_created_api_v1_orgs_current_payment_method_post'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/payment-method': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/StripePaymentInformation'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/payment-method': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/payment-method': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/business-info': {'get': {'tags': ['orgs'],\n",
       "     'summary': 'Get Company Info',\n",
       "     'operationId': 'get_company_info_api_v1_orgs_current_business_info_get'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/business-info': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/StripeBusinessInfo-Output'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/business-info': {'get': {'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/business-info': {'post': {'tags': ['orgs'],\n",
       "     'summary': 'Set Company Info',\n",
       "     'operationId': 'set_company_info_api_v1_orgs_current_business_info_post'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/business-info': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/StripeBusinessInfo-Input'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/business-info': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/business-info': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/plan': {'post': {'tags': ['orgs'],\n",
       "     'summary': 'Change Payment Plan',\n",
       "     'operationId': 'change_payment_plan_api_v1_orgs_current_plan_post'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/plan': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ChangePaymentPlanSchema'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/plan': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/plan': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles': {'get': {'tags': ['orgs'],\n",
       "     'summary': 'List Organization Roles',\n",
       "     'operationId': 'list_organization_roles_api_v1_orgs_current_roles_get'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/Role'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response List Organization Roles Api V1 Orgs Current Roles Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles': {'get': {'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles': {'post': {'tags': ['orgs'],\n",
       "     'summary': 'Create Organization Roles',\n",
       "     'operationId': 'create_organization_roles_api_v1_orgs_current_roles_post'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CreateRoleRequest'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Role'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles/{role_id}': {'delete': {'tags': ['orgs'],\n",
       "     'summary': 'Delete Organization Roles',\n",
       "     'operationId': 'delete_organization_roles_api_v1_orgs_current_roles__role_id__delete',\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles/{role_id}': {'delete': {'parameters': [{'name': 'role_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Role Id'}}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles/{role_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Role'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles/{role_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles/{role_id}': {'patch': {'tags': ['orgs'],\n",
       "     'summary': 'Update Organization Roles',\n",
       "     'operationId': 'update_organization_roles_api_v1_orgs_current_roles__role_id__patch',\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles/{role_id}': {'patch': {'parameters': [{'name': 'role_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Role Id'}}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles/{role_id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/UpdateRoleRequest'}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles/{role_id}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Role'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/roles/{role_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/permissions': {'get': {'tags': ['orgs'],\n",
       "     'summary': 'List Permissions',\n",
       "     'operationId': 'list_permissions_api_v1_orgs_permissions_get'}}}},\n",
       " {'paths': {'/api/v1/orgs/permissions': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/PermissionResponse'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response List Permissions Api V1 Orgs Permissions Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/permissions': {'get': {'security': [{'Bearer Auth': []}]}},\n",
       "   '/api/v1/orgs/pending': {'get': {'tags': ['orgs'],\n",
       "     'summary': 'List Pending Organization Invites',\n",
       "     'description': 'Get all pending orgs visible to this auth'}}}},\n",
       " {'paths': {'/api/v1/orgs/pending': {'get': {'operationId': 'list_pending_organization_invites_api_v1_orgs_pending_get'}}}},\n",
       " {'paths': {'/api/v1/orgs/pending': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/OrganizationPGSchemaSlim'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response List Pending Organization Invites Api V1 Orgs Pending Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/pending': {'get': {'security': [{'Bearer Auth': []}]}},\n",
       "   '/api/v1/orgs/current/members': {'get': {'tags': ['orgs'],\n",
       "     'summary': 'Get Current Org Members',\n",
       "     'operationId': 'get_current_org_members_api_v1_orgs_current_members_get'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/OrganizationMembers'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members': {'post': {'tags': ['orgs'],\n",
       "     'summary': 'Add Member To Current Org',\n",
       "     'operationId': 'add_member_to_current_org_api_v1_orgs_current_members_post'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PendingIdentityCreate'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PendingIdentity'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/batch': {'post': {'tags': ['orgs'],\n",
       "     'summary': 'Add Members To Current Org Batch',\n",
       "     'description': 'Batch invite up to 500 users to the current org.',\n",
       "     'operationId': 'add_members_to_current_org_batch_api_v1_orgs_current_members_batch_post'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/batch': {'post': {'requestBody': {'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/PendingIdentityCreate'},\n",
       "         'type': 'array',\n",
       "         'title': 'Payloads'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/batch': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/PendingIdentity'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response Add Members To Current Org Batch Api V1 Orgs Current Members Batch Post'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/batch': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}/pending': {'delete': {'tags': ['orgs'],\n",
       "     'summary': 'Delete Current Org Pending Member',\n",
       "     'description': 'When an admin deletes a pending member invite.'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}/pending': {'delete': {'operationId': 'delete_current_org_pending_member_api_v1_orgs_current_members__identity_id__pending_delete',\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}/pending': {'delete': {'parameters': [{'name': 'identity_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Identity Id'}}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}/pending': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}/pending': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/pending/{organization_id}': {'delete': {'tags': ['orgs'],\n",
       "     'summary': 'Delete Pending Organization Invite',\n",
       "     'operationId': 'delete_pending_organization_invite_api_v1_orgs_pending__organization_id__delete',\n",
       "     'security': [{'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/pending/{organization_id}': {'delete': {'parameters': [{'name': 'organization_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Organization Id'}}]}}}},\n",
       " {'paths': {'/api/v1/orgs/pending/{organization_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/pending/{organization_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/pending/{organization_id}/claim': {'post': {'tags': ['orgs'],\n",
       "     'summary': 'Claim Pending Organization Invite',\n",
       "     'operationId': 'claim_pending_organization_invite_api_v1_orgs_pending__organization_id__claim_post',\n",
       "     'security': [{'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/pending/{organization_id}/claim': {'post': {'parameters': [{'name': 'organization_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Organization Id'}}]}}}},\n",
       " {'paths': {'/api/v1/orgs/pending/{organization_id}/claim': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Identity'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/pending/{organization_id}/claim': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}': {'delete': {'tags': ['orgs'],\n",
       "     'summary': 'Remove Member From Current Org',\n",
       "     'description': 'Hard delete a user from the current organization.'}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}': {'delete': {'operationId': 'remove_member_from_current_org_api_v1_orgs_current_members__identity_id__delete',\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}': {'delete': {'parameters': [{'name': 'identity_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Identity Id'}}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}': {'patch': {'tags': ['orgs'],\n",
       "     'summary': 'Update Current Org Member',\n",
       "     'description': \"This is used for updating a user's role (all auth modes) or full_name/password (basic auth)\"}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}': {'patch': {'operationId': 'update_current_org_member_api_v1_orgs_current_members__identity_id__patch',\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}': {'patch': {'parameters': [{'name': 'identity_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Identity Id'}}]}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/OrgIdentityPatch'}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/current/members/{identity_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/ttl-settings': {'get': {'tags': ['orgs'],\n",
       "     'summary': 'List Ttl Settings',\n",
       "     'description': 'List out the configured TTL settings for a given org (org-level and tenant-level).',\n",
       "     'operationId': 'list_ttl_settings_api_v1_orgs_ttl_settings_get'}}}},\n",
       " {'paths': {'/api/v1/orgs/ttl-settings': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/TTLSettings'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response List Ttl Settings Api V1 Orgs Ttl Settings Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/ttl-settings': {'get': {'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/orgs/ttl-settings': {'put': {'tags': ['orgs'],\n",
       "     'summary': 'Upsert Ttl Settings',\n",
       "     'operationId': 'upsert_ttl_settings_api_v1_orgs_ttl_settings_put'}}}},\n",
       " {'paths': {'/api/v1/orgs/ttl-settings': {'put': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/UpsertOrgOrWorkspaceTTLSettingsRequest'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/orgs/ttl-settings': {'put': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TTLSettings'}}}}}}}}},\n",
       " {'paths': {'/api/v1/orgs/ttl-settings': {'put': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/login': {'post': {'tags': ['auth'],\n",
       "     'summary': 'Login',\n",
       "     'operationId': 'login_api_v1_login_post',\n",
       "     'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BasicAuthResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/api-key': {'get': {'tags': ['api-key'],\n",
       "     'summary': 'Get Api Keys',\n",
       "     'description': \"Get the current tenant's API keys\",\n",
       "     'operationId': 'get_api_keys_api_v1_api_key_get'}}}},\n",
       " {'paths': {'/api/v1/api-key': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/APIKeyGetResponse'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response Get Api Keys Api V1 Api Key Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/api-key': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/api-key': {'post': {'tags': ['api-key'],\n",
       "     'summary': 'Generate Api Key',\n",
       "     'description': 'Generate an api key for the user',\n",
       "     'operationId': 'generate_api_key_api_v1_api_key_post'}}}},\n",
       " {'paths': {'/api/v1/api-key': {'post': {'requestBody': {'content': {'application/json': {'schema': {'allOf': [{'$ref': '#/components/schemas/APIKeyCreateRequest'}],\n",
       "         'title': 'Payload',\n",
       "         'default': {'description': 'Default API key',\n",
       "          'read_only': False}}}}}}}}},\n",
       " {'paths': {'/api/v1/api-key': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/APIKeyCreateResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/api-key': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/api-key/{api_key_id}': {'delete': {'tags': ['api-key'],\n",
       "     'summary': 'Delete Api Key',\n",
       "     'description': 'Delete an api key for the user',\n",
       "     'operationId': 'delete_api_key_api_v1_api_key__api_key_id__delete',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/api-key/{api_key_id}': {'delete': {'parameters': [{'name': 'api_key_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Api Key Id'}}]}}}},\n",
       " {'paths': {'/api/v1/api-key/{api_key_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/APIKeyGetResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/api-key/{api_key_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/api-key/current': {'get': {'tags': ['api-key'],\n",
       "     'summary': 'Get Personal Access Tokens',\n",
       "     'description': 'Get the current users PATs for this tenant',\n",
       "     'operationId': 'get_personal_access_tokens_api_v1_api_key_current_get'}}}},\n",
       " {'paths': {'/api/v1/api-key/current': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/APIKeyGetResponse'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response Get Personal Access Tokens Api V1 Api Key Current Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/api-key/current': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/api-key/current': {'post': {'tags': ['api-key'],\n",
       "     'summary': 'Generate Personal Access Token',\n",
       "     'description': 'Generate a Personal Access Token the user',\n",
       "     'operationId': 'generate_personal_access_token_api_v1_api_key_current_post'}}}},\n",
       " {'paths': {'/api/v1/api-key/current': {'post': {'requestBody': {'content': {'application/json': {'schema': {'allOf': [{'$ref': '#/components/schemas/APIKeyCreateRequest'}],\n",
       "         'title': 'Payload',\n",
       "         'default': {'description': 'Default API key',\n",
       "          'read_only': False}}}}}}}}},\n",
       " {'paths': {'/api/v1/api-key/current': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/APIKeyCreateResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/api-key/current': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/api-key/current/{pat_id}': {'delete': {'tags': ['api-key'],\n",
       "     'summary': 'Delete Personal Access Token',\n",
       "     'description': 'Delete a Personal Access Token for the user',\n",
       "     'operationId': 'delete_personal_access_token_api_v1_api_key_current__pat_id__delete'}}}},\n",
       " {'paths': {'/api/v1/api-key/current/{pat_id}': {'delete': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'pat_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Pat Id'}}]}}}},\n",
       " {'paths': {'/api/v1/api-key/current/{pat_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/APIKeyGetResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/api-key/current/{pat_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples/{example_id}': {'get': {'tags': ['examples'],\n",
       "     'summary': 'Read Example',\n",
       "     'description': 'Get a specific example.',\n",
       "     'operationId': 'read_example_api_v1_examples__example_id__get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/examples/{example_id}': {'get': {'parameters': [{'name': 'example_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Example Id'}},\n",
       "      {'name': 'as_of',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'string'}],\n",
       "        'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.',\n",
       "        'default': 'latest',\n",
       "        'title': 'As Of'},\n",
       "       'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'}]}}}},\n",
       " {'paths': {'/api/v1/examples/{example_id}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Example'}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples/{example_id}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples/{example_id}': {'patch': {'tags': ['examples'],\n",
       "     'summary': 'Update Example',\n",
       "     'description': 'Update a specific example.',\n",
       "     'operationId': 'update_example_api_v1_examples__example_id__patch',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/examples/{example_id}': {'patch': {'parameters': [{'name': 'example_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Example Id'}}]}}}},\n",
       " {'paths': {'/api/v1/examples/{example_id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ExampleUpdate'}}}}}}}},\n",
       " {'paths': {'/api/v1/examples/{example_id}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples/{example_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples/{example_id}': {'delete': {'tags': ['examples'],\n",
       "     'summary': 'Delete Example',\n",
       "     'description': 'Delete a specific example.',\n",
       "     'operationId': 'delete_example_api_v1_examples__example_id__delete',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/examples/{example_id}': {'delete': {'parameters': [{'name': 'example_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Example Id'}}]}}}},\n",
       " {'paths': {'/api/v1/examples/{example_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples/{example_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples': {'get': {'tags': ['examples'],\n",
       "     'summary': 'Read Examples',\n",
       "     'description': 'Get all examples by query params',\n",
       "     'operationId': 'read_examples_api_v1_examples_get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/examples': {'get': {'parameters': [{'name': 'id',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Id'}},\n",
       "      {'name': 'as_of',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'string'}],\n",
       "        'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.',\n",
       "        'default': 'latest',\n",
       "        'title': 'As Of'},\n",
       "       'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'},\n",
       "      {'name': 'metadata',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Metadata'}},\n",
       "      {'name': 'full_text_contains',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array', 'items': {'type': 'string'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Full Text Contains'}},\n",
       "      {'name': 'splits',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array', 'items': {'type': 'string'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Splits'}},\n",
       "      {'name': 'dataset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Dataset'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 100,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'order',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'allOf': [{'$ref': '#/components/schemas/ExampleListOrder'}],\n",
       "        'default': 'recent',\n",
       "        'title': 'Order'}},\n",
       "      {'name': 'random_seed',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'number'}, {'type': 'null'}],\n",
       "        'title': 'Random Seed'}},\n",
       "      {'name': 'select',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'array',\n",
       "        'items': {'$ref': '#/components/schemas/ExampleSelect'},\n",
       "        'default': ['id',\n",
       "         'created_at',\n",
       "         'modified_at',\n",
       "         'name',\n",
       "         'dataset_id',\n",
       "         'source_run_id',\n",
       "         'metadata',\n",
       "         'inputs',\n",
       "         'outputs'],\n",
       "        'title': 'Select'}},\n",
       "      {'name': 'filter',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Filter'}}]}}}},\n",
       " {'paths': {'/api/v1/examples': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/Example'},\n",
       "          'title': 'Response Read Examples Api V1 Examples Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples': {'post': {'tags': ['examples'],\n",
       "     'summary': 'Create Example',\n",
       "     'description': 'Create a new example.',\n",
       "     'operationId': 'create_example_api_v1_examples_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/examples': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ExampleCreate'}}}}}}}},\n",
       " {'paths': {'/api/v1/examples': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Example'}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples': {'delete': {'tags': ['examples'],\n",
       "     'summary': 'Delete Examples',\n",
       "     'description': 'Delete a specific set of examples.',\n",
       "     'operationId': 'delete_examples_api_v1_examples_delete',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/examples': {'delete': {'parameters': [{'name': 'example_ids',\n",
       "       'in': 'query',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'array',\n",
       "        'items': {'type': 'string', 'format': 'uuid'},\n",
       "        'title': 'Example Ids'}}]}}}},\n",
       " {'paths': {'/api/v1/examples': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}},\n",
       "      '422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples/bulk': {'post': {'tags': ['examples'],\n",
       "     'summary': 'Create Examples',\n",
       "     'description': 'Create a new example.',\n",
       "     'operationId': 'create_examples_api_v1_examples_bulk_post'}}}},\n",
       " {'paths': {'/api/v1/examples/bulk': {'post': {'requestBody': {'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/ExampleBulkCreate'},\n",
       "         'type': 'array',\n",
       "         'title': 'Examples'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/examples/bulk': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/Example'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response Create Examples Api V1 Examples Bulk Post'}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples/bulk': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/examples/bulk': {'patch': {'tags': ['examples'],\n",
       "     'summary': 'Update Examples',\n",
       "     'description': 'Update examples in bulk.',\n",
       "     'operationId': 'update_examples_api_v1_examples_bulk_patch'}}}},\n",
       " {'paths': {'/api/v1/examples/bulk': {'patch': {'requestBody': {'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/ExampleUpdateWithID'},\n",
       "         'type': 'array',\n",
       "         'title': 'Example Updates'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/examples/bulk': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples/bulk': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/examples/upload/{dataset_id}': {'post': {'tags': ['examples'],\n",
       "     'summary': 'Upload Examples',\n",
       "     'description': 'Create a new example.',\n",
       "     'operationId': 'upload_examples_api_v1_examples_upload__dataset_id__post'}}}},\n",
       " {'paths': {'/api/v1/examples/upload/{dataset_id}': {'post': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/examples/upload/{dataset_id}': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'multipart/form-data': {'schema': {'$ref': '#/components/schemas/Body_upload_examples_api_v1_examples_upload__dataset_id__post'}}}}}}}},\n",
       " {'paths': {'/api/v1/examples/upload/{dataset_id}': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/Example'},\n",
       "          'title': 'Response Upload Examples Api V1 Examples Upload  Dataset Id  Post'}}}}}}}}},\n",
       " {'paths': {'/api/v1/examples/upload/{dataset_id}': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}': {'get': {'tags': ['datasets'],\n",
       "     'summary': 'Read Dataset',\n",
       "     'description': 'Get a specific dataset.',\n",
       "     'operationId': 'read_dataset_api_v1_datasets__dataset_id__get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}': {'get': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Dataset'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}': {'delete': {'tags': ['datasets'],\n",
       "     'summary': 'Delete Dataset',\n",
       "     'description': 'Delete a specific dataset.',\n",
       "     'operationId': 'delete_dataset_api_v1_datasets__dataset_id__delete',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}': {'delete': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}': {'patch': {'tags': ['datasets'],\n",
       "     'summary': 'Update Dataset',\n",
       "     'description': 'Update a specific dataset.',\n",
       "     'operationId': 'update_dataset_api_v1_datasets__dataset_id__patch',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}': {'patch': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetUpdate'}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}': {'patch': {'responses': {'200': {'description': 'Dataset updated successfully',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetSchemaForUpdate'}}},\n",
       "       'headers': {'X-Updated-Examples-Count': {'description': 'Number of examples updated',\n",
       "         'schema': {'type': 'integer'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets': {'get': {'tags': ['datasets'],\n",
       "     'summary': 'Read Datasets',\n",
       "     'description': 'Get all datasets by query params and owner.',\n",
       "     'operationId': 'read_datasets_api_v1_datasets_get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets': {'get': {'parameters': [{'name': 'id',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Id'}},\n",
       "      {'name': 'data_type',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'$ref': '#/components/schemas/DataType'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Data Type'}},\n",
       "      {'name': 'name',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Name'}},\n",
       "      {'name': 'name_contains',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Name Contains'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 100,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'sort_by',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'allOf': [{'$ref': '#/components/schemas/SortByDatasetColumn'}],\n",
       "        'default': 'last_session_start_time',\n",
       "        'title': 'Sort By'}},\n",
       "      {'name': 'sort_by_desc',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': True,\n",
       "        'title': 'Sort By Desc'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/Dataset'},\n",
       "          'title': 'Response Read Datasets Api V1 Datasets Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets': {'post': {'tags': ['datasets'],\n",
       "     'summary': 'Create Dataset',\n",
       "     'description': 'Create a new dataset.',\n",
       "     'operationId': 'create_dataset_api_v1_datasets_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetCreate'}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Dataset'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/upload': {'post': {'tags': ['datasets'],\n",
       "     'summary': 'Upload Csv Dataset',\n",
       "     'description': 'Create a new dataset from a CSV file.',\n",
       "     'operationId': 'upload_csv_dataset_api_v1_datasets_upload_post'}}}},\n",
       " {'paths': {'/api/v1/datasets/upload': {'post': {'requestBody': {'content': {'multipart/form-data': {'schema': {'$ref': '#/components/schemas/Body_upload_csv_dataset_api_v1_datasets_upload_post'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/datasets/upload': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Dataset'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/upload': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/versions': {'get': {'tags': ['datasets'],\n",
       "     'summary': 'Get Dataset Versions',\n",
       "     'description': 'Get dataset versions.',\n",
       "     'operationId': 'get_dataset_versions_api_v1_datasets__dataset_id__versions_get'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/versions': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/versions': {'get': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "      {'name': 'search',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Search'}},\n",
       "      {'name': 'example',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Example'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 100,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/versions': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/DatasetVersion'},\n",
       "          'title': 'Response Get Dataset Versions Api V1 Datasets  Dataset Id  Versions Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/versions': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/versions/diff': {'get': {'tags': ['datasets'],\n",
       "     'summary': 'Diff Dataset Versions',\n",
       "     'description': 'Get diff between two dataset versions.',\n",
       "     'operationId': 'diff_dataset_versions_api_v1_datasets__dataset_id__versions_diff_get'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/versions/diff': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/versions/diff': {'get': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "      {'name': 'from_version',\n",
       "       'in': 'query',\n",
       "       'required': True,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'string'}],\n",
       "        'title': 'From Version'}},\n",
       "      {'name': 'to_version',\n",
       "       'in': 'query',\n",
       "       'required': True,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'string'}],\n",
       "        'title': 'To Version'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/versions/diff': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetDiffInfo'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/versions/diff': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/version': {'get': {'tags': ['datasets'],\n",
       "     'summary': 'Get Dataset Version',\n",
       "     'description': 'Get dataset version by as_of or exact tag.',\n",
       "     'operationId': 'get_dataset_version_api_v1_datasets__dataset_id__version_get'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/version': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/version': {'get': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "      {'name': 'as_of',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'As Of'}},\n",
       "      {'name': 'tag',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Tag'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/version': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetVersion'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/version': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/tags': {'put': {'tags': ['datasets'],\n",
       "     'summary': 'Update Dataset Version',\n",
       "     'description': 'Set a tag on a dataset version.',\n",
       "     'operationId': 'update_dataset_version_api_v1_datasets__dataset_id__tags_put'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/tags': {'put': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/tags': {'put': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PutDatasetVersionsSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/tags': {'put': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetVersion'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/tags': {'put': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/openai': {'get': {'tags': ['datasets'],\n",
       "     'summary': 'Download Dataset Openai',\n",
       "     'description': 'Download a dataset as OpenAI Evals Jsonl format.',\n",
       "     'operationId': 'download_dataset_openai_api_v1_datasets__dataset_id__openai_get'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/openai': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/openai': {'get': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "      {'name': 'as_of',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'null'}],\n",
       "        'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.',\n",
       "        'title': 'As Of'},\n",
       "       'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/openai': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/openai': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/openai_ft': {'get': {'tags': ['datasets'],\n",
       "     'summary': 'Download Dataset Openai Ft',\n",
       "     'description': 'Download a dataset as OpenAI Jsonl format.',\n",
       "     'operationId': 'download_dataset_openai_ft_api_v1_datasets__dataset_id__openai_ft_get'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/openai_ft': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/openai_ft': {'get': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "      {'name': 'as_of',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'null'}],\n",
       "        'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.',\n",
       "        'title': 'As Of'},\n",
       "       'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/openai_ft': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/openai_ft': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/csv': {'get': {'tags': ['datasets'],\n",
       "     'summary': 'Download Dataset Csv',\n",
       "     'description': 'Download a dataset as CSV format.',\n",
       "     'operationId': 'download_dataset_csv_api_v1_datasets__dataset_id__csv_get'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/csv': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/csv': {'get': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "      {'name': 'as_of',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'null'}],\n",
       "        'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.',\n",
       "        'title': 'As Of'},\n",
       "       'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/csv': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/csv': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/runs': {'post': {'tags': ['datasets'],\n",
       "     'summary': 'Read Examples With Runs',\n",
       "     'description': 'Fetch examples for a dataset, and fetch the runs for each example if they are associated with the given session_ids.'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/runs': {'post': {'operationId': 'read_examples_with_runs_api_v1_datasets__dataset_id__runs_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/runs': {'post': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/runs': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/QueryExampleSchemaWithRuns'}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/runs': {'post': {'responses': {'200': {'description': 'Successful Response'}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/runs': {'post': {'responses': {'200': {'content': {'application/json': {'schema': {'anyOf': [{'type': 'array',\n",
       "            'items': {'$ref': '#/components/schemas/ExampleWithRuns'}},\n",
       "           {'type': 'array',\n",
       "            'items': {'$ref': '#/components/schemas/ExampleWithRunsCH'}}],\n",
       "          'title': 'Response Read Examples With Runs Api V1 Datasets  Dataset Id  Runs Post'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/runs': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/runs/delta': {'post': {'tags': ['datasets'],\n",
       "     'summary': 'Read Delta',\n",
       "     'description': 'Fetch the number of regressions/improvements for each example in a dataset, between sessions[0] and sessions[1].'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/runs/delta': {'post': {'operationId': 'read_delta_api_v1_datasets__dataset_id__runs_delta_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/runs/delta': {'post': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/runs/delta': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/QueryFeedbackDelta'}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/runs/delta': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SessionFeedbackDelta'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/runs/delta': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/share': {'get': {'tags': ['datasets'],\n",
       "     'summary': 'Read Dataset Share State',\n",
       "     'description': 'Get the state of sharing a dataset',\n",
       "     'operationId': 'read_dataset_share_state_api_v1_datasets__dataset_id__share_get'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/share': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/share': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'anyOf': [{'$ref': '#/components/schemas/DatasetShareSchema'},\n",
       "           {'type': 'null'}],\n",
       "          'title': 'Response Read Dataset Share State Api V1 Datasets  Dataset Id  Share Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/share': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/share': {'put': {'tags': ['datasets'],\n",
       "     'summary': 'Share Dataset',\n",
       "     'description': 'Share a dataset.',\n",
       "     'operationId': 'share_dataset_api_v1_datasets__dataset_id__share_put',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/share': {'put': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "      {'name': 'share_projects',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': False,\n",
       "        'title': 'Share Projects'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/share': {'put': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetShareSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/share': {'put': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/share': {'delete': {'tags': ['datasets'],\n",
       "     'summary': 'Unshare Dataset',\n",
       "     'description': 'Unshare a dataset.',\n",
       "     'operationId': 'unshare_dataset_api_v1_datasets__dataset_id__share_delete'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/share': {'delete': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/share': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/share': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/comparative': {'get': {'tags': ['datasets'],\n",
       "     'summary': 'Read Comparative Experiments',\n",
       "     'description': 'Get all comparative experiments for a given dataset.',\n",
       "     'operationId': 'read_comparative_experiments_api_v1_datasets__dataset_id__comparative_get'}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/comparative': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/comparative': {'get': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "      {'name': 'name',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Name'}},\n",
       "      {'name': 'name_contains',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Name Contains'}},\n",
       "      {'name': 'id',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Id'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 100,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'sort_by',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'allOf': [{'$ref': '#/components/schemas/SortByComparativeExperimentColumn'}],\n",
       "        'default': 'created_at',\n",
       "        'title': 'Sort By'}},\n",
       "      {'name': 'sort_by_desc',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': True,\n",
       "        'title': 'Sort By Desc'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/comparative': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/ComparativeExperiment'},\n",
       "          'title': 'Response Read Comparative Experiments Api V1 Datasets  Dataset Id  Comparative Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/comparative': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/comparative': {'post': {'tags': ['datasets'],\n",
       "     'summary': 'Create Comparative Experiment',\n",
       "     'description': 'Create a comparative experiment.',\n",
       "     'operationId': 'create_comparative_experiment_api_v1_datasets_comparative_post'}}}},\n",
       " {'paths': {'/api/v1/datasets/comparative': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ComparativeExperimentCreate'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/datasets/comparative': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ComparativeExperimentBase'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/comparative': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/comparative/{comparative_experiment_id}': {'delete': {'tags': ['datasets'],\n",
       "     'summary': 'Delete Comparative Experiment',\n",
       "     'description': 'Delete a specific comparative experiment.'}}}},\n",
       " {'paths': {'/api/v1/datasets/comparative/{comparative_experiment_id}': {'delete': {'operationId': 'delete_comparative_experiment_api_v1_datasets_comparative__comparative_experiment_id__delete',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/comparative/{comparative_experiment_id}': {'delete': {'parameters': [{'name': 'comparative_experiment_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Comparative Experiment Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/comparative/{comparative_experiment_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/comparative/{comparative_experiment_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/clone': {'post': {'tags': ['datasets'],\n",
       "     'summary': 'Clone Dataset',\n",
       "     'description': 'Clone a dataset.',\n",
       "     'operationId': 'clone_dataset_api_v1_datasets_clone_post'}}}},\n",
       " {'paths': {'/api/v1/datasets/clone': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Body_clone_dataset_api_v1_datasets_clone_post'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/datasets/clone': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/Example'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response Clone Dataset Api V1 Datasets Clone Post'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/clone': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/splits': {'get': {'tags': ['datasets'],\n",
       "     'summary': 'Get Dataset Splits',\n",
       "     'operationId': 'get_dataset_splits_api_v1_datasets__dataset_id__splits_get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/splits': {'get': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Dataset Id'}},\n",
       "      {'name': 'as_of',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'string'}],\n",
       "        'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.',\n",
       "        'default': 'latest',\n",
       "        'title': 'As Of'},\n",
       "       'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/splits': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'type': 'string'},\n",
       "          'title': 'Response Get Dataset Splits Api V1 Datasets  Dataset Id  Splits Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/splits': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/splits': {'put': {'tags': ['datasets'],\n",
       "     'summary': 'Update Dataset Splits',\n",
       "     'operationId': 'update_dataset_splits_api_v1_datasets__dataset_id__splits_put',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/splits': {'put': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/splits': {'put': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Body_update_dataset_splits_api_v1_datasets__dataset_id__splits_put'}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/splits': {'put': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'},\n",
       "          'title': 'Response Update Dataset Splits Api V1 Datasets  Dataset Id  Splits Put'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/splits': {'put': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/serve': {'post': {'tags': ['datasets'],\n",
       "     'summary': 'Serve',\n",
       "     'description': 'Serve a dataset.',\n",
       "     'operationId': 'serve_api_v1_datasets__dataset_id__serve_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/serve': {'post': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/serve': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetServeRequest'}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/serve': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/serve': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/unserve': {'post': {'tags': ['datasets'],\n",
       "     'summary': 'Unserve',\n",
       "     'description': 'Serve a dataset.',\n",
       "     'operationId': 'unserve_api_v1_datasets__dataset_id__unserve_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/unserve': {'post': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Dataset Id'}}]}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/unserve': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/datasets/{dataset_id}/unserve': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules': {'get': {'tags': ['run'],\n",
       "     'summary': 'List Rules',\n",
       "     'description': 'List all run rules.',\n",
       "     'operationId': 'list_rules_api_v1_runs_rules_get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/rules': {'get': {'parameters': [{'name': 'dataset_id',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Dataset Id'}},\n",
       "      {'name': 'session_id',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Session Id'}}]}}}},\n",
       " {'paths': {'/api/v1/runs/rules': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/RunRulesSchema'},\n",
       "          'title': 'Response List Rules Api V1 Runs Rules Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules': {'post': {'tags': ['run'],\n",
       "     'summary': 'Create Rule',\n",
       "     'description': 'Create a new run rule.',\n",
       "     'operationId': 'create_rule_api_v1_runs_rules_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/rules': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunRulesCreateSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunRulesSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}': {'patch': {'tags': ['run'],\n",
       "     'summary': 'Update Rule',\n",
       "     'description': 'Update a run rule.',\n",
       "     'operationId': 'update_rule_api_v1_runs_rules__rule_id__patch',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}': {'patch': {'parameters': [{'name': 'rule_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Rule Id'}}]}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunRulesCreateSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunRulesSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}': {'delete': {'tags': ['run'],\n",
       "     'summary': 'Delete Rule',\n",
       "     'description': 'Delete a run rule.',\n",
       "     'operationId': 'delete_rule_api_v1_runs_rules__rule_id__delete',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}': {'delete': {'parameters': [{'name': 'rule_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Rule Id'}}]}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}/logs': {'get': {'tags': ['run'],\n",
       "     'summary': 'List Rule Logs',\n",
       "     'description': 'List logs for a particular rule',\n",
       "     'operationId': 'list_rule_logs_api_v1_runs_rules__rule_id__logs_get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}/logs': {'get': {'parameters': [{'name': 'rule_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Rule Id'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 1440,\n",
       "        'minimum': 100,\n",
       "        'default': 720,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'start_time',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Start Time'}},\n",
       "      {'name': 'end_time',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'End Time'}}]}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}/logs': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/RuleLogSchema'},\n",
       "          'title': 'Response List Rule Logs Api V1 Runs Rules  Rule Id  Logs Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}/logs': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}/trigger': {'post': {'tags': ['run'],\n",
       "     'summary': 'Trigger Rule',\n",
       "     'description': 'Trigger a run rule manually.',\n",
       "     'operationId': 'trigger_rule_api_v1_runs_rules__rule_id__trigger_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}/trigger': {'post': {'parameters': [{'name': 'rule_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Rule Id'}}]}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}/trigger': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunRulesSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/rules/{rule_id}/trigger': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}': {'get': {'tags': ['run'],\n",
       "     'summary': 'Read Run',\n",
       "     'description': 'Get a specific run.',\n",
       "     'operationId': 'read_run_api_v1_runs__run_id__get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}': {'get': {'parameters': [{'name': 'run_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'}},\n",
       "      {'name': 'exclude_s3_stored_attributes',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': False,\n",
       "        'title': 'Exclude S3 Stored Attributes'}}]}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}': {'patch': {'tags': ['run'],\n",
       "     'summary': 'Update Run',\n",
       "     'description': 'Update a run.',\n",
       "     'operationId': 'update_run_api_v1_runs__run_id__patch',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}': {'patch': {'parameters': [{'name': 'run_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'}}]}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/UpdateRunRequest'}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}/share': {'get': {'tags': ['run'],\n",
       "     'summary': 'Read Run Share State',\n",
       "     'description': 'Get the state of sharing of a run.',\n",
       "     'operationId': 'read_run_share_state_api_v1_runs__run_id__share_get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}/share': {'get': {'parameters': [{'name': 'run_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'}}]}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}/share': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'anyOf': [{'$ref': '#/components/schemas/RunShareSchema'},\n",
       "           {'type': 'null'}],\n",
       "          'title': 'Response Read Run Share State Api V1 Runs  Run Id  Share Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}/share': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}/share': {'put': {'tags': ['run'],\n",
       "     'summary': 'Share Run',\n",
       "     'description': 'Share a run.',\n",
       "     'operationId': 'share_run_api_v1_runs__run_id__share_put',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}/share': {'put': {'parameters': [{'name': 'run_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'}}]}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}/share': {'put': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunShareSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}/share': {'put': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}/share': {'delete': {'tags': ['run'],\n",
       "     'summary': 'Unshare Run',\n",
       "     'description': 'Unshare a run.',\n",
       "     'operationId': 'unshare_run_api_v1_runs__run_id__share_delete',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}/share': {'delete': {'parameters': [{'name': 'run_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'}}]}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}/share': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/{run_id}/share': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/query': {'post': {'tags': ['run'],\n",
       "     'summary': 'Query Runs',\n",
       "     'description': 'Get all runs by query in body payload.',\n",
       "     'operationId': 'query_runs_api_v1_runs_query_post'}}}},\n",
       " {'paths': {'/api/v1/runs/query': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BodyParamsForRunSchema'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/runs/query': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ListRunsResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/query': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/generate-query': {'post': {'tags': ['run'],\n",
       "     'summary': 'Generate Query For Runs',\n",
       "     'description': 'Get runs filter expression query for a given natural language query.',\n",
       "     'operationId': 'generate_query_for_runs_api_v1_runs_generate_query_post'}}}},\n",
       " {'paths': {'/api/v1/runs/generate-query': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RequestBodyForRunsGenerateQuery'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/runs/generate-query': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ResponseBodyForRunsGenerateQuery'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/generate-query': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/stats': {'post': {'tags': ['run'],\n",
       "     'summary': 'Stats Runs',\n",
       "     'description': 'Get all runs by query in body payload.',\n",
       "     'operationId': 'stats_runs_api_v1_runs_stats_post'}}}},\n",
       " {'paths': {'/api/v1/runs/stats': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FilterQueryParamsForRunSchema'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/runs/stats': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunStats'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/stats': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/monitor': {'post': {'tags': ['run'],\n",
       "     'summary': 'Monitor Tracer Session',\n",
       "     'description': 'Get monitoring data for a specific session.',\n",
       "     'operationId': 'monitor_tracer_session_api_v1_runs_monitor_post'}}}},\n",
       " {'paths': {'/api/v1/runs/monitor': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/MonitorRequest'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/runs/monitor': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/MonitorResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/monitor': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs': {'post': {'tags': ['run'],\n",
       "     'summary': 'Create Run',\n",
       "     'description': 'Create a new run.',\n",
       "     'operationId': 'create_run_api_v1_runs_post',\n",
       "     'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs': {'post': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CreateRunRequest'}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/batch': {'post': {'tags': ['run'],\n",
       "     'summary': 'Batch Ingest Runs',\n",
       "     'description': 'Batch ingest runs.',\n",
       "     'operationId': 'batch_ingest_runs_api_v1_runs_batch_post'}}}},\n",
       " {'paths': {'/api/v1/runs/batch': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/batch': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BatchIngestRunsRequest'}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/group': {'post': {'tags': ['run'],\n",
       "     'summary': 'Group Runs',\n",
       "     'description': 'Get runs grouped by an expression',\n",
       "     'operationId': 'group_runs_api_v1_runs_group_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/runs/group': {'post': {'parameters': [{'name': 'accept',\n",
       "       'in': 'header',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Accept'}}]}}}},\n",
       " {'paths': {'/api/v1/runs/group': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunGroupRequest'}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/group': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}},\n",
       "      '422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/group/stats': {'post': {'tags': ['run'],\n",
       "     'summary': 'Stats Group Runs',\n",
       "     'description': 'Get stats for the grouped runs.',\n",
       "     'operationId': 'stats_group_runs_api_v1_runs_group_stats_post'}}}},\n",
       " {'paths': {'/api/v1/runs/group/stats': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunGroupRequest'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/runs/group/stats': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunGroupStats'}}}}}}}}},\n",
       " {'paths': {'/api/v1/runs/group/stats': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/feedback/{feedback_id}': {'get': {'tags': ['feedback'],\n",
       "     'summary': 'Read Feedback',\n",
       "     'description': 'Get a specific feedback.',\n",
       "     'operationId': 'read_feedback_api_v1_feedback__feedback_id__get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/feedback/{feedback_id}': {'get': {'parameters': [{'name': 'feedback_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Feedback Id'}}]}}}},\n",
       " {'paths': {'/api/v1/feedback/{feedback_id}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/{feedback_id}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/{feedback_id}': {'patch': {'tags': ['feedback'],\n",
       "     'summary': 'Update Feedback',\n",
       "     'description': 'Replace an existing feedback entry with a new, modified entry.',\n",
       "     'operationId': 'update_feedback_api_v1_feedback__feedback_id__patch'}}}},\n",
       " {'paths': {'/api/v1/feedback/{feedback_id}': {'patch': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'feedback_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Feedback Id'}}]}}}},\n",
       " {'paths': {'/api/v1/feedback/{feedback_id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackUpdateSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/{feedback_id}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/{feedback_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/{feedback_id}': {'delete': {'tags': ['feedback'],\n",
       "     'summary': 'Delete Feedback',\n",
       "     'description': 'Delete a feedback.',\n",
       "     'operationId': 'delete_feedback_api_v1_feedback__feedback_id__delete',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/feedback/{feedback_id}': {'delete': {'parameters': [{'name': 'feedback_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Feedback Id'}}]}}}},\n",
       " {'paths': {'/api/v1/feedback/{feedback_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/{feedback_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback': {'get': {'tags': ['feedback'],\n",
       "     'summary': 'Read Feedbacks',\n",
       "     'description': 'List all Feedback by query params.',\n",
       "     'operationId': 'read_feedbacks_api_v1_feedback_get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/feedback': {'get': {'parameters': [{'name': 'run',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Run'}},\n",
       "      {'name': 'key',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array', 'items': {'type': 'string'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Key'}},\n",
       "      {'name': 'session',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Session'}},\n",
       "      {'name': 'source',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/SourceType'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Source'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 100,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'user',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'User'}},\n",
       "      {'name': 'has_comment',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "        'title': 'Has Comment'}},\n",
       "      {'name': 'has_score',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "        'title': 'Has Score'}},\n",
       "      {'name': 'level',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'$ref': '#/components/schemas/FeedbackLevel'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Level'}},\n",
       "      {'name': 'max_created_at',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Max Created At'}},\n",
       "      {'name': 'min_created_at',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Min Created At'}}]}}}},\n",
       " {'paths': {'/api/v1/feedback': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/FeedbackSchema'},\n",
       "          'title': 'Response Read Feedbacks Api V1 Feedback Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback': {'post': {'tags': ['feedback'],\n",
       "     'summary': 'Create Feedback',\n",
       "     'description': 'Create a new feedback.',\n",
       "     'operationId': 'create_feedback_api_v1_feedback_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/feedback': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackCreateSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/eager': {'post': {'tags': ['feedback'],\n",
       "     'summary': 'Eagerly Create Feedback',\n",
       "     'description': 'Create a new feedback.\\n\\nThis method is invoked under the assumption that the run\\nis already visible in the app, thus already present in DB'}}}},\n",
       " {'paths': {'/api/v1/feedback/eager': {'post': {'operationId': 'eagerly_create_feedback_api_v1_feedback_eager_post',\n",
       "     'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackCreateSchema'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/feedback/eager': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/eager': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens': {'post': {'tags': ['feedback'],\n",
       "     'summary': 'Create Feedback Ingest Token',\n",
       "     'description': 'Create a new feedback ingest token.',\n",
       "     'operationId': 'create_feedback_ingest_token_api_v1_feedback_tokens_post'}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens': {'post': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'anyOf': [{'$ref': '#/components/schemas/FeedbackIngestTokenCreateSchema'},\n",
       "          {'type': 'array',\n",
       "           'items': {'$ref': '#/components/schemas/FeedbackIngestTokenCreateSchema'}}]}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens': {'post': {'requestBody': {'content': {'application/json': {'schema': {'title': 'Feedback Ingest Token'}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens': {'post': {'responses': {'200': {'description': 'Successful Response'}}}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens': {'post': {'responses': {'200': {'content': {'application/json': {'schema': {'anyOf': [{'$ref': '#/components/schemas/FeedbackIngestTokenSchema'},\n",
       "           {'type': 'array',\n",
       "            'items': {'$ref': '#/components/schemas/FeedbackIngestTokenSchema'}}],\n",
       "          'title': 'Response Create Feedback Ingest Token Api V1 Feedback Tokens Post'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens': {'get': {'tags': ['feedback'],\n",
       "     'summary': 'List Feedback Ingest Tokens',\n",
       "     'description': 'List all feedback ingest tokens for a run.',\n",
       "     'operationId': 'list_feedback_ingest_tokens_api_v1_feedback_tokens_get'}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'run_id',\n",
       "       'in': 'query',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'}}]}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/FeedbackIngestTokenSchema'},\n",
       "          'title': 'Response List Feedback Ingest Tokens Api V1 Feedback Tokens Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens/{token}': {'get': {'tags': ['feedback'],\n",
       "     'summary': 'Create Feedback With Token Get',\n",
       "     'description': 'Create a new feedback with a token.',\n",
       "     'operationId': 'create_feedback_with_token_get_api_v1_feedback_tokens__token__get'}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens/{token}': {'get': {'parameters': [{'name': 'token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Token'}},\n",
       "      {'name': 'score',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'number'},\n",
       "         {'type': 'integer'},\n",
       "         {'type': 'boolean'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Score'}},\n",
       "      {'name': 'value',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'number'},\n",
       "         {'type': 'integer'},\n",
       "         {'type': 'boolean'},\n",
       "         {'type': 'string'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Value'}},\n",
       "      {'name': 'comment',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Comment'}},\n",
       "      {'name': 'correction',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Correction'}}]}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens/{token}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens/{token}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens/{token}': {'post': {'tags': ['feedback'],\n",
       "     'summary': 'Create Feedback With Token Post',\n",
       "     'description': 'Create a new feedback with a token.',\n",
       "     'operationId': 'create_feedback_with_token_post_api_v1_feedback_tokens__token__post'}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens/{token}': {'post': {'parameters': [{'name': 'token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Token'}}]}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens/{token}': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackCreateWithTokenExtendedSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens/{token}': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback/tokens/{token}': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/run': {'get': {'tags': ['public'],\n",
       "     'summary': 'Get Shared Run',\n",
       "     'description': 'Get the shared run.',\n",
       "     'operationId': 'get_shared_run_api_v1_public__share_token__run_get'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/run': {'get': {'parameters': [{'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "      {'name': 'exclude_s3_stored_attributes',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': False,\n",
       "        'title': 'Exclude S3 Stored Attributes'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/run': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunPublicSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/run': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/run/{id}': {'get': {'tags': ['public'],\n",
       "     'summary': 'Get Shared Run By Id',\n",
       "     'description': 'Get the shared run.',\n",
       "     'operationId': 'get_shared_run_by_id_api_v1_public__share_token__run__id__get'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/run/{id}': {'get': {'parameters': [{'name': 'id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Id'}},\n",
       "      {'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "      {'name': 'exclude_s3_stored_attributes',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': False,\n",
       "        'title': 'Exclude S3 Stored Attributes'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/run/{id}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunPublicSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/run/{id}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/runs/query': {'post': {'tags': ['public'],\n",
       "     'summary': 'Query Shared Runs',\n",
       "     'description': 'Get run by ids or the shared run if not specifed.',\n",
       "     'operationId': 'query_shared_runs_api_v1_public__share_token__runs_query_post'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/runs/query': {'post': {'parameters': [{'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Share Token'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/runs/query': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/QueryParamsForPublicRunSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/runs/query': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ListPublicRunsResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/runs/query': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/feedbacks': {'get': {'tags': ['public'],\n",
       "     'summary': 'Read Shared Feedbacks',\n",
       "     'operationId': 'read_shared_feedbacks_api_v1_public__share_token__feedbacks_get'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/feedbacks': {'get': {'parameters': [{'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "      {'name': 'run',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Run'}},\n",
       "      {'name': 'key',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array', 'items': {'type': 'string'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Key'}},\n",
       "      {'name': 'session',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Session'}},\n",
       "      {'name': 'source',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/SourceType'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Source'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 100,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'user',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'User'}},\n",
       "      {'name': 'has_comment',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "        'title': 'Has Comment'}},\n",
       "      {'name': 'has_score',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "        'title': 'Has Score'}},\n",
       "      {'name': 'level',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'$ref': '#/components/schemas/FeedbackLevel'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Level'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/feedbacks': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/FeedbackSchema'},\n",
       "          'title': 'Response Read Shared Feedbacks Api V1 Public  Share Token  Feedbacks Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/feedbacks': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets': {'get': {'tags': ['public'],\n",
       "     'summary': 'Read Shared Dataset',\n",
       "     'description': 'Get dataset by ids or the shared dataset if not specifed.',\n",
       "     'operationId': 'read_shared_dataset_api_v1_public__share_token__datasets_get'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets': {'get': {'parameters': [{'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 100,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'sort_by',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'allOf': [{'$ref': '#/components/schemas/SortByDatasetColumn'}],\n",
       "        'default': 'last_session_start_time',\n",
       "        'title': 'Sort By'}},\n",
       "      {'name': 'sort_by_desc',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': True,\n",
       "        'title': 'Sort By Desc'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/DatasetPublicSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/examples': {'get': {'tags': ['public'],\n",
       "     'summary': 'Read Shared Examples',\n",
       "     'description': 'Get example by ids or the shared example if not specifed.',\n",
       "     'operationId': 'read_shared_examples_api_v1_public__share_token__examples_get'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/examples': {'get': {'parameters': [{'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "      {'name': 'id',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Id'}},\n",
       "      {'name': 'as_of',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "         {'type': 'string'}],\n",
       "        'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.',\n",
       "        'default': 'latest',\n",
       "        'title': 'As Of'},\n",
       "       'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'},\n",
       "      {'name': 'metadata',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Metadata'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 100,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'select',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'array',\n",
       "        'items': {'$ref': '#/components/schemas/ExampleSelect'},\n",
       "        'default': ['id',\n",
       "         'created_at',\n",
       "         'modified_at',\n",
       "         'name',\n",
       "         'dataset_id',\n",
       "         'metadata',\n",
       "         'inputs',\n",
       "         'outputs'],\n",
       "        'title': 'Select'}},\n",
       "      {'name': 'filter',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Filter'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/examples': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/Example'},\n",
       "          'title': 'Response Read Shared Examples Api V1 Public  Share Token  Examples Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/examples': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/sessions': {'get': {'tags': ['public'],\n",
       "     'summary': 'Read Shared Dataset Tracer Sessions',\n",
       "     'description': 'Get projects run on a dataset that has been shared.'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/sessions': {'get': {'operationId': 'read_shared_dataset_tracer_sessions_api_v1_public__share_token__datasets_sessions_get'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/sessions': {'get': {'parameters': [{'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "      {'name': 'id',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Id'}},\n",
       "      {'name': 'name',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Name'}},\n",
       "      {'name': 'name_contains',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Name Contains'}},\n",
       "      {'name': 'dataset_version',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Dataset Version'}},\n",
       "      {'name': 'sort_by',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'allOf': [{'$ref': '#/components/schemas/SessionSortableColumns'}],\n",
       "        'default': 'start_time',\n",
       "        'title': 'Sort By'}},\n",
       "      {'name': 'sort_by_desc',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': True,\n",
       "        'title': 'Sort By Desc'}},\n",
       "      {'name': 'sort_by_feedback_key',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Sort By Feedback Key'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 100,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'facets',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean', 'default': False, 'title': 'Facets'}},\n",
       "      {'name': 'accept',\n",
       "       'in': 'header',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Accept'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/sessions': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/TracerSession'},\n",
       "          'title': 'Response Read Shared Dataset Tracer Sessions Api V1 Public  Share Token  Datasets Sessions Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/sessions': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/examples/runs': {'post': {'tags': ['public'],\n",
       "     'summary': 'Read Shared Dataset Examples With Runs',\n",
       "     'description': 'Get examples with associated runs from sessions in a dataset that has been shared.'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/examples/runs': {'post': {'operationId': 'read_shared_dataset_examples_with_runs_api_v1_public__share_token__examples_runs_post'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/examples/runs': {'post': {'parameters': [{'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Share Token'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/examples/runs': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/QueryExampleSchemaWithRuns'}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/examples/runs': {'post': {'responses': {'200': {'description': 'Successful Response'}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/examples/runs': {'post': {'responses': {'200': {'content': {'application/json': {'schema': {'anyOf': [{'type': 'array',\n",
       "            'items': {'$ref': '#/components/schemas/PublicExampleWithRuns'}},\n",
       "           {'type': 'array',\n",
       "            'items': {'$ref': '#/components/schemas/ExampleWithRunsCH'}}],\n",
       "          'title': 'Response Read Shared Dataset Examples With Runs Api V1 Public  Share Token  Examples Runs Post'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/examples/runs': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/delta': {'post': {'tags': ['public'],\n",
       "     'summary': 'Read Shared Delta',\n",
       "     'description': 'Fetch the number of regressions/improvements for each example in a dataset, between sessions[0] and sessions[1].'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/delta': {'post': {'operationId': 'read_shared_delta_api_v1_public__share_token__datasets_runs_delta_post'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/delta': {'post': {'parameters': [{'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Share Token'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/delta': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/QueryFeedbackDelta'}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/delta': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SessionFeedbackDelta'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/delta': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/query': {'post': {'tags': ['public'],\n",
       "     'summary': 'Query Shared Dataset Runs',\n",
       "     'description': 'Get runs in projects run over a dataset that has been shared.'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/query': {'post': {'operationId': 'query_shared_dataset_runs_api_v1_public__share_token__datasets_runs_query_post'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/query': {'post': {'parameters': [{'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Share Token'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/query': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/BodyParamsForRunSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/query': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ListPublicDatasetRunsResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/query': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/generate-query': {'post': {'tags': ['public'],\n",
       "     'summary': 'Generate Query For Shared Dataset Runs',\n",
       "     'description': 'Get runs in projects run over a dataset that has been shared.'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/generate-query': {'post': {'operationId': 'generate_query_for_shared_dataset_runs_api_v1_public__share_token__datasets_runs_generate_query_post'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/generate-query': {'post': {'parameters': [{'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Share Token'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/generate-query': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RequestBodyForRunsGenerateQuery'}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/generate-query': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ResponseBodyForRunsGenerateQuery'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/generate-query': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/stats': {'post': {'tags': ['public'],\n",
       "     'summary': 'Stats Shared Dataset Runs',\n",
       "     'description': 'Get run stats in projects run over a dataset that has been shared.'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/stats': {'post': {'operationId': 'stats_shared_dataset_runs_api_v1_public__share_token__datasets_runs_stats_post'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/stats': {'post': {'parameters': [{'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Share Token'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/stats': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FilterQueryParamsForRunSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/stats': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunStats'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/stats': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/{run_id}': {'get': {'tags': ['public'],\n",
       "     'summary': 'Read Shared Dataset Run',\n",
       "     'description': 'Get runs in projects run over a dataset that has been shared.'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/{run_id}': {'get': {'operationId': 'read_shared_dataset_run_api_v1_public__share_token__datasets_runs__run_id__get'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/{run_id}': {'get': {'parameters': [{'name': 'run_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'}},\n",
       "      {'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "      {'name': 'exclude_s3_stored_attributes',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': False,\n",
       "        'title': 'Exclude S3 Stored Attributes'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/{run_id}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunPublicDatasetSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/runs/{run_id}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/feedback': {'get': {'tags': ['public'],\n",
       "     'summary': 'Read Shared Dataset Feedback',\n",
       "     'description': 'Get feedback for runs in projects run over a dataset that has been shared.'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/feedback': {'get': {'operationId': 'read_shared_dataset_feedback_api_v1_public__share_token__datasets_feedback_get'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/feedback': {'get': {'parameters': [{'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "      {'name': 'run',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Run'}},\n",
       "      {'name': 'key',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array', 'items': {'type': 'string'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Key'}},\n",
       "      {'name': 'session',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Session'}},\n",
       "      {'name': 'source',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/SourceType'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Source'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 100,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'user',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'User'}},\n",
       "      {'name': 'has_comment',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "        'title': 'Has Comment'}},\n",
       "      {'name': 'has_score',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "        'title': 'Has Score'}},\n",
       "      {'name': 'level',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'$ref': '#/components/schemas/FeedbackLevel'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Level'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/feedback': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/FeedbackSchema'},\n",
       "          'title': 'Response Read Shared Dataset Feedback Api V1 Public  Share Token  Datasets Feedback Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/feedback': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/comparative': {'get': {'tags': ['public'],\n",
       "     'summary': 'Read Shared Comparative Experiments',\n",
       "     'description': 'Get all comparative experiments for a given dataset.'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/comparative': {'get': {'operationId': 'read_shared_comparative_experiments_api_v1_public__share_token__datasets_comparative_get'}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/comparative': {'get': {'parameters': [{'name': 'share_token',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Share Token'}},\n",
       "      {'name': 'name',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Name'}},\n",
       "      {'name': 'name_contains',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Name Contains'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 100,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'sort_by',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'allOf': [{'$ref': '#/components/schemas/SortByComparativeExperimentColumn'}],\n",
       "        'default': 'created_at',\n",
       "        'title': 'Sort By'}},\n",
       "      {'name': 'sort_by_desc',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': True,\n",
       "        'title': 'Sort By Desc'}}]}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/comparative': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/PublicComparativeExperiment'},\n",
       "          'title': 'Response Read Shared Comparative Experiments Api V1 Public  Share Token  Datasets Comparative Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/public/{share_token}/datasets/comparative': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues': {'get': {'tags': ['annotation-queues'],\n",
       "     'summary': 'Get Annotation Queues',\n",
       "     'operationId': 'get_annotation_queues_api_v1_annotation_queues_get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues': {'get': {'parameters': [{'name': 'ids',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string', 'format': 'uuid'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Ids'}},\n",
       "      {'name': 'name',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Name'}},\n",
       "      {'name': 'name_contains',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Name Contains'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 100,\n",
       "        'title': 'Limit'}}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/AnnotationQueueSchema'},\n",
       "          'title': 'Response Get Annotation Queues Api V1 Annotation Queues Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues': {'post': {'tags': ['annotation-queues'],\n",
       "     'summary': 'Create Annotation Queue',\n",
       "     'operationId': 'create_annotation_queue_api_v1_annotation_queues_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/AnnotationQueueCreateSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/AnnotationQueueSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}': {'delete': {'tags': ['annotation-queues'],\n",
       "     'summary': 'Delete Annotation Queue',\n",
       "     'operationId': 'delete_annotation_queue_api_v1_annotation_queues__queue_id__delete',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}': {'delete': {'parameters': [{'name': 'queue_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Queue Id'}}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}': {'patch': {'tags': ['annotation-queues'],\n",
       "     'summary': 'Update Annotation Queue',\n",
       "     'operationId': 'update_annotation_queue_api_v1_annotation_queues__queue_id__patch',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}': {'patch': {'parameters': [{'name': 'queue_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Queue Id'}}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/AnnotationQueueUpdateSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs': {'post': {'tags': ['annotation-queues'],\n",
       "     'summary': 'Add Runs To Annotation Queue',\n",
       "     'operationId': 'add_runs_to_annotation_queue_api_v1_annotation_queues__queue_id__runs_post'}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs': {'post': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'queue_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Queue Id'}}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'type': 'array',\n",
       "         'items': {'type': 'string', 'format': 'uuid'},\n",
       "         'title': 'Run Ids'}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/AnnotationQueueRunSchema'},\n",
       "          'title': 'Response Add Runs To Annotation Queue Api V1 Annotation Queues  Queue Id  Runs Post'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/run/{index}': {'get': {'tags': ['annotation-queues'],\n",
       "     'summary': 'Get Run From Annotation Queue',\n",
       "     'operationId': 'get_run_from_annotation_queue_api_v1_annotation_queues__queue_id__run__index__get'}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/run/{index}': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/run/{index}': {'get': {'parameters': [{'name': 'queue_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Queue Id'}},\n",
       "      {'name': 'index',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'integer', 'title': 'Index'}}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/run/{index}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/RunSchemaWithAnnotationQueueInfo'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/run/{index}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{run_id}/queues': {'get': {'tags': ['annotation-queues'],\n",
       "     'summary': 'Get Annotation Queues For Run',\n",
       "     'operationId': 'get_annotation_queues_for_run_api_v1_annotation_queues__run_id__queues_get'}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{run_id}/queues': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'run_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Run Id'}}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{run_id}/queues': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/AnnotationQueueSchema'},\n",
       "          'title': 'Response Get Annotation Queues For Run Api V1 Annotation Queues  Run Id  Queues Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{run_id}/queues': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs/{queue_run_id}': {'patch': {'tags': ['annotation-queues'],\n",
       "     'summary': 'Update Run In Annotation Queue',\n",
       "     'operationId': 'update_run_in_annotation_queue_api_v1_annotation_queues__queue_id__runs__queue_run_id__patch'}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs/{queue_run_id}': {'patch': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs/{queue_run_id}': {'patch': {'parameters': [{'name': 'queue_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Queue Id'}},\n",
       "      {'name': 'queue_run_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Queue Run Id'}}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs/{queue_run_id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/AnnotationQueueRunUpdateSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs/{queue_run_id}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs/{queue_run_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs/{queue_run_id}': {'delete': {'tags': ['annotation-queues'],\n",
       "     'summary': 'Delete Run From Annotation Queue',\n",
       "     'operationId': 'delete_run_from_annotation_queue_api_v1_annotation_queues__queue_id__runs__queue_run_id__delete'}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs/{queue_run_id}': {'delete': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs/{queue_run_id}': {'delete': {'parameters': [{'name': 'queue_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Queue Id'}},\n",
       "      {'name': 'queue_run_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Queue Run Id'}}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs/{queue_run_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/runs/{queue_run_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/size': {'get': {'tags': ['annotation-queues'],\n",
       "     'summary': 'Get Size From Annotation Queue',\n",
       "     'operationId': 'get_size_from_annotation_queue_api_v1_annotation_queues__queue_id__size_get'}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/size': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'queue_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Queue Id'}}]}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/size': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/AnnotationQueueSizeSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/annotation-queues/{queue_id}/size': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants': {'get': {'tags': ['tenant'],\n",
       "     'summary': 'List Tenants',\n",
       "     'description': 'Get all tenants visible to this auth',\n",
       "     'operationId': 'list_tenants_api_v1_tenants_get'}}}},\n",
       " {'paths': {'/api/v1/tenants': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/TenantForUser'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response List Tenants Api V1 Tenants Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants': {'get': {'security': [{'Bearer Auth': []}]},\n",
       "    'post': {'tags': ['tenant'],\n",
       "     'summary': 'Create Tenant',\n",
       "     'description': 'Create a new organization and corresponding workspace.',\n",
       "     'operationId': 'create_tenant_api_v1_tenants_post'}}}},\n",
       " {'paths': {'/api/v1/tenants': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TenantCreate'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/tenants': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/app__schemas__Tenant'}}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/tenants/pending': {'get': {'tags': ['tenant'],\n",
       "     'summary': 'List Pending Tenant Invites',\n",
       "     'description': 'Deprecated: replaced by /workspaces/pending',\n",
       "     'operationId': 'list_pending_tenant_invites_api_v1_tenants_pending_get'}}}},\n",
       " {'paths': {'/api/v1/tenants/pending': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/app__schemas__Tenant'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response List Pending Tenant Invites Api V1 Tenants Pending Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants/pending': {'get': {'deprecated': True,\n",
       "     'security': [{'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/tenants/pending/{id}': {'delete': {'tags': ['tenant'],\n",
       "     'summary': 'Delete Pending Tenant Invite',\n",
       "     'description': 'Deprecated: replaced by /workspaces/pending/{id}',\n",
       "     'operationId': 'delete_pending_tenant_invite_api_v1_tenants_pending__id__delete',\n",
       "     'deprecated': True}}}},\n",
       " {'paths': {'/api/v1/tenants/pending/{id}': {'delete': {'security': [{'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Id'}}]}}}},\n",
       " {'paths': {'/api/v1/tenants/pending/{id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants/pending/{id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants/pending/{tenant_id}/claim': {'post': {'tags': ['tenant'],\n",
       "     'summary': 'Claim Pending Tenant Invite',\n",
       "     'description': 'Deprecated: replaced by /orgs/pending/{organization_id}/claim'}}}},\n",
       " {'paths': {'/api/v1/tenants/pending/{tenant_id}/claim': {'post': {'operationId': 'claim_pending_tenant_invite_api_v1_tenants_pending__tenant_id__claim_post',\n",
       "     'deprecated': True,\n",
       "     'security': [{'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/tenants/pending/{tenant_id}/claim': {'post': {'parameters': [{'name': 'tenant_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Tenant Id'}}]}}}},\n",
       " {'paths': {'/api/v1/tenants/pending/{tenant_id}/claim': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants/pending/{tenant_id}/claim': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants/current/stats': {'get': {'tags': ['tenant'],\n",
       "     'summary': 'Get Current Tenant Stats',\n",
       "     'description': 'Deprecated: replaced by /workspaces/current/stats',\n",
       "     'operationId': 'get_current_tenant_stats_api_v1_tenants_current_stats_get'}}}},\n",
       " {'paths': {'/api/v1/tenants/current/stats': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TenantStats'}}}}},\n",
       "     'deprecated': True,\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/tenants/stats': {'get': {'tags': ['tenant'],\n",
       "     'summary': 'Get Current Tenant Stats',\n",
       "     'description': 'Deprecated: replaced by /workspaces/current/stats',\n",
       "     'operationId': 'get_current_tenant_stats_api_v1_tenants_stats_get'}}}},\n",
       " {'paths': {'/api/v1/tenants/stats': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TenantStats'}}}}},\n",
       "     'deprecated': True,\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/tenants/current/members': {'get': {'tags': ['tenant'],\n",
       "     'summary': 'Get Current Tenant Members',\n",
       "     'description': 'Deprecated: replaced by /workspaces/current/members',\n",
       "     'operationId': 'get_current_tenant_members_api_v1_tenants_current_members_get'}}}},\n",
       " {'paths': {'/api/v1/tenants/current/members': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TenantMembers'}}}}},\n",
       "     'deprecated': True}}}},\n",
       " {'paths': {'/api/v1/tenants/current/members': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/tenants/current/members': {'post': {'tags': ['tenant'],\n",
       "     'summary': 'Add Member To Current Tenant',\n",
       "     'description': 'Deprecated: replaced by /workspaces/current/members',\n",
       "     'operationId': 'add_member_to_current_tenant_api_v1_tenants_current_members_post'}}}},\n",
       " {'paths': {'/api/v1/tenants/current/members': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PendingIdentityCreate'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/tenants/current/members': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PendingIdentity'}}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants/current/members': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'deprecated': True}}}},\n",
       " {'paths': {'/api/v1/tenants/current/members': {'post': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/tenants/current/roles': {'get': {'tags': ['tenant'],\n",
       "     'summary': 'List Organization Roles',\n",
       "     'description': 'Deprecated: replaced by /orgs/current/roles',\n",
       "     'operationId': 'list_organization_roles_api_v1_tenants_current_roles_get'}}}},\n",
       " {'paths': {'/api/v1/tenants/current/roles': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/Role'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response List Organization Roles Api V1 Tenants Current Roles Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants/current/roles': {'get': {'deprecated': True,\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/tenants/current/shared': {'get': {'tags': ['tenant'],\n",
       "     'summary': 'Get Shared Tokens',\n",
       "     'description': 'Deprecated: replaced by /workspaces/current/shared',\n",
       "     'operationId': 'get_shared_tokens_api_v1_tenants_current_shared_get',\n",
       "     'deprecated': True}}}},\n",
       " {'paths': {'/api/v1/tenants/current/shared': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/tenants/current/shared': {'get': {'parameters': [{'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 50,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}}]}}}},\n",
       " {'paths': {'/api/v1/tenants/current/shared': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TenantShareTokensResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants/current/shared': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants/current/shared': {'delete': {'tags': ['tenant'],\n",
       "     'summary': 'Bulk Unshare Entities',\n",
       "     'description': 'Deprecated: replaced by /workspaces/current/shared',\n",
       "     'operationId': 'bulk_unshare_entities_api_v1_tenants_current_shared_delete',\n",
       "     'deprecated': True}}}},\n",
       " {'paths': {'/api/v1/tenants/current/shared': {'delete': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TenantBulkUnshareRequest'}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants/current/shared': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants/current/shared': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants/current/members/{identity_id}': {'delete': {'tags': ['tenant'],\n",
       "     'summary': 'Delete Current Tenant Member',\n",
       "     'description': 'Deprecated: replaced by /workspaces/current/members/{identity_id}'}}}},\n",
       " {'paths': {'/api/v1/tenants/current/members/{identity_id}': {'delete': {'operationId': 'delete_current_tenant_member_api_v1_tenants_current_members__identity_id__delete',\n",
       "     'deprecated': True,\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/tenants/current/members/{identity_id}': {'delete': {'parameters': [{'name': 'identity_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Identity Id'}}]}}}},\n",
       " {'paths': {'/api/v1/tenants/current/members/{identity_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants/current/members/{identity_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants/current/members/{identity_id}': {'patch': {'tags': ['tenant'],\n",
       "     'summary': 'Patch Current Tenant Member',\n",
       "     'description': 'Deprecated: replaced by /workspaces/current/members/{identity_id}'}}}},\n",
       " {'paths': {'/api/v1/tenants/current/members/{identity_id}': {'patch': {'operationId': 'patch_current_tenant_member_api_v1_tenants_current_members__identity_id__patch',\n",
       "     'deprecated': True,\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/tenants/current/members/{identity_id}': {'patch': {'parameters': [{'name': 'identity_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Identity Id'}}]}}}},\n",
       " {'paths': {'/api/v1/tenants/current/members/{identity_id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/IdentityPatch'}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants/current/members/{identity_id}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants/current/members/{identity_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants/current/members/{identity_id}/pending': {'delete': {'tags': ['tenant'],\n",
       "     'summary': 'Delete Current Tenant Pending Member',\n",
       "     'description': 'Deprecated: replaced by /workspaces/current/members/{identity_id}/pending'}}}},\n",
       " {'paths': {'/api/v1/tenants/current/members/{identity_id}/pending': {'delete': {'operationId': 'delete_current_tenant_pending_member_api_v1_tenants_current_members__identity_id__pending_delete',\n",
       "     'deprecated': True,\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/tenants/current/members/{identity_id}/pending': {'delete': {'parameters': [{'name': 'identity_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Identity Id'}}]}}}},\n",
       " {'paths': {'/api/v1/tenants/current/members/{identity_id}/pending': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants/current/members/{identity_id}/pending': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants/current/usage_limits': {'get': {'tags': ['tenant'],\n",
       "     'summary': 'Get Current Tenant Usage Limits Info',\n",
       "     'description': 'Deprecated: replaced by /workspaces/current/usage_limits'}}}},\n",
       " {'paths': {'/api/v1/tenants/current/usage_limits': {'get': {'operationId': 'get_current_tenant_usage_limits_info_api_v1_tenants_current_usage_limits_get'}}}},\n",
       " {'paths': {'/api/v1/tenants/current/usage_limits': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TenantUsageLimitInfo'}}}}},\n",
       "     'deprecated': True}}}},\n",
       " {'paths': {'/api/v1/tenants/current/usage_limits': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/tenants/current/secrets': {'get': {'tags': ['tenant'],\n",
       "     'summary': 'List Current Tenant Secrets',\n",
       "     'description': 'Deprecated: replaced by /workspaces/current/secrets',\n",
       "     'operationId': 'list_current_tenant_secrets_api_v1_tenants_current_secrets_get'}}}},\n",
       " {'paths': {'/api/v1/tenants/current/secrets': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/SecretKey'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response List Current Tenant Secrets Api V1 Tenants Current Secrets Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants/current/secrets': {'get': {'deprecated': True,\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/tenants/current/secrets': {'post': {'tags': ['tenant'],\n",
       "     'summary': 'Upsert Current Tenant Secrets',\n",
       "     'description': 'Deprecated: replaced by /workspaces/current/secrets',\n",
       "     'operationId': 'upsert_current_tenant_secrets_api_v1_tenants_current_secrets_post'}}}},\n",
       " {'paths': {'/api/v1/tenants/current/secrets': {'post': {'requestBody': {'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/SecretUpsert'},\n",
       "         'type': 'array',\n",
       "         'title': 'Secrets'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/tenants/current/secrets': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/tenants/current/secrets': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'deprecated': True}}}},\n",
       " {'paths': {'/api/v1/tenants/current/secrets': {'post': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/info': {'get': {'tags': ['info'],\n",
       "     'summary': 'Get Server Info',\n",
       "     'description': 'Get information about the current deployment of LangSmith.',\n",
       "     'operationId': 'get_server_info_api_v1_info_get'}}}},\n",
       " {'paths': {'/api/v1/info': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/InfoGetResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback-configs': {'get': {'tags': ['feedback-configs'],\n",
       "     'summary': 'List Feedback Configs Endpoint',\n",
       "     'operationId': 'list_feedback_configs_endpoint_api_v1_feedback_configs_get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/feedback-configs': {'get': {'parameters': [{'name': 'key',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array',\n",
       "          'items': {'type': 'string'},\n",
       "          'maxItems': 50},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Key'}}]}}}},\n",
       " {'paths': {'/api/v1/feedback-configs': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'array',\n",
       "          'items': {'$ref': '#/components/schemas/FeedbackConfigSchema'},\n",
       "          'title': 'Response List Feedback Configs Endpoint Api V1 Feedback Configs Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback-configs': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback-configs': {'post': {'tags': ['feedback-configs'],\n",
       "     'summary': 'Create Feedback Config Endpoint',\n",
       "     'operationId': 'create_feedback_config_endpoint_api_v1_feedback_configs_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/feedback-configs': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CreateFeedbackConfigSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback-configs': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackConfigSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback-configs': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback-configs': {'patch': {'tags': ['feedback-configs'],\n",
       "     'summary': 'Update Feedback Config Endpoint',\n",
       "     'operationId': 'update_feedback_config_endpoint_api_v1_feedback_configs_patch',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/feedback-configs': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/UpdateFeedbackConfigSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback-configs': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/FeedbackConfigSchema'}}}}}}}}},\n",
       " {'paths': {'/api/v1/feedback-configs': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/model-price-map': {'get': {'tags': ['model-price-map'],\n",
       "     'summary': 'Read Model Price Map',\n",
       "     'operationId': 'read_model_price_map_api_v1_model_price_map_get',\n",
       "     'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/model-price-map': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/model-price-map': {'post': {'tags': ['model-price-map'],\n",
       "     'summary': 'Create New Model Price',\n",
       "     'operationId': 'create_new_model_price_api_v1_model_price_map_post'}}}},\n",
       " {'paths': {'/api/v1/model-price-map': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ModelPriceMapCreateSchema'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/model-price-map': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/model-price-map': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/model-price-map/{id}': {'put': {'tags': ['model-price-map'],\n",
       "     'summary': 'Update Model Price',\n",
       "     'operationId': 'update_model_price_api_v1_model_price_map__id__put',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/model-price-map/{id}': {'put': {'parameters': [{'name': 'id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Id'}}]}}}},\n",
       " {'paths': {'/api/v1/model-price-map/{id}': {'put': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ModelPriceMapUpdateSchema'}}}}}}}},\n",
       " {'paths': {'/api/v1/model-price-map/{id}': {'put': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/model-price-map/{id}': {'put': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/model-price-map/{id}': {'delete': {'tags': ['model-price-map'],\n",
       "     'summary': 'Delete Model Price',\n",
       "     'operationId': 'delete_model_price_api_v1_model_price_map__id__delete',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/model-price-map/{id}': {'delete': {'parameters': [{'name': 'id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Id'}}]}}}},\n",
       " {'paths': {'/api/v1/model-price-map/{id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/model-price-map/{id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/usage-limits': {'get': {'tags': ['usage-limits'],\n",
       "     'summary': 'List Usage Limits',\n",
       "     'description': 'List out the configured usage limits for a given tenant.',\n",
       "     'operationId': 'list_usage_limits_api_v1_usage_limits_get'}}}},\n",
       " {'paths': {'/api/v1/usage-limits': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/UsageLimit'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response List Usage Limits Api V1 Usage Limits Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/usage-limits': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/usage-limits': {'put': {'tags': ['usage-limits'],\n",
       "     'summary': 'Upsert Usage Limit',\n",
       "     'description': 'Create a new usage limit.',\n",
       "     'operationId': 'upsert_usage_limit_api_v1_usage_limits_put'}}}},\n",
       " {'paths': {'/api/v1/usage-limits': {'put': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/UpsertUsageLimit'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/usage-limits': {'put': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/UsageLimit'}}}}}}}}},\n",
       " {'paths': {'/api/v1/usage-limits': {'put': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/usage-limits/org': {'get': {'tags': ['usage-limits'],\n",
       "     'summary': 'List Org Usage Limits',\n",
       "     'description': 'List out the configured usage limits for a given organization.',\n",
       "     'operationId': 'list_org_usage_limits_api_v1_usage_limits_org_get'}}}},\n",
       " {'paths': {'/api/v1/usage-limits/org': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/UsageLimit'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response List Org Usage Limits Api V1 Usage Limits Org Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/usage-limits/org': {'get': {'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/usage-limits/{usage_limit_id}': {'delete': {'tags': ['usage-limits'],\n",
       "     'summary': 'Delete Usage Limit',\n",
       "     'description': 'Delete a specific usage limit.',\n",
       "     'operationId': 'delete_usage_limit_api_v1_usage_limits__usage_limit_id__delete'}}}},\n",
       " {'paths': {'/api/v1/usage-limits/{usage_limit_id}': {'delete': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'usage_limit_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Usage Limit Id'}}]}}}},\n",
       " {'paths': {'/api/v1/usage-limits/{usage_limit_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/usage-limits/{usage_limit_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/ttl-settings': {'get': {'tags': ['ttl-settings'],\n",
       "     'summary': 'List Ttl Settings',\n",
       "     'description': 'List out the configured TTL settings for a given tenant.',\n",
       "     'operationId': 'list_ttl_settings_api_v1_ttl_settings_get'}}}},\n",
       " {'paths': {'/api/v1/ttl-settings': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/TTLSettings'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response List Ttl Settings Api V1 Ttl Settings Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/ttl-settings': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/ttl-settings': {'put': {'tags': ['ttl-settings'],\n",
       "     'summary': 'Upsert Ttl Settings',\n",
       "     'operationId': 'upsert_ttl_settings_api_v1_ttl_settings_put'}}}},\n",
       " {'paths': {'/api/v1/ttl-settings': {'put': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/UpsertTTLSettingsRequest'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/ttl-settings': {'put': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TTLSettings'}}}}}}}}},\n",
       " {'paths': {'/api/v1/ttl-settings': {'put': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/prompts/invoke_prompt': {'post': {'tags': ['prompts'],\n",
       "     'summary': 'Invoke Prompt',\n",
       "     'operationId': 'invoke_prompt_api_v1_prompts_invoke_prompt_post'}}}},\n",
       " {'paths': {'/api/v1/prompts/invoke_prompt': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/InvokePromptPayload'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/prompts/invoke_prompt': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/prompts/invoke_prompt': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces': {'get': {'tags': ['workspaces'],\n",
       "     'summary': 'List Workspaces',\n",
       "     'description': 'Get all workspaces visible to this auth in the current org. Does not create a new workspace/org.',\n",
       "     'operationId': 'list_workspaces_api_v1_workspaces_get'}}}},\n",
       " {'paths': {'/api/v1/workspaces': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/TenantForUser'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response List Workspaces Api V1 Workspaces Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces': {'get': {'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/workspaces': {'post': {'tags': ['workspaces'],\n",
       "     'summary': 'Create Workspace',\n",
       "     'description': 'Create a new workspace.',\n",
       "     'operationId': 'create_workspace_api_v1_workspaces_post'}}}},\n",
       " {'paths': {'/api/v1/workspaces': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/WorkspaceCreate'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/workspaces': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/app__schemas__Tenant'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/{workspace_id}': {'patch': {'tags': ['workspaces'],\n",
       "     'summary': 'Patch Workspace',\n",
       "     'operationId': 'patch_workspace_api_v1_workspaces__workspace_id__patch',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/{workspace_id}': {'patch': {'parameters': [{'name': 'workspace_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Workspace Id'}}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/{workspace_id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/WorkspacePatch'}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/{workspace_id}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/app__schemas__Tenant'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/{workspace_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/pending': {'get': {'tags': ['workspaces'],\n",
       "     'summary': 'List Pending Workspace Invites',\n",
       "     'description': 'Get all workspaces visible to this auth',\n",
       "     'operationId': 'list_pending_workspace_invites_api_v1_workspaces_pending_get'}}}},\n",
       " {'paths': {'/api/v1/workspaces/pending': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/app__schemas__Tenant'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response List Pending Workspace Invites Api V1 Workspaces Pending Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/pending': {'get': {'security': [{'Bearer Auth': []}]}},\n",
       "   '/api/v1/workspaces/pending/{id}': {'delete': {'tags': ['workspaces'],\n",
       "     'summary': 'Delete Pending Workspace Invite',\n",
       "     'operationId': 'delete_pending_workspace_invite_api_v1_workspaces_pending__id__delete'}}}},\n",
       " {'paths': {'/api/v1/workspaces/pending/{id}': {'delete': {'security': [{'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'format': 'uuid', 'title': 'Id'}}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/pending/{id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/pending/{id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/pending/{workspace_id}/claim': {'post': {'tags': ['workspaces'],\n",
       "     'summary': 'Claim Pending Workspace Invite',\n",
       "     'operationId': 'claim_pending_workspace_invite_api_v1_workspaces_pending__workspace_id__claim_post',\n",
       "     'deprecated': True,\n",
       "     'security': [{'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/pending/{workspace_id}/claim': {'post': {'parameters': [{'name': 'workspace_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Workspace Id'}}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/pending/{workspace_id}/claim': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/pending/{workspace_id}/claim': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/stats': {'get': {'tags': ['workspaces'],\n",
       "     'summary': 'Get Current Workspace Stats',\n",
       "     'operationId': 'get_current_workspace_stats_api_v1_workspaces_current_stats_get'}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/stats': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TenantStats'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members': {'get': {'tags': ['workspaces'],\n",
       "     'summary': 'Get Current Workspace Members',\n",
       "     'operationId': 'get_current_workspace_members_api_v1_workspaces_current_members_get'}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TenantMembers'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members': {'post': {'tags': ['workspaces'],\n",
       "     'summary': 'Add Member To Current Workspace',\n",
       "     'description': 'Add an existing organization member to the current workspace.'}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members': {'post': {'operationId': 'add_member_to_current_workspace_api_v1_workspaces_current_members_post',\n",
       "     'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/IdentityCreate'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Identity'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/batch': {'post': {'tags': ['workspaces'],\n",
       "     'summary': 'Add Members To Current Workspace Batch',\n",
       "     'description': 'Batch invite up to 500 users to the current workspace and organization.'}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/batch': {'post': {'operationId': 'add_members_to_current_workspace_batch_api_v1_workspaces_current_members_batch_post'}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/batch': {'post': {'requestBody': {'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/PendingIdentityCreate'},\n",
       "         'type': 'array',\n",
       "         'title': 'Payloads'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/batch': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/PendingIdentity'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response Add Members To Current Workspace Batch Api V1 Workspaces Current Members Batch Post'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/batch': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/batch': {'post': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []},\n",
       "      {'Organization ID': []}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/shared': {'get': {'tags': ['workspaces'],\n",
       "     'summary': 'Get Shared Tokens',\n",
       "     'description': 'List all shared entities and their tokens by the workspace.',\n",
       "     'operationId': 'get_shared_tokens_api_v1_workspaces_current_shared_get'}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/shared': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/shared': {'get': {'parameters': [{'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 50,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/shared': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TenantShareTokensResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/shared': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/shared': {'delete': {'tags': ['workspaces'],\n",
       "     'summary': 'Bulk Unshare Entities',\n",
       "     'description': 'Bulk unshare entities by share tokens for the workspace.',\n",
       "     'operationId': 'bulk_unshare_entities_api_v1_workspaces_current_shared_delete'}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/shared': {'delete': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TenantBulkUnshareRequest'}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/shared': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/shared': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/{identity_id}': {'delete': {'tags': ['workspaces'],\n",
       "     'summary': 'Delete Current Workspace Member',\n",
       "     'operationId': 'delete_current_workspace_member_api_v1_workspaces_current_members__identity_id__delete'}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/{identity_id}': {'delete': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'identity_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Identity Id'}}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/{identity_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/{identity_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/{identity_id}': {'patch': {'tags': ['workspaces'],\n",
       "     'summary': 'Patch Current Workspace Member',\n",
       "     'operationId': 'patch_current_workspace_member_api_v1_workspaces_current_members__identity_id__patch'}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/{identity_id}': {'patch': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}],\n",
       "     'parameters': [{'name': 'identity_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Identity Id'}}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/{identity_id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/IdentityPatch'}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/{identity_id}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/{identity_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/{identity_id}/pending': {'delete': {'tags': ['workspaces'],\n",
       "     'summary': 'Delete Current Workspace Pending Member',\n",
       "     'operationId': 'delete_current_workspace_pending_member_api_v1_workspaces_current_members__identity_id__pending_delete'}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/{identity_id}/pending': {'delete': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/{identity_id}/pending': {'delete': {'parameters': [{'name': 'identity_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Identity Id'}}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/{identity_id}/pending': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/members/{identity_id}/pending': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/usage_limits': {'get': {'tags': ['workspaces'],\n",
       "     'summary': 'Get Current Workspace Usage Limits Info',\n",
       "     'operationId': 'get_current_workspace_usage_limits_info_api_v1_workspaces_current_usage_limits_get'}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/usage_limits': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TenantUsageLimitInfo'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/secrets': {'get': {'tags': ['workspaces'],\n",
       "     'summary': 'List Current Workspace Secrets',\n",
       "     'operationId': 'list_current_workspace_secrets_api_v1_workspaces_current_secrets_get'}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/secrets': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/SecretKey'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response List Current Workspace Secrets Api V1 Workspaces Current Secrets Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/secrets': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/secrets': {'post': {'tags': ['workspaces'],\n",
       "     'summary': 'Upsert Current Workspace Secrets',\n",
       "     'operationId': 'upsert_current_workspace_secrets_api_v1_workspaces_current_secrets_post'}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/secrets': {'post': {'requestBody': {'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/SecretUpsert'},\n",
       "         'type': 'array',\n",
       "         'title': 'Secrets'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/secrets': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/workspaces/current/secrets': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/playground-settings': {'get': {'tags': ['playground-settings'],\n",
       "     'summary': 'List Playground Settings',\n",
       "     'description': 'Get all playground settings for this tenant id.',\n",
       "     'operationId': 'list_playground_settings_api_v1_playground_settings_get'}}}},\n",
       " {'paths': {'/api/v1/playground-settings': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/PlaygroundSettingsResponse'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response List Playground Settings Api V1 Playground Settings Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/playground-settings': {'get': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/playground-settings': {'post': {'tags': ['playground-settings'],\n",
       "     'summary': 'Create Playground Settings',\n",
       "     'description': 'Create playground settings.',\n",
       "     'operationId': 'create_playground_settings_api_v1_playground_settings_post'}}}},\n",
       " {'paths': {'/api/v1/playground-settings': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PlaygroundSettingsCreateRequest'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/playground-settings': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PlaygroundSettingsResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/playground-settings': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/playground-settings/{playground_settings_id}': {'patch': {'tags': ['playground-settings'],\n",
       "     'summary': 'Update Playground Settings',\n",
       "     'description': 'Update playground settings.'}}}},\n",
       " {'paths': {'/api/v1/playground-settings/{playground_settings_id}': {'patch': {'operationId': 'update_playground_settings_api_v1_playground_settings__playground_settings_id__patch',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/playground-settings/{playground_settings_id}': {'patch': {'parameters': [{'name': 'playground_settings_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Playground Settings Id'}}]}}}},\n",
       " {'paths': {'/api/v1/playground-settings/{playground_settings_id}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PlaygroundSettingsUpdateRequest'}}}}}}}},\n",
       " {'paths': {'/api/v1/playground-settings/{playground_settings_id}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/PlaygroundSettingsResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/playground-settings/{playground_settings_id}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/playground-settings/{playground_settings_id}': {'delete': {'tags': ['playground-settings'],\n",
       "     'summary': 'Delete Playground Settings',\n",
       "     'description': 'Delete playground settings.'}}}},\n",
       " {'paths': {'/api/v1/playground-settings/{playground_settings_id}': {'delete': {'operationId': 'delete_playground_settings_api_v1_playground_settings__playground_settings_id__delete',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/playground-settings/{playground_settings_id}': {'delete': {'parameters': [{'name': 'playground_settings_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Playground Settings Id'}}]}}}},\n",
       " {'paths': {'/api/v1/playground-settings/{playground_settings_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/playground-settings/{playground_settings_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/service-accounts': {'get': {'tags': ['service-accounts'],\n",
       "     'summary': 'Get Service Accounts',\n",
       "     'description': \"Get the current organization's service accounts.\",\n",
       "     'operationId': 'get_service_accounts_api_v1_service_accounts_get'}}}},\n",
       " {'paths': {'/api/v1/service-accounts': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'items': {'$ref': '#/components/schemas/ServiceAccount'},\n",
       "          'type': 'array',\n",
       "          'title': 'Response Get Service Accounts Api V1 Service Accounts Get'}}}}}}}}},\n",
       " {'paths': {'/api/v1/service-accounts': {'get': {'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/service-accounts': {'post': {'tags': ['service-accounts'],\n",
       "     'summary': 'Create Service Account',\n",
       "     'description': 'Create a service account',\n",
       "     'operationId': 'create_service_account_api_v1_service_accounts_post'}}}},\n",
       " {'paths': {'/api/v1/service-accounts': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ServiceAccountCreateRequest'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/service-accounts': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ServiceAccountCreateResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/service-accounts': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/service-accounts/{service_account_id}': {'delete': {'tags': ['service-accounts'],\n",
       "     'summary': 'Delete Service Account',\n",
       "     'description': 'Delete a service account',\n",
       "     'operationId': 'delete_service_account_api_v1_service_accounts__service_account_id__delete'}}}},\n",
       " {'paths': {'/api/v1/service-accounts/{service_account_id}': {'delete': {'security': [{'API Key': []},\n",
       "      {'Organization ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/service-accounts/{service_account_id}': {'delete': {'parameters': [{'name': 'service_account_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Service Account Id'}}]}}}},\n",
       " {'paths': {'/api/v1/service-accounts/{service_account_id}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ServiceAccountDeleteResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/service-accounts/{service_account_id}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/repos': {'get': {'tags': ['repos'],\n",
       "     'summary': 'List Repos',\n",
       "     'description': 'Get all repos.',\n",
       "     'operationId': 'list_repos_api_v1_repos_get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/repos': {'get': {'parameters': [{'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 20,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'tenant_handle',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Tenant Handle'}},\n",
       "      {'name': 'tenant_id',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Tenant Id'}},\n",
       "      {'name': 'query',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Query'}},\n",
       "      {'name': 'has_commits',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "        'title': 'Has Commits'}},\n",
       "      {'name': 'tags',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array', 'items': {'type': 'string'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Tags'}},\n",
       "      {'name': 'is_archived',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'enum': ['true', 'allow', 'false'],\n",
       "          'type': 'string'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Is Archived'}},\n",
       "      {'name': 'is_public',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'enum': ['true', 'false'], 'type': 'string'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Is Public'}},\n",
       "      {'name': 'upstream_repo_owner',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Upstream Repo Owner'}},\n",
       "      {'name': 'upstream_repo_handle',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Upstream Repo Handle'}},\n",
       "      {'name': 'match_prefix',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "        'default': False,\n",
       "        'title': 'Match Prefix'}},\n",
       "      {'name': 'sort_field',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Sort Field'}},\n",
       "      {'name': 'sort_direction',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'enum': ['asc'],\n",
       "          'const': 'asc',\n",
       "          'type': 'string'},\n",
       "         {'enum': ['desc'], 'const': 'desc', 'type': 'string'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Sort Direction'}}]}}}},\n",
       " {'paths': {'/api/v1/repos': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ListReposResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/repos': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/repos': {'post': {'tags': ['repos'],\n",
       "     'summary': 'Create Repo',\n",
       "     'description': 'Create a repo.',\n",
       "     'operationId': 'create_repo_api_v1_repos_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/repos': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CreateRepoRequest'}}}}}}}},\n",
       " {'paths': {'/api/v1/repos': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CreateRepoResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/repos': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/repos/{owner}/{repo}': {'get': {'tags': ['repos'],\n",
       "     'summary': 'Get Repo',\n",
       "     'description': 'Get a repo.',\n",
       "     'operationId': 'get_repo_api_v1_repos__owner___repo__get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/repos/{owner}/{repo}': {'get': {'parameters': [{'name': 'owner',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Owner'}},\n",
       "      {'name': 'repo',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Repo'}}]}}}},\n",
       " {'paths': {'/api/v1/repos/{owner}/{repo}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/GetRepoResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/repos/{owner}/{repo}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/repos/{owner}/{repo}': {'patch': {'tags': ['repos'],\n",
       "     'summary': 'Update Repo',\n",
       "     'description': 'Update a repo.',\n",
       "     'operationId': 'update_repo_api_v1_repos__owner___repo__patch',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/repos/{owner}/{repo}': {'patch': {'parameters': [{'name': 'owner',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Owner'}},\n",
       "      {'name': 'repo',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Repo'}}]}}}},\n",
       " {'paths': {'/api/v1/repos/{owner}/{repo}': {'patch': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/UpdateRepoRequest'}}}}}}}},\n",
       " {'paths': {'/api/v1/repos/{owner}/{repo}': {'patch': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CreateRepoResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/repos/{owner}/{repo}': {'patch': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/repos/{owner}/{repo}': {'delete': {'tags': ['repos'],\n",
       "     'summary': 'Delete Repo',\n",
       "     'description': 'Delete a repo.',\n",
       "     'operationId': 'delete_repo_api_v1_repos__owner___repo__delete',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/repos/{owner}/{repo}': {'delete': {'parameters': [{'name': 'owner',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Owner'}},\n",
       "      {'name': 'repo',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Repo'}}]}}}},\n",
       " {'paths': {'/api/v1/repos/{owner}/{repo}': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/repos/{owner}/{repo}': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/repos/{owner}/{repo}/fork': {'post': {'tags': ['repos'],\n",
       "     'summary': 'Fork Repo',\n",
       "     'description': 'Fork a repo.',\n",
       "     'operationId': 'fork_repo_api_v1_repos__owner___repo__fork_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/repos/{owner}/{repo}/fork': {'post': {'parameters': [{'name': 'owner',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Owner'}},\n",
       "      {'name': 'repo',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Repo'}}]}}}},\n",
       " {'paths': {'/api/v1/repos/{owner}/{repo}/fork': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ForkRepoRequest'}}}}}}}},\n",
       " {'paths': {'/api/v1/repos/{owner}/{repo}/fork': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/GetRepoResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/repos/{owner}/{repo}/fork': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/repos/tags': {'get': {'tags': ['repos'],\n",
       "     'summary': 'List Repo Tags',\n",
       "     'description': 'Get all repo tags.',\n",
       "     'operationId': 'list_repo_tags_api_v1_repos_tags_get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/repos/tags': {'get': {'parameters': [{'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 20,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}},\n",
       "      {'name': 'tenant_handle',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Tenant Handle'}},\n",
       "      {'name': 'tenant_id',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Tenant Id'}},\n",
       "      {'name': 'query',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Query'}},\n",
       "      {'name': 'has_commits',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "        'title': 'Has Commits'}},\n",
       "      {'name': 'tags',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'array', 'items': {'type': 'string'}},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Tags'}},\n",
       "      {'name': 'is_archived',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'enum': ['true', 'allow', 'false'],\n",
       "          'type': 'string'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Is Archived'}},\n",
       "      {'name': 'is_public',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'enum': ['true', 'false'], 'type': 'string'},\n",
       "         {'type': 'null'}],\n",
       "        'title': 'Is Public'}},\n",
       "      {'name': 'upstream_repo_owner',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Upstream Repo Owner'}},\n",
       "      {'name': 'upstream_repo_handle',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "        'title': 'Upstream Repo Handle'}},\n",
       "      {'name': 'match_prefix',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "        'default': False,\n",
       "        'title': 'Match Prefix'}}]}}}},\n",
       " {'paths': {'/api/v1/repos/tags': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ListTagsResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/repos/tags': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/likes/{owner}/{repo}': {'post': {'tags': ['likes'],\n",
       "     'summary': 'Like Repo',\n",
       "     'description': 'Like a repo.',\n",
       "     'operationId': 'like_repo_api_v1_likes__owner___repo__post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/likes/{owner}/{repo}': {'post': {'parameters': [{'name': 'owner',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Owner'}},\n",
       "      {'name': 'repo',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Repo'}}]}}}},\n",
       " {'paths': {'/api/v1/likes/{owner}/{repo}': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/LikeRepoRequest'}}}}}}}},\n",
       " {'paths': {'/api/v1/likes/{owner}/{repo}': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/LikeRepoResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/likes/{owner}/{repo}': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/commits/{owner}/{repo}': {'get': {'tags': ['commits'],\n",
       "     'summary': 'List Commits',\n",
       "     'description': 'Get all commits.',\n",
       "     'operationId': 'list_commits_api_v1_commits__owner___repo__get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/commits/{owner}/{repo}': {'get': {'parameters': [{'name': 'owner',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Owner'}},\n",
       "      {'name': 'repo',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Repo'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 20,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}}]}}}},\n",
       " {'paths': {'/api/v1/commits/{owner}/{repo}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ListCommitsResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/commits/{owner}/{repo}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/commits/{owner}/{repo}': {'post': {'tags': ['commits'],\n",
       "     'summary': 'Create Commit',\n",
       "     'description': 'Upload a repo.',\n",
       "     'operationId': 'create_commit_api_v1_commits__owner___repo__post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/commits/{owner}/{repo}': {'post': {'parameters': [{'name': 'owner',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Owner'}},\n",
       "      {'name': 'repo',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Repo'}}]}}}},\n",
       " {'paths': {'/api/v1/commits/{owner}/{repo}': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CreateRepoCommitRequest'}}}}}}}},\n",
       " {'paths': {'/api/v1/commits/{owner}/{repo}': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CreateRepoCommitResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/commits/{owner}/{repo}': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/commits/{owner}/{repo}/{commit}': {'get': {'tags': ['commits'],\n",
       "     'summary': 'Get Commit',\n",
       "     'description': 'Download a repo.',\n",
       "     'operationId': 'get_commit_api_v1_commits__owner___repo___commit__get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/commits/{owner}/{repo}/{commit}': {'get': {'parameters': [{'name': 'owner',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Owner'}},\n",
       "      {'name': 'repo',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Repo'}},\n",
       "      {'name': 'commit',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Commit'}},\n",
       "      {'name': 'get_examples',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean',\n",
       "        'default': False,\n",
       "        'title': 'Get Examples'}},\n",
       "      {'name': 'is_view',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'boolean', 'default': False, 'title': 'Is View'}},\n",
       "      {'name': 'include_model',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "        'default': False,\n",
       "        'title': 'Include Model'}}]}}}},\n",
       " {'paths': {'/api/v1/commits/{owner}/{repo}/{commit}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CommitManifestResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/commits/{owner}/{repo}/{commit}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/settings': {'get': {'tags': ['settings'],\n",
       "     'summary': 'Get Settings',\n",
       "     'description': 'Get settings.',\n",
       "     'operationId': 'get_settings_api_v1_settings_get'}}}},\n",
       " {'paths': {'/api/v1/settings': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/app__hub__crud__tenants__Tenant'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/settings/handle': {'post': {'tags': ['settings'],\n",
       "     'summary': 'Set Tenant Handle',\n",
       "     'description': 'Set tenant handle.',\n",
       "     'operationId': 'set_tenant_handle_api_v1_settings_handle_post'}}}},\n",
       " {'paths': {'/api/v1/settings/handle': {'post': {'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/SetTenantHandleRequest'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/settings/handle': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/app__hub__crud__tenants__Tenant'}}}}}}}}},\n",
       " {'paths': {'/api/v1/settings/handle': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}},\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/events': {'post': {'tags': ['events'],\n",
       "     'summary': 'Create Event',\n",
       "     'operationId': 'create_event_api_v1_events_post',\n",
       "     'requestBody': {'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CreateEventRequest'}}},\n",
       "      'required': True}}}}},\n",
       " {'paths': {'/api/v1/events': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}},\n",
       "      '422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/events': {'post': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/comments/{owner}/{repo}': {'post': {'tags': ['comments'],\n",
       "     'summary': 'Create Comment',\n",
       "     'operationId': 'create_comment_api_v1_comments__owner___repo__post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/comments/{owner}/{repo}': {'post': {'parameters': [{'name': 'owner',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Owner'}},\n",
       "      {'name': 'repo',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Repo'}}]}}}},\n",
       " {'paths': {'/api/v1/comments/{owner}/{repo}': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CreateCommentRequest'}}}}}}}},\n",
       " {'paths': {'/api/v1/comments/{owner}/{repo}': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'paths': {'/api/v1/comments/{owner}/{repo}': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/comments/{owner}/{repo}': {'get': {'tags': ['comments'],\n",
       "     'summary': 'Get Comments',\n",
       "     'operationId': 'get_comments_api_v1_comments__owner___repo__get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/comments/{owner}/{repo}': {'get': {'parameters': [{'name': 'owner',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Owner'}},\n",
       "      {'name': 'repo',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Repo'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 20,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}}]}}}},\n",
       " {'paths': {'/api/v1/comments/{owner}/{repo}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ListCommentsResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/comments/{owner}/{repo}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/comments/{owner}/{repo}/{parent_comment_id}': {'get': {'tags': ['comments'],\n",
       "     'summary': 'Get Sub Comments',\n",
       "     'operationId': 'get_sub_comments_api_v1_comments__owner___repo___parent_comment_id__get',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/comments/{owner}/{repo}/{parent_comment_id}': {'get': {'parameters': [{'name': 'owner',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Owner'}},\n",
       "      {'name': 'repo',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Repo'}},\n",
       "      {'name': 'parent_comment_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Parent Comment Id'}},\n",
       "      {'name': 'limit',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'maximum': 100,\n",
       "        'minimum': 1,\n",
       "        'default': 20,\n",
       "        'title': 'Limit'}},\n",
       "      {'name': 'offset',\n",
       "       'in': 'query',\n",
       "       'required': False,\n",
       "       'schema': {'type': 'integer',\n",
       "        'minimum': 0,\n",
       "        'default': 0,\n",
       "        'title': 'Offset'}}]}}}},\n",
       " {'paths': {'/api/v1/comments/{owner}/{repo}/{parent_comment_id}': {'get': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/ListCommentsResponse'}}}}}}}}},\n",
       " {'paths': {'/api/v1/comments/{owner}/{repo}/{parent_comment_id}': {'get': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/comments/{owner}/{repo}/{parent_comment_id}': {'post': {'tags': ['comments'],\n",
       "     'summary': 'Create Sub Comment',\n",
       "     'operationId': 'create_sub_comment_api_v1_comments__owner___repo___parent_comment_id__post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/comments/{owner}/{repo}/{parent_comment_id}': {'post': {'parameters': [{'name': 'owner',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Owner'}},\n",
       "      {'name': 'repo',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Repo'}},\n",
       "      {'name': 'parent_comment_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Parent Comment Id'}}]}}}},\n",
       " {'paths': {'/api/v1/comments/{owner}/{repo}/{parent_comment_id}': {'post': {'requestBody': {'required': True,\n",
       "      'content': {'application/json': {'schema': {'$ref': '#/components/schemas/CreateCommentRequest'}}}}}}}},\n",
       " {'paths': {'/api/v1/comments/{owner}/{repo}/{parent_comment_id}': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/Comment'}}}}}}}}},\n",
       " {'paths': {'/api/v1/comments/{owner}/{repo}/{parent_comment_id}': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/comments/{owner}/{repo}/{parent_comment_id}/like': {'post': {'tags': ['comments'],\n",
       "     'summary': 'Like Comment',\n",
       "     'operationId': 'like_comment_api_v1_comments__owner___repo___parent_comment_id__like_post',\n",
       "     'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/comments/{owner}/{repo}/{parent_comment_id}/like': {'post': {'parameters': [{'name': 'owner',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Owner'}},\n",
       "      {'name': 'repo',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Repo'}},\n",
       "      {'name': 'parent_comment_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Parent Comment Id'}}]}}}},\n",
       " {'paths': {'/api/v1/comments/{owner}/{repo}/{parent_comment_id}/like': {'post': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'object',\n",
       "          'title': 'Response Like Comment Api V1 Comments  Owner   Repo   Parent Comment Id  Like Post'}}}}}}}}},\n",
       " {'paths': {'/api/v1/comments/{owner}/{repo}/{parent_comment_id}/like': {'post': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/api/v1/comments/{owner}/{repo}/{parent_comment_id}/like': {'delete': {'tags': ['comments'],\n",
       "     'summary': 'Unlike Comment',\n",
       "     'operationId': 'unlike_comment_api_v1_comments__owner___repo___parent_comment_id__like_delete'}}}},\n",
       " {'paths': {'/api/v1/comments/{owner}/{repo}/{parent_comment_id}/like': {'delete': {'security': [{'API Key': []},\n",
       "      {'Tenant ID': []},\n",
       "      {'Bearer Auth': []}]}}}},\n",
       " {'paths': {'/api/v1/comments/{owner}/{repo}/{parent_comment_id}/like': {'delete': {'parameters': [{'name': 'owner',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Owner'}},\n",
       "      {'name': 'repo',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string', 'title': 'Repo'}},\n",
       "      {'name': 'parent_comment_id',\n",
       "       'in': 'path',\n",
       "       'required': True,\n",
       "       'schema': {'type': 'string',\n",
       "        'format': 'uuid',\n",
       "        'title': 'Parent Comment Id'}}]}}}},\n",
       " {'paths': {'/api/v1/comments/{owner}/{repo}/{parent_comment_id}/like': {'delete': {'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {'type': 'object',\n",
       "          'title': 'Response Unlike Comment Api V1 Comments  Owner   Repo   Parent Comment Id  Like Delete'}}}}}}}}},\n",
       " {'paths': {'/api/v1/comments/{owner}/{repo}/{parent_comment_id}/like': {'delete': {'responses': {'422': {'description': 'Validation Error',\n",
       "       'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}},\n",
       " {'paths': {'/ok': {'get': {'summary': 'Ok',\n",
       "     'operationId': 'ok_ok_get',\n",
       "     'responses': {'200': {'description': 'Successful Response',\n",
       "       'content': {'application/json': {'schema': {}}}}}}}}},\n",
       " {'components': {'schemas': {'APIFeedbackSource': {'properties': {'type': {'type': 'string',\n",
       "       'title': 'Type',\n",
       "       'default': 'api'},\n",
       "      'metadata': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "       'title': 'Metadata'}},\n",
       "     'type': 'object',\n",
       "     'title': 'APIFeedbackSource',\n",
       "     'description': 'API feedback source.'}}}},\n",
       " {'components': {'schemas': {'APIKeyCreateRequest': {'properties': {'description': {'type': 'string',\n",
       "       'title': 'Description',\n",
       "       'default': 'Default API key'},\n",
       "      'read_only': {'type': 'boolean',\n",
       "       'title': 'Read Only',\n",
       "       'default': False}},\n",
       "     'type': 'object',\n",
       "     'title': 'APIKeyCreateRequest'}}}},\n",
       " {'components': {'schemas': {'APIKeyCreateRequest': {'description': 'API key POST schema.'},\n",
       "    'APIKeyCreateResponse': {'properties': {'created_at': {'anyOf': [{'type': 'string',\n",
       "         'format': 'date-time'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Created At'}}}}}},\n",
       " {'components': {'schemas': {'APIKeyCreateResponse': {'properties': {'id': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Id'},\n",
       "      'short_key': {'type': 'string', 'title': 'Short Key'},\n",
       "      'description': {'type': 'string', 'title': 'Description'}}}}}},\n",
       " {'components': {'schemas': {'APIKeyCreateResponse': {'properties': {'read_only': {'type': 'boolean',\n",
       "       'title': 'Read Only',\n",
       "       'default': False},\n",
       "      'key': {'type': 'string', 'title': 'Key'}},\n",
       "     'type': 'object',\n",
       "     'required': ['id', 'short_key', 'description', 'key'],\n",
       "     'title': 'APIKeyCreateResponse'}}}},\n",
       " {'components': {'schemas': {'APIKeyCreateResponse': {'description': 'API key POST schema.'},\n",
       "    'APIKeyGetResponse': {'properties': {'created_at': {'anyOf': [{'type': 'string',\n",
       "         'format': 'date-time'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Created At'}}}}}},\n",
       " {'components': {'schemas': {'APIKeyGetResponse': {'properties': {'id': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Id'},\n",
       "      'short_key': {'type': 'string', 'title': 'Short Key'},\n",
       "      'description': {'type': 'string', 'title': 'Description'}}}}}},\n",
       " {'components': {'schemas': {'APIKeyGetResponse': {'properties': {'read_only': {'type': 'boolean',\n",
       "       'title': 'Read Only',\n",
       "       'default': False}},\n",
       "     'type': 'object',\n",
       "     'required': ['id', 'short_key', 'description'],\n",
       "     'title': 'APIKeyGetResponse',\n",
       "     'description': 'API key GET schema.'}}}},\n",
       " {'components': {'schemas': {'AccessScope': {'type': 'string',\n",
       "     'enum': ['organization', 'workspace'],\n",
       "     'title': 'AccessScope'}}}},\n",
       " {'components': {'schemas': {'AnnotationQueueCreateSchema': {'properties': {'name': {'type': 'string',\n",
       "       'title': 'Name'},\n",
       "      'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Description'},\n",
       "      'created_at': {'type': 'string',\n",
       "       'format': 'date-time',\n",
       "       'title': 'Created At'}}}}}},\n",
       " {'components': {'schemas': {'AnnotationQueueCreateSchema': {'properties': {'updated_at': {'type': 'string',\n",
       "       'format': 'date-time',\n",
       "       'title': 'Updated At'},\n",
       "      'default_dataset': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Default Dataset'}}}}}},\n",
       " {'components': {'schemas': {'AnnotationQueueCreateSchema': {'properties': {'id': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Id'}},\n",
       "     'type': 'object',\n",
       "     'required': ['name'],\n",
       "     'title': 'AnnotationQueueCreateSchema',\n",
       "     'description': 'AnnotationQueue schema.'}}}},\n",
       " {'components': {'schemas': {'AnnotationQueueRunSchema': {'properties': {'run_id': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Run Id'},\n",
       "      'queue_id': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Queue Id'}}}}}},\n",
       " {'components': {'schemas': {'AnnotationQueueRunSchema': {'properties': {'last_reviewed_time': {'anyOf': [{'type': 'string',\n",
       "         'format': 'date-time'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Last Reviewed Time'},\n",
       "      'added_at': {'type': 'string',\n",
       "       'format': 'date-time',\n",
       "       'title': 'Added At'}}}}}},\n",
       " {'components': {'schemas': {'AnnotationQueueRunSchema': {'properties': {'id': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Id'}},\n",
       "     'type': 'object',\n",
       "     'required': ['run_id', 'queue_id', 'id'],\n",
       "     'title': 'AnnotationQueueRunSchema'}}}},\n",
       " {'components': {'schemas': {'AnnotationQueueRunUpdateSchema': {'properties': {'last_reviewed_time': {'anyOf': [{'type': 'string',\n",
       "         'format': 'date-time'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Last Reviewed Time'},\n",
       "      'added_at': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Added At'}}}}}},\n",
       " {'components': {'schemas': {'AnnotationQueueRunUpdateSchema': {'type': 'object',\n",
       "     'title': 'AnnotationQueueRunUpdateSchema'}}}},\n",
       " {'components': {'schemas': {'AnnotationQueueSchema': {'properties': {'name': {'type': 'string',\n",
       "       'title': 'Name'},\n",
       "      'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Description'},\n",
       "      'created_at': {'type': 'string',\n",
       "       'format': 'date-time',\n",
       "       'title': 'Created At'}}}}}},\n",
       " {'components': {'schemas': {'AnnotationQueueSchema': {'properties': {'updated_at': {'type': 'string',\n",
       "       'format': 'date-time',\n",
       "       'title': 'Updated At'},\n",
       "      'default_dataset': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Default Dataset'}}}}}},\n",
       " {'components': {'schemas': {'AnnotationQueueSchema': {'properties': {'id': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Id'},\n",
       "      'tenant_id': {'type': 'string', 'format': 'uuid', 'title': 'Tenant Id'}},\n",
       "     'type': 'object',\n",
       "     'required': ['name', 'id', 'tenant_id'],\n",
       "     'title': 'AnnotationQueueSchema'}}}},\n",
       " {'components': {'schemas': {'AnnotationQueueSchema': {'description': 'AnnotationQueue schema.'},\n",
       "    'AnnotationQueueSizeSchema': {'properties': {'size': {'type': 'integer',\n",
       "       'title': 'Size'}},\n",
       "     'type': 'object',\n",
       "     'required': ['size'],\n",
       "     'title': 'AnnotationQueueSizeSchema'}}}},\n",
       " {'components': {'schemas': {'AnnotationQueueSizeSchema': {'description': 'Size of an Annotation Queue'}}}},\n",
       " {'components': {'schemas': {'AnnotationQueueUpdateSchema': {'properties': {'name': {'anyOf': [{'type': 'string'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Name'},\n",
       "      'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Description'}}}}}},\n",
       " {'components': {'schemas': {'AnnotationQueueUpdateSchema': {'properties': {'default_dataset': {'anyOf': [{'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Default Dataset'}},\n",
       "     'type': 'object',\n",
       "     'title': 'AnnotationQueueUpdateSchema'}}}},\n",
       " {'components': {'schemas': {'AnnotationQueueUpdateSchema': {'description': 'AnnotationQueue update schema.'}}}},\n",
       " {'components': {'schemas': {'AppFeedbackSource': {'properties': {'type': {'type': 'string',\n",
       "       'title': 'Type',\n",
       "       'default': 'app'},\n",
       "      'metadata': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "       'title': 'Metadata'}},\n",
       "     'type': 'object',\n",
       "     'title': 'AppFeedbackSource'}}}},\n",
       " {'components': {'schemas': {'AppFeedbackSource': {'description': 'Feedback from the LangChainPlus App.'}}}},\n",
       " {'components': {'schemas': {'AutoEvalFeedbackSource': {'properties': {'type': {'type': 'string',\n",
       "       'title': 'Type',\n",
       "       'default': 'auto_eval'},\n",
       "      'metadata': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "       'title': 'Metadata'}},\n",
       "     'type': 'object',\n",
       "     'title': 'AutoEvalFeedbackSource'}}}},\n",
       " {'components': {'schemas': {'AutoEvalFeedbackSource': {'description': 'Auto eval feedback source.'},\n",
       "    'BasicAuthResponse': {'properties': {'access_token': {'type': 'string',\n",
       "       'title': 'Access Token'}},\n",
       "     'type': 'object',\n",
       "     'required': ['access_token'],\n",
       "     'title': 'BasicAuthResponse'}}}},\n",
       " {'components': {'schemas': {'BatchIngestConfig': {'properties': {'scale_up_qsize_trigger': {'type': 'integer',\n",
       "       'title': 'Scale Up Qsize Trigger',\n",
       "       'default': 1000},\n",
       "      'scale_up_nthreads_limit': {'type': 'integer',\n",
       "       'title': 'Scale Up Nthreads Limit',\n",
       "       'default': 16}}}}}},\n",
       " {'components': {'schemas': {'BatchIngestConfig': {'properties': {'scale_down_nempty_trigger': {'type': 'integer',\n",
       "       'title': 'Scale Down Nempty Trigger',\n",
       "       'default': 4},\n",
       "      'size_limit': {'type': 'integer',\n",
       "       'title': 'Size Limit',\n",
       "       'default': 100}}}}}},\n",
       " {'components': {'schemas': {'BatchIngestConfig': {'properties': {'size_limit_bytes': {'type': 'integer',\n",
       "       'title': 'Size Limit Bytes',\n",
       "       'default': 20971520}},\n",
       "     'type': 'object',\n",
       "     'title': 'BatchIngestConfig',\n",
       "     'description': 'Batch ingest config.'}}}},\n",
       " {'components': {'schemas': {'BodyParamsForRunSchema': {'properties': {'id': {'anyOf': [{'items': {'type': 'string',\n",
       "          'format': 'uuid'},\n",
       "         'type': 'array'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Id'},\n",
       "      'trace': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Trace'}}}}}},\n",
       " {'components': {'schemas': {'BodyParamsForRunSchema': {'properties': {'parent_run': {'anyOf': [{'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Parent Run'},\n",
       "      'run_type': {'anyOf': [{'$ref': '#/components/schemas/RunTypeEnum'},\n",
       "        {'type': 'null'}]}}}}}},\n",
       " {'components': {'schemas': {'BodyParamsForRunSchema': {'properties': {'session': {'anyOf': [{'items': {'type': 'string',\n",
       "          'format': 'uuid'},\n",
       "         'type': 'array'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Session'}}}}}},\n",
       " {'components': {'schemas': {'BodyParamsForRunSchema': {'properties': {'reference_example': {'anyOf': [{'items': {'type': 'string',\n",
       "          'format': 'uuid'},\n",
       "         'type': 'array'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Reference Example'}}}}}},\n",
       " {'components': {'schemas': {'BodyParamsForRunSchema': {'properties': {'execution_order': {'anyOf': [{'type': 'integer',\n",
       "         'maximum': 1.0,\n",
       "         'minimum': 1.0},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Execution Order'}}}}}},\n",
       " {'components': {'schemas': {'BodyParamsForRunSchema': {'properties': {'start_time': {'anyOf': [{'type': 'string',\n",
       "         'format': 'date-time'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Start Time'},\n",
       "      'end_time': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'End Time'}}}}}},\n",
       " {'components': {'schemas': {'BodyParamsForRunSchema': {'properties': {'error': {'anyOf': [{'type': 'boolean'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Error'},\n",
       "      'query': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Query'}}}}}},\n",
       " {'components': {'schemas': {'BodyParamsForRunSchema': {'properties': {'filter': {'anyOf': [{'type': 'string'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Filter'},\n",
       "      'trace_filter': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Trace Filter'}}}}}},\n",
       " {'components': {'schemas': {'BodyParamsForRunSchema': {'properties': {'tree_filter': {'anyOf': [{'type': 'string'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Tree Filter'},\n",
       "      'is_root': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "       'title': 'Is Root'}}}}}},\n",
       " {'components': {'schemas': {'BodyParamsForRunSchema': {'properties': {'data_source_type': {'anyOf': [{'$ref': '#/components/schemas/RunsFilterDataSourceTypeEnum'},\n",
       "        {'type': 'null'}]},\n",
       "      'cursor': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Cursor'}}}}}},\n",
       " {'components': {'schemas': {'BodyParamsForRunSchema': {'properties': {'limit': {'type': 'integer',\n",
       "       'maximum': 100.0,\n",
       "       'minimum': 1.0,\n",
       "       'title': 'Limit',\n",
       "       'default': 100}}}}}},\n",
       " {'components': {'schemas': {'BodyParamsForRunSchema': {'properties': {'select': {'items': {'$ref': '#/components/schemas/RunSelect'},\n",
       "       'type': 'array',\n",
       "       'title': 'Select'}}}}}},\n",
       " {'components': {'schemas': {'BodyParamsForRunSchema': {'properties': {'select': {'default': ['id',\n",
       "        'name',\n",
       "        'run_type',\n",
       "        'start_time',\n",
       "        'end_time',\n",
       "        'status',\n",
       "        'error',\n",
       "        'extra',\n",
       "        'events',\n",
       "        'inputs',\n",
       "        'outputs',\n",
       "        'parent_run_id',\n",
       "        'manifest_id',\n",
       "        'manifest_s3_id',\n",
       "        'session_id',\n",
       "        'serialized',\n",
       "        'reference_example_id',\n",
       "        'total_tokens',\n",
       "        'prompt_tokens',\n",
       "        'completion_tokens',\n",
       "        'total_cost',\n",
       "        'prompt_cost',\n",
       "        'completion_cost',\n",
       "        'price_model_id',\n",
       "        'first_token_time',\n",
       "        'trace_id',\n",
       "        'dotted_order',\n",
       "        'last_queued_at',\n",
       "        'feedback_stats',\n",
       "        'child_run_ids',\n",
       "        'parent_run_ids',\n",
       "        'tags',\n",
       "        'in_dataset',\n",
       "        'app_path',\n",
       "        'share_token',\n",
       "        'trace_tier',\n",
       "        'trace_first_received_at',\n",
       "        'ttl_seconds',\n",
       "        'trace_upgrade']}}}}}},\n",
       " {'components': {'schemas': {'BodyParamsForRunSchema': {'properties': {'order': {'allOf': [{'$ref': '#/components/schemas/RunDateOrder'}],\n",
       "       'default': 'desc'}},\n",
       "     'type': 'object',\n",
       "     'title': 'BodyParamsForRunSchema',\n",
       "     'description': 'Query params for run endpoints.'}}}},\n",
       " {'components': {'schemas': {'Body_clone_dataset_api_v1_datasets_clone_post': {'properties': {'target_dataset_id': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Target Dataset Id'},\n",
       "      'source_dataset_id': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Source Dataset Id'}}}}}},\n",
       " {'components': {'schemas': {'Body_clone_dataset_api_v1_datasets_clone_post': {'properties': {'as_of': {'anyOf': [{'anyOf': [{'type': 'string',\n",
       "           'format': 'date-time'},\n",
       "          {'type': 'string'}],\n",
       "         'description': 'Only modifications made on or before this time are included. If None, the latest version of the dataset is used.'},\n",
       "        {'type': 'null'}]}}}}}},\n",
       " {'components': {'schemas': {'Body_clone_dataset_api_v1_datasets_clone_post': {'properties': {'as_of': {'title': 'As Of'},\n",
       "      'examples': {'items': {'type': 'string', 'format': 'uuid'},\n",
       "       'type': 'array',\n",
       "       'title': 'Examples',\n",
       "       'default': []}},\n",
       "     'type': 'object'}}}},\n",
       " {'components': {'schemas': {'Body_clone_dataset_api_v1_datasets_clone_post': {'required': ['target_dataset_id',\n",
       "      'source_dataset_id'],\n",
       "     'title': 'Body_clone_dataset_api_v1_datasets_clone_post'}}}},\n",
       " {'components': {'schemas': {'Body_update_dataset_splits_api_v1_datasets__dataset_id__splits_put': {'properties': {'split_name': {'type': 'string',\n",
       "       'title': 'Split Name'},\n",
       "      'examples': {'items': {'type': 'string', 'format': 'uuid'},\n",
       "       'type': 'array',\n",
       "       'title': 'Examples'},\n",
       "      'remove': {'type': 'boolean', 'title': 'Remove', 'default': False}}}}}},\n",
       " {'components': {'schemas': {'Body_update_dataset_splits_api_v1_datasets__dataset_id__splits_put': {'type': 'object',\n",
       "     'required': ['split_name', 'examples'],\n",
       "     'title': 'Body_update_dataset_splits_api_v1_datasets__dataset_id__splits_put'}}}},\n",
       " {'components': {'schemas': {'Body_upload_csv_dataset_api_v1_datasets_upload_post': {'properties': {'file': {'type': 'string',\n",
       "       'format': 'binary',\n",
       "       'title': 'File'},\n",
       "      'input_keys': {'items': {'type': 'string'},\n",
       "       'type': 'array',\n",
       "       'title': 'Input Keys'}}}}}},\n",
       " {'components': {'schemas': {'Body_upload_csv_dataset_api_v1_datasets_upload_post': {'properties': {'name': {'anyOf': [{'type': 'string'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Name'},\n",
       "      'data_type': {'allOf': [{'$ref': '#/components/schemas/DataType'}],\n",
       "       'default': 'kv'}}}}}},\n",
       " {'components': {'schemas': {'Body_upload_csv_dataset_api_v1_datasets_upload_post': {'properties': {'output_keys': {'items': {'type': 'string'},\n",
       "       'type': 'array',\n",
       "       'title': 'Output Keys',\n",
       "       'default': []},\n",
       "      'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Description'}}}}}},\n",
       " {'components': {'schemas': {'Body_upload_csv_dataset_api_v1_datasets_upload_post': {'type': 'object',\n",
       "     'required': ['file', 'input_keys'],\n",
       "     'title': 'Body_upload_csv_dataset_api_v1_datasets_upload_post'}}}},\n",
       " {'components': {'schemas': {'Body_upload_examples_api_v1_examples_upload__dataset_id__post': {'properties': {'file': {'type': 'string',\n",
       "       'format': 'binary',\n",
       "       'title': 'File'},\n",
       "      'input_keys': {'items': {'type': 'string'},\n",
       "       'type': 'array',\n",
       "       'title': 'Input Keys'},\n",
       "      'output_keys': {'items': {'type': 'string'},\n",
       "       'type': 'array',\n",
       "       'title': 'Output Keys'}}}}}},\n",
       " {'components': {'schemas': {'Body_upload_examples_api_v1_examples_upload__dataset_id__post': {'type': 'object',\n",
       "     'required': ['file', 'input_keys'],\n",
       "     'title': 'Body_upload_examples_api_v1_examples_upload__dataset_id__post'}}}},\n",
       " {'components': {'schemas': {'ChangePaymentPlanReq': {'type': 'string',\n",
       "     'enum': ['disabled',\n",
       "      'developer',\n",
       "      'plus',\n",
       "      'startup',\n",
       "      'partner',\n",
       "      'premier'],\n",
       "     'title': 'ChangePaymentPlanReq'}}}},\n",
       " {'components': {'schemas': {'ChangePaymentPlanReq': {'description': 'Enum for payment plans that the user can change to. Developer plans are permanent and enterprise plans will be changed manually.'}}}},\n",
       " {'components': {'schemas': {'ChangePaymentPlanSchema': {'properties': {'tier': {'$ref': '#/components/schemas/ChangePaymentPlanReq'}},\n",
       "     'type': 'object',\n",
       "     'required': ['tier'],\n",
       "     'title': 'ChangePaymentPlanSchema',\n",
       "     'description': 'Change payment plan schema.'}}}},\n",
       " {'components': {'schemas': {'Comment': {'properties': {'id': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Id'},\n",
       "      'comment_by': {'anyOf': [{'type': 'string', 'format': 'uuid'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Comment By'},\n",
       "      'comment_on': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Comment On'}}}}}},\n",
       " {'components': {'schemas': {'Comment': {'properties': {'parent_id': {'anyOf': [{'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Parent Id'},\n",
       "      'content': {'type': 'string', 'title': 'Content'},\n",
       "      'created_at': {'type': 'string',\n",
       "       'format': 'date-time',\n",
       "       'title': 'Created At'}}}}}},\n",
       " {'components': {'schemas': {'Comment': {'properties': {'updated_at': {'type': 'string',\n",
       "       'format': 'date-time',\n",
       "       'title': 'Updated At'},\n",
       "      'comment_by_name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Comment By Name'}}}}}},\n",
       " {'components': {'schemas': {'Comment': {'properties': {'num_sub_comments': {'type': 'integer',\n",
       "       'title': 'Num Sub Comments'},\n",
       "      'num_likes': {'type': 'integer', 'title': 'Num Likes'},\n",
       "      'liked_by_auth_user': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "       'title': 'Liked By Auth User'}}}}}},\n",
       " {'components': {'schemas': {'Comment': {'type': 'object',\n",
       "     'required': ['id',\n",
       "      'comment_on',\n",
       "      'content',\n",
       "      'created_at',\n",
       "      'updated_at',\n",
       "      'num_sub_comments',\n",
       "      'num_likes'],\n",
       "     'title': 'Comment'}}}},\n",
       " {'components': {'schemas': {'CommitManifestResponse': {'properties': {'commit_hash': {'type': 'string',\n",
       "       'title': 'Commit Hash'},\n",
       "      'manifest': {'type': 'object', 'title': 'Manifest'},\n",
       "      'examples': {'anyOf': [{'items': {'$ref': '#/components/schemas/RepoExampleResponse'},\n",
       "         'type': 'array'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Examples'}}}}}},\n",
       " {'components': {'schemas': {'CommitManifestResponse': {'type': 'object',\n",
       "     'required': ['commit_hash', 'manifest'],\n",
       "     'title': 'CommitManifestResponse',\n",
       "     'description': 'Response model for get_commit_manifest.'}}}},\n",
       " {'components': {'schemas': {'CommitWithLookups': {'properties': {'id': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Id'},\n",
       "      'manifest_id': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Manifest Id'},\n",
       "      'repo_id': {'type': 'string', 'format': 'uuid', 'title': 'Repo Id'}}}}}},\n",
       " {'components': {'schemas': {'CommitWithLookups': {'properties': {'parent_id': {'anyOf': [{'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Parent Id'},\n",
       "      'commit_hash': {'type': 'string', 'title': 'Commit Hash'}}}}}},\n",
       " {'components': {'schemas': {'CommitWithLookups': {'properties': {'created_at': {'type': 'string',\n",
       "       'format': 'date-time',\n",
       "       'title': 'Created At'},\n",
       "      'updated_at': {'type': 'string',\n",
       "       'format': 'date-time',\n",
       "       'title': 'Updated At'}}}}}},\n",
       " {'components': {'schemas': {'CommitWithLookups': {'properties': {'example_run_ids': {'items': {'type': 'string',\n",
       "        'format': 'uuid'},\n",
       "       'type': 'array',\n",
       "       'title': 'Example Run Ids'},\n",
       "      'num_downloads': {'type': 'integer', 'title': 'Num Downloads'}}}}}},\n",
       " {'components': {'schemas': {'CommitWithLookups': {'properties': {'num_views': {'type': 'integer',\n",
       "       'title': 'Num Views'},\n",
       "      'parent_commit_hash': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Parent Commit Hash'}},\n",
       "     'type': 'object'}}}},\n",
       " {'components': {'schemas': {'CommitWithLookups': {'required': ['id',\n",
       "      'manifest_id',\n",
       "      'repo_id',\n",
       "      'commit_hash',\n",
       "      'created_at',\n",
       "      'updated_at',\n",
       "      'example_run_ids',\n",
       "      'num_downloads',\n",
       "      'num_views'],\n",
       "     'title': 'CommitWithLookups'}}}},\n",
       " {'components': {'schemas': {'CommitWithLookups': {'description': 'All database fields for commits, plus helpful computed fields.'}}}},\n",
       " {'components': {'schemas': {'ComparativeExperiment': {'properties': {'id': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Id'},\n",
       "      'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Name'},\n",
       "      'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Description'}}}}}},\n",
       " {'components': {'schemas': {'ComparativeExperiment': {'properties': {'tenant_id': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Tenant Id'},\n",
       "      'created_at': {'type': 'string',\n",
       "       'format': 'date-time',\n",
       "       'title': 'Created At'}}}}}},\n",
       " {'components': {'schemas': {'ComparativeExperiment': {'properties': {'modified_at': {'type': 'string',\n",
       "       'format': 'date-time',\n",
       "       'title': 'Modified At'},\n",
       "      'reference_dataset_id': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Reference Dataset Id'}}}}}},\n",
       " {'components': {'schemas': {'ComparativeExperiment': {'properties': {'extra': {'anyOf': [{'type': 'object'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Extra'},\n",
       "      'experiments_info': {'items': {'$ref': '#/components/schemas/SimpleExperimentInfo'},\n",
       "       'type': 'array',\n",
       "       'title': 'Experiments Info'}}}}}},\n",
       " {'components': {'schemas': {'ComparativeExperiment': {'properties': {'feedback_stats': {'anyOf': [{'type': 'object'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Feedback Stats'}},\n",
       "     'type': 'object',\n",
       "     'required': ['id',\n",
       "      'tenant_id',\n",
       "      'created_at',\n",
       "      'modified_at',\n",
       "      'reference_dataset_id',\n",
       "      'experiments_info']}}}},\n",
       " {'components': {'schemas': {'ComparativeExperiment': {'title': 'ComparativeExperiment',\n",
       "     'description': 'ComparativeExperiment schema.'}}}},\n",
       " {'components': {'schemas': {'ComparativeExperimentBase': {'properties': {'id': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Id'},\n",
       "      'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Name'}}}}}},\n",
       " {'components': {'schemas': {'ComparativeExperimentBase': {'properties': {'description': {'anyOf': [{'type': 'string'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Description'},\n",
       "      'tenant_id': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Tenant Id'}}}}}},\n",
       " {'components': {'schemas': {'ComparativeExperimentBase': {'properties': {'created_at': {'type': 'string',\n",
       "       'format': 'date-time',\n",
       "       'title': 'Created At'},\n",
       "      'modified_at': {'type': 'string',\n",
       "       'format': 'date-time',\n",
       "       'title': 'Modified At'}}}}}},\n",
       " {'components': {'schemas': {'ComparativeExperimentBase': {'properties': {'reference_dataset_id': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Reference Dataset Id'},\n",
       "      'extra': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "       'title': 'Extra'}},\n",
       "     'type': 'object'}}}},\n",
       " {'components': {'schemas': {'ComparativeExperimentBase': {'required': ['id',\n",
       "      'tenant_id',\n",
       "      'created_at',\n",
       "      'modified_at',\n",
       "      'reference_dataset_id'],\n",
       "     'title': 'ComparativeExperimentBase',\n",
       "     'description': 'ComparativeExperiment schema.'}}}},\n",
       " {'components': {'schemas': {'ComparativeExperimentCreate': {'properties': {'id': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Id'},\n",
       "      'experiment_ids': {'items': {'type': 'string', 'format': 'uuid'},\n",
       "       'type': 'array',\n",
       "       'title': 'Experiment Ids'}}}}}},\n",
       " {'components': {'schemas': {'ComparativeExperimentCreate': {'properties': {'name': {'anyOf': [{'type': 'string'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Name'},\n",
       "      'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Description'}}}}}},\n",
       " {'components': {'schemas': {'ComparativeExperimentCreate': {'properties': {'created_at': {'type': 'string',\n",
       "       'format': 'date-time',\n",
       "       'title': 'Created At'},\n",
       "      'modified_at': {'type': 'string',\n",
       "       'format': 'date-time',\n",
       "       'title': 'Modified At'}}}}}},\n",
       " {'components': {'schemas': {'ComparativeExperimentCreate': {'properties': {'reference_dataset_id': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Reference Dataset Id'},\n",
       "      'extra': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "       'title': 'Extra'}},\n",
       "     'type': 'object'}}}},\n",
       " {'components': {'schemas': {'ComparativeExperimentCreate': {'required': ['experiment_ids',\n",
       "      'reference_dataset_id'],\n",
       "     'title': 'ComparativeExperimentCreate',\n",
       "     'description': 'Create class for ComparativeExperiment.'}}}},\n",
       " {'components': {'schemas': {'ConfiguredBy': {'type': 'string',\n",
       "     'enum': ['system', 'user'],\n",
       "     'title': 'ConfiguredBy'},\n",
       "    'CreateCommentRequest': {'properties': {'content': {'type': 'string',\n",
       "       'title': 'Content'}},\n",
       "     'type': 'object',\n",
       "     'required': ['content'],\n",
       "     'title': 'CreateCommentRequest'}}}},\n",
       " {'components': {'schemas': {'CreateEventRequest': {'properties': {'event_type': {'type': 'string',\n",
       "       'enum': ['playground-view', 'playground-run'],\n",
       "       'title': 'Event Type'},\n",
       "      'owner': {'type': 'string', 'title': 'Owner'},\n",
       "      'repo': {'type': 'string', 'title': 'Repo'},\n",
       "      'commit': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Commit'}}}}}},\n",
       " {'components': {'schemas': {'CreateEventRequest': {'type': 'object',\n",
       "     'required': ['event_type', 'owner', 'repo'],\n",
       "     'title': 'CreateEventRequest'}}}},\n",
       " {'components': {'schemas': {'CreateFeedbackConfigSchema': {'properties': {'feedback_key': {'type': 'string',\n",
       "       'title': 'Feedback Key'},\n",
       "      'feedback_config': {'$ref': '#/components/schemas/FeedbackConfig'},\n",
       "      'is_lower_score_better': {'anyOf': [{'type': 'boolean'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Is Lower Score Better',\n",
       "       'default': False}}}}}},\n",
       " {'components': {'schemas': {'CreateFeedbackConfigSchema': {'type': 'object',\n",
       "     'required': ['feedback_key', 'feedback_config'],\n",
       "     'title': 'CreateFeedbackConfigSchema'}}}},\n",
       " {'components': {'schemas': {'CreateRepoCommitRequest': {'properties': {'manifest': {'type': 'object',\n",
       "       'title': 'Manifest'},\n",
       "      'parent_commit': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Parent Commit'}}}}}},\n",
       " {'components': {'schemas': {'CreateRepoCommitRequest': {'properties': {'example_run_ids': {'anyOf': [{'items': {'type': 'string',\n",
       "          'format': 'uuid'},\n",
       "         'type': 'array'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Example Run Ids'}},\n",
       "     'type': 'object',\n",
       "     'required': ['manifest'],\n",
       "     'title': 'CreateRepoCommitRequest'}}}},\n",
       " {'components': {'schemas': {'CreateRepoCommitResponse': {'properties': {'commit': {'$ref': '#/components/schemas/CommitWithLookups'}},\n",
       "     'type': 'object',\n",
       "     'required': ['commit'],\n",
       "     'title': 'CreateRepoCommitResponse'}}}},\n",
       " {'components': {'schemas': {'CreateRepoRequest': {'properties': {'repo_handle': {'type': 'string',\n",
       "       'title': 'Repo Handle'},\n",
       "      'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Description'},\n",
       "      'readme': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Readme'}}}}}},\n",
       " {'components': {'schemas': {'CreateRepoRequest': {'properties': {'is_public': {'type': 'boolean',\n",
       "       'title': 'Is Public'},\n",
       "      'tags': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Tags'}},\n",
       "     'type': 'object',\n",
       "     'required': ['repo_handle', 'is_public']}}}},\n",
       " {'components': {'schemas': {'CreateRepoRequest': {'title': 'CreateRepoRequest',\n",
       "     'description': 'Fields to create a repo'},\n",
       "    'CreateRepoResponse': {'properties': {'repo': {'$ref': '#/components/schemas/RepoWithLookups'}},\n",
       "     'type': 'object',\n",
       "     'required': ['repo'],\n",
       "     'title': 'CreateRepoResponse'}}}},\n",
       " {'components': {'schemas': {'CreateRoleRequest': {'properties': {'display_name': {'type': 'string',\n",
       "       'title': 'Display Name'},\n",
       "      'description': {'type': 'string', 'title': 'Description'},\n",
       "      'permissions': {'items': {'type': 'string'},\n",
       "       'type': 'array',\n",
       "       'title': 'Permissions'}},\n",
       "     'type': 'object'}}}},\n",
       " {'components': {'schemas': {'CreateRoleRequest': {'required': ['display_name',\n",
       "      'description',\n",
       "      'permissions'],\n",
       "     'title': 'CreateRoleRequest'}}}},\n",
       " {'components': {'schemas': {'CustomerVisiblePlanInfo': {'properties': {'tier': {'$ref': '#/components/schemas/PaymentPlanTier'},\n",
       "      'started_on': {'type': 'string',\n",
       "       'format': 'date-time',\n",
       "       'title': 'Started On'},\n",
       "      'ends_on': {'anyOf': [{'type': 'string', 'format': 'date-time'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Ends On'}}}}}},\n",
       " {'components': {'schemas': {'CustomerVisiblePlanInfo': {'type': 'object',\n",
       "     'required': ['tier', 'started_on'],\n",
       "     'title': 'CustomerVisiblePlanInfo',\n",
       "     'description': 'Customer visible plan information.'}}}},\n",
       " {'components': {'schemas': {'DataType': {'type': 'string',\n",
       "     'enum': ['kv', 'llm', 'chat'],\n",
       "     'title': 'DataType',\n",
       "     'description': 'Enum for dataset data types.'}}}},\n",
       " {'components': {'schemas': {'Dataset': {'properties': {'name': {'type': 'string',\n",
       "       'title': 'Name'},\n",
       "      'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Description'},\n",
       "      'created_at': {'type': 'string',\n",
       "       'format': 'date-time',\n",
       "       'title': 'Created At'}}}}}},\n",
       " {'components': {'schemas': {'Dataset': {'properties': {'data_type': {'anyOf': [{'$ref': '#/components/schemas/DataType'},\n",
       "        {'type': 'null'}],\n",
       "       'default': 'kv'},\n",
       "      'inputs_schema_definition': {'anyOf': [{'type': 'object'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Inputs Schema Definition'}}}}}},\n",
       " {'components': {'schemas': {'Dataset': {'properties': {'outputs_schema_definition': {'anyOf': [{'type': 'object'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Outputs Schema Definition'},\n",
       "      'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'}}}}}},\n",
       " {'components': {'schemas': {'Dataset': {'properties': {'tenant_id': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Tenant Id'},\n",
       "      'example_count': {'type': 'integer', 'title': 'Example Count'},\n",
       "      'session_count': {'type': 'integer', 'title': 'Session Count'}}}}}},\n",
       " {'components': {'schemas': {'Dataset': {'properties': {'modified_at': {'type': 'string',\n",
       "       'format': 'date-time',\n",
       "       'title': 'Modified At'},\n",
       "      'last_session_start_time': {'anyOf': [{'type': 'string',\n",
       "         'format': 'date-time'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Last Session Start Time'}},\n",
       "     'type': 'object'}}}},\n",
       " {'components': {'schemas': {'Dataset': {'required': ['name',\n",
       "      'id',\n",
       "      'tenant_id',\n",
       "      'example_count',\n",
       "      'session_count',\n",
       "      'modified_at'],\n",
       "     'title': 'Dataset',\n",
       "     'description': 'Dataset schema.'}}}},\n",
       " {'components': {'schemas': {'DatasetCreate': {'properties': {'name': {'type': 'string',\n",
       "       'title': 'Name'},\n",
       "      'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Description'},\n",
       "      'created_at': {'type': 'string',\n",
       "       'format': 'date-time',\n",
       "       'title': 'Created At'}}}}}},\n",
       " {'components': {'schemas': {'DatasetCreate': {'properties': {'data_type': {'anyOf': [{'$ref': '#/components/schemas/DataType'},\n",
       "        {'type': 'null'}],\n",
       "       'default': 'kv'},\n",
       "      'inputs_schema_definition': {'anyOf': [{'type': 'object'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Inputs Schema Definition'}}}}}},\n",
       " {'components': {'schemas': {'DatasetCreate': {'properties': {'outputs_schema_definition': {'anyOf': [{'type': 'object'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Outputs Schema Definition'},\n",
       "      'id': {'anyOf': [{'type': 'string', 'format': 'uuid'}, {'type': 'null'}],\n",
       "       'title': 'Id'}}}}}},\n",
       " {'components': {'schemas': {'DatasetCreate': {'properties': {'extra': {'anyOf': [{'type': 'object'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Extra'}},\n",
       "     'type': 'object',\n",
       "     'required': ['name'],\n",
       "     'title': 'DatasetCreate',\n",
       "     'description': 'Create class for Dataset.'}}}},\n",
       " {'components': {'schemas': {'DatasetDiffInfo': {'properties': {'examples_modified': {'items': {'type': 'string',\n",
       "        'format': 'uuid'},\n",
       "       'type': 'array',\n",
       "       'title': 'Examples Modified'},\n",
       "      'examples_added': {'items': {'type': 'string', 'format': 'uuid'},\n",
       "       'type': 'array',\n",
       "       'title': 'Examples Added'}}}}}},\n",
       " {'components': {'schemas': {'DatasetDiffInfo': {'properties': {'examples_removed': {'items': {'type': 'string',\n",
       "        'format': 'uuid'},\n",
       "       'type': 'array',\n",
       "       'title': 'Examples Removed'}},\n",
       "     'type': 'object',\n",
       "     'required': ['examples_modified',\n",
       "      'examples_added',\n",
       "      'examples_removed']}}}},\n",
       " {'components': {'schemas': {'DatasetDiffInfo': {'title': 'DatasetDiffInfo',\n",
       "     'description': 'Dataset diff schema.'}}}},\n",
       " {'components': {'schemas': {'DatasetPublicSchema': {'properties': {'name': {'type': 'string',\n",
       "       'title': 'Name'},\n",
       "      'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Description'},\n",
       "      'created_at': {'type': 'string',\n",
       "       'format': 'date-time',\n",
       "       'title': 'Created At'}}}}}},\n",
       " {'components': {'schemas': {'DatasetPublicSchema': {'properties': {'data_type': {'anyOf': [{'$ref': '#/components/schemas/DataType'},\n",
       "        {'type': 'null'}],\n",
       "       'default': 'kv'},\n",
       "      'inputs_schema_definition': {'anyOf': [{'type': 'object'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Inputs Schema Definition'}}}}}},\n",
       " {'components': {'schemas': {'DatasetPublicSchema': {'properties': {'outputs_schema_definition': {'anyOf': [{'type': 'object'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Outputs Schema Definition'},\n",
       "      'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'}}}}}},\n",
       " {'components': {'schemas': {'DatasetPublicSchema': {'properties': {'example_count': {'type': 'integer',\n",
       "       'title': 'Example Count'}},\n",
       "     'type': 'object',\n",
       "     'required': ['name', 'id', 'example_count'],\n",
       "     'title': 'DatasetPublicSchema'}}}},\n",
       " {'components': {'schemas': {'DatasetPublicSchema': {'description': \"Public schema for datasets.\\n\\nDoesn't currently include session counts/stats\\nsince public test project sharing is not yet shipped\"}}}},\n",
       " {'components': {'schemas': {'DatasetSchemaForUpdate': {'properties': {'name': {'type': 'string',\n",
       "       'title': 'Name'},\n",
       "      'description': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "       'title': 'Description'},\n",
       "      'created_at': {'type': 'string',\n",
       "       'format': 'date-time',\n",
       "       'title': 'Created At'}}}}}},\n",
       " {'components': {'schemas': {'DatasetSchemaForUpdate': {'properties': {'data_type': {'anyOf': [{'$ref': '#/components/schemas/DataType'},\n",
       "        {'type': 'null'}],\n",
       "       'default': 'kv'},\n",
       "      'inputs_schema_definition': {'anyOf': [{'type': 'object'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Inputs Schema Definition'}}}}}},\n",
       " {'components': {'schemas': {'DatasetSchemaForUpdate': {'properties': {'outputs_schema_definition': {'anyOf': [{'type': 'object'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Outputs Schema Definition'},\n",
       "      'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'}}}}}},\n",
       " {'components': {'schemas': {'DatasetSchemaForUpdate': {'properties': {'tenant_id': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Tenant Id'}},\n",
       "     'type': 'object',\n",
       "     'required': ['name', 'id', 'tenant_id'],\n",
       "     'title': 'DatasetSchemaForUpdate'}}}},\n",
       " {'components': {'schemas': {'DatasetServeRequest': {'properties': {'tag': {'anyOf': [{'type': 'string'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Tag',\n",
       "       'default': 'latest'}},\n",
       "     'type': 'object',\n",
       "     'title': 'DatasetServeRequest',\n",
       "     'description': 'Dataset schema for serving.'}}}},\n",
       " {'components': {'schemas': {'DatasetShareSchema': {'properties': {'dataset_id': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Dataset Id'},\n",
       "      'share_token': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Share Token'}},\n",
       "     'type': 'object',\n",
       "     'required': ['dataset_id', 'share_token']}}}},\n",
       " {'components': {'schemas': {'DatasetShareSchema': {'title': 'DatasetShareSchema'},\n",
       "    'DatasetUpdate': {'properties': {'name': {'anyOf': [{'type': 'string'},\n",
       "        {'$ref': '#/components/schemas/Missing'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Name',\n",
       "       'default': {}}}}}}},\n",
       " {'components': {'schemas': {'DatasetUpdate': {'properties': {'description': {'anyOf': [{'type': 'string'},\n",
       "        {'$ref': '#/components/schemas/Missing'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Description',\n",
       "       'default': {}}}}}}},\n",
       " {'components': {'schemas': {'DatasetUpdate': {'properties': {'inputs_schema_definition': {'anyOf': [{'type': 'object'},\n",
       "        {'$ref': '#/components/schemas/Missing'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Inputs Schema Definition',\n",
       "       'default': {}}}}}}},\n",
       " {'components': {'schemas': {'DatasetUpdate': {'properties': {'outputs_schema_definition': {'anyOf': [{'type': 'object'},\n",
       "        {'$ref': '#/components/schemas/Missing'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Outputs Schema Definition',\n",
       "       'default': {}}}}}}},\n",
       " {'components': {'schemas': {'DatasetUpdate': {'properties': {'patch_examples': {'anyOf': [{'additionalProperties': {'$ref': '#/components/schemas/ExampleUpdate'},\n",
       "         'type': 'object'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Patch Examples'}},\n",
       "     'type': 'object',\n",
       "     'title': 'DatasetUpdate'}}}},\n",
       " {'components': {'schemas': {'DatasetUpdate': {'description': 'Update class for Dataset.'},\n",
       "    'DatasetVersion': {'properties': {'tags': {'anyOf': [{'items': {'type': 'string'},\n",
       "         'type': 'array'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Tags'},\n",
       "      'as_of': {'type': 'string',\n",
       "       'format': 'date-time',\n",
       "       'title': 'As Of'}}}}}},\n",
       " {'components': {'schemas': {'DatasetVersion': {'type': 'object',\n",
       "     'required': ['as_of'],\n",
       "     'title': 'DatasetVersion',\n",
       "     'description': 'Dataset version schema.'}}}},\n",
       " {'components': {'schemas': {'EvaluatorStructuredOutput': {'properties': {'hub_ref': {'anyOf': [{'type': 'string'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Hub Ref'}}}}}},\n",
       " {'components': {'schemas': {'EvaluatorStructuredOutput': {'properties': {'prompt': {'anyOf': [{'items': {'prefixItems': [{'type': 'string'},\n",
       "           {'type': 'string'}],\n",
       "          'type': 'array',\n",
       "          'maxItems': 2,\n",
       "          'minItems': 2},\n",
       "         'type': 'array'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Prompt'}}}}}},\n",
       " {'components': {'schemas': {'EvaluatorStructuredOutput': {'properties': {'template_format': {'anyOf': [{'type': 'string'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Template Format'},\n",
       "      'schema': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "       'title': 'Schema'}}}}}},\n",
       " {'components': {'schemas': {'EvaluatorStructuredOutput': {'properties': {'variable_mapping': {'anyOf': [{'additionalProperties': {'type': 'string'},\n",
       "         'type': 'object'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Variable Mapping'},\n",
       "      'model': {'type': 'object', 'title': 'Model'}},\n",
       "     'type': 'object'}}}},\n",
       " {'components': {'schemas': {'EvaluatorStructuredOutput': {'required': ['model'],\n",
       "     'title': 'EvaluatorStructuredOutput',\n",
       "     'description': 'Evaluator structured output schema.'}}}},\n",
       " {'components': {'schemas': {'EvaluatorTopLevel': {'properties': {'structured': {'$ref': '#/components/schemas/EvaluatorStructuredOutput'}},\n",
       "     'type': 'object',\n",
       "     'required': ['structured'],\n",
       "     'title': 'EvaluatorTopLevel'}}}},\n",
       " {'components': {'schemas': {'Example': {'properties': {'inputs': {'type': 'object',\n",
       "       'title': 'Inputs'},\n",
       "      'outputs': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "       'title': 'Outputs'},\n",
       "      'dataset_id': {'type': 'string',\n",
       "       'format': 'uuid',\n",
       "       'title': 'Dataset Id'}}}}}},\n",
       " {'components': {'schemas': {'Example': {'properties': {'source_run_id': {'anyOf': [{'type': 'string',\n",
       "         'format': 'uuid'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Source Run Id'},\n",
       "      'metadata': {'anyOf': [{'type': 'object'}, {'type': 'null'}],\n",
       "       'title': 'Metadata'}}}}}},\n",
       " {'components': {'schemas': {'Example': {'properties': {'created_at': {'type': 'string',\n",
       "       'format': 'date-time',\n",
       "       'title': 'Created At'},\n",
       "      'id': {'type': 'string', 'format': 'uuid', 'title': 'Id'},\n",
       "      'name': {'type': 'string', 'title': 'Name'}}}}}},\n",
       " {'components': {'schemas': {'Example': {'properties': {'modified_at': {'anyOf': [{'type': 'string',\n",
       "         'format': 'date-time'},\n",
       "        {'type': 'null'}],\n",
       "       'title': 'Modified At'}},\n",
       "     'type': 'object',\n",
       "     'required': ['inputs', 'dataset_id', 'id', 'name'],\n",
       "     'title': 'Example',\n",
       "     'description': 'Example schema.'}}}},\n",
       " ...]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'openapi': '3.1.0', 'info': {'title': 'LangSmith', 'version': '0.1.0'}, 'paths': {'/api/v1/sessions/{session_id}': {'get': {'tags': ['tracer-sessions'], 'summary': 'Read Tracer Session', 'description': 'Get a specific session.'}}}}\n",
      "{'paths': {'/api/v1/sessions/{session_id}': {'get': {'operationId': 'read_tracer_session_api_v1_sessions__session_id__get', 'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}}\n",
      "{'paths': {'/api/v1/sessions/{session_id}': {'get': {'parameters': [{'name': 'session_id', 'in': 'path', 'required': True, 'schema': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'}}, {'name': 'include_stats', 'in': 'query', 'required': False, 'schema': {'type': 'boolean', 'default': False, 'title': 'Include Stats'}}, {'name': 'accept', 'in': 'header', 'required': False, 'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Accept'}}]}}}}\n"
     ]
    }
   ],
   "source": [
    "for chunk in json_chunks[:3]:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON Splitter to get document format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = json_splitter.create_documents(texts=[json_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='{\"openapi\": \"3.1.0\", \"info\": {\"title\": \"LangSmith\", \"version\": \"0.1.0\"}, \"paths\": {\"/api/v1/sessions/{session_id}\": {\"get\": {\"tags\": [\"tracer-sessions\"], \"summary\": \"Read Tracer Session\", \"description\": \"Get a specific session.\"}}}}'\n",
      "page_content='{\"paths\": {\"/api/v1/sessions/{session_id}\": {\"get\": {\"operationId\": \"read_tracer_session_api_v1_sessions__session_id__get\", \"security\": [{\"API Key\": []}, {\"Tenant ID\": []}, {\"Bearer Auth\": []}]}}}}'\n",
      "page_content='{\"paths\": {\"/api/v1/sessions/{session_id}\": {\"get\": {\"parameters\": [{\"name\": \"session_id\", \"in\": \"path\", \"required\": true, \"schema\": {\"type\": \"string\", \"format\": \"uuid\", \"title\": \"Session Id\"}}, {\"name\": \"include_stats\", \"in\": \"query\", \"required\": false, \"schema\": {\"type\": \"boolean\", \"default\": false, \"title\": \"Include Stats\"}}, {\"name\": \"accept\", \"in\": \"header\", \"required\": false, \"schema\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Accept\"}}]}}}}'\n"
     ]
    }
   ],
   "source": [
    "for doc in docs[:3]:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"openapi\": \"3.1.0\", \"info\": {\"title\": \"LangSmith\", \"version\": \"0.1.0\"}, \"paths\": {\"/api/v1/sessions/{session_id}\": {\"get\": {\"tags\": [\"tracer-sessions\"], \"summary\": \"Read Tracer Session\", \"description\": \"Get a specific session.\"}}}}\n",
      "{\"paths\": {\"/api/v1/sessions/{session_id}\": {\"get\": {\"operationId\": \"read_tracer_session_api_v1_sessions__session_id__get\", \"security\": [{\"API Key\": []}, {\"Tenant ID\": []}, {\"Bearer Auth\": []}]}}}}\n"
     ]
    }
   ],
   "source": [
    "texts = json_splitter.split_text(json_data)\n",
    "print(texts[0])\n",
    "print(texts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
