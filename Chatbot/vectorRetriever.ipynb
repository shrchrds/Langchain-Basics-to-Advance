{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"\",\n",
    "        metadata={\"source\":\"\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\",\n",
    "        metadata={\"source\":\"\"}\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "import random\n",
    "\n",
    "# Sample synthetic data for demonstration\n",
    "sample_contents = [\n",
    "    \"Artificial Intelligence is transforming industries.\",\n",
    "    \"Machine Learning allows computers to learn from data.\",\n",
    "    \"Natural Language Processing enables communication between humans and machines.\",\n",
    "    \"Deep Learning is a subset of Machine Learning.\",\n",
    "    \"Generative AI can create new content based on existing data.\",\n",
    "    \"Data Science combines statistics and computer science.\",\n",
    "    \"AI ethics is crucial for responsible AI deployment.\",\n",
    "    \"Reinforcement Learning is used in robotics and gaming.\",\n",
    "    \"Computer Vision allows machines to interpret visual information.\",\n",
    "    \"Big Data analytics drives insights in various fields.\"\n",
    "]\n",
    "\n",
    "# Generate 10 synthetic Document objects\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=random.choice(sample_contents),\n",
    "        metadata={\"source\": f\"source_{i+1}\"}\n",
    "    ) for i in range(10)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'source_1'}, page_content='Computer Vision allows machines to interpret visual information.'),\n",
       " Document(metadata={'source': 'source_2'}, page_content='Natural Language Processing enables communication between humans and machines.'),\n",
       " Document(metadata={'source': 'source_3'}, page_content='Reinforcement Learning is used in robotics and gaming.'),\n",
       " Document(metadata={'source': 'source_4'}, page_content='AI ethics is crucial for responsible AI deployment.'),\n",
       " Document(metadata={'source': 'source_5'}, page_content='Natural Language Processing enables communication between humans and machines.'),\n",
       " Document(metadata={'source': 'source_6'}, page_content='AI ethics is crucial for responsible AI deployment.'),\n",
       " Document(metadata={'source': 'source_7'}, page_content='Big Data analytics drives insights in various fields.'),\n",
       " Document(metadata={'source': 'source_8'}, page_content='Deep Learning is a subset of Machine Learning.'),\n",
       " Document(metadata={'source': 'source_9'}, page_content='Reinforcement Learning is used in robotics and gaming.'),\n",
       " Document(metadata={'source': 'source_10'}, page_content='Machine Learning allows computers to learn from data.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACE_API_TOKEN\"] = os.getenv(\"HUGGINGFACE_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Creating Embeddings\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VectorStores\n",
    "\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'source_1'}, page_content='Computer Vision allows machines to interpret visual information.'),\n",
       " Document(metadata={'source': 'source_1'}, page_content='Computer Vision allows machines to interpret visual information.'),\n",
       " Document(metadata={'source': 'source_1'}, page_content='Computer Vision allows machines to interpret visual information.'),\n",
       " Document(metadata={'source': 'source_4'}, page_content='Machine Learning allows computers to learn from data.')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.similarity_search(\"Computer Vision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'source_1'}, page_content='Computer Vision allows machines to interpret visual information.'),\n",
       " Document(metadata={'source': 'source_1'}, page_content='Computer Vision allows machines to interpret visual information.'),\n",
       " Document(metadata={'source': 'source_1'}, page_content='Computer Vision allows machines to interpret visual information.'),\n",
       " Document(metadata={'source': 'source_4'}, page_content='Machine Learning allows computers to learn from data.')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Async query\n",
    "\n",
    "await vectorstore.asimilarity_search(\"Computer Vision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'source_1'}, page_content='Computer Vision allows machines to interpret visual information.'),\n",
       "  0.5013437271118164),\n",
       " (Document(metadata={'source': 'source_1'}, page_content='Computer Vision allows machines to interpret visual information.'),\n",
       "  0.5013437271118164),\n",
       " (Document(metadata={'source': 'source_1'}, page_content='Computer Vision allows machines to interpret visual information.'),\n",
       "  0.5013437271118164),\n",
       " (Document(metadata={'source': 'source_4'}, page_content='Machine Learning allows computers to learn from data.'),\n",
       "  1.2406715154647827)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.similarity_search_with_score(\"Computer Vision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(metadata={'source': 'source_1'}, page_content='Computer Vision allows machines to interpret visual information.')],\n",
       " [Document(metadata={'source': 'source_4'}, page_content='Machine Learning allows computers to learn from data.')]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = RunnableLambda(vectorstore.similarity_search).bind(k=1)\n",
    "retriever.batch([\"Computer Vision\", \"Machien Learning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(metadata={'source': 'source_1'}, page_content='Computer Vision allows machines to interpret visual information.')],\n",
       " [Document(metadata={'source': 'source_4'}, page_content='Machine Learning allows computers to learn from data.')]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\":1}\n",
    ")\n",
    "\n",
    "retriever.batch([\"Computer Vision\", \"Machien Learning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "According to the provided context, Computer Vision allows machines to interpret visual information."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "message = \"\"\"\n",
    "        Answer this question using the provided context only\n",
    "        {question}\n",
    "\n",
    "        Context:\n",
    "        {context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\"human\", message])\n",
    "\n",
    "rag_chain = {\"context\":retriever,\n",
    "            \"question\":RunnablePassthrough()}| prompt | llm\n",
    "\n",
    "response = rag_chain.invoke(\"Tell me about Computer Vision\")\n",
    "\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
