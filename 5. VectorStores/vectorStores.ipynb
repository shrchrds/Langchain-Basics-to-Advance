{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"4. Embedding/super_DS.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_embeddings = OllamaEmbeddings(model=\"gemma2\")\n",
    "db = FAISS.from_documents(docs, ollama_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '4. Embedding/super_DS.txt'}, page_content='Show Notes: http://www.superdatascience.com/802 1\\nSDS PODCAST\\nEPISODE 802:\\nIN CASE YOU MISSED\\nIT IN JUNE 2024\\n    Show Notes: http://www.superdatascience.com/802 2\\nJon: 00:02 This is episode number 802, our In Case You Missed it in\\nJune episode.\\n    00:19 Welcome back to the Super Data Science Podcast. I\\'m\\nyour host, Jon Krohn. This is an In Case You Missed It\\nepisode that highlights the best parts of conversations we\\nhad on the show in the last month. This first clip you\\'ll\\nhear is from my interview with Dr. Jason Yosinski, one of\\nmy all-time favorite AI researchers. We had a great\\nconversation about making your AI and ML models\\nattractive to customers.\\n    00:40 In this clip, I got him to speak from his experience as\\nCEO of the climate technology startup he founded,\\nWindscape AI. This is a great case study if you\\'re\\nplanning to launch your own AI models commercially.\\n00:51 I\\'m sure that kind of engineering mindset is applicable to\\na lot of our listeners, and it seems like your approach is\\nworking. So EDP, a large Portuguese utility company,\\nrecently selected Windscape as one of nine startups for its\\nrenewable innovation program in Singapore to accelerate\\nthe global energy transition. What opportunities do you\\nsee emerging from Windscape AI\\'s participation in this\\nprogram?\\n    Jason: 01:16 Yeah. Well, thanks for mentioning that. We did apply for\\nthis program. We were selected. EDP is a huge utility. I\\nbelieve they\\'re the fourth-largest wind owner in the world.\\nSo they own tons and tons of turbines. They generate a\\nlot of wind energy. When I met with folks from EDP, I\\nfound them to be a very forward-looking organization.\\nSometimes you get a big company and they\\'re impossibly\\nslow or something, but these folks are really pushing the\\nboundaries, all the boundaries they can, which I thought\\nwas super cool.\\n    Show Notes: http://www.superdatascience.com/802 3\\n01:50 What we hope to get out of it and where that collaboration\\nmight go is to pilot our technology, start working with\\nthem, see how it works on their wind farms around the\\nworld. And then if it does work really well, hopefully we\\nroll out more broadly and we can also maybe use that as\\na demo for new potential customers.\\n    Jon: 02:08 Very cool. So it sounds like EDP is forward-looking. But\\nin general, do you counter resistance or hurdles as you\\ntry to come to energy utilities and say, \"Hey, you could be\\nusing AI like Windscape\\'s to be improving the efficiency of\\nyour systems.\" Do you encounter resistance or hurdles,\\nor is it relatively straightforward to convince people that\\nyou\\'re doing something valuable?\\n    Jason: 02:31 I wouldn\\'t say it\\'s straightforward. No. Convincing people\\nthat what you\\'re doing is valuable is maybe always hard. I\\nwould say saying the words AI or machine learning\\ndoesn\\'t immediately open all the doors. It can open some\\ndoors. Some of these companies realize that AI might be\\nrevolutionizing things that happen internally, and they\\'re\\nnot quite sure how yet, but maybe we should talk to these\\nrandos from Windscape and see what they think.\\n02:59 It does open some doors, but not all. Just as probably\\nwithin any industry, there are some organizations that\\nare very forward-looking and others early adopters of any\\ntechnology and others that are slower, that are later\\nadopters. They literally, some have told us, \"We don\\'t care\\nwhat you\\'re [inaudible 00:03:17], just show us when four\\nother companies are using it and then we\\'ll consider\\nusing it because how we work,\" which is potentially an\\nefficient choice from their perspective.\\n    03:27 There\\'s also small energy companies and large energy\\ncompanies, and there\\'s a spectrum there of how you sell\\nto these companies and how you get adoption and so on.\\nSo yeah, and convincing everyone, it can be hard. You\\nShow Notes: http://www.superdatascience.com/802 4\\nhave to convince people that your technology will work,\\nthat it won\\'t be a huge headache to adopt. The people in\\nthe field need to buy into it. It can\\'t ruin their workflow or\\nsomething. It has to be possible to actually integrate. So\\nsome of these systems run software that\\'s hard to work\\nwith and simply integrating can be difficult at times. So I\\ndon\\'t know, there\\'s a lot of factors probably as in any\\nindustry.\\n    Jon: 04:10 Yeah, it makes so much sense. And hopefully I\\'m not\\ngoing too deep here, and if I am asking a question that\\nwould give away some kind of IP, just feel free to not\\nanswer this. But it seems to me like in a situation like\\nyours, where you are providing software to hardware\\ncompanies, say the turbine manufacturers, you are not,\\nat least in the immediate term, planning on building, say\\nyour own turbines, your own wind farms.\\n    04:37 You are a software company. You need to be partnering\\nwith turbine manufacturers, with wind farm operators.\\nHow does that work? Are people... I guess maybe your\\nresponse is going to be similar, where there\\'s a range of\\nresponses where some turbine manufacturers are\\nrelatively early adopters. They see the potential. They say,\\n\"Wow, Jason\\'s done a lot of amazing research in the past.\\nHe seems like the kind of person we should be working\\nwith to accelerate our roadmap.\" And then other folks are\\njust like, \"Yeah, we\\'ve got our own team,\" or I don\\'t know.\\nHow does it look for you? Yeah.\\n    Jason: 05:09 What we started this whole endeavor, what we imagined\\nwould happen is we would first build products that we\\nwould sell to people that own the turbines. Why do they\\nwant them? Because our product would help them make\\nmore money starting next month. We help them make\\nmore money. They like our product, we roll out, they tell\\ntheir friends. We deploy to more and more farms, more\\nand more companies. As we start to increase our market\\nShow Notes: http://www.superdatascience.com/802 5\\npenetration in the industry, then much later, turbine\\nmanufacturers would notice and they would say, \"Hey,\\neveryone\\'s using these Windscape people. Maybe we\\nshould talk to them and consider integrating their thing\\noff the factory floor rather than an as aftermarket add-on\\non.\"\\n    05:48 That\\'s still the process we\\'re following, although we\\'ve\\nbeen surprised that some OEMs are interested in chatting\\nearly. I think they just want to have on their radar what\\'s\\ngoing on in the world. And if there\\'s any promising\\ntechnology, they want to be there first. So I guess we\\'re\\nalready having some of those conversations too.\\nJon: 06:05 And now, we move from offers that tech companies can\\nrefuse to regulations that startups have a duty to follow.\\nIn this clip with the systems engineering and AI\\nregulation guru, Dr. Gina Guillaume-Joseph, she lays out\\nthe evolving regulatory field for AI, which can be difficult\\nto navigate even if you\\'ve got the best of intentions.\\nSpecifically, Gina and I talk about the AI Bill of Rights,\\nthe NIST AI regulatory framework, and her work on the\\nMITRE ATLAS.\\n    06:32 Explain for us... You mentioned there, so there\\'s the NIST\\nAI risk management framework. So NIST is the National\\nInstitutes of Science and Technology, that may be familiar\\nas an acronym. The NIST thing is something for those of\\nus who have done any deep learning to kind of Hello\\nworld deep learning example involves this handwritten\\ndata set of digits. So it\\'s 60,000 handwritten digits done\\nby, if I remember correctly, US postal workers, as well as\\nelementary school students. And so it\\'s just each image is\\na different digit. So it\\'s some of them are zero, some are\\none, some are two, some are threes, all the way up to\\nnine. And this handwritten dataset was curated initially, I\\nguess in the \\'90s, maybe even in the \\'80s by NIST.\\nShow Notes: http://www.superdatascience.com/802 6\\n    07:24 And then Yann Le Cun, who\\'s one of the most famous AI\\nresearchers of all time, he modified with his research\\nteam at the time, I believe they were AT&T Bell Labs, they\\nmodified that NIST handwritten digit dataset to create the\\nMNIST, modified NIST, handwritten dataset. So I don\\'t\\nknow, it\\'s a bit of an aside, but that MNIST dataset is\\nprobably familiar to anyone who\\'s done any kind of deep\\nlearning at all. And so yeah, so that same organization,\\nNIST, has been around for a long time in the US I don\\'t\\nknow how many decades.\\n    07:58 But has been trying to set up frameworks for all different\\nkinds of industries in science and technology, and has\\nnow created this AI risk management framework, which\\nagain, I\\'ll have a link to that in the show notes alongside\\nthe AI Bill of Rights. A third framework, I guess, you can\\ncorrect me if I\\'m not using the right word there, that you\\nbrought up in your talk that also seems really helpful\\nhere is something called the MITRE ATLAS.\\n    08:26 So I\\'ve been trying to, as you\\'ve been speaking, dig up\\nwhat MITRE stands for, M-I-T-R-E. It doesn\\'t seem like it\\nstands for anything. Can you tell us a bit about MITRE\\nand the MITRE ATLAS and then maybe you can weave\\ntogether these three different things; the AI Bill of Rights,\\nthe NIST AI regulatory framework, as well as MITRE\\nATLAS. And tell us how we can integrate these three\\nframeworks together in order to have a good sense of how\\nto move forward with the AI systems that we built.\\nGina: 08:58 So MITRE is a not-for-profit organization. I worked for\\nthem for 10 years, and they support the federal\\ngovernment across all the federal government agencies to\\nhelp them solve some of the most pressing challenges. So\\nMITRE operates federally funded research and\\ndevelopment centers in support of the federal government\\nto solve problems for a safer world, essentially is what\\nMITRE does. And while at MITRE, I supported multiple\\nShow Notes: http://www.superdatascience.com/802 7\\nagencies; Department of Homeland Security, Social\\nSecurity Administration, Veterans Affairs, Department of\\nDefense, in some of the challenges that they were facing\\nat the time.\\n    09:45 Societal challenges to include when the economy was\\ndoing some downward slides and banks were failing, part\\nof some of the work that I did was at the FDIC, that was\\nwith Booz Allen. But MITRE was involved in other aspects\\nof that as well, to really understand the failures and to\\nfigure out the mitigation strategies to ensure that society\\ndidn\\'t feel those impacts as broadly and as strongly.\\n10:24 And MITRE created the ATLAS threat model introduction,\\nthreat model. It\\'s this comprehensive coverage of AIspecific adversary tactics techniques that includes realworld observation and reporting. It talks about\\naccessibility and usability of AI alignment with existing\\ncybersecurity frameworks in terms of from an AI\\nperspective. And that community engagement\\ncontribution and the educational resources and training.\\n10:58 So they\\'re developing a detailed taxonomy of tactics, of\\ntechniques, of procedures specific to AI systems that\\ncover the entire lifecycle from data collection to model\\ndevelopment and deployment and maintenance. Where\\nthey establish those mechanisms for continuously\\ngathering and updating threat intelligence based on realworld cybersecurity incidents involving AI so that the\\nknowledge base remains current and relevant. So that\\'s\\nwhat MITRE is doing it with their MITRE ATLAS\\nframework. And the framework integrates their existing\\nMITRE attack for enterprise framework that shows that\\nthey bring in that consistency and interoperability across\\ncybersecurity efforts as it pertains to AI systems. And\\nthat\\'s MITRE ATLAS threat model.\\nShow Notes: http://www.superdatascience.com/802 8\\nJon: 12:01 Terrifically useful context there from Gina. In my next\\nclip, Alex Andorra and I discuss Bayesian statistics,\\nnamely why being able to crunch larger and larger data\\nsets has helped us to use a powerful modeling technique\\nthat was originally devised centuries ago.\\n12:15 In addition to the podcast, also, I mentioned this at the\\noutset, I said that you\\'re co-founder and principal data\\nscientist of the popular Bayesian stats modeling platform,\\nPyMC. So like many things in data science, it\\'s uppercase\\nP, lowercase Y, for Python. What\\'s the MC? PyMC, one\\nword, M and the C are capitalized.\\nAlex: 12:38 So it\\'s very confusing because it stands for Python and\\nthen MC is Monte Carlo. So I understand, but why Monte\\nCarlo? It\\'s because it comes from Markov chain Monte\\nCarlo. So actually, it should be PyMCMC or PyMC\\nsquared, which is what I\\'m saying since the beginning.\\nBut anyways, yeah, it\\'s actually PyMC squared. So for\\nMarkov chain Monte Carlo and Markov chain Monte Carlo\\nis one of the main ways... All the algorithms now, new\\nones, but the blockbuster algorithm to run Bayesian\\nmodels is to use MCMC.\\nJon: 13:21 So in the same way that stochastic gradient descent is\\nlike the defacto standard for finding your model weights\\nin machine learning, Markov chain Monte Carlo is the\\nstandard way of doing it with the Bayesian network?\\nAlex: 13:36 Yeah. Yeah, yeah. And so now there are newer versions,\\nmore efficient versions. That\\'s basically the name of the\\ngame, making the algorithm more and more efficient. But\\nthe first algorithm dates back... I think it was actually\\ninvented during the project Manhattan. So during World\\nWar II.\\nJon: 13:57 Theme of the day.\\nShow Notes: http://www.superdatascience.com/802 9\\nAlex: 13:58 Yeah. And lots of physicists actually, statistical physics is\\na field that\\'s contributed a lot to MCMC. And so yeah,\\nphysicists who came to the field of statistics and trying to\\nmake the algorithms more efficient for their models. So\\nthey have contributed a lot. The field of physics has\\ncontributed a lot of big names and people to great leaps\\ninto the realm of more efficient algorithms. And so, I don\\'t\\nknow who your audience is, but that may sound boring.\\n14:37 Yeah, the algorithm, it\\'s like the workhorse, but it\\'s\\nextremely powerful. And that\\'s also one of the main\\nreasons why Bayesian statistics are increasing in\\npopularity lately, because I\\'m going to argue that it\\'s\\nalways been the best framework to do statistics, to do\\nscience. But it was hard to do with pen and paper\\nbecause the problem is that you have a huge, nasty\\nintegral on the numerator, on the denominator, sorry.\\nAnd this integral is not computable by pen and paper. So\\nfor a long, long time, Bayesian statistics combined two\\nfeatures like campaigns, PR campaigns. Bayesian\\nstatistics was relegated to the margins because it was just\\nsuper hard to do.\\n15:31 And so for other problems, other than very trivial ones, it\\nwas not very applicable. But now with the advent of\\npersonal computing, you have these incredible\\nalgorithms. So now most of the time, it\\'s HMC, Hamilton\\nand Monte Carlo. That\\'s what we use under the hood with\\nPyMC. But if you stand, if you use [inaudible 00:15:54] ,\\nit\\'s the same. And thanks to these algorithms, now we\\ncan make extremely powerful models because we can\\napproximate the [inaudible 00:16:03] distributions thanks\\nto, well, computer\\'s computing power. A computer is very\\ngood at computing. I think that\\'s why it\\'s called that.\\nJon: 16:15 Yes. And so that reminds me of deep learning. It\\'s a\\nsimilar kind of thing where the applications we have\\ntoday, like your ChatGPT or whatever your favorite large\\nShow Notes: http://www.superdatascience.com/802 10\\nlanguage model is, these amazing. Video generation like\\nSora, all of this is happening thanks to deep learning,\\nwhich is an approach we\\'ve had since the \\'50s. Certainly\\nnot as old as Bayesian statistics, but similarly, it has\\nbeen able to take off with much larger data sets and\\nmuch more compute.\\nAlex: 16:46 Yeah, yeah. Yeah, yeah, very good point. And I think\\nthat\\'s even more the point in deep learning for sure,\\nbecause Bayesian stats doesn\\'t need the scale, but the\\nway we\\'re doing deep learning for now, definitely need the\\nscale.\\nJon: 16:58 Yeah, yeah. Scale of data.\\nAlex: 17:00 Yeah, yeah, exactly. Yeah, sorry, yeah, the scale, because\\nour two scales, data and computing. Yeah. You\\'re right.\\nJon: 17:05 And for model parameters. So that has actually... I mean,\\ntying back to something you said near the beginning of\\nthis episode, is that actually one of the advantages of\\nBayesian statistics is that you can do it with very few\\ndata. Maybe fewer data than with a frequentist approach\\nor a machine learning approach, because you can bake in\\nyour prior assumptions. And those prior assumptions\\ngive some kind of structure, some kind of framework for\\nyour data to make an impact.\\nAlex: 17:32 Yeah. Yeah, completely.\\nJon: 17:34 And in keeping with the theme of returning to the past to\\nfind golden opportunities, I speak to Dr. Nathan Lambert\\nabout historical influences on contemporary\\nmethodologies. I also managed to sneak in a question\\nabout reinforcement learning from human feedback.\\nNathan is a research scientist for the Allen Institute for\\nAI, and previously built out the RLHF team at Hugging\\nFace. So there was no better person to ask about the lack\\nShow Notes: http://www.superdatascience.com/802 11\\nof robustness in RLHF and how that could impact the\\nfuture development and deployment of AI systems.\\n18:02 Another really cool thing that you\\'ve done related to RLHF\\nis you have traced it back to ancient philosophy and\\nmodern economics. So mentioning Aristotle and von\\nNeumann-Morganstern utility theorem, for example. I\\ndon\\'t really know what the VNM utility theorem is, but\\nhow do these historical foundations influence current\\nmethodologies and what can modern AI research learn\\nfrom these early theories?\\nNathan: 18:30 Yeah. So this is a fun paper with a few colleagues that I\\nstarted working with at Berkeley, and now we\\'re kind of\\nspread out. This is all based on the fact that RL is very\\ndeep field multidisciplinary history, where it goes way\\nback. And then the notion of preference is a very vague\\nthing in economics. And it\\'s like the von NeumannMorganstern theory is a foundational thing that\\nessentially it\\'s like you can express either all behaviors or\\nall goals as probability and expected value distributions,\\nwhich essentially lets you do expected value math over\\npreferences.\\n19:10 And then it led to a bunch of debates on whether or not\\npreferences actually exist and are tractable in any of\\nthese things, or if they\\'re actually measurable or not due\\nto the preference shift over time based on context. So\\nthese are the kinds of things that we take and it\\'s ask a\\nlot of questions on how this impacts the modern RLHF\\nprocess. It\\'s things like is the final model\\'s preferences,\\nwhich is like we\\'re mapping onto very human terms, is\\nthat actually based more on the the base model, which is\\nscraped from the internet than the human preferences\\nthat they get from somewhere like Scale AI.\\n19:46 So it\\'s like if it\\'s based more on the internet crawling than\\nthis million dollar dataset they\\'re getting from Scale AI,\\nShow Notes: http://www.superdatascience.com/802 12\\nit\\'s kind of confusing to the marketing where we\\'re saying\\nwe\\'re learning a preference model, but it might not\\nactually do that much. Is other things like OpenAI now\\nhas a ton of user data and it\\'s like what does the\\neconomics literature say about generating data for\\ntraining that comes from a user context or a professional\\ncontext where someone is paid to do it and they\\'re paid to\\nact in a certain way? And how does all of this mix? So it\\'s\\nreally just a super long list of questions of why we should\\nlook at other social sciences if we\\'re making grand claims\\nabout human preferences and all of these things.\\nJon: 20:26 Nice. Well, fascinating. Tons to dig into there for our\\nlisteners. Final topic that I planned related to RLHF, I\\'m\\nsure it\\'ll come up again organically in the conversation,\\nbut you\\'ve mentioned that RLHF is not even robust to\\nfine-tuning. And so removing the safety layer from models\\nlike GPT-4 and Llama 2 can break down the notion of\\nsafety. Can you elaborate on the implications of this\\nfragility for the future development and deployment of AI\\nsystems?\\nNathan: 20:59 Yeah, so this is a specific line of research. So there\\'s a few\\npapers that showed that if you take a model like Zephyr\\nor Tulu that we were mentioning, if they have safety in\\nthe dataset, if you then go and fine-tune it again on some\\ndifferent tasks, you\\'ll do some of the behaviors that are\\n\"ingrained\" in the model. I honestly think this is a little\\nbit more clickbaity than actually worrisome because it\\'s\\nreally not surprising given that if you just look at the\\namount of compute applied at fine-tuning, we pre-trained\\nthese models for trillions of tokens. And then we apply a\\ncouple billion tokens of compute at fine-tuning.\\n21:36 And it\\'s like we\\'re not changing the weights of the model\\nsubstantially. We\\'re doing a slight nudge, and it makes\\nsense that a slight nudge could be undone at the same\\nway. But if you were to take this to some of the bigger\\nShow Notes: http://www.superdatascience.com/802 13\\nlabs, what you hear is that safety is not just a single\\nartifact thing. Safety is much more about a complete\\nsystem than a model. So open weight models being\\nunsafe or unsafe, I don\\'t consider to be that big of a deal.\\nIt\\'s like if you were to apply them to a free endpoint that\\neveryone on the internet could talk to, then I don\\'t want\\nmy model saying good things about Hitler and all these\\nobvious things.\\n22:09 But if it\\'s a research artifact that you need to spin up\\nGPUs to use yourself, and it\\'s a little bit more... I\\'m more\\nopen to having these diversity of models exist. But if you\\nask [inaudible 00:22:22] or somebody, it\\'s like, \"What\\nhappens... How do you get safety into your model?\" And\\nit\\'s like, it\\'s not just RLHF. You need to have safety at the\\npre-training, any preference model you trained. And then\\nall of these models have a safety filter on the output. So\\nChatGPT, it reads all the text generated from the base\\nmodel, and then there\\'s a go, no go where it will rephrase\\nthe text if it gets a no-go signal, which is like their content\\nmoderation API.\\n22:45 So it\\'s kind of a double. It\\'s the type of thing where\\nresearchers need to market their work, but it\\'s not as big\\nof a detail as I think it is. It\\'s like, okay, I think it has\\ninteresting business downstream things with liability. So\\nit\\'s just like if you want to fine-tune a Llama model, you\\nnormally do that on your own hardware, but OpenAI has\\na fine-tuning API. And if they claim their model is safe,\\nbut any fine-tuning on their API that they then host\\nmakes it unsafe, that seems like more of a business\\nproblem. Which is like, oh, it\\'s a nice way that open\\necosystem might be better off because it breaks the\\nliability chain. But we\\'ll see this research continue to\\nevolve. It\\'s so early in all of these things for a year in.\\nJon: 23:31 All right. That\\'s it for today\\'s In Case You Missed It\\nepisode, to be sure not to miss any of our exciting\\nShow Notes: http://www.superdatascience.com/802 14\\nupcoming episodes. Be sure to subscribe to this podcast\\nif you haven\\'t already. But most importantly, I hope you\\'ll\\njust keep on listening. Until next time, keep on rocking it\\nout there. And I\\'m looking forward to enjoying another\\nround of Super Data Science Podcast with you very soon.')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1 = \"What is EDP?\"\n",
    "query_result = db.similarity_search(q1)\n",
    "query_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Show Notes: http://www.superdatascience.com/802 1\\nSDS PODCAST\\nEPISODE 802:\\nIN CASE YOU MISSED\\nIT IN JUNE 2024\\n    Show Notes: http://www.superdatascience.com/802 2\\nJon: 00:02 This is episode number 802, our In Case You Missed it in\\nJune episode.\\n    00:19 Welcome back to the Super Data Science Podcast. I\\'m\\nyour host, Jon Krohn. This is an In Case You Missed It\\nepisode that highlights the best parts of conversations we\\nhad on the show in the last month. This first clip you\\'ll\\nhear is from my interview with Dr. Jason Yosinski, one of\\nmy all-time favorite AI researchers. We had a great\\nconversation about making your AI and ML models\\nattractive to customers.\\n    00:40 In this clip, I got him to speak from his experience as\\nCEO of the climate technology startup he founded,\\nWindscape AI. This is a great case study if you\\'re\\nplanning to launch your own AI models commercially.\\n00:51 I\\'m sure that kind of engineering mindset is applicable to\\na lot of our listeners, and it seems like your approach is\\nworking. So EDP, a large Portuguese utility company,\\nrecently selected Windscape as one of nine startups for its\\nrenewable innovation program in Singapore to accelerate\\nthe global energy transition. What opportunities do you\\nsee emerging from Windscape AI\\'s participation in this\\nprogram?\\n    Jason: 01:16 Yeah. Well, thanks for mentioning that. We did apply for\\nthis program. We were selected. EDP is a huge utility. I\\nbelieve they\\'re the fourth-largest wind owner in the world.\\nSo they own tons and tons of turbines. They generate a\\nlot of wind energy. When I met with folks from EDP, I\\nfound them to be a very forward-looking organization.\\nSometimes you get a big company and they\\'re impossibly\\nslow or something, but these folks are really pushing the\\nboundaries, all the boundaries they can, which I thought\\nwas super cool.\\n    Show Notes: http://www.superdatascience.com/802 3\\n01:50 What we hope to get out of it and where that collaboration\\nmight go is to pilot our technology, start working with\\nthem, see how it works on their wind farms around the\\nworld. And then if it does work really well, hopefully we\\nroll out more broadly and we can also maybe use that as\\na demo for new potential customers.\\n    Jon: 02:08 Very cool. So it sounds like EDP is forward-looking. But\\nin general, do you counter resistance or hurdles as you\\ntry to come to energy utilities and say, \"Hey, you could be\\nusing AI like Windscape\\'s to be improving the efficiency of\\nyour systems.\" Do you encounter resistance or hurdles,\\nor is it relatively straightforward to convince people that\\nyou\\'re doing something valuable?\\n    Jason: 02:31 I wouldn\\'t say it\\'s straightforward. No. Convincing people\\nthat what you\\'re doing is valuable is maybe always hard. I\\nwould say saying the words AI or machine learning\\ndoesn\\'t immediately open all the doors. It can open some\\ndoors. Some of these companies realize that AI might be\\nrevolutionizing things that happen internally, and they\\'re\\nnot quite sure how yet, but maybe we should talk to these\\nrandos from Windscape and see what they think.\\n02:59 It does open some doors, but not all. Just as probably\\nwithin any industry, there are some organizations that\\nare very forward-looking and others early adopters of any\\ntechnology and others that are slower, that are later\\nadopters. They literally, some have told us, \"We don\\'t care\\nwhat you\\'re [inaudible 00:03:17], just show us when four\\nother companies are using it and then we\\'ll consider\\nusing it because how we work,\" which is potentially an\\nefficient choice from their perspective.\\n    03:27 There\\'s also small energy companies and large energy\\ncompanies, and there\\'s a spectrum there of how you sell\\nto these companies and how you get adoption and so on.\\nSo yeah, and convincing everyone, it can be hard. You\\nShow Notes: http://www.superdatascience.com/802 4\\nhave to convince people that your technology will work,\\nthat it won\\'t be a huge headache to adopt. The people in\\nthe field need to buy into it. It can\\'t ruin their workflow or\\nsomething. It has to be possible to actually integrate. So\\nsome of these systems run software that\\'s hard to work\\nwith and simply integrating can be difficult at times. So I\\ndon\\'t know, there\\'s a lot of factors probably as in any\\nindustry.\\n    Jon: 04:10 Yeah, it makes so much sense. And hopefully I\\'m not\\ngoing too deep here, and if I am asking a question that\\nwould give away some kind of IP, just feel free to not\\nanswer this. But it seems to me like in a situation like\\nyours, where you are providing software to hardware\\ncompanies, say the turbine manufacturers, you are not,\\nat least in the immediate term, planning on building, say\\nyour own turbines, your own wind farms.\\n    04:37 You are a software company. You need to be partnering\\nwith turbine manufacturers, with wind farm operators.\\nHow does that work? Are people... I guess maybe your\\nresponse is going to be similar, where there\\'s a range of\\nresponses where some turbine manufacturers are\\nrelatively early adopters. They see the potential. They say,\\n\"Wow, Jason\\'s done a lot of amazing research in the past.\\nHe seems like the kind of person we should be working\\nwith to accelerate our roadmap.\" And then other folks are\\njust like, \"Yeah, we\\'ve got our own team,\" or I don\\'t know.\\nHow does it look for you? Yeah.\\n    Jason: 05:09 What we started this whole endeavor, what we imagined\\nwould happen is we would first build products that we\\nwould sell to people that own the turbines. Why do they\\nwant them? Because our product would help them make\\nmore money starting next month. We help them make\\nmore money. They like our product, we roll out, they tell\\ntheir friends. We deploy to more and more farms, more\\nand more companies. As we start to increase our market\\nShow Notes: http://www.superdatascience.com/802 5\\npenetration in the industry, then much later, turbine\\nmanufacturers would notice and they would say, \"Hey,\\neveryone\\'s using these Windscape people. Maybe we\\nshould talk to them and consider integrating their thing\\noff the factory floor rather than an as aftermarket add-on\\non.\"\\n    05:48 That\\'s still the process we\\'re following, although we\\'ve\\nbeen surprised that some OEMs are interested in chatting\\nearly. I think they just want to have on their radar what\\'s\\ngoing on in the world. And if there\\'s any promising\\ntechnology, they want to be there first. So I guess we\\'re\\nalready having some of those conversations too.\\nJon: 06:05 And now, we move from offers that tech companies can\\nrefuse to regulations that startups have a duty to follow.\\nIn this clip with the systems engineering and AI\\nregulation guru, Dr. Gina Guillaume-Joseph, she lays out\\nthe evolving regulatory field for AI, which can be difficult\\nto navigate even if you\\'ve got the best of intentions.\\nSpecifically, Gina and I talk about the AI Bill of Rights,\\nthe NIST AI regulatory framework, and her work on the\\nMITRE ATLAS.\\n    06:32 Explain for us... You mentioned there, so there\\'s the NIST\\nAI risk management framework. So NIST is the National\\nInstitutes of Science and Technology, that may be familiar\\nas an acronym. The NIST thing is something for those of\\nus who have done any deep learning to kind of Hello\\nworld deep learning example involves this handwritten\\ndata set of digits. So it\\'s 60,000 handwritten digits done\\nby, if I remember correctly, US postal workers, as well as\\nelementary school students. And so it\\'s just each image is\\na different digit. So it\\'s some of them are zero, some are\\none, some are two, some are threes, all the way up to\\nnine. And this handwritten dataset was curated initially, I\\nguess in the \\'90s, maybe even in the \\'80s by NIST.\\nShow Notes: http://www.superdatascience.com/802 6\\n    07:24 And then Yann Le Cun, who\\'s one of the most famous AI\\nresearchers of all time, he modified with his research\\nteam at the time, I believe they were AT&T Bell Labs, they\\nmodified that NIST handwritten digit dataset to create the\\nMNIST, modified NIST, handwritten dataset. So I don\\'t\\nknow, it\\'s a bit of an aside, but that MNIST dataset is\\nprobably familiar to anyone who\\'s done any kind of deep\\nlearning at all. And so yeah, so that same organization,\\nNIST, has been around for a long time in the US I don\\'t\\nknow how many decades.\\n    07:58 But has been trying to set up frameworks for all different\\nkinds of industries in science and technology, and has\\nnow created this AI risk management framework, which\\nagain, I\\'ll have a link to that in the show notes alongside\\nthe AI Bill of Rights. A third framework, I guess, you can\\ncorrect me if I\\'m not using the right word there, that you\\nbrought up in your talk that also seems really helpful\\nhere is something called the MITRE ATLAS.\\n    08:26 So I\\'ve been trying to, as you\\'ve been speaking, dig up\\nwhat MITRE stands for, M-I-T-R-E. It doesn\\'t seem like it\\nstands for anything. Can you tell us a bit about MITRE\\nand the MITRE ATLAS and then maybe you can weave\\ntogether these three different things; the AI Bill of Rights,\\nthe NIST AI regulatory framework, as well as MITRE\\nATLAS. And tell us how we can integrate these three\\nframeworks together in order to have a good sense of how\\nto move forward with the AI systems that we built.\\nGina: 08:58 So MITRE is a not-for-profit organization. I worked for\\nthem for 10 years, and they support the federal\\ngovernment across all the federal government agencies to\\nhelp them solve some of the most pressing challenges. So\\nMITRE operates federally funded research and\\ndevelopment centers in support of the federal government\\nto solve problems for a safer world, essentially is what\\nMITRE does. And while at MITRE, I supported multiple\\nShow Notes: http://www.superdatascience.com/802 7\\nagencies; Department of Homeland Security, Social\\nSecurity Administration, Veterans Affairs, Department of\\nDefense, in some of the challenges that they were facing\\nat the time.\\n    09:45 Societal challenges to include when the economy was\\ndoing some downward slides and banks were failing, part\\nof some of the work that I did was at the FDIC, that was\\nwith Booz Allen. But MITRE was involved in other aspects\\nof that as well, to really understand the failures and to\\nfigure out the mitigation strategies to ensure that society\\ndidn\\'t feel those impacts as broadly and as strongly.\\n10:24 And MITRE created the ATLAS threat model introduction,\\nthreat model. It\\'s this comprehensive coverage of AIspecific adversary tactics techniques that includes realworld observation and reporting. It talks about\\naccessibility and usability of AI alignment with existing\\ncybersecurity frameworks in terms of from an AI\\nperspective. And that community engagement\\ncontribution and the educational resources and training.\\n10:58 So they\\'re developing a detailed taxonomy of tactics, of\\ntechniques, of procedures specific to AI systems that\\ncover the entire lifecycle from data collection to model\\ndevelopment and deployment and maintenance. Where\\nthey establish those mechanisms for continuously\\ngathering and updating threat intelligence based on realworld cybersecurity incidents involving AI so that the\\nknowledge base remains current and relevant. So that\\'s\\nwhat MITRE is doing it with their MITRE ATLAS\\nframework. And the framework integrates their existing\\nMITRE attack for enterprise framework that shows that\\nthey bring in that consistency and interoperability across\\ncybersecurity efforts as it pertains to AI systems. And\\nthat\\'s MITRE ATLAS threat model.\\nShow Notes: http://www.superdatascience.com/802 8\\nJon: 12:01 Terrifically useful context there from Gina. In my next\\nclip, Alex Andorra and I discuss Bayesian statistics,\\nnamely why being able to crunch larger and larger data\\nsets has helped us to use a powerful modeling technique\\nthat was originally devised centuries ago.\\n12:15 In addition to the podcast, also, I mentioned this at the\\noutset, I said that you\\'re co-founder and principal data\\nscientist of the popular Bayesian stats modeling platform,\\nPyMC. So like many things in data science, it\\'s uppercase\\nP, lowercase Y, for Python. What\\'s the MC? PyMC, one\\nword, M and the C are capitalized.\\nAlex: 12:38 So it\\'s very confusing because it stands for Python and\\nthen MC is Monte Carlo. So I understand, but why Monte\\nCarlo? It\\'s because it comes from Markov chain Monte\\nCarlo. So actually, it should be PyMCMC or PyMC\\nsquared, which is what I\\'m saying since the beginning.\\nBut anyways, yeah, it\\'s actually PyMC squared. So for\\nMarkov chain Monte Carlo and Markov chain Monte Carlo\\nis one of the main ways... All the algorithms now, new\\nones, but the blockbuster algorithm to run Bayesian\\nmodels is to use MCMC.\\nJon: 13:21 So in the same way that stochastic gradient descent is\\nlike the defacto standard for finding your model weights\\nin machine learning, Markov chain Monte Carlo is the\\nstandard way of doing it with the Bayesian network?\\nAlex: 13:36 Yeah. Yeah, yeah. And so now there are newer versions,\\nmore efficient versions. That\\'s basically the name of the\\ngame, making the algorithm more and more efficient. But\\nthe first algorithm dates back... I think it was actually\\ninvented during the project Manhattan. So during World\\nWar II.\\nJon: 13:57 Theme of the day.\\nShow Notes: http://www.superdatascience.com/802 9\\nAlex: 13:58 Yeah. And lots of physicists actually, statistical physics is\\na field that\\'s contributed a lot to MCMC. And so yeah,\\nphysicists who came to the field of statistics and trying to\\nmake the algorithms more efficient for their models. So\\nthey have contributed a lot. The field of physics has\\ncontributed a lot of big names and people to great leaps\\ninto the realm of more efficient algorithms. And so, I don\\'t\\nknow who your audience is, but that may sound boring.\\n14:37 Yeah, the algorithm, it\\'s like the workhorse, but it\\'s\\nextremely powerful. And that\\'s also one of the main\\nreasons why Bayesian statistics are increasing in\\npopularity lately, because I\\'m going to argue that it\\'s\\nalways been the best framework to do statistics, to do\\nscience. But it was hard to do with pen and paper\\nbecause the problem is that you have a huge, nasty\\nintegral on the numerator, on the denominator, sorry.\\nAnd this integral is not computable by pen and paper. So\\nfor a long, long time, Bayesian statistics combined two\\nfeatures like campaigns, PR campaigns. Bayesian\\nstatistics was relegated to the margins because it was just\\nsuper hard to do.\\n15:31 And so for other problems, other than very trivial ones, it\\nwas not very applicable. But now with the advent of\\npersonal computing, you have these incredible\\nalgorithms. So now most of the time, it\\'s HMC, Hamilton\\nand Monte Carlo. That\\'s what we use under the hood with\\nPyMC. But if you stand, if you use [inaudible 00:15:54] ,\\nit\\'s the same. And thanks to these algorithms, now we\\ncan make extremely powerful models because we can\\napproximate the [inaudible 00:16:03] distributions thanks\\nto, well, computer\\'s computing power. A computer is very\\ngood at computing. I think that\\'s why it\\'s called that.\\nJon: 16:15 Yes. And so that reminds me of deep learning. It\\'s a\\nsimilar kind of thing where the applications we have\\ntoday, like your ChatGPT or whatever your favorite large\\nShow Notes: http://www.superdatascience.com/802 10\\nlanguage model is, these amazing. Video generation like\\nSora, all of this is happening thanks to deep learning,\\nwhich is an approach we\\'ve had since the \\'50s. Certainly\\nnot as old as Bayesian statistics, but similarly, it has\\nbeen able to take off with much larger data sets and\\nmuch more compute.\\nAlex: 16:46 Yeah, yeah. Yeah, yeah, very good point. And I think\\nthat\\'s even more the point in deep learning for sure,\\nbecause Bayesian stats doesn\\'t need the scale, but the\\nway we\\'re doing deep learning for now, definitely need the\\nscale.\\nJon: 16:58 Yeah, yeah. Scale of data.\\nAlex: 17:00 Yeah, yeah, exactly. Yeah, sorry, yeah, the scale, because\\nour two scales, data and computing. Yeah. You\\'re right.\\nJon: 17:05 And for model parameters. So that has actually... I mean,\\ntying back to something you said near the beginning of\\nthis episode, is that actually one of the advantages of\\nBayesian statistics is that you can do it with very few\\ndata. Maybe fewer data than with a frequentist approach\\nor a machine learning approach, because you can bake in\\nyour prior assumptions. And those prior assumptions\\ngive some kind of structure, some kind of framework for\\nyour data to make an impact.\\nAlex: 17:32 Yeah. Yeah, completely.\\nJon: 17:34 And in keeping with the theme of returning to the past to\\nfind golden opportunities, I speak to Dr. Nathan Lambert\\nabout historical influences on contemporary\\nmethodologies. I also managed to sneak in a question\\nabout reinforcement learning from human feedback.\\nNathan is a research scientist for the Allen Institute for\\nAI, and previously built out the RLHF team at Hugging\\nFace. So there was no better person to ask about the lack\\nShow Notes: http://www.superdatascience.com/802 11\\nof robustness in RLHF and how that could impact the\\nfuture development and deployment of AI systems.\\n18:02 Another really cool thing that you\\'ve done related to RLHF\\nis you have traced it back to ancient philosophy and\\nmodern economics. So mentioning Aristotle and von\\nNeumann-Morganstern utility theorem, for example. I\\ndon\\'t really know what the VNM utility theorem is, but\\nhow do these historical foundations influence current\\nmethodologies and what can modern AI research learn\\nfrom these early theories?\\nNathan: 18:30 Yeah. So this is a fun paper with a few colleagues that I\\nstarted working with at Berkeley, and now we\\'re kind of\\nspread out. This is all based on the fact that RL is very\\ndeep field multidisciplinary history, where it goes way\\nback. And then the notion of preference is a very vague\\nthing in economics. And it\\'s like the von NeumannMorganstern theory is a foundational thing that\\nessentially it\\'s like you can express either all behaviors or\\nall goals as probability and expected value distributions,\\nwhich essentially lets you do expected value math over\\npreferences.\\n19:10 And then it led to a bunch of debates on whether or not\\npreferences actually exist and are tractable in any of\\nthese things, or if they\\'re actually measurable or not due\\nto the preference shift over time based on context. So\\nthese are the kinds of things that we take and it\\'s ask a\\nlot of questions on how this impacts the modern RLHF\\nprocess. It\\'s things like is the final model\\'s preferences,\\nwhich is like we\\'re mapping onto very human terms, is\\nthat actually based more on the the base model, which is\\nscraped from the internet than the human preferences\\nthat they get from somewhere like Scale AI.\\n19:46 So it\\'s like if it\\'s based more on the internet crawling than\\nthis million dollar dataset they\\'re getting from Scale AI,\\nShow Notes: http://www.superdatascience.com/802 12\\nit\\'s kind of confusing to the marketing where we\\'re saying\\nwe\\'re learning a preference model, but it might not\\nactually do that much. Is other things like OpenAI now\\nhas a ton of user data and it\\'s like what does the\\neconomics literature say about generating data for\\ntraining that comes from a user context or a professional\\ncontext where someone is paid to do it and they\\'re paid to\\nact in a certain way? And how does all of this mix? So it\\'s\\nreally just a super long list of questions of why we should\\nlook at other social sciences if we\\'re making grand claims\\nabout human preferences and all of these things.\\nJon: 20:26 Nice. Well, fascinating. Tons to dig into there for our\\nlisteners. Final topic that I planned related to RLHF, I\\'m\\nsure it\\'ll come up again organically in the conversation,\\nbut you\\'ve mentioned that RLHF is not even robust to\\nfine-tuning. And so removing the safety layer from models\\nlike GPT-4 and Llama 2 can break down the notion of\\nsafety. Can you elaborate on the implications of this\\nfragility for the future development and deployment of AI\\nsystems?\\nNathan: 20:59 Yeah, so this is a specific line of research. So there\\'s a few\\npapers that showed that if you take a model like Zephyr\\nor Tulu that we were mentioning, if they have safety in\\nthe dataset, if you then go and fine-tune it again on some\\ndifferent tasks, you\\'ll do some of the behaviors that are\\n\"ingrained\" in the model. I honestly think this is a little\\nbit more clickbaity than actually worrisome because it\\'s\\nreally not surprising given that if you just look at the\\namount of compute applied at fine-tuning, we pre-trained\\nthese models for trillions of tokens. And then we apply a\\ncouple billion tokens of compute at fine-tuning.\\n21:36 And it\\'s like we\\'re not changing the weights of the model\\nsubstantially. We\\'re doing a slight nudge, and it makes\\nsense that a slight nudge could be undone at the same\\nway. But if you were to take this to some of the bigger\\nShow Notes: http://www.superdatascience.com/802 13\\nlabs, what you hear is that safety is not just a single\\nartifact thing. Safety is much more about a complete\\nsystem than a model. So open weight models being\\nunsafe or unsafe, I don\\'t consider to be that big of a deal.\\nIt\\'s like if you were to apply them to a free endpoint that\\neveryone on the internet could talk to, then I don\\'t want\\nmy model saying good things about Hitler and all these\\nobvious things.\\n22:09 But if it\\'s a research artifact that you need to spin up\\nGPUs to use yourself, and it\\'s a little bit more... I\\'m more\\nopen to having these diversity of models exist. But if you\\nask [inaudible 00:22:22] or somebody, it\\'s like, \"What\\nhappens... How do you get safety into your model?\" And\\nit\\'s like, it\\'s not just RLHF. You need to have safety at the\\npre-training, any preference model you trained. And then\\nall of these models have a safety filter on the output. So\\nChatGPT, it reads all the text generated from the base\\nmodel, and then there\\'s a go, no go where it will rephrase\\nthe text if it gets a no-go signal, which is like their content\\nmoderation API.\\n22:45 So it\\'s kind of a double. It\\'s the type of thing where\\nresearchers need to market their work, but it\\'s not as big\\nof a detail as I think it is. It\\'s like, okay, I think it has\\ninteresting business downstream things with liability. So\\nit\\'s just like if you want to fine-tune a Llama model, you\\nnormally do that on your own hardware, but OpenAI has\\na fine-tuning API. And if they claim their model is safe,\\nbut any fine-tuning on their API that they then host\\nmakes it unsafe, that seems like more of a business\\nproblem. Which is like, oh, it\\'s a nice way that open\\necosystem might be better off because it breaks the\\nliability chain. But we\\'ll see this research continue to\\nevolve. It\\'s so early in all of these things for a year in.\\nJon: 23:31 All right. That\\'s it for today\\'s In Case You Missed It\\nepisode, to be sure not to miss any of our exciting\\nShow Notes: http://www.superdatascience.com/802 14\\nupcoming episodes. Be sure to subscribe to this podcast\\nif you haven\\'t already. But most importantly, I hope you\\'ll\\njust keep on listening. Until next time, keep on rocking it\\nout there. And I\\'m looking forward to enjoying another\\nround of Super Data Science Podcast with you very soon.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = retriever.invoke(q1)\n",
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Searach With Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': '4. Embedding/super_DS.txt'}, page_content='Show Notes: http://www.superdatascience.com/802 1\\nSDS PODCAST\\nEPISODE 802:\\nIN CASE YOU MISSED\\nIT IN JUNE 2024\\n    Show Notes: http://www.superdatascience.com/802 2\\nJon: 00:02 This is episode number 802, our In Case You Missed it in\\nJune episode.\\n    00:19 Welcome back to the Super Data Science Podcast. I\\'m\\nyour host, Jon Krohn. This is an In Case You Missed It\\nepisode that highlights the best parts of conversations we\\nhad on the show in the last month. This first clip you\\'ll\\nhear is from my interview with Dr. Jason Yosinski, one of\\nmy all-time favorite AI researchers. We had a great\\nconversation about making your AI and ML models\\nattractive to customers.\\n    00:40 In this clip, I got him to speak from his experience as\\nCEO of the climate technology startup he founded,\\nWindscape AI. This is a great case study if you\\'re\\nplanning to launch your own AI models commercially.\\n00:51 I\\'m sure that kind of engineering mindset is applicable to\\na lot of our listeners, and it seems like your approach is\\nworking. So EDP, a large Portuguese utility company,\\nrecently selected Windscape as one of nine startups for its\\nrenewable innovation program in Singapore to accelerate\\nthe global energy transition. What opportunities do you\\nsee emerging from Windscape AI\\'s participation in this\\nprogram?\\n    Jason: 01:16 Yeah. Well, thanks for mentioning that. We did apply for\\nthis program. We were selected. EDP is a huge utility. I\\nbelieve they\\'re the fourth-largest wind owner in the world.\\nSo they own tons and tons of turbines. They generate a\\nlot of wind energy. When I met with folks from EDP, I\\nfound them to be a very forward-looking organization.\\nSometimes you get a big company and they\\'re impossibly\\nslow or something, but these folks are really pushing the\\nboundaries, all the boundaries they can, which I thought\\nwas super cool.\\n    Show Notes: http://www.superdatascience.com/802 3\\n01:50 What we hope to get out of it and where that collaboration\\nmight go is to pilot our technology, start working with\\nthem, see how it works on their wind farms around the\\nworld. And then if it does work really well, hopefully we\\nroll out more broadly and we can also maybe use that as\\na demo for new potential customers.\\n    Jon: 02:08 Very cool. So it sounds like EDP is forward-looking. But\\nin general, do you counter resistance or hurdles as you\\ntry to come to energy utilities and say, \"Hey, you could be\\nusing AI like Windscape\\'s to be improving the efficiency of\\nyour systems.\" Do you encounter resistance or hurdles,\\nor is it relatively straightforward to convince people that\\nyou\\'re doing something valuable?\\n    Jason: 02:31 I wouldn\\'t say it\\'s straightforward. No. Convincing people\\nthat what you\\'re doing is valuable is maybe always hard. I\\nwould say saying the words AI or machine learning\\ndoesn\\'t immediately open all the doors. It can open some\\ndoors. Some of these companies realize that AI might be\\nrevolutionizing things that happen internally, and they\\'re\\nnot quite sure how yet, but maybe we should talk to these\\nrandos from Windscape and see what they think.\\n02:59 It does open some doors, but not all. Just as probably\\nwithin any industry, there are some organizations that\\nare very forward-looking and others early adopters of any\\ntechnology and others that are slower, that are later\\nadopters. They literally, some have told us, \"We don\\'t care\\nwhat you\\'re [inaudible 00:03:17], just show us when four\\nother companies are using it and then we\\'ll consider\\nusing it because how we work,\" which is potentially an\\nefficient choice from their perspective.\\n    03:27 There\\'s also small energy companies and large energy\\ncompanies, and there\\'s a spectrum there of how you sell\\nto these companies and how you get adoption and so on.\\nSo yeah, and convincing everyone, it can be hard. You\\nShow Notes: http://www.superdatascience.com/802 4\\nhave to convince people that your technology will work,\\nthat it won\\'t be a huge headache to adopt. The people in\\nthe field need to buy into it. It can\\'t ruin their workflow or\\nsomething. It has to be possible to actually integrate. So\\nsome of these systems run software that\\'s hard to work\\nwith and simply integrating can be difficult at times. So I\\ndon\\'t know, there\\'s a lot of factors probably as in any\\nindustry.\\n    Jon: 04:10 Yeah, it makes so much sense. And hopefully I\\'m not\\ngoing too deep here, and if I am asking a question that\\nwould give away some kind of IP, just feel free to not\\nanswer this. But it seems to me like in a situation like\\nyours, where you are providing software to hardware\\ncompanies, say the turbine manufacturers, you are not,\\nat least in the immediate term, planning on building, say\\nyour own turbines, your own wind farms.\\n    04:37 You are a software company. You need to be partnering\\nwith turbine manufacturers, with wind farm operators.\\nHow does that work? Are people... I guess maybe your\\nresponse is going to be similar, where there\\'s a range of\\nresponses where some turbine manufacturers are\\nrelatively early adopters. They see the potential. They say,\\n\"Wow, Jason\\'s done a lot of amazing research in the past.\\nHe seems like the kind of person we should be working\\nwith to accelerate our roadmap.\" And then other folks are\\njust like, \"Yeah, we\\'ve got our own team,\" or I don\\'t know.\\nHow does it look for you? Yeah.\\n    Jason: 05:09 What we started this whole endeavor, what we imagined\\nwould happen is we would first build products that we\\nwould sell to people that own the turbines. Why do they\\nwant them? Because our product would help them make\\nmore money starting next month. We help them make\\nmore money. They like our product, we roll out, they tell\\ntheir friends. We deploy to more and more farms, more\\nand more companies. As we start to increase our market\\nShow Notes: http://www.superdatascience.com/802 5\\npenetration in the industry, then much later, turbine\\nmanufacturers would notice and they would say, \"Hey,\\neveryone\\'s using these Windscape people. Maybe we\\nshould talk to them and consider integrating their thing\\noff the factory floor rather than an as aftermarket add-on\\non.\"\\n    05:48 That\\'s still the process we\\'re following, although we\\'ve\\nbeen surprised that some OEMs are interested in chatting\\nearly. I think they just want to have on their radar what\\'s\\ngoing on in the world. And if there\\'s any promising\\ntechnology, they want to be there first. So I guess we\\'re\\nalready having some of those conversations too.\\nJon: 06:05 And now, we move from offers that tech companies can\\nrefuse to regulations that startups have a duty to follow.\\nIn this clip with the systems engineering and AI\\nregulation guru, Dr. Gina Guillaume-Joseph, she lays out\\nthe evolving regulatory field for AI, which can be difficult\\nto navigate even if you\\'ve got the best of intentions.\\nSpecifically, Gina and I talk about the AI Bill of Rights,\\nthe NIST AI regulatory framework, and her work on the\\nMITRE ATLAS.\\n    06:32 Explain for us... You mentioned there, so there\\'s the NIST\\nAI risk management framework. So NIST is the National\\nInstitutes of Science and Technology, that may be familiar\\nas an acronym. The NIST thing is something for those of\\nus who have done any deep learning to kind of Hello\\nworld deep learning example involves this handwritten\\ndata set of digits. So it\\'s 60,000 handwritten digits done\\nby, if I remember correctly, US postal workers, as well as\\nelementary school students. And so it\\'s just each image is\\na different digit. So it\\'s some of them are zero, some are\\none, some are two, some are threes, all the way up to\\nnine. And this handwritten dataset was curated initially, I\\nguess in the \\'90s, maybe even in the \\'80s by NIST.\\nShow Notes: http://www.superdatascience.com/802 6\\n    07:24 And then Yann Le Cun, who\\'s one of the most famous AI\\nresearchers of all time, he modified with his research\\nteam at the time, I believe they were AT&T Bell Labs, they\\nmodified that NIST handwritten digit dataset to create the\\nMNIST, modified NIST, handwritten dataset. So I don\\'t\\nknow, it\\'s a bit of an aside, but that MNIST dataset is\\nprobably familiar to anyone who\\'s done any kind of deep\\nlearning at all. And so yeah, so that same organization,\\nNIST, has been around for a long time in the US I don\\'t\\nknow how many decades.\\n    07:58 But has been trying to set up frameworks for all different\\nkinds of industries in science and technology, and has\\nnow created this AI risk management framework, which\\nagain, I\\'ll have a link to that in the show notes alongside\\nthe AI Bill of Rights. A third framework, I guess, you can\\ncorrect me if I\\'m not using the right word there, that you\\nbrought up in your talk that also seems really helpful\\nhere is something called the MITRE ATLAS.\\n    08:26 So I\\'ve been trying to, as you\\'ve been speaking, dig up\\nwhat MITRE stands for, M-I-T-R-E. It doesn\\'t seem like it\\nstands for anything. Can you tell us a bit about MITRE\\nand the MITRE ATLAS and then maybe you can weave\\ntogether these three different things; the AI Bill of Rights,\\nthe NIST AI regulatory framework, as well as MITRE\\nATLAS. And tell us how we can integrate these three\\nframeworks together in order to have a good sense of how\\nto move forward with the AI systems that we built.\\nGina: 08:58 So MITRE is a not-for-profit organization. I worked for\\nthem for 10 years, and they support the federal\\ngovernment across all the federal government agencies to\\nhelp them solve some of the most pressing challenges. So\\nMITRE operates federally funded research and\\ndevelopment centers in support of the federal government\\nto solve problems for a safer world, essentially is what\\nMITRE does. And while at MITRE, I supported multiple\\nShow Notes: http://www.superdatascience.com/802 7\\nagencies; Department of Homeland Security, Social\\nSecurity Administration, Veterans Affairs, Department of\\nDefense, in some of the challenges that they were facing\\nat the time.\\n    09:45 Societal challenges to include when the economy was\\ndoing some downward slides and banks were failing, part\\nof some of the work that I did was at the FDIC, that was\\nwith Booz Allen. But MITRE was involved in other aspects\\nof that as well, to really understand the failures and to\\nfigure out the mitigation strategies to ensure that society\\ndidn\\'t feel those impacts as broadly and as strongly.\\n10:24 And MITRE created the ATLAS threat model introduction,\\nthreat model. It\\'s this comprehensive coverage of AIspecific adversary tactics techniques that includes realworld observation and reporting. It talks about\\naccessibility and usability of AI alignment with existing\\ncybersecurity frameworks in terms of from an AI\\nperspective. And that community engagement\\ncontribution and the educational resources and training.\\n10:58 So they\\'re developing a detailed taxonomy of tactics, of\\ntechniques, of procedures specific to AI systems that\\ncover the entire lifecycle from data collection to model\\ndevelopment and deployment and maintenance. Where\\nthey establish those mechanisms for continuously\\ngathering and updating threat intelligence based on realworld cybersecurity incidents involving AI so that the\\nknowledge base remains current and relevant. So that\\'s\\nwhat MITRE is doing it with their MITRE ATLAS\\nframework. And the framework integrates their existing\\nMITRE attack for enterprise framework that shows that\\nthey bring in that consistency and interoperability across\\ncybersecurity efforts as it pertains to AI systems. And\\nthat\\'s MITRE ATLAS threat model.\\nShow Notes: http://www.superdatascience.com/802 8\\nJon: 12:01 Terrifically useful context there from Gina. In my next\\nclip, Alex Andorra and I discuss Bayesian statistics,\\nnamely why being able to crunch larger and larger data\\nsets has helped us to use a powerful modeling technique\\nthat was originally devised centuries ago.\\n12:15 In addition to the podcast, also, I mentioned this at the\\noutset, I said that you\\'re co-founder and principal data\\nscientist of the popular Bayesian stats modeling platform,\\nPyMC. So like many things in data science, it\\'s uppercase\\nP, lowercase Y, for Python. What\\'s the MC? PyMC, one\\nword, M and the C are capitalized.\\nAlex: 12:38 So it\\'s very confusing because it stands for Python and\\nthen MC is Monte Carlo. So I understand, but why Monte\\nCarlo? It\\'s because it comes from Markov chain Monte\\nCarlo. So actually, it should be PyMCMC or PyMC\\nsquared, which is what I\\'m saying since the beginning.\\nBut anyways, yeah, it\\'s actually PyMC squared. So for\\nMarkov chain Monte Carlo and Markov chain Monte Carlo\\nis one of the main ways... All the algorithms now, new\\nones, but the blockbuster algorithm to run Bayesian\\nmodels is to use MCMC.\\nJon: 13:21 So in the same way that stochastic gradient descent is\\nlike the defacto standard for finding your model weights\\nin machine learning, Markov chain Monte Carlo is the\\nstandard way of doing it with the Bayesian network?\\nAlex: 13:36 Yeah. Yeah, yeah. And so now there are newer versions,\\nmore efficient versions. That\\'s basically the name of the\\ngame, making the algorithm more and more efficient. But\\nthe first algorithm dates back... I think it was actually\\ninvented during the project Manhattan. So during World\\nWar II.\\nJon: 13:57 Theme of the day.\\nShow Notes: http://www.superdatascience.com/802 9\\nAlex: 13:58 Yeah. And lots of physicists actually, statistical physics is\\na field that\\'s contributed a lot to MCMC. And so yeah,\\nphysicists who came to the field of statistics and trying to\\nmake the algorithms more efficient for their models. So\\nthey have contributed a lot. The field of physics has\\ncontributed a lot of big names and people to great leaps\\ninto the realm of more efficient algorithms. And so, I don\\'t\\nknow who your audience is, but that may sound boring.\\n14:37 Yeah, the algorithm, it\\'s like the workhorse, but it\\'s\\nextremely powerful. And that\\'s also one of the main\\nreasons why Bayesian statistics are increasing in\\npopularity lately, because I\\'m going to argue that it\\'s\\nalways been the best framework to do statistics, to do\\nscience. But it was hard to do with pen and paper\\nbecause the problem is that you have a huge, nasty\\nintegral on the numerator, on the denominator, sorry.\\nAnd this integral is not computable by pen and paper. So\\nfor a long, long time, Bayesian statistics combined two\\nfeatures like campaigns, PR campaigns. Bayesian\\nstatistics was relegated to the margins because it was just\\nsuper hard to do.\\n15:31 And so for other problems, other than very trivial ones, it\\nwas not very applicable. But now with the advent of\\npersonal computing, you have these incredible\\nalgorithms. So now most of the time, it\\'s HMC, Hamilton\\nand Monte Carlo. That\\'s what we use under the hood with\\nPyMC. But if you stand, if you use [inaudible 00:15:54] ,\\nit\\'s the same. And thanks to these algorithms, now we\\ncan make extremely powerful models because we can\\napproximate the [inaudible 00:16:03] distributions thanks\\nto, well, computer\\'s computing power. A computer is very\\ngood at computing. I think that\\'s why it\\'s called that.\\nJon: 16:15 Yes. And so that reminds me of deep learning. It\\'s a\\nsimilar kind of thing where the applications we have\\ntoday, like your ChatGPT or whatever your favorite large\\nShow Notes: http://www.superdatascience.com/802 10\\nlanguage model is, these amazing. Video generation like\\nSora, all of this is happening thanks to deep learning,\\nwhich is an approach we\\'ve had since the \\'50s. Certainly\\nnot as old as Bayesian statistics, but similarly, it has\\nbeen able to take off with much larger data sets and\\nmuch more compute.\\nAlex: 16:46 Yeah, yeah. Yeah, yeah, very good point. And I think\\nthat\\'s even more the point in deep learning for sure,\\nbecause Bayesian stats doesn\\'t need the scale, but the\\nway we\\'re doing deep learning for now, definitely need the\\nscale.\\nJon: 16:58 Yeah, yeah. Scale of data.\\nAlex: 17:00 Yeah, yeah, exactly. Yeah, sorry, yeah, the scale, because\\nour two scales, data and computing. Yeah. You\\'re right.\\nJon: 17:05 And for model parameters. So that has actually... I mean,\\ntying back to something you said near the beginning of\\nthis episode, is that actually one of the advantages of\\nBayesian statistics is that you can do it with very few\\ndata. Maybe fewer data than with a frequentist approach\\nor a machine learning approach, because you can bake in\\nyour prior assumptions. And those prior assumptions\\ngive some kind of structure, some kind of framework for\\nyour data to make an impact.\\nAlex: 17:32 Yeah. Yeah, completely.\\nJon: 17:34 And in keeping with the theme of returning to the past to\\nfind golden opportunities, I speak to Dr. Nathan Lambert\\nabout historical influences on contemporary\\nmethodologies. I also managed to sneak in a question\\nabout reinforcement learning from human feedback.\\nNathan is a research scientist for the Allen Institute for\\nAI, and previously built out the RLHF team at Hugging\\nFace. So there was no better person to ask about the lack\\nShow Notes: http://www.superdatascience.com/802 11\\nof robustness in RLHF and how that could impact the\\nfuture development and deployment of AI systems.\\n18:02 Another really cool thing that you\\'ve done related to RLHF\\nis you have traced it back to ancient philosophy and\\nmodern economics. So mentioning Aristotle and von\\nNeumann-Morganstern utility theorem, for example. I\\ndon\\'t really know what the VNM utility theorem is, but\\nhow do these historical foundations influence current\\nmethodologies and what can modern AI research learn\\nfrom these early theories?\\nNathan: 18:30 Yeah. So this is a fun paper with a few colleagues that I\\nstarted working with at Berkeley, and now we\\'re kind of\\nspread out. This is all based on the fact that RL is very\\ndeep field multidisciplinary history, where it goes way\\nback. And then the notion of preference is a very vague\\nthing in economics. And it\\'s like the von NeumannMorganstern theory is a foundational thing that\\nessentially it\\'s like you can express either all behaviors or\\nall goals as probability and expected value distributions,\\nwhich essentially lets you do expected value math over\\npreferences.\\n19:10 And then it led to a bunch of debates on whether or not\\npreferences actually exist and are tractable in any of\\nthese things, or if they\\'re actually measurable or not due\\nto the preference shift over time based on context. So\\nthese are the kinds of things that we take and it\\'s ask a\\nlot of questions on how this impacts the modern RLHF\\nprocess. It\\'s things like is the final model\\'s preferences,\\nwhich is like we\\'re mapping onto very human terms, is\\nthat actually based more on the the base model, which is\\nscraped from the internet than the human preferences\\nthat they get from somewhere like Scale AI.\\n19:46 So it\\'s like if it\\'s based more on the internet crawling than\\nthis million dollar dataset they\\'re getting from Scale AI,\\nShow Notes: http://www.superdatascience.com/802 12\\nit\\'s kind of confusing to the marketing where we\\'re saying\\nwe\\'re learning a preference model, but it might not\\nactually do that much. Is other things like OpenAI now\\nhas a ton of user data and it\\'s like what does the\\neconomics literature say about generating data for\\ntraining that comes from a user context or a professional\\ncontext where someone is paid to do it and they\\'re paid to\\nact in a certain way? And how does all of this mix? So it\\'s\\nreally just a super long list of questions of why we should\\nlook at other social sciences if we\\'re making grand claims\\nabout human preferences and all of these things.\\nJon: 20:26 Nice. Well, fascinating. Tons to dig into there for our\\nlisteners. Final topic that I planned related to RLHF, I\\'m\\nsure it\\'ll come up again organically in the conversation,\\nbut you\\'ve mentioned that RLHF is not even robust to\\nfine-tuning. And so removing the safety layer from models\\nlike GPT-4 and Llama 2 can break down the notion of\\nsafety. Can you elaborate on the implications of this\\nfragility for the future development and deployment of AI\\nsystems?\\nNathan: 20:59 Yeah, so this is a specific line of research. So there\\'s a few\\npapers that showed that if you take a model like Zephyr\\nor Tulu that we were mentioning, if they have safety in\\nthe dataset, if you then go and fine-tune it again on some\\ndifferent tasks, you\\'ll do some of the behaviors that are\\n\"ingrained\" in the model. I honestly think this is a little\\nbit more clickbaity than actually worrisome because it\\'s\\nreally not surprising given that if you just look at the\\namount of compute applied at fine-tuning, we pre-trained\\nthese models for trillions of tokens. And then we apply a\\ncouple billion tokens of compute at fine-tuning.\\n21:36 And it\\'s like we\\'re not changing the weights of the model\\nsubstantially. We\\'re doing a slight nudge, and it makes\\nsense that a slight nudge could be undone at the same\\nway. But if you were to take this to some of the bigger\\nShow Notes: http://www.superdatascience.com/802 13\\nlabs, what you hear is that safety is not just a single\\nartifact thing. Safety is much more about a complete\\nsystem than a model. So open weight models being\\nunsafe or unsafe, I don\\'t consider to be that big of a deal.\\nIt\\'s like if you were to apply them to a free endpoint that\\neveryone on the internet could talk to, then I don\\'t want\\nmy model saying good things about Hitler and all these\\nobvious things.\\n22:09 But if it\\'s a research artifact that you need to spin up\\nGPUs to use yourself, and it\\'s a little bit more... I\\'m more\\nopen to having these diversity of models exist. But if you\\nask [inaudible 00:22:22] or somebody, it\\'s like, \"What\\nhappens... How do you get safety into your model?\" And\\nit\\'s like, it\\'s not just RLHF. You need to have safety at the\\npre-training, any preference model you trained. And then\\nall of these models have a safety filter on the output. So\\nChatGPT, it reads all the text generated from the base\\nmodel, and then there\\'s a go, no go where it will rephrase\\nthe text if it gets a no-go signal, which is like their content\\nmoderation API.\\n22:45 So it\\'s kind of a double. It\\'s the type of thing where\\nresearchers need to market their work, but it\\'s not as big\\nof a detail as I think it is. It\\'s like, okay, I think it has\\ninteresting business downstream things with liability. So\\nit\\'s just like if you want to fine-tune a Llama model, you\\nnormally do that on your own hardware, but OpenAI has\\na fine-tuning API. And if they claim their model is safe,\\nbut any fine-tuning on their API that they then host\\nmakes it unsafe, that seems like more of a business\\nproblem. Which is like, oh, it\\'s a nice way that open\\necosystem might be better off because it breaks the\\nliability chain. But we\\'ll see this research continue to\\nevolve. It\\'s so early in all of these things for a year in.\\nJon: 23:31 All right. That\\'s it for today\\'s In Case You Missed It\\nepisode, to be sure not to miss any of our exciting\\nShow Notes: http://www.superdatascience.com/802 14\\nupcoming episodes. Be sure to subscribe to this podcast\\nif you haven\\'t already. But most importantly, I hope you\\'ll\\njust keep on listening. Until next time, keep on rocking it\\nout there. And I\\'m looking forward to enjoying another\\nround of Super Data Science Podcast with you very soon.'),\n",
       "  7497.7583)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_and_score = db.similarity_search_with_score(q1)\n",
    "docs_and_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector = ollama_embeddings.embed_query(q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3584"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.8230404853820801,\n",
       " -1.8964414596557617,\n",
       " -0.14863909780979156,\n",
       " -0.6310588121414185,\n",
       " -3.0927000045776367]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_vector[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_score = db.similarity_search_by_vector(embedding_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '4. Embedding/super_DS.txt'}, page_content='Show Notes: http://www.superdatascience.com/802 1\\nSDS PODCAST\\nEPISODE 802:\\nIN CASE YOU MISSED\\nIT IN JUNE 2024\\n    Show Notes: http://www.superdatascience.com/802 2\\nJon: 00:02 This is episode number 802, our In Case You Missed it in\\nJune episode.\\n    00:19 Welcome back to the Super Data Science Podcast. I\\'m\\nyour host, Jon Krohn. This is an In Case You Missed It\\nepisode that highlights the best parts of conversations we\\nhad on the show in the last month. This first clip you\\'ll\\nhear is from my interview with Dr. Jason Yosinski, one of\\nmy all-time favorite AI researchers. We had a great\\nconversation about making your AI and ML models\\nattractive to customers.\\n    00:40 In this clip, I got him to speak from his experience as\\nCEO of the climate technology startup he founded,\\nWindscape AI. This is a great case study if you\\'re\\nplanning to launch your own AI models commercially.\\n00:51 I\\'m sure that kind of engineering mindset is applicable to\\na lot of our listeners, and it seems like your approach is\\nworking. So EDP, a large Portuguese utility company,\\nrecently selected Windscape as one of nine startups for its\\nrenewable innovation program in Singapore to accelerate\\nthe global energy transition. What opportunities do you\\nsee emerging from Windscape AI\\'s participation in this\\nprogram?\\n    Jason: 01:16 Yeah. Well, thanks for mentioning that. We did apply for\\nthis program. We were selected. EDP is a huge utility. I\\nbelieve they\\'re the fourth-largest wind owner in the world.\\nSo they own tons and tons of turbines. They generate a\\nlot of wind energy. When I met with folks from EDP, I\\nfound them to be a very forward-looking organization.\\nSometimes you get a big company and they\\'re impossibly\\nslow or something, but these folks are really pushing the\\nboundaries, all the boundaries they can, which I thought\\nwas super cool.\\n    Show Notes: http://www.superdatascience.com/802 3\\n01:50 What we hope to get out of it and where that collaboration\\nmight go is to pilot our technology, start working with\\nthem, see how it works on their wind farms around the\\nworld. And then if it does work really well, hopefully we\\nroll out more broadly and we can also maybe use that as\\na demo for new potential customers.\\n    Jon: 02:08 Very cool. So it sounds like EDP is forward-looking. But\\nin general, do you counter resistance or hurdles as you\\ntry to come to energy utilities and say, \"Hey, you could be\\nusing AI like Windscape\\'s to be improving the efficiency of\\nyour systems.\" Do you encounter resistance or hurdles,\\nor is it relatively straightforward to convince people that\\nyou\\'re doing something valuable?\\n    Jason: 02:31 I wouldn\\'t say it\\'s straightforward. No. Convincing people\\nthat what you\\'re doing is valuable is maybe always hard. I\\nwould say saying the words AI or machine learning\\ndoesn\\'t immediately open all the doors. It can open some\\ndoors. Some of these companies realize that AI might be\\nrevolutionizing things that happen internally, and they\\'re\\nnot quite sure how yet, but maybe we should talk to these\\nrandos from Windscape and see what they think.\\n02:59 It does open some doors, but not all. Just as probably\\nwithin any industry, there are some organizations that\\nare very forward-looking and others early adopters of any\\ntechnology and others that are slower, that are later\\nadopters. They literally, some have told us, \"We don\\'t care\\nwhat you\\'re [inaudible 00:03:17], just show us when four\\nother companies are using it and then we\\'ll consider\\nusing it because how we work,\" which is potentially an\\nefficient choice from their perspective.\\n    03:27 There\\'s also small energy companies and large energy\\ncompanies, and there\\'s a spectrum there of how you sell\\nto these companies and how you get adoption and so on.\\nSo yeah, and convincing everyone, it can be hard. You\\nShow Notes: http://www.superdatascience.com/802 4\\nhave to convince people that your technology will work,\\nthat it won\\'t be a huge headache to adopt. The people in\\nthe field need to buy into it. It can\\'t ruin their workflow or\\nsomething. It has to be possible to actually integrate. So\\nsome of these systems run software that\\'s hard to work\\nwith and simply integrating can be difficult at times. So I\\ndon\\'t know, there\\'s a lot of factors probably as in any\\nindustry.\\n    Jon: 04:10 Yeah, it makes so much sense. And hopefully I\\'m not\\ngoing too deep here, and if I am asking a question that\\nwould give away some kind of IP, just feel free to not\\nanswer this. But it seems to me like in a situation like\\nyours, where you are providing software to hardware\\ncompanies, say the turbine manufacturers, you are not,\\nat least in the immediate term, planning on building, say\\nyour own turbines, your own wind farms.\\n    04:37 You are a software company. You need to be partnering\\nwith turbine manufacturers, with wind farm operators.\\nHow does that work? Are people... I guess maybe your\\nresponse is going to be similar, where there\\'s a range of\\nresponses where some turbine manufacturers are\\nrelatively early adopters. They see the potential. They say,\\n\"Wow, Jason\\'s done a lot of amazing research in the past.\\nHe seems like the kind of person we should be working\\nwith to accelerate our roadmap.\" And then other folks are\\njust like, \"Yeah, we\\'ve got our own team,\" or I don\\'t know.\\nHow does it look for you? Yeah.\\n    Jason: 05:09 What we started this whole endeavor, what we imagined\\nwould happen is we would first build products that we\\nwould sell to people that own the turbines. Why do they\\nwant them? Because our product would help them make\\nmore money starting next month. We help them make\\nmore money. They like our product, we roll out, they tell\\ntheir friends. We deploy to more and more farms, more\\nand more companies. As we start to increase our market\\nShow Notes: http://www.superdatascience.com/802 5\\npenetration in the industry, then much later, turbine\\nmanufacturers would notice and they would say, \"Hey,\\neveryone\\'s using these Windscape people. Maybe we\\nshould talk to them and consider integrating their thing\\noff the factory floor rather than an as aftermarket add-on\\non.\"\\n    05:48 That\\'s still the process we\\'re following, although we\\'ve\\nbeen surprised that some OEMs are interested in chatting\\nearly. I think they just want to have on their radar what\\'s\\ngoing on in the world. And if there\\'s any promising\\ntechnology, they want to be there first. So I guess we\\'re\\nalready having some of those conversations too.\\nJon: 06:05 And now, we move from offers that tech companies can\\nrefuse to regulations that startups have a duty to follow.\\nIn this clip with the systems engineering and AI\\nregulation guru, Dr. Gina Guillaume-Joseph, she lays out\\nthe evolving regulatory field for AI, which can be difficult\\nto navigate even if you\\'ve got the best of intentions.\\nSpecifically, Gina and I talk about the AI Bill of Rights,\\nthe NIST AI regulatory framework, and her work on the\\nMITRE ATLAS.\\n    06:32 Explain for us... You mentioned there, so there\\'s the NIST\\nAI risk management framework. So NIST is the National\\nInstitutes of Science and Technology, that may be familiar\\nas an acronym. The NIST thing is something for those of\\nus who have done any deep learning to kind of Hello\\nworld deep learning example involves this handwritten\\ndata set of digits. So it\\'s 60,000 handwritten digits done\\nby, if I remember correctly, US postal workers, as well as\\nelementary school students. And so it\\'s just each image is\\na different digit. So it\\'s some of them are zero, some are\\none, some are two, some are threes, all the way up to\\nnine. And this handwritten dataset was curated initially, I\\nguess in the \\'90s, maybe even in the \\'80s by NIST.\\nShow Notes: http://www.superdatascience.com/802 6\\n    07:24 And then Yann Le Cun, who\\'s one of the most famous AI\\nresearchers of all time, he modified with his research\\nteam at the time, I believe they were AT&T Bell Labs, they\\nmodified that NIST handwritten digit dataset to create the\\nMNIST, modified NIST, handwritten dataset. So I don\\'t\\nknow, it\\'s a bit of an aside, but that MNIST dataset is\\nprobably familiar to anyone who\\'s done any kind of deep\\nlearning at all. And so yeah, so that same organization,\\nNIST, has been around for a long time in the US I don\\'t\\nknow how many decades.\\n    07:58 But has been trying to set up frameworks for all different\\nkinds of industries in science and technology, and has\\nnow created this AI risk management framework, which\\nagain, I\\'ll have a link to that in the show notes alongside\\nthe AI Bill of Rights. A third framework, I guess, you can\\ncorrect me if I\\'m not using the right word there, that you\\nbrought up in your talk that also seems really helpful\\nhere is something called the MITRE ATLAS.\\n    08:26 So I\\'ve been trying to, as you\\'ve been speaking, dig up\\nwhat MITRE stands for, M-I-T-R-E. It doesn\\'t seem like it\\nstands for anything. Can you tell us a bit about MITRE\\nand the MITRE ATLAS and then maybe you can weave\\ntogether these three different things; the AI Bill of Rights,\\nthe NIST AI regulatory framework, as well as MITRE\\nATLAS. And tell us how we can integrate these three\\nframeworks together in order to have a good sense of how\\nto move forward with the AI systems that we built.\\nGina: 08:58 So MITRE is a not-for-profit organization. I worked for\\nthem for 10 years, and they support the federal\\ngovernment across all the federal government agencies to\\nhelp them solve some of the most pressing challenges. So\\nMITRE operates federally funded research and\\ndevelopment centers in support of the federal government\\nto solve problems for a safer world, essentially is what\\nMITRE does. And while at MITRE, I supported multiple\\nShow Notes: http://www.superdatascience.com/802 7\\nagencies; Department of Homeland Security, Social\\nSecurity Administration, Veterans Affairs, Department of\\nDefense, in some of the challenges that they were facing\\nat the time.\\n    09:45 Societal challenges to include when the economy was\\ndoing some downward slides and banks were failing, part\\nof some of the work that I did was at the FDIC, that was\\nwith Booz Allen. But MITRE was involved in other aspects\\nof that as well, to really understand the failures and to\\nfigure out the mitigation strategies to ensure that society\\ndidn\\'t feel those impacts as broadly and as strongly.\\n10:24 And MITRE created the ATLAS threat model introduction,\\nthreat model. It\\'s this comprehensive coverage of AIspecific adversary tactics techniques that includes realworld observation and reporting. It talks about\\naccessibility and usability of AI alignment with existing\\ncybersecurity frameworks in terms of from an AI\\nperspective. And that community engagement\\ncontribution and the educational resources and training.\\n10:58 So they\\'re developing a detailed taxonomy of tactics, of\\ntechniques, of procedures specific to AI systems that\\ncover the entire lifecycle from data collection to model\\ndevelopment and deployment and maintenance. Where\\nthey establish those mechanisms for continuously\\ngathering and updating threat intelligence based on realworld cybersecurity incidents involving AI so that the\\nknowledge base remains current and relevant. So that\\'s\\nwhat MITRE is doing it with their MITRE ATLAS\\nframework. And the framework integrates their existing\\nMITRE attack for enterprise framework that shows that\\nthey bring in that consistency and interoperability across\\ncybersecurity efforts as it pertains to AI systems. And\\nthat\\'s MITRE ATLAS threat model.\\nShow Notes: http://www.superdatascience.com/802 8\\nJon: 12:01 Terrifically useful context there from Gina. In my next\\nclip, Alex Andorra and I discuss Bayesian statistics,\\nnamely why being able to crunch larger and larger data\\nsets has helped us to use a powerful modeling technique\\nthat was originally devised centuries ago.\\n12:15 In addition to the podcast, also, I mentioned this at the\\noutset, I said that you\\'re co-founder and principal data\\nscientist of the popular Bayesian stats modeling platform,\\nPyMC. So like many things in data science, it\\'s uppercase\\nP, lowercase Y, for Python. What\\'s the MC? PyMC, one\\nword, M and the C are capitalized.\\nAlex: 12:38 So it\\'s very confusing because it stands for Python and\\nthen MC is Monte Carlo. So I understand, but why Monte\\nCarlo? It\\'s because it comes from Markov chain Monte\\nCarlo. So actually, it should be PyMCMC or PyMC\\nsquared, which is what I\\'m saying since the beginning.\\nBut anyways, yeah, it\\'s actually PyMC squared. So for\\nMarkov chain Monte Carlo and Markov chain Monte Carlo\\nis one of the main ways... All the algorithms now, new\\nones, but the blockbuster algorithm to run Bayesian\\nmodels is to use MCMC.\\nJon: 13:21 So in the same way that stochastic gradient descent is\\nlike the defacto standard for finding your model weights\\nin machine learning, Markov chain Monte Carlo is the\\nstandard way of doing it with the Bayesian network?\\nAlex: 13:36 Yeah. Yeah, yeah. And so now there are newer versions,\\nmore efficient versions. That\\'s basically the name of the\\ngame, making the algorithm more and more efficient. But\\nthe first algorithm dates back... I think it was actually\\ninvented during the project Manhattan. So during World\\nWar II.\\nJon: 13:57 Theme of the day.\\nShow Notes: http://www.superdatascience.com/802 9\\nAlex: 13:58 Yeah. And lots of physicists actually, statistical physics is\\na field that\\'s contributed a lot to MCMC. And so yeah,\\nphysicists who came to the field of statistics and trying to\\nmake the algorithms more efficient for their models. So\\nthey have contributed a lot. The field of physics has\\ncontributed a lot of big names and people to great leaps\\ninto the realm of more efficient algorithms. And so, I don\\'t\\nknow who your audience is, but that may sound boring.\\n14:37 Yeah, the algorithm, it\\'s like the workhorse, but it\\'s\\nextremely powerful. And that\\'s also one of the main\\nreasons why Bayesian statistics are increasing in\\npopularity lately, because I\\'m going to argue that it\\'s\\nalways been the best framework to do statistics, to do\\nscience. But it was hard to do with pen and paper\\nbecause the problem is that you have a huge, nasty\\nintegral on the numerator, on the denominator, sorry.\\nAnd this integral is not computable by pen and paper. So\\nfor a long, long time, Bayesian statistics combined two\\nfeatures like campaigns, PR campaigns. Bayesian\\nstatistics was relegated to the margins because it was just\\nsuper hard to do.\\n15:31 And so for other problems, other than very trivial ones, it\\nwas not very applicable. But now with the advent of\\npersonal computing, you have these incredible\\nalgorithms. So now most of the time, it\\'s HMC, Hamilton\\nand Monte Carlo. That\\'s what we use under the hood with\\nPyMC. But if you stand, if you use [inaudible 00:15:54] ,\\nit\\'s the same. And thanks to these algorithms, now we\\ncan make extremely powerful models because we can\\napproximate the [inaudible 00:16:03] distributions thanks\\nto, well, computer\\'s computing power. A computer is very\\ngood at computing. I think that\\'s why it\\'s called that.\\nJon: 16:15 Yes. And so that reminds me of deep learning. It\\'s a\\nsimilar kind of thing where the applications we have\\ntoday, like your ChatGPT or whatever your favorite large\\nShow Notes: http://www.superdatascience.com/802 10\\nlanguage model is, these amazing. Video generation like\\nSora, all of this is happening thanks to deep learning,\\nwhich is an approach we\\'ve had since the \\'50s. Certainly\\nnot as old as Bayesian statistics, but similarly, it has\\nbeen able to take off with much larger data sets and\\nmuch more compute.\\nAlex: 16:46 Yeah, yeah. Yeah, yeah, very good point. And I think\\nthat\\'s even more the point in deep learning for sure,\\nbecause Bayesian stats doesn\\'t need the scale, but the\\nway we\\'re doing deep learning for now, definitely need the\\nscale.\\nJon: 16:58 Yeah, yeah. Scale of data.\\nAlex: 17:00 Yeah, yeah, exactly. Yeah, sorry, yeah, the scale, because\\nour two scales, data and computing. Yeah. You\\'re right.\\nJon: 17:05 And for model parameters. So that has actually... I mean,\\ntying back to something you said near the beginning of\\nthis episode, is that actually one of the advantages of\\nBayesian statistics is that you can do it with very few\\ndata. Maybe fewer data than with a frequentist approach\\nor a machine learning approach, because you can bake in\\nyour prior assumptions. And those prior assumptions\\ngive some kind of structure, some kind of framework for\\nyour data to make an impact.\\nAlex: 17:32 Yeah. Yeah, completely.\\nJon: 17:34 And in keeping with the theme of returning to the past to\\nfind golden opportunities, I speak to Dr. Nathan Lambert\\nabout historical influences on contemporary\\nmethodologies. I also managed to sneak in a question\\nabout reinforcement learning from human feedback.\\nNathan is a research scientist for the Allen Institute for\\nAI, and previously built out the RLHF team at Hugging\\nFace. So there was no better person to ask about the lack\\nShow Notes: http://www.superdatascience.com/802 11\\nof robustness in RLHF and how that could impact the\\nfuture development and deployment of AI systems.\\n18:02 Another really cool thing that you\\'ve done related to RLHF\\nis you have traced it back to ancient philosophy and\\nmodern economics. So mentioning Aristotle and von\\nNeumann-Morganstern utility theorem, for example. I\\ndon\\'t really know what the VNM utility theorem is, but\\nhow do these historical foundations influence current\\nmethodologies and what can modern AI research learn\\nfrom these early theories?\\nNathan: 18:30 Yeah. So this is a fun paper with a few colleagues that I\\nstarted working with at Berkeley, and now we\\'re kind of\\nspread out. This is all based on the fact that RL is very\\ndeep field multidisciplinary history, where it goes way\\nback. And then the notion of preference is a very vague\\nthing in economics. And it\\'s like the von NeumannMorganstern theory is a foundational thing that\\nessentially it\\'s like you can express either all behaviors or\\nall goals as probability and expected value distributions,\\nwhich essentially lets you do expected value math over\\npreferences.\\n19:10 And then it led to a bunch of debates on whether or not\\npreferences actually exist and are tractable in any of\\nthese things, or if they\\'re actually measurable or not due\\nto the preference shift over time based on context. So\\nthese are the kinds of things that we take and it\\'s ask a\\nlot of questions on how this impacts the modern RLHF\\nprocess. It\\'s things like is the final model\\'s preferences,\\nwhich is like we\\'re mapping onto very human terms, is\\nthat actually based more on the the base model, which is\\nscraped from the internet than the human preferences\\nthat they get from somewhere like Scale AI.\\n19:46 So it\\'s like if it\\'s based more on the internet crawling than\\nthis million dollar dataset they\\'re getting from Scale AI,\\nShow Notes: http://www.superdatascience.com/802 12\\nit\\'s kind of confusing to the marketing where we\\'re saying\\nwe\\'re learning a preference model, but it might not\\nactually do that much. Is other things like OpenAI now\\nhas a ton of user data and it\\'s like what does the\\neconomics literature say about generating data for\\ntraining that comes from a user context or a professional\\ncontext where someone is paid to do it and they\\'re paid to\\nact in a certain way? And how does all of this mix? So it\\'s\\nreally just a super long list of questions of why we should\\nlook at other social sciences if we\\'re making grand claims\\nabout human preferences and all of these things.\\nJon: 20:26 Nice. Well, fascinating. Tons to dig into there for our\\nlisteners. Final topic that I planned related to RLHF, I\\'m\\nsure it\\'ll come up again organically in the conversation,\\nbut you\\'ve mentioned that RLHF is not even robust to\\nfine-tuning. And so removing the safety layer from models\\nlike GPT-4 and Llama 2 can break down the notion of\\nsafety. Can you elaborate on the implications of this\\nfragility for the future development and deployment of AI\\nsystems?\\nNathan: 20:59 Yeah, so this is a specific line of research. So there\\'s a few\\npapers that showed that if you take a model like Zephyr\\nor Tulu that we were mentioning, if they have safety in\\nthe dataset, if you then go and fine-tune it again on some\\ndifferent tasks, you\\'ll do some of the behaviors that are\\n\"ingrained\" in the model. I honestly think this is a little\\nbit more clickbaity than actually worrisome because it\\'s\\nreally not surprising given that if you just look at the\\namount of compute applied at fine-tuning, we pre-trained\\nthese models for trillions of tokens. And then we apply a\\ncouple billion tokens of compute at fine-tuning.\\n21:36 And it\\'s like we\\'re not changing the weights of the model\\nsubstantially. We\\'re doing a slight nudge, and it makes\\nsense that a slight nudge could be undone at the same\\nway. But if you were to take this to some of the bigger\\nShow Notes: http://www.superdatascience.com/802 13\\nlabs, what you hear is that safety is not just a single\\nartifact thing. Safety is much more about a complete\\nsystem than a model. So open weight models being\\nunsafe or unsafe, I don\\'t consider to be that big of a deal.\\nIt\\'s like if you were to apply them to a free endpoint that\\neveryone on the internet could talk to, then I don\\'t want\\nmy model saying good things about Hitler and all these\\nobvious things.\\n22:09 But if it\\'s a research artifact that you need to spin up\\nGPUs to use yourself, and it\\'s a little bit more... I\\'m more\\nopen to having these diversity of models exist. But if you\\nask [inaudible 00:22:22] or somebody, it\\'s like, \"What\\nhappens... How do you get safety into your model?\" And\\nit\\'s like, it\\'s not just RLHF. You need to have safety at the\\npre-training, any preference model you trained. And then\\nall of these models have a safety filter on the output. So\\nChatGPT, it reads all the text generated from the base\\nmodel, and then there\\'s a go, no go where it will rephrase\\nthe text if it gets a no-go signal, which is like their content\\nmoderation API.\\n22:45 So it\\'s kind of a double. It\\'s the type of thing where\\nresearchers need to market their work, but it\\'s not as big\\nof a detail as I think it is. It\\'s like, okay, I think it has\\ninteresting business downstream things with liability. So\\nit\\'s just like if you want to fine-tune a Llama model, you\\nnormally do that on your own hardware, but OpenAI has\\na fine-tuning API. And if they claim their model is safe,\\nbut any fine-tuning on their API that they then host\\nmakes it unsafe, that seems like more of a business\\nproblem. Which is like, oh, it\\'s a nice way that open\\necosystem might be better off because it breaks the\\nliability chain. But we\\'ll see this research continue to\\nevolve. It\\'s so early in all of these things for a year in.\\nJon: 23:31 All right. That\\'s it for today\\'s In Case You Missed It\\nepisode, to be sure not to miss any of our exciting\\nShow Notes: http://www.superdatascience.com/802 14\\nupcoming episodes. Be sure to subscribe to this podcast\\nif you haven\\'t already. But most importantly, I hope you\\'ll\\njust keep on listening. Until next time, keep on rocking it\\nout there. And I\\'m looking forward to enjoying another\\nround of Super Data Science Podcast with you very soon.')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_db = FAISS.load_local(\"faiss_index\", ollama_embeddings,allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = new_db.similarity_search(q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '4. Embedding/super_DS.txt'}, page_content='Show Notes: http://www.superdatascience.com/802 1\\nSDS PODCAST\\nEPISODE 802:\\nIN CASE YOU MISSED\\nIT IN JUNE 2024\\n    Show Notes: http://www.superdatascience.com/802 2\\nJon: 00:02 This is episode number 802, our In Case You Missed it in\\nJune episode.\\n    00:19 Welcome back to the Super Data Science Podcast. I\\'m\\nyour host, Jon Krohn. This is an In Case You Missed It\\nepisode that highlights the best parts of conversations we\\nhad on the show in the last month. This first clip you\\'ll\\nhear is from my interview with Dr. Jason Yosinski, one of\\nmy all-time favorite AI researchers. We had a great\\nconversation about making your AI and ML models\\nattractive to customers.\\n    00:40 In this clip, I got him to speak from his experience as\\nCEO of the climate technology startup he founded,\\nWindscape AI. This is a great case study if you\\'re\\nplanning to launch your own AI models commercially.\\n00:51 I\\'m sure that kind of engineering mindset is applicable to\\na lot of our listeners, and it seems like your approach is\\nworking. So EDP, a large Portuguese utility company,\\nrecently selected Windscape as one of nine startups for its\\nrenewable innovation program in Singapore to accelerate\\nthe global energy transition. What opportunities do you\\nsee emerging from Windscape AI\\'s participation in this\\nprogram?\\n    Jason: 01:16 Yeah. Well, thanks for mentioning that. We did apply for\\nthis program. We were selected. EDP is a huge utility. I\\nbelieve they\\'re the fourth-largest wind owner in the world.\\nSo they own tons and tons of turbines. They generate a\\nlot of wind energy. When I met with folks from EDP, I\\nfound them to be a very forward-looking organization.\\nSometimes you get a big company and they\\'re impossibly\\nslow or something, but these folks are really pushing the\\nboundaries, all the boundaries they can, which I thought\\nwas super cool.\\n    Show Notes: http://www.superdatascience.com/802 3\\n01:50 What we hope to get out of it and where that collaboration\\nmight go is to pilot our technology, start working with\\nthem, see how it works on their wind farms around the\\nworld. And then if it does work really well, hopefully we\\nroll out more broadly and we can also maybe use that as\\na demo for new potential customers.\\n    Jon: 02:08 Very cool. So it sounds like EDP is forward-looking. But\\nin general, do you counter resistance or hurdles as you\\ntry to come to energy utilities and say, \"Hey, you could be\\nusing AI like Windscape\\'s to be improving the efficiency of\\nyour systems.\" Do you encounter resistance or hurdles,\\nor is it relatively straightforward to convince people that\\nyou\\'re doing something valuable?\\n    Jason: 02:31 I wouldn\\'t say it\\'s straightforward. No. Convincing people\\nthat what you\\'re doing is valuable is maybe always hard. I\\nwould say saying the words AI or machine learning\\ndoesn\\'t immediately open all the doors. It can open some\\ndoors. Some of these companies realize that AI might be\\nrevolutionizing things that happen internally, and they\\'re\\nnot quite sure how yet, but maybe we should talk to these\\nrandos from Windscape and see what they think.\\n02:59 It does open some doors, but not all. Just as probably\\nwithin any industry, there are some organizations that\\nare very forward-looking and others early adopters of any\\ntechnology and others that are slower, that are later\\nadopters. They literally, some have told us, \"We don\\'t care\\nwhat you\\'re [inaudible 00:03:17], just show us when four\\nother companies are using it and then we\\'ll consider\\nusing it because how we work,\" which is potentially an\\nefficient choice from their perspective.\\n    03:27 There\\'s also small energy companies and large energy\\ncompanies, and there\\'s a spectrum there of how you sell\\nto these companies and how you get adoption and so on.\\nSo yeah, and convincing everyone, it can be hard. You\\nShow Notes: http://www.superdatascience.com/802 4\\nhave to convince people that your technology will work,\\nthat it won\\'t be a huge headache to adopt. The people in\\nthe field need to buy into it. It can\\'t ruin their workflow or\\nsomething. It has to be possible to actually integrate. So\\nsome of these systems run software that\\'s hard to work\\nwith and simply integrating can be difficult at times. So I\\ndon\\'t know, there\\'s a lot of factors probably as in any\\nindustry.\\n    Jon: 04:10 Yeah, it makes so much sense. And hopefully I\\'m not\\ngoing too deep here, and if I am asking a question that\\nwould give away some kind of IP, just feel free to not\\nanswer this. But it seems to me like in a situation like\\nyours, where you are providing software to hardware\\ncompanies, say the turbine manufacturers, you are not,\\nat least in the immediate term, planning on building, say\\nyour own turbines, your own wind farms.\\n    04:37 You are a software company. You need to be partnering\\nwith turbine manufacturers, with wind farm operators.\\nHow does that work? Are people... I guess maybe your\\nresponse is going to be similar, where there\\'s a range of\\nresponses where some turbine manufacturers are\\nrelatively early adopters. They see the potential. They say,\\n\"Wow, Jason\\'s done a lot of amazing research in the past.\\nHe seems like the kind of person we should be working\\nwith to accelerate our roadmap.\" And then other folks are\\njust like, \"Yeah, we\\'ve got our own team,\" or I don\\'t know.\\nHow does it look for you? Yeah.\\n    Jason: 05:09 What we started this whole endeavor, what we imagined\\nwould happen is we would first build products that we\\nwould sell to people that own the turbines. Why do they\\nwant them? Because our product would help them make\\nmore money starting next month. We help them make\\nmore money. They like our product, we roll out, they tell\\ntheir friends. We deploy to more and more farms, more\\nand more companies. As we start to increase our market\\nShow Notes: http://www.superdatascience.com/802 5\\npenetration in the industry, then much later, turbine\\nmanufacturers would notice and they would say, \"Hey,\\neveryone\\'s using these Windscape people. Maybe we\\nshould talk to them and consider integrating their thing\\noff the factory floor rather than an as aftermarket add-on\\non.\"\\n    05:48 That\\'s still the process we\\'re following, although we\\'ve\\nbeen surprised that some OEMs are interested in chatting\\nearly. I think they just want to have on their radar what\\'s\\ngoing on in the world. And if there\\'s any promising\\ntechnology, they want to be there first. So I guess we\\'re\\nalready having some of those conversations too.\\nJon: 06:05 And now, we move from offers that tech companies can\\nrefuse to regulations that startups have a duty to follow.\\nIn this clip with the systems engineering and AI\\nregulation guru, Dr. Gina Guillaume-Joseph, she lays out\\nthe evolving regulatory field for AI, which can be difficult\\nto navigate even if you\\'ve got the best of intentions.\\nSpecifically, Gina and I talk about the AI Bill of Rights,\\nthe NIST AI regulatory framework, and her work on the\\nMITRE ATLAS.\\n    06:32 Explain for us... You mentioned there, so there\\'s the NIST\\nAI risk management framework. So NIST is the National\\nInstitutes of Science and Technology, that may be familiar\\nas an acronym. The NIST thing is something for those of\\nus who have done any deep learning to kind of Hello\\nworld deep learning example involves this handwritten\\ndata set of digits. So it\\'s 60,000 handwritten digits done\\nby, if I remember correctly, US postal workers, as well as\\nelementary school students. And so it\\'s just each image is\\na different digit. So it\\'s some of them are zero, some are\\none, some are two, some are threes, all the way up to\\nnine. And this handwritten dataset was curated initially, I\\nguess in the \\'90s, maybe even in the \\'80s by NIST.\\nShow Notes: http://www.superdatascience.com/802 6\\n    07:24 And then Yann Le Cun, who\\'s one of the most famous AI\\nresearchers of all time, he modified with his research\\nteam at the time, I believe they were AT&T Bell Labs, they\\nmodified that NIST handwritten digit dataset to create the\\nMNIST, modified NIST, handwritten dataset. So I don\\'t\\nknow, it\\'s a bit of an aside, but that MNIST dataset is\\nprobably familiar to anyone who\\'s done any kind of deep\\nlearning at all. And so yeah, so that same organization,\\nNIST, has been around for a long time in the US I don\\'t\\nknow how many decades.\\n    07:58 But has been trying to set up frameworks for all different\\nkinds of industries in science and technology, and has\\nnow created this AI risk management framework, which\\nagain, I\\'ll have a link to that in the show notes alongside\\nthe AI Bill of Rights. A third framework, I guess, you can\\ncorrect me if I\\'m not using the right word there, that you\\nbrought up in your talk that also seems really helpful\\nhere is something called the MITRE ATLAS.\\n    08:26 So I\\'ve been trying to, as you\\'ve been speaking, dig up\\nwhat MITRE stands for, M-I-T-R-E. It doesn\\'t seem like it\\nstands for anything. Can you tell us a bit about MITRE\\nand the MITRE ATLAS and then maybe you can weave\\ntogether these three different things; the AI Bill of Rights,\\nthe NIST AI regulatory framework, as well as MITRE\\nATLAS. And tell us how we can integrate these three\\nframeworks together in order to have a good sense of how\\nto move forward with the AI systems that we built.\\nGina: 08:58 So MITRE is a not-for-profit organization. I worked for\\nthem for 10 years, and they support the federal\\ngovernment across all the federal government agencies to\\nhelp them solve some of the most pressing challenges. So\\nMITRE operates federally funded research and\\ndevelopment centers in support of the federal government\\nto solve problems for a safer world, essentially is what\\nMITRE does. And while at MITRE, I supported multiple\\nShow Notes: http://www.superdatascience.com/802 7\\nagencies; Department of Homeland Security, Social\\nSecurity Administration, Veterans Affairs, Department of\\nDefense, in some of the challenges that they were facing\\nat the time.\\n    09:45 Societal challenges to include when the economy was\\ndoing some downward slides and banks were failing, part\\nof some of the work that I did was at the FDIC, that was\\nwith Booz Allen. But MITRE was involved in other aspects\\nof that as well, to really understand the failures and to\\nfigure out the mitigation strategies to ensure that society\\ndidn\\'t feel those impacts as broadly and as strongly.\\n10:24 And MITRE created the ATLAS threat model introduction,\\nthreat model. It\\'s this comprehensive coverage of AIspecific adversary tactics techniques that includes realworld observation and reporting. It talks about\\naccessibility and usability of AI alignment with existing\\ncybersecurity frameworks in terms of from an AI\\nperspective. And that community engagement\\ncontribution and the educational resources and training.\\n10:58 So they\\'re developing a detailed taxonomy of tactics, of\\ntechniques, of procedures specific to AI systems that\\ncover the entire lifecycle from data collection to model\\ndevelopment and deployment and maintenance. Where\\nthey establish those mechanisms for continuously\\ngathering and updating threat intelligence based on realworld cybersecurity incidents involving AI so that the\\nknowledge base remains current and relevant. So that\\'s\\nwhat MITRE is doing it with their MITRE ATLAS\\nframework. And the framework integrates their existing\\nMITRE attack for enterprise framework that shows that\\nthey bring in that consistency and interoperability across\\ncybersecurity efforts as it pertains to AI systems. And\\nthat\\'s MITRE ATLAS threat model.\\nShow Notes: http://www.superdatascience.com/802 8\\nJon: 12:01 Terrifically useful context there from Gina. In my next\\nclip, Alex Andorra and I discuss Bayesian statistics,\\nnamely why being able to crunch larger and larger data\\nsets has helped us to use a powerful modeling technique\\nthat was originally devised centuries ago.\\n12:15 In addition to the podcast, also, I mentioned this at the\\noutset, I said that you\\'re co-founder and principal data\\nscientist of the popular Bayesian stats modeling platform,\\nPyMC. So like many things in data science, it\\'s uppercase\\nP, lowercase Y, for Python. What\\'s the MC? PyMC, one\\nword, M and the C are capitalized.\\nAlex: 12:38 So it\\'s very confusing because it stands for Python and\\nthen MC is Monte Carlo. So I understand, but why Monte\\nCarlo? It\\'s because it comes from Markov chain Monte\\nCarlo. So actually, it should be PyMCMC or PyMC\\nsquared, which is what I\\'m saying since the beginning.\\nBut anyways, yeah, it\\'s actually PyMC squared. So for\\nMarkov chain Monte Carlo and Markov chain Monte Carlo\\nis one of the main ways... All the algorithms now, new\\nones, but the blockbuster algorithm to run Bayesian\\nmodels is to use MCMC.\\nJon: 13:21 So in the same way that stochastic gradient descent is\\nlike the defacto standard for finding your model weights\\nin machine learning, Markov chain Monte Carlo is the\\nstandard way of doing it with the Bayesian network?\\nAlex: 13:36 Yeah. Yeah, yeah. And so now there are newer versions,\\nmore efficient versions. That\\'s basically the name of the\\ngame, making the algorithm more and more efficient. But\\nthe first algorithm dates back... I think it was actually\\ninvented during the project Manhattan. So during World\\nWar II.\\nJon: 13:57 Theme of the day.\\nShow Notes: http://www.superdatascience.com/802 9\\nAlex: 13:58 Yeah. And lots of physicists actually, statistical physics is\\na field that\\'s contributed a lot to MCMC. And so yeah,\\nphysicists who came to the field of statistics and trying to\\nmake the algorithms more efficient for their models. So\\nthey have contributed a lot. The field of physics has\\ncontributed a lot of big names and people to great leaps\\ninto the realm of more efficient algorithms. And so, I don\\'t\\nknow who your audience is, but that may sound boring.\\n14:37 Yeah, the algorithm, it\\'s like the workhorse, but it\\'s\\nextremely powerful. And that\\'s also one of the main\\nreasons why Bayesian statistics are increasing in\\npopularity lately, because I\\'m going to argue that it\\'s\\nalways been the best framework to do statistics, to do\\nscience. But it was hard to do with pen and paper\\nbecause the problem is that you have a huge, nasty\\nintegral on the numerator, on the denominator, sorry.\\nAnd this integral is not computable by pen and paper. So\\nfor a long, long time, Bayesian statistics combined two\\nfeatures like campaigns, PR campaigns. Bayesian\\nstatistics was relegated to the margins because it was just\\nsuper hard to do.\\n15:31 And so for other problems, other than very trivial ones, it\\nwas not very applicable. But now with the advent of\\npersonal computing, you have these incredible\\nalgorithms. So now most of the time, it\\'s HMC, Hamilton\\nand Monte Carlo. That\\'s what we use under the hood with\\nPyMC. But if you stand, if you use [inaudible 00:15:54] ,\\nit\\'s the same. And thanks to these algorithms, now we\\ncan make extremely powerful models because we can\\napproximate the [inaudible 00:16:03] distributions thanks\\nto, well, computer\\'s computing power. A computer is very\\ngood at computing. I think that\\'s why it\\'s called that.\\nJon: 16:15 Yes. And so that reminds me of deep learning. It\\'s a\\nsimilar kind of thing where the applications we have\\ntoday, like your ChatGPT or whatever your favorite large\\nShow Notes: http://www.superdatascience.com/802 10\\nlanguage model is, these amazing. Video generation like\\nSora, all of this is happening thanks to deep learning,\\nwhich is an approach we\\'ve had since the \\'50s. Certainly\\nnot as old as Bayesian statistics, but similarly, it has\\nbeen able to take off with much larger data sets and\\nmuch more compute.\\nAlex: 16:46 Yeah, yeah. Yeah, yeah, very good point. And I think\\nthat\\'s even more the point in deep learning for sure,\\nbecause Bayesian stats doesn\\'t need the scale, but the\\nway we\\'re doing deep learning for now, definitely need the\\nscale.\\nJon: 16:58 Yeah, yeah. Scale of data.\\nAlex: 17:00 Yeah, yeah, exactly. Yeah, sorry, yeah, the scale, because\\nour two scales, data and computing. Yeah. You\\'re right.\\nJon: 17:05 And for model parameters. So that has actually... I mean,\\ntying back to something you said near the beginning of\\nthis episode, is that actually one of the advantages of\\nBayesian statistics is that you can do it with very few\\ndata. Maybe fewer data than with a frequentist approach\\nor a machine learning approach, because you can bake in\\nyour prior assumptions. And those prior assumptions\\ngive some kind of structure, some kind of framework for\\nyour data to make an impact.\\nAlex: 17:32 Yeah. Yeah, completely.\\nJon: 17:34 And in keeping with the theme of returning to the past to\\nfind golden opportunities, I speak to Dr. Nathan Lambert\\nabout historical influences on contemporary\\nmethodologies. I also managed to sneak in a question\\nabout reinforcement learning from human feedback.\\nNathan is a research scientist for the Allen Institute for\\nAI, and previously built out the RLHF team at Hugging\\nFace. So there was no better person to ask about the lack\\nShow Notes: http://www.superdatascience.com/802 11\\nof robustness in RLHF and how that could impact the\\nfuture development and deployment of AI systems.\\n18:02 Another really cool thing that you\\'ve done related to RLHF\\nis you have traced it back to ancient philosophy and\\nmodern economics. So mentioning Aristotle and von\\nNeumann-Morganstern utility theorem, for example. I\\ndon\\'t really know what the VNM utility theorem is, but\\nhow do these historical foundations influence current\\nmethodologies and what can modern AI research learn\\nfrom these early theories?\\nNathan: 18:30 Yeah. So this is a fun paper with a few colleagues that I\\nstarted working with at Berkeley, and now we\\'re kind of\\nspread out. This is all based on the fact that RL is very\\ndeep field multidisciplinary history, where it goes way\\nback. And then the notion of preference is a very vague\\nthing in economics. And it\\'s like the von NeumannMorganstern theory is a foundational thing that\\nessentially it\\'s like you can express either all behaviors or\\nall goals as probability and expected value distributions,\\nwhich essentially lets you do expected value math over\\npreferences.\\n19:10 And then it led to a bunch of debates on whether or not\\npreferences actually exist and are tractable in any of\\nthese things, or if they\\'re actually measurable or not due\\nto the preference shift over time based on context. So\\nthese are the kinds of things that we take and it\\'s ask a\\nlot of questions on how this impacts the modern RLHF\\nprocess. It\\'s things like is the final model\\'s preferences,\\nwhich is like we\\'re mapping onto very human terms, is\\nthat actually based more on the the base model, which is\\nscraped from the internet than the human preferences\\nthat they get from somewhere like Scale AI.\\n19:46 So it\\'s like if it\\'s based more on the internet crawling than\\nthis million dollar dataset they\\'re getting from Scale AI,\\nShow Notes: http://www.superdatascience.com/802 12\\nit\\'s kind of confusing to the marketing where we\\'re saying\\nwe\\'re learning a preference model, but it might not\\nactually do that much. Is other things like OpenAI now\\nhas a ton of user data and it\\'s like what does the\\neconomics literature say about generating data for\\ntraining that comes from a user context or a professional\\ncontext where someone is paid to do it and they\\'re paid to\\nact in a certain way? And how does all of this mix? So it\\'s\\nreally just a super long list of questions of why we should\\nlook at other social sciences if we\\'re making grand claims\\nabout human preferences and all of these things.\\nJon: 20:26 Nice. Well, fascinating. Tons to dig into there for our\\nlisteners. Final topic that I planned related to RLHF, I\\'m\\nsure it\\'ll come up again organically in the conversation,\\nbut you\\'ve mentioned that RLHF is not even robust to\\nfine-tuning. And so removing the safety layer from models\\nlike GPT-4 and Llama 2 can break down the notion of\\nsafety. Can you elaborate on the implications of this\\nfragility for the future development and deployment of AI\\nsystems?\\nNathan: 20:59 Yeah, so this is a specific line of research. So there\\'s a few\\npapers that showed that if you take a model like Zephyr\\nor Tulu that we were mentioning, if they have safety in\\nthe dataset, if you then go and fine-tune it again on some\\ndifferent tasks, you\\'ll do some of the behaviors that are\\n\"ingrained\" in the model. I honestly think this is a little\\nbit more clickbaity than actually worrisome because it\\'s\\nreally not surprising given that if you just look at the\\namount of compute applied at fine-tuning, we pre-trained\\nthese models for trillions of tokens. And then we apply a\\ncouple billion tokens of compute at fine-tuning.\\n21:36 And it\\'s like we\\'re not changing the weights of the model\\nsubstantially. We\\'re doing a slight nudge, and it makes\\nsense that a slight nudge could be undone at the same\\nway. But if you were to take this to some of the bigger\\nShow Notes: http://www.superdatascience.com/802 13\\nlabs, what you hear is that safety is not just a single\\nartifact thing. Safety is much more about a complete\\nsystem than a model. So open weight models being\\nunsafe or unsafe, I don\\'t consider to be that big of a deal.\\nIt\\'s like if you were to apply them to a free endpoint that\\neveryone on the internet could talk to, then I don\\'t want\\nmy model saying good things about Hitler and all these\\nobvious things.\\n22:09 But if it\\'s a research artifact that you need to spin up\\nGPUs to use yourself, and it\\'s a little bit more... I\\'m more\\nopen to having these diversity of models exist. But if you\\nask [inaudible 00:22:22] or somebody, it\\'s like, \"What\\nhappens... How do you get safety into your model?\" And\\nit\\'s like, it\\'s not just RLHF. You need to have safety at the\\npre-training, any preference model you trained. And then\\nall of these models have a safety filter on the output. So\\nChatGPT, it reads all the text generated from the base\\nmodel, and then there\\'s a go, no go where it will rephrase\\nthe text if it gets a no-go signal, which is like their content\\nmoderation API.\\n22:45 So it\\'s kind of a double. It\\'s the type of thing where\\nresearchers need to market their work, but it\\'s not as big\\nof a detail as I think it is. It\\'s like, okay, I think it has\\ninteresting business downstream things with liability. So\\nit\\'s just like if you want to fine-tune a Llama model, you\\nnormally do that on your own hardware, but OpenAI has\\na fine-tuning API. And if they claim their model is safe,\\nbut any fine-tuning on their API that they then host\\nmakes it unsafe, that seems like more of a business\\nproblem. Which is like, oh, it\\'s a nice way that open\\necosystem might be better off because it breaks the\\nliability chain. But we\\'ll see this research continue to\\nevolve. It\\'s so early in all of these things for a year in.\\nJon: 23:31 All right. That\\'s it for today\\'s In Case You Missed It\\nepisode, to be sure not to miss any of our exciting\\nShow Notes: http://www.superdatascience.com/802 14\\nupcoming episodes. Be sure to subscribe to this podcast\\nif you haven\\'t already. But most importantly, I hope you\\'ll\\njust keep on listening. Until next time, keep on rocking it\\nout there. And I\\'m looking forward to enjoying another\\nround of Super Data Science Podcast with you very soon.')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chroma DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building sample vectorDB\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '5. VectorStores/vectorStores.ipynb'}, page_content='{\\n \"cells\": [\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 1,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"from langchain_community.document_loaders import TextLoader\\\\n\",\\n    \"from langchain_community.vectorstores import FAISS\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 2,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"from langchain_community.embeddings import OllamaEmbeddings\\\\n\",\\n    \"from langchain_text_splitters import CharacterTextSplitter\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 3,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"loader = TextLoader(\\\\\"4. Embedding/super_DS.txt\\\\\")\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 8,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"documents = loader.load()\\\\n\",\\n    \"text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=20)\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 9,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"docs = text_splitter.split_documents(documents)\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 13,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"ollama_embeddings = OllamaEmbeddings(model=\\\\\"gemma2\\\\\")\\\\n\",\\n    \"db = FAISS.from_documents(docs, ollama_embeddings)\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 14,\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"data\": {\\n      \"text/plain\": [\\n       \"[Document(metadata={\\'source\\': \\'4. Embedding/super_DS.txt\\'}, page_content=\\'Show Notes: http://www.superdatascience.com/802 1\\\\\\\\nSDS PODCAST\\\\\\\\nEPISODE 802:\\\\\\\\nIN CASE YOU MISSED\\\\\\\\nIT IN JUNE 2024\\\\\\\\n    Show Notes: http://www.superdatascience.com/802 2\\\\\\\\nJon: 00:02 This is episode number 802, our In Case You Missed it in\\\\\\\\nJune episode.\\\\\\\\n    00:19 Welcome back to the Super Data Science Podcast. I\\\\\\\\\\'m\\\\\\\\nyour host, Jon Krohn. This is an In Case You Missed It\\\\\\\\nepisode that highlights the best parts of conversations we\\\\\\\\nhad on the show in the last month. This first clip you\\\\\\\\\\'ll\\\\\\\\nhear is from my interview with Dr. Jason Yosinski, one of\\\\\\\\nmy all-time favorite AI researchers. We had a great\\\\\\\\nconversation about making your AI and ML models\\\\\\\\nattractive to customers.\\\\\\\\n    00:40 In this clip, I got him to speak from his experience as\\\\\\\\nCEO of the climate technology startup he founded,\\\\\\\\nWindscape AI. This is a great case study if you\\\\\\\\\\'re\\\\\\\\nplanning to launch your own AI models commercially.\\\\\\\\n00:51 I\\\\\\\\\\'m sure that kind of engineering mindset is applicable to\\\\\\\\na lot of our listeners, and it seems like your approach is\\\\\\\\nworking. So EDP, a large Portuguese utility company,\\\\\\\\nrecently selected Windscape as one of nine startups for its\\\\\\\\nrenewable innovation program in Singapore to accelerate\\\\\\\\nthe global energy transition. What opportunities do you\\\\\\\\nsee emerging from Windscape AI\\\\\\\\\\'s participation in this\\\\\\\\nprogram?\\\\\\\\n    Jason: 01:16 Yeah. Well, thanks for mentioning that. We did apply for\\\\\\\\nthis program. We were selected. EDP is a huge utility. I\\\\\\\\nbelieve they\\\\\\\\\\'re the fourth-largest wind owner in the world.\\\\\\\\nSo they own tons and tons of turbines. They generate a\\\\\\\\nlot of wind energy. When I met with folks from EDP, I\\\\\\\\nfound them to be a very forward-looking organization.\\\\\\\\nSometimes you get a big company and they\\\\\\\\\\'re impossibly\\\\\\\\nslow or something, but these folks are really pushing the\\\\\\\\nboundaries, all the boundaries they can, which I thought\\\\\\\\nwas super cool.\\\\\\\\n    Show Notes: http://www.superdatascience.com/802 3\\\\\\\\n01:50 What we hope to get out of it and where that collaboration\\\\\\\\nmight go is to pilot our technology, start working with\\\\\\\\nthem, see how it works on their wind farms around the\\\\\\\\nworld. And then if it does work really well, hopefully we\\\\\\\\nroll out more broadly and we can also maybe use that as\\\\\\\\na demo for new potential customers.\\\\\\\\n    Jon: 02:08 Very cool. So it sounds like EDP is forward-looking. But\\\\\\\\nin general, do you counter resistance or hurdles as you\\\\\\\\ntry to come to energy utilities and say, \\\\\"Hey, you could be\\\\\\\\nusing AI like Windscape\\\\\\\\\\'s to be improving the efficiency of\\\\\\\\nyour systems.\\\\\" Do you encounter resistance or hurdles,\\\\\\\\nor is it relatively straightforward to convince people that\\\\\\\\nyou\\\\\\\\\\'re doing something valuable?\\\\\\\\n    Jason: 02:31 I wouldn\\\\\\\\\\'t say it\\\\\\\\\\'s straightforward. No. Convincing people\\\\\\\\nthat what you\\\\\\\\\\'re doing is valuable is maybe always hard. I\\\\\\\\nwould say saying the words AI or machine learning\\\\\\\\ndoesn\\\\\\\\\\'t immediately open all the doors. It can open some\\\\\\\\ndoors. Some of these companies realize that AI might be\\\\\\\\nrevolutionizing things that happen internally, and they\\\\\\\\\\'re\\\\\\\\nnot quite sure how yet, but maybe we should talk to these\\\\\\\\nrandos from Windscape and see what they think.\\\\\\\\n02:59 It does open some doors, but not all. Just as probably\\\\\\\\nwithin any industry, there are some organizations that\\\\\\\\nare very forward-looking and others early adopters of any\\\\\\\\ntechnology and others that are slower, that are later\\\\\\\\nadopters. They literally, some have told us, \\\\\"We don\\\\\\\\\\'t care\\\\\\\\nwhat you\\\\\\\\\\'re [inaudible 00:03:17], just show us when four\\\\\\\\nother companies are using it and then we\\\\\\\\\\'ll consider\\\\\\\\nusing it because how we work,\\\\\" which is potentially an\\\\\\\\nefficient choice from their perspective.\\\\\\\\n    03:27 There\\\\\\\\\\'s also small energy companies and large energy\\\\\\\\ncompanies, and there\\\\\\\\\\'s a spectrum there of how you sell\\\\\\\\nto these companies and how you get adoption and so on.\\\\\\\\nSo yeah, and convincing everyone, it can be hard. You\\\\\\\\nShow Notes: http://www.superdatascience.com/802 4\\\\\\\\nhave to convince people that your technology will work,\\\\\\\\nthat it won\\\\\\\\\\'t be a huge headache to adopt. The people in\\\\\\\\nthe field need to buy into it. It can\\\\\\\\\\'t ruin their workflow or\\\\\\\\nsomething. It has to be possible to actually integrate. So\\\\\\\\nsome of these systems run software that\\\\\\\\\\'s hard to work\\\\\\\\nwith and simply integrating can be difficult at times. So I\\\\\\\\ndon\\\\\\\\\\'t know, there\\\\\\\\\\'s a lot of factors probably as in any\\\\\\\\nindustry.\\\\\\\\n    Jon: 04:10 Yeah, it makes so much sense. And hopefully I\\\\\\\\\\'m not\\\\\\\\ngoing too deep here, and if I am asking a question that\\\\\\\\nwould give away some kind of IP, just feel free to not\\\\\\\\nanswer this. But it seems to me like in a situation like\\\\\\\\nyours, where you are providing software to hardware\\\\\\\\ncompanies, say the turbine manufacturers, you are not,\\\\\\\\nat least in the immediate term, planning on building, say\\\\\\\\nyour own turbines, your own wind farms.\\\\\\\\n    04:37 You are a software company. You need to be partnering\\\\\\\\nwith turbine manufacturers, with wind farm operators.\\\\\\\\nHow does that work? Are people... I guess maybe your\\\\\\\\nresponse is going to be similar, where there\\\\\\\\\\'s a range of\\\\\\\\nresponses where some turbine manufacturers are\\\\\\\\nrelatively early adopters. They see the potential. They say,\\\\\\\\n\\\\\"Wow, Jason\\\\\\\\\\'s done a lot of amazing research in the past.\\\\\\\\nHe seems like the kind of person we should be working\\\\\\\\nwith to accelerate our roadmap.\\\\\" And then other folks are\\\\\\\\njust like, \\\\\"Yeah, we\\\\\\\\\\'ve got our own team,\\\\\" or I don\\\\\\\\\\'t know.\\\\\\\\nHow does it look for you? Yeah.\\\\\\\\n    Jason: 05:09 What we started this whole endeavor, what we imagined\\\\\\\\nwould happen is we would first build products that we\\\\\\\\nwould sell to people that own the turbines. Why do they\\\\\\\\nwant them? Because our product would help them make\\\\\\\\nmore money starting next month. We help them make\\\\\\\\nmore money. They like our product, we roll out, they tell\\\\\\\\ntheir friends. We deploy to more and more farms, more\\\\\\\\nand more companies. As we start to increase our market\\\\\\\\nShow Notes: http://www.superdatascience.com/802 5\\\\\\\\npenetration in the industry, then much later, turbine\\\\\\\\nmanufacturers would notice and they would say, \\\\\"Hey,\\\\\\\\neveryone\\\\\\\\\\'s using these Windscape people. Maybe we\\\\\\\\nshould talk to them and consider integrating their thing\\\\\\\\noff the factory floor rather than an as aftermarket add-on\\\\\\\\non.\\\\\"\\\\\\\\n    05:48 That\\\\\\\\\\'s still the process we\\\\\\\\\\'re following, although we\\\\\\\\\\'ve\\\\\\\\nbeen surprised that some OEMs are interested in chatting\\\\\\\\nearly. I think they just want to have on their radar what\\\\\\\\\\'s\\\\\\\\ngoing on in the world. And if there\\\\\\\\\\'s any promising\\\\\\\\ntechnology, they want to be there first. So I guess we\\\\\\\\\\'re\\\\\\\\nalready having some of those conversations too.\\\\\\\\nJon: 06:05 And now, we move from offers that tech companies can\\\\\\\\nrefuse to regulations that startups have a duty to follow.\\\\\\\\nIn this clip with the systems engineering and AI\\\\\\\\nregulation guru, Dr. Gina Guillaume-Joseph, she lays out\\\\\\\\nthe evolving regulatory field for AI, which can be difficult\\\\\\\\nto navigate even if you\\\\\\\\\\'ve got the best of intentions.\\\\\\\\nSpecifically, Gina and I talk about the AI Bill of Rights,\\\\\\\\nthe NIST AI regulatory framework, and her work on the\\\\\\\\nMITRE ATLAS.\\\\\\\\n    06:32 Explain for us... You mentioned there, so there\\\\\\\\\\'s the NIST\\\\\\\\nAI risk management framework. So NIST is the National\\\\\\\\nInstitutes of Science and Technology, that may be familiar\\\\\\\\nas an acronym. The NIST thing is something for those of\\\\\\\\nus who have done any deep learning to kind of Hello\\\\\\\\nworld deep learning example involves this handwritten\\\\\\\\ndata set of digits. So it\\\\\\\\\\'s 60,000 handwritten digits done\\\\\\\\nby, if I remember correctly, US postal workers, as well as\\\\\\\\nelementary school students. And so it\\\\\\\\\\'s just each image is\\\\\\\\na different digit. So it\\\\\\\\\\'s some of them are zero, some are\\\\\\\\none, some are two, some are threes, all the way up to\\\\\\\\nnine. And this handwritten dataset was curated initially, I\\\\\\\\nguess in the \\\\\\\\\\'90s, maybe even in the \\\\\\\\\\'80s by NIST.\\\\\\\\nShow Notes: http://www.superdatascience.com/802 6\\\\\\\\n    07:24 And then Yann Le Cun, who\\\\\\\\\\'s one of the most famous AI\\\\\\\\nresearchers of all time, he modified with his research\\\\\\\\nteam at the time, I believe they were AT&T Bell Labs, they\\\\\\\\nmodified that NIST handwritten digit dataset to create the\\\\\\\\nMNIST, modified NIST, handwritten dataset. So I don\\\\\\\\\\'t\\\\\\\\nknow, it\\\\\\\\\\'s a bit of an aside, but that MNIST dataset is\\\\\\\\nprobably familiar to anyone who\\\\\\\\\\'s done any kind of deep\\\\\\\\nlearning at all. And so yeah, so that same organization,\\\\\\\\nNIST, has been around for a long time in the US I don\\\\\\\\\\'t\\\\\\\\nknow how many decades.\\\\\\\\n    07:58 But has been trying to set up frameworks for all different\\\\\\\\nkinds of industries in science and technology, and has\\\\\\\\nnow created this AI risk management framework, which\\\\\\\\nagain, I\\\\\\\\\\'ll have a link to that in the show notes alongside\\\\\\\\nthe AI Bill of Rights. A third framework, I guess, you can\\\\\\\\ncorrect me if I\\\\\\\\\\'m not using the right word there, that you\\\\\\\\nbrought up in your talk that also seems really helpful\\\\\\\\nhere is something called the MITRE ATLAS.\\\\\\\\n    08:26 So I\\\\\\\\\\'ve been trying to, as you\\\\\\\\\\'ve been speaking, dig up\\\\\\\\nwhat MITRE stands for, M-I-T-R-E. It doesn\\\\\\\\\\'t seem like it\\\\\\\\nstands for anything. Can you tell us a bit about MITRE\\\\\\\\nand the MITRE ATLAS and then maybe you can weave\\\\\\\\ntogether these three different things; the AI Bill of Rights,\\\\\\\\nthe NIST AI regulatory framework, as well as MITRE\\\\\\\\nATLAS. And tell us how we can integrate these three\\\\\\\\nframeworks together in order to have a good sense of how\\\\\\\\nto move forward with the AI systems that we built.\\\\\\\\nGina: 08:58 So MITRE is a not-for-profit organization. I worked for\\\\\\\\nthem for 10 years, and they support the federal\\\\\\\\ngovernment across all the federal government agencies to\\\\\\\\nhelp them solve some of the most pressing challenges. So\\\\\\\\nMITRE operates federally funded research and\\\\\\\\ndevelopment centers in support of the federal government\\\\\\\\nto solve problems for a safer world, essentially is what\\\\\\\\nMITRE does. And while at MITRE, I supported multiple\\\\\\\\nShow Notes: http://www.superdatascience.com/802 7\\\\\\\\nagencies; Department of Homeland Security, Social\\\\\\\\nSecurity Administration, Veterans Affairs, Department of\\\\\\\\nDefense, in some of the challenges that they were facing\\\\\\\\nat the time.\\\\\\\\n    09:45 Societal challenges to include when the economy was\\\\\\\\ndoing some downward slides and banks were failing, part\\\\\\\\nof some of the work that I did was at the FDIC, that was\\\\\\\\nwith Booz Allen. But MITRE was involved in other aspects\\\\\\\\nof that as well, to really understand the failures and to\\\\\\\\nfigure out the mitigation strategies to ensure that society\\\\\\\\ndidn\\\\\\\\\\'t feel those impacts as broadly and as strongly.\\\\\\\\n10:24 And MITRE created the ATLAS threat model introduction,\\\\\\\\nthreat model. It\\\\\\\\\\'s this comprehensive coverage of AIspecific adversary tactics techniques that includes realworld observation and reporting. It talks about\\\\\\\\naccessibility and usability of AI alignment with existing\\\\\\\\ncybersecurity frameworks in terms of from an AI\\\\\\\\nperspective. And that community engagement\\\\\\\\ncontribution and the educational resources and training.\\\\\\\\n10:58 So they\\\\\\\\\\'re developing a detailed taxonomy of tactics, of\\\\\\\\ntechniques, of procedures specific to AI systems that\\\\\\\\ncover the entire lifecycle from data collection to model\\\\\\\\ndevelopment and deployment and maintenance. Where\\\\\\\\nthey establish those mechanisms for continuously\\\\\\\\ngathering and updating threat intelligence based on realworld cybersecurity incidents involving AI so that the\\\\\\\\nknowledge base remains current and relevant. So that\\\\\\\\\\'s\\\\\\\\nwhat MITRE is doing it with their MITRE ATLAS\\\\\\\\nframework. And the framework integrates their existing\\\\\\\\nMITRE attack for enterprise framework that shows that\\\\\\\\nthey bring in that consistency and interoperability across\\\\\\\\ncybersecurity efforts as it pertains to AI systems. And\\\\\\\\nthat\\\\\\\\\\'s MITRE ATLAS threat model.\\\\\\\\nShow Notes: http://www.superdatascience.com/802 8\\\\\\\\nJon: 12:01 Terrifically useful context there from Gina. In my next\\\\\\\\nclip, Alex Andorra and I discuss Bayesian statistics,\\\\\\\\nnamely why being able to crunch larger and larger data\\\\\\\\nsets has helped us to use a powerful modeling technique\\\\\\\\nthat was originally devised centuries ago.\\\\\\\\n12:15 In addition to the podcast, also, I mentioned this at the\\\\\\\\noutset, I said that you\\\\\\\\\\'re co-founder and principal data\\\\\\\\nscientist of the popular Bayesian stats modeling platform,\\\\\\\\nPyMC. So like many things in data science, it\\\\\\\\\\'s uppercase\\\\\\\\nP, lowercase Y, for Python. What\\\\\\\\\\'s the MC? PyMC, one\\\\\\\\nword, M and the C are capitalized.\\\\\\\\nAlex: 12:38 So it\\\\\\\\\\'s very confusing because it stands for Python and\\\\\\\\nthen MC is Monte Carlo. So I understand, but why Monte\\\\\\\\nCarlo? It\\\\\\\\\\'s because it comes from Markov chain Monte\\\\\\\\nCarlo. So actually, it should be PyMCMC or PyMC\\\\\\\\nsquared, which is what I\\\\\\\\\\'m saying since the beginning.\\\\\\\\nBut anyways, yeah, it\\\\\\\\\\'s actually PyMC squared. So for\\\\\\\\nMarkov chain Monte Carlo and Markov chain Monte Carlo\\\\\\\\nis one of the main ways... All the algorithms now, new\\\\\\\\nones, but the blockbuster algorithm to run Bayesian\\\\\\\\nmodels is to use MCMC.\\\\\\\\nJon: 13:21 So in the same way that stochastic gradient descent is\\\\\\\\nlike the defacto standard for finding your model weights\\\\\\\\nin machine learning, Markov chain Monte Carlo is the\\\\\\\\nstandard way of doing it with the Bayesian network?\\\\\\\\nAlex: 13:36 Yeah. Yeah, yeah. And so now there are newer versions,\\\\\\\\nmore efficient versions. That\\\\\\\\\\'s basically the name of the\\\\\\\\ngame, making the algorithm more and more efficient. But\\\\\\\\nthe first algorithm dates back... I think it was actually\\\\\\\\ninvented during the project Manhattan. So during World\\\\\\\\nWar II.\\\\\\\\nJon: 13:57 Theme of the day.\\\\\\\\nShow Notes: http://www.superdatascience.com/802 9\\\\\\\\nAlex: 13:58 Yeah. And lots of physicists actually, statistical physics is\\\\\\\\na field that\\\\\\\\\\'s contributed a lot to MCMC. And so yeah,\\\\\\\\nphysicists who came to the field of statistics and trying to\\\\\\\\nmake the algorithms more efficient for their models. So\\\\\\\\nthey have contributed a lot. The field of physics has\\\\\\\\ncontributed a lot of big names and people to great leaps\\\\\\\\ninto the realm of more efficient algorithms. And so, I don\\\\\\\\\\'t\\\\\\\\nknow who your audience is, but that may sound boring.\\\\\\\\n14:37 Yeah, the algorithm, it\\\\\\\\\\'s like the workhorse, but it\\\\\\\\\\'s\\\\\\\\nextremely powerful. And that\\\\\\\\\\'s also one of the main\\\\\\\\nreasons why Bayesian statistics are increasing in\\\\\\\\npopularity lately, because I\\\\\\\\\\'m going to argue that it\\\\\\\\\\'s\\\\\\\\nalways been the best framework to do statistics, to do\\\\\\\\nscience. But it was hard to do with pen and paper\\\\\\\\nbecause the problem is that you have a huge, nasty\\\\\\\\nintegral on the numerator, on the denominator, sorry.\\\\\\\\nAnd this integral is not computable by pen and paper. So\\\\\\\\nfor a long, long time, Bayesian statistics combined two\\\\\\\\nfeatures like campaigns, PR campaigns. Bayesian\\\\\\\\nstatistics was relegated to the margins because it was just\\\\\\\\nsuper hard to do.\\\\\\\\n15:31 And so for other problems, other than very trivial ones, it\\\\\\\\nwas not very applicable. But now with the advent of\\\\\\\\npersonal computing, you have these incredible\\\\\\\\nalgorithms. So now most of the time, it\\\\\\\\\\'s HMC, Hamilton\\\\\\\\nand Monte Carlo. That\\\\\\\\\\'s what we use under the hood with\\\\\\\\nPyMC. But if you stand, if you use [inaudible 00:15:54] ,\\\\\\\\nit\\\\\\\\\\'s the same. And thanks to these algorithms, now we\\\\\\\\ncan make extremely powerful models because we can\\\\\\\\napproximate the [inaudible 00:16:03] distributions thanks\\\\\\\\nto, well, computer\\\\\\\\\\'s computing power. A computer is very\\\\\\\\ngood at computing. I think that\\\\\\\\\\'s why it\\\\\\\\\\'s called that.\\\\\\\\nJon: 16:15 Yes. And so that reminds me of deep learning. It\\\\\\\\\\'s a\\\\\\\\nsimilar kind of thing where the applications we have\\\\\\\\ntoday, like your ChatGPT or whatever your favorite large\\\\\\\\nShow Notes: http://www.superdatascience.com/802 10\\\\\\\\nlanguage model is, these amazing. Video generation like\\\\\\\\nSora, all of this is happening thanks to deep learning,\\\\\\\\nwhich is an approach we\\\\\\\\\\'ve had since the \\\\\\\\\\'50s. Certainly\\\\\\\\nnot as old as Bayesian statistics, but similarly, it has\\\\\\\\nbeen able to take off with much larger data sets and\\\\\\\\nmuch more compute.\\\\\\\\nAlex: 16:46 Yeah, yeah. Yeah, yeah, very good point. And I think\\\\\\\\nthat\\\\\\\\\\'s even more the point in deep learning for sure,\\\\\\\\nbecause Bayesian stats doesn\\\\\\\\\\'t need the scale, but the\\\\\\\\nway we\\\\\\\\\\'re doing deep learning for now, definitely need the\\\\\\\\nscale.\\\\\\\\nJon: 16:58 Yeah, yeah. Scale of data.\\\\\\\\nAlex: 17:00 Yeah, yeah, exactly. Yeah, sorry, yeah, the scale, because\\\\\\\\nour two scales, data and computing. Yeah. You\\\\\\\\\\'re right.\\\\\\\\nJon: 17:05 And for model parameters. So that has actually... I mean,\\\\\\\\ntying back to something you said near the beginning of\\\\\\\\nthis episode, is that actually one of the advantages of\\\\\\\\nBayesian statistics is that you can do it with very few\\\\\\\\ndata. Maybe fewer data than with a frequentist approach\\\\\\\\nor a machine learning approach, because you can bake in\\\\\\\\nyour prior assumptions. And those prior assumptions\\\\\\\\ngive some kind of structure, some kind of framework for\\\\\\\\nyour data to make an impact.\\\\\\\\nAlex: 17:32 Yeah. Yeah, completely.\\\\\\\\nJon: 17:34 And in keeping with the theme of returning to the past to\\\\\\\\nfind golden opportunities, I speak to Dr. Nathan Lambert\\\\\\\\nabout historical influences on contemporary\\\\\\\\nmethodologies. I also managed to sneak in a question\\\\\\\\nabout reinforcement learning from human feedback.\\\\\\\\nNathan is a research scientist for the Allen Institute for\\\\\\\\nAI, and previously built out the RLHF team at Hugging\\\\\\\\nFace. So there was no better person to ask about the lack\\\\\\\\nShow Notes: http://www.superdatascience.com/802 11\\\\\\\\nof robustness in RLHF and how that could impact the\\\\\\\\nfuture development and deployment of AI systems.\\\\\\\\n18:02 Another really cool thing that you\\\\\\\\\\'ve done related to RLHF\\\\\\\\nis you have traced it back to ancient philosophy and\\\\\\\\nmodern economics. So mentioning Aristotle and von\\\\\\\\nNeumann-Morganstern utility theorem, for example. I\\\\\\\\ndon\\\\\\\\\\'t really know what the VNM utility theorem is, but\\\\\\\\nhow do these historical foundations influence current\\\\\\\\nmethodologies and what can modern AI research learn\\\\\\\\nfrom these early theories?\\\\\\\\nNathan: 18:30 Yeah. So this is a fun paper with a few colleagues that I\\\\\\\\nstarted working with at Berkeley, and now we\\\\\\\\\\'re kind of\\\\\\\\nspread out. This is all based on the fact that RL is very\\\\\\\\ndeep field multidisciplinary history, where it goes way\\\\\\\\nback. And then the notion of preference is a very vague\\\\\\\\nthing in economics. And it\\\\\\\\\\'s like the von NeumannMorganstern theory is a foundational thing that\\\\\\\\nessentially it\\\\\\\\\\'s like you can express either all behaviors or\\\\\\\\nall goals as probability and expected value distributions,\\\\\\\\nwhich essentially lets you do expected value math over\\\\\\\\npreferences.\\\\\\\\n19:10 And then it led to a bunch of debates on whether or not\\\\\\\\npreferences actually exist and are tractable in any of\\\\\\\\nthese things, or if they\\\\\\\\\\'re actually measurable or not due\\\\\\\\nto the preference shift over time based on context. So\\\\\\\\nthese are the kinds of things that we take and it\\\\\\\\\\'s ask a\\\\\\\\nlot of questions on how this impacts the modern RLHF\\\\\\\\nprocess. It\\\\\\\\\\'s things like is the final model\\\\\\\\\\'s preferences,\\\\\\\\nwhich is like we\\\\\\\\\\'re mapping onto very human terms, is\\\\\\\\nthat actually based more on the the base model, which is\\\\\\\\nscraped from the internet than the human preferences\\\\\\\\nthat they get from somewhere like Scale AI.\\\\\\\\n19:46 So it\\\\\\\\\\'s like if it\\\\\\\\\\'s based more on the internet crawling than\\\\\\\\nthis million dollar dataset they\\\\\\\\\\'re getting from Scale AI,\\\\\\\\nShow Notes: http://www.superdatascience.com/802 12\\\\\\\\nit\\\\\\\\\\'s kind of confusing to the marketing where we\\\\\\\\\\'re saying\\\\\\\\nwe\\\\\\\\\\'re learning a preference model, but it might not\\\\\\\\nactually do that much. Is other things like OpenAI now\\\\\\\\nhas a ton of user data and it\\\\\\\\\\'s like what does the\\\\\\\\neconomics literature say about generating data for\\\\\\\\ntraining that comes from a user context or a professional\\\\\\\\ncontext where someone is paid to do it and they\\\\\\\\\\'re paid to\\\\\\\\nact in a certain way? And how does all of this mix? So it\\\\\\\\\\'s\\\\\\\\nreally just a super long list of questions of why we should\\\\\\\\nlook at other social sciences if we\\\\\\\\\\'re making grand claims\\\\\\\\nabout human preferences and all of these things.\\\\\\\\nJon: 20:26 Nice. Well, fascinating. Tons to dig into there for our\\\\\\\\nlisteners. Final topic that I planned related to RLHF, I\\\\\\\\\\'m\\\\\\\\nsure it\\\\\\\\\\'ll come up again organically in the conversation,\\\\\\\\nbut you\\\\\\\\\\'ve mentioned that RLHF is not even robust to\\\\\\\\nfine-tuning. And so removing the safety layer from models\\\\\\\\nlike GPT-4 and Llama 2 can break down the notion of\\\\\\\\nsafety. Can you elaborate on the implications of this\\\\\\\\nfragility for the future development and deployment of AI\\\\\\\\nsystems?\\\\\\\\nNathan: 20:59 Yeah, so this is a specific line of research. So there\\\\\\\\\\'s a few\\\\\\\\npapers that showed that if you take a model like Zephyr\\\\\\\\nor Tulu that we were mentioning, if they have safety in\\\\\\\\nthe dataset, if you then go and fine-tune it again on some\\\\\\\\ndifferent tasks, you\\\\\\\\\\'ll do some of the behaviors that are\\\\\\\\n\\\\\"ingrained\\\\\" in the model. I honestly think this is a little\\\\\\\\nbit more clickbaity than actually worrisome because it\\\\\\\\\\'s\\\\\\\\nreally not surprising given that if you just look at the\\\\\\\\namount of compute applied at fine-tuning, we pre-trained\\\\\\\\nthese models for trillions of tokens. And then we apply a\\\\\\\\ncouple billion tokens of compute at fine-tuning.\\\\\\\\n21:36 And it\\\\\\\\\\'s like we\\\\\\\\\\'re not changing the weights of the model\\\\\\\\nsubstantially. We\\\\\\\\\\'re doing a slight nudge, and it makes\\\\\\\\nsense that a slight nudge could be undone at the same\\\\\\\\nway. But if you were to take this to some of the bigger\\\\\\\\nShow Notes: http://www.superdatascience.com/802 13\\\\\\\\nlabs, what you hear is that safety is not just a single\\\\\\\\nartifact thing. Safety is much more about a complete\\\\\\\\nsystem than a model. So open weight models being\\\\\\\\nunsafe or unsafe, I don\\\\\\\\\\'t consider to be that big of a deal.\\\\\\\\nIt\\\\\\\\\\'s like if you were to apply them to a free endpoint that\\\\\\\\neveryone on the internet could talk to, then I don\\\\\\\\\\'t want\\\\\\\\nmy model saying good things about Hitler and all these\\\\\\\\nobvious things.\\\\\\\\n22:09 But if it\\\\\\\\\\'s a research artifact that you need to spin up\\\\\\\\nGPUs to use yourself, and it\\\\\\\\\\'s a little bit more... I\\\\\\\\\\'m more\\\\\\\\nopen to having these diversity of models exist. But if you\\\\\\\\nask [inaudible 00:22:22] or somebody, it\\\\\\\\\\'s like, \\\\\"What\\\\\\\\nhappens... How do you get safety into your model?\\\\\" And\\\\\\\\nit\\\\\\\\\\'s like, it\\\\\\\\\\'s not just RLHF. You need to have safety at the\\\\\\\\npre-training, any preference model you trained. And then\\\\\\\\nall of these models have a safety filter on the output. So\\\\\\\\nChatGPT, it reads all the text generated from the base\\\\\\\\nmodel, and then there\\\\\\\\\\'s a go, no go where it will rephrase\\\\\\\\nthe text if it gets a no-go signal, which is like their content\\\\\\\\nmoderation API.\\\\\\\\n22:45 So it\\\\\\\\\\'s kind of a double. It\\\\\\\\\\'s the type of thing where\\\\\\\\nresearchers need to market their work, but it\\\\\\\\\\'s not as big\\\\\\\\nof a detail as I think it is. It\\\\\\\\\\'s like, okay, I think it has\\\\\\\\ninteresting business downstream things with liability. So\\\\\\\\nit\\\\\\\\\\'s just like if you want to fine-tune a Llama model, you\\\\\\\\nnormally do that on your own hardware, but OpenAI has\\\\\\\\na fine-tuning API. And if they claim their model is safe,\\\\\\\\nbut any fine-tuning on their API that they then host\\\\\\\\nmakes it unsafe, that seems like more of a business\\\\\\\\nproblem. Which is like, oh, it\\\\\\\\\\'s a nice way that open\\\\\\\\necosystem might be better off because it breaks the\\\\\\\\nliability chain. But we\\\\\\\\\\'ll see this research continue to\\\\\\\\nevolve. It\\\\\\\\\\'s so early in all of these things for a year in.\\\\\\\\nJon: 23:31 All right. That\\\\\\\\\\'s it for today\\\\\\\\\\'s In Case You Missed It\\\\\\\\nepisode, to be sure not to miss any of our exciting\\\\\\\\nShow Notes: http://www.superdatascience.com/802 14\\\\\\\\nupcoming episodes. Be sure to subscribe to this podcast\\\\\\\\nif you haven\\\\\\\\\\'t already. But most importantly, I hope you\\\\\\\\\\'ll\\\\\\\\njust keep on listening. Until next time, keep on rocking it\\\\\\\\nout there. And I\\\\\\\\\\'m looking forward to enjoying another\\\\\\\\nround of Super Data Science Podcast with you very soon.\\')]\"\\n      ]\\n     },\\n     \"execution_count\": 14,\\n     \"metadata\": {},\\n     \"output_type\": \"execute_result\"\\n    }\\n   ],\\n   \"source\": [\\n    \"q1 = \\\\\"What is EDP?\\\\\"\\\\n\",\\n    \"query_result = db.similarity_search(q1)\\\\n\",\\n    \"query_result\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"## Retriever\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 17,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"retriever = db.as_retriever()\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 20,\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"data\": {\\n      \"text/plain\": [\\n       \"\\'Show Notes: http://www.superdatascience.com/802 1\\\\\\\\nSDS PODCAST\\\\\\\\nEPISODE 802:\\\\\\\\nIN CASE YOU MISSED\\\\\\\\nIT IN JUNE 2024\\\\\\\\n    Show Notes: http://www.superdatascience.com/802 2\\\\\\\\nJon: 00:02 This is episode number 802, our In Case You Missed it in\\\\\\\\nJune episode.\\\\\\\\n    00:19 Welcome back to the Super Data Science Podcast. I\\\\\\\\\\'m\\\\\\\\nyour host, Jon Krohn. This is an In Case You Missed It\\\\\\\\nepisode that highlights the best parts of conversations we\\\\\\\\nhad on the show in the last month. This first clip you\\\\\\\\\\'ll\\\\\\\\nhear is from my interview with Dr. Jason Yosinski, one of\\\\\\\\nmy all-time favorite AI researchers. We had a great\\\\\\\\nconversation about making your AI and ML models\\\\\\\\nattractive to customers.\\\\\\\\n    00:40 In this clip, I got him to speak from his experience as\\\\\\\\nCEO of the climate technology startup he founded,\\\\\\\\nWindscape AI. This is a great case study if you\\\\\\\\\\'re\\\\\\\\nplanning to launch your own AI models commercially.\\\\\\\\n00:51 I\\\\\\\\\\'m sure that kind of engineering mindset is applicable to\\\\\\\\na lot of our listeners, and it seems like your approach is\\\\\\\\nworking. So EDP, a large Portuguese utility company,\\\\\\\\nrecently selected Windscape as one of nine startups for its\\\\\\\\nrenewable innovation program in Singapore to accelerate\\\\\\\\nthe global energy transition. What opportunities do you\\\\\\\\nsee emerging from Windscape AI\\\\\\\\\\'s participation in this\\\\\\\\nprogram?\\\\\\\\n    Jason: 01:16 Yeah. Well, thanks for mentioning that. We did apply for\\\\\\\\nthis program. We were selected. EDP is a huge utility. I\\\\\\\\nbelieve they\\\\\\\\\\'re the fourth-largest wind owner in the world.\\\\\\\\nSo they own tons and tons of turbines. They generate a\\\\\\\\nlot of wind energy. When I met with folks from EDP, I\\\\\\\\nfound them to be a very forward-looking organization.\\\\\\\\nSometimes you get a big company and they\\\\\\\\\\'re impossibly\\\\\\\\nslow or something, but these folks are really pushing the\\\\\\\\nboundaries, all the boundaries they can, which I thought\\\\\\\\nwas super cool.\\\\\\\\n    Show Notes: http://www.superdatascience.com/802 3\\\\\\\\n01:50 What we hope to get out of it and where that collaboration\\\\\\\\nmight go is to pilot our technology, start working with\\\\\\\\nthem, see how it works on their wind farms around the\\\\\\\\nworld. And then if it does work really well, hopefully we\\\\\\\\nroll out more broadly and we can also maybe use that as\\\\\\\\na demo for new potential customers.\\\\\\\\n    Jon: 02:08 Very cool. So it sounds like EDP is forward-looking. But\\\\\\\\nin general, do you counter resistance or hurdles as you\\\\\\\\ntry to come to energy utilities and say, \\\\\"Hey, you could be\\\\\\\\nusing AI like Windscape\\\\\\\\\\'s to be improving the efficiency of\\\\\\\\nyour systems.\\\\\" Do you encounter resistance or hurdles,\\\\\\\\nor is it relatively straightforward to convince people that\\\\\\\\nyou\\\\\\\\\\'re doing something valuable?\\\\\\\\n    Jason: 02:31 I wouldn\\\\\\\\\\'t say it\\\\\\\\\\'s straightforward. No. Convincing people\\\\\\\\nthat what you\\\\\\\\\\'re doing is valuable is maybe always hard. I\\\\\\\\nwould say saying the words AI or machine learning\\\\\\\\ndoesn\\\\\\\\\\'t immediately open all the doors. It can open some\\\\\\\\ndoors. Some of these companies realize that AI might be\\\\\\\\nrevolutionizing things that happen internally, and they\\\\\\\\\\'re\\\\\\\\nnot quite sure how yet, but maybe we should talk to these\\\\\\\\nrandos from Windscape and see what they think.\\\\\\\\n02:59 It does open some doors, but not all. Just as probably\\\\\\\\nwithin any industry, there are some organizations that\\\\\\\\nare very forward-looking and others early adopters of any\\\\\\\\ntechnology and others that are slower, that are later\\\\\\\\nadopters. They literally, some have told us, \\\\\"We don\\\\\\\\\\'t care\\\\\\\\nwhat you\\\\\\\\\\'re [inaudible 00:03:17], just show us when four\\\\\\\\nother companies are using it and then we\\\\\\\\\\'ll consider\\\\\\\\nusing it because how we work,\\\\\" which is potentially an\\\\\\\\nefficient choice from their perspective.\\\\\\\\n    03:27 There\\\\\\\\\\'s also small energy companies and large energy\\\\\\\\ncompanies, and there\\\\\\\\\\'s a spectrum there of how you sell\\\\\\\\nto these companies and how you get adoption and so on.\\\\\\\\nSo yeah, and convincing everyone, it can be hard. You\\\\\\\\nShow Notes: http://www.superdatascience.com/802 4\\\\\\\\nhave to convince people that your technology will work,\\\\\\\\nthat it won\\\\\\\\\\'t be a huge headache to adopt. The people in\\\\\\\\nthe field need to buy into it. It can\\\\\\\\\\'t ruin their workflow or\\\\\\\\nsomething. It has to be possible to actually integrate. So\\\\\\\\nsome of these systems run software that\\\\\\\\\\'s hard to work\\\\\\\\nwith and simply integrating can be difficult at times. So I\\\\\\\\ndon\\\\\\\\\\'t know, there\\\\\\\\\\'s a lot of factors probably as in any\\\\\\\\nindustry.\\\\\\\\n    Jon: 04:10 Yeah, it makes so much sense. And hopefully I\\\\\\\\\\'m not\\\\\\\\ngoing too deep here, and if I am asking a question that\\\\\\\\nwould give away some kind of IP, just feel free to not\\\\\\\\nanswer this. But it seems to me like in a situation like\\\\\\\\nyours, where you are providing software to hardware\\\\\\\\ncompanies, say the turbine manufacturers, you are not,\\\\\\\\nat least in the immediate term, planning on building, say\\\\\\\\nyour own turbines, your own wind farms.\\\\\\\\n    04:37 You are a software company. You need to be partnering\\\\\\\\nwith turbine manufacturers, with wind farm operators.\\\\\\\\nHow does that work? Are people... I guess maybe your\\\\\\\\nresponse is going to be similar, where there\\\\\\\\\\'s a range of\\\\\\\\nresponses where some turbine manufacturers are\\\\\\\\nrelatively early adopters. They see the potential. They say,\\\\\\\\n\\\\\"Wow, Jason\\\\\\\\\\'s done a lot of amazing research in the past.\\\\\\\\nHe seems like the kind of person we should be working\\\\\\\\nwith to accelerate our roadmap.\\\\\" And then other folks are\\\\\\\\njust like, \\\\\"Yeah, we\\\\\\\\\\'ve got our own team,\\\\\" or I don\\\\\\\\\\'t know.\\\\\\\\nHow does it look for you? Yeah.\\\\\\\\n    Jason: 05:09 What we started this whole endeavor, what we imagined\\\\\\\\nwould happen is we would first build products that we\\\\\\\\nwould sell to people that own the turbines. Why do they\\\\\\\\nwant them? Because our product would help them make\\\\\\\\nmore money starting next month. We help them make\\\\\\\\nmore money. They like our product, we roll out, they tell\\\\\\\\ntheir friends. We deploy to more and more farms, more\\\\\\\\nand more companies. As we start to increase our market\\\\\\\\nShow Notes: http://www.superdatascience.com/802 5\\\\\\\\npenetration in the industry, then much later, turbine\\\\\\\\nmanufacturers would notice and they would say, \\\\\"Hey,\\\\\\\\neveryone\\\\\\\\\\'s using these Windscape people. Maybe we\\\\\\\\nshould talk to them and consider integrating their thing\\\\\\\\noff the factory floor rather than an as aftermarket add-on\\\\\\\\non.\\\\\"\\\\\\\\n    05:48 That\\\\\\\\\\'s still the process we\\\\\\\\\\'re following, although we\\\\\\\\\\'ve\\\\\\\\nbeen surprised that some OEMs are interested in chatting\\\\\\\\nearly. I think they just want to have on their radar what\\\\\\\\\\'s\\\\\\\\ngoing on in the world. And if there\\\\\\\\\\'s any promising\\\\\\\\ntechnology, they want to be there first. So I guess we\\\\\\\\\\'re\\\\\\\\nalready having some of those conversations too.\\\\\\\\nJon: 06:05 And now, we move from offers that tech companies can\\\\\\\\nrefuse to regulations that startups have a duty to follow.\\\\\\\\nIn this clip with the systems engineering and AI\\\\\\\\nregulation guru, Dr. Gina Guillaume-Joseph, she lays out\\\\\\\\nthe evolving regulatory field for AI, which can be difficult\\\\\\\\nto navigate even if you\\\\\\\\\\'ve got the best of intentions.\\\\\\\\nSpecifically, Gina and I talk about the AI Bill of Rights,\\\\\\\\nthe NIST AI regulatory framework, and her work on the\\\\\\\\nMITRE ATLAS.\\\\\\\\n    06:32 Explain for us... You mentioned there, so there\\\\\\\\\\'s the NIST\\\\\\\\nAI risk management framework. So NIST is the National\\\\\\\\nInstitutes of Science and Technology, that may be familiar\\\\\\\\nas an acronym. The NIST thing is something for those of\\\\\\\\nus who have done any deep learning to kind of Hello\\\\\\\\nworld deep learning example involves this handwritten\\\\\\\\ndata set of digits. So it\\\\\\\\\\'s 60,000 handwritten digits done\\\\\\\\nby, if I remember correctly, US postal workers, as well as\\\\\\\\nelementary school students. And so it\\\\\\\\\\'s just each image is\\\\\\\\na different digit. So it\\\\\\\\\\'s some of them are zero, some are\\\\\\\\none, some are two, some are threes, all the way up to\\\\\\\\nnine. And this handwritten dataset was curated initially, I\\\\\\\\nguess in the \\\\\\\\\\'90s, maybe even in the \\\\\\\\\\'80s by NIST.\\\\\\\\nShow Notes: http://www.superdatascience.com/802 6\\\\\\\\n    07:24 And then Yann Le Cun, who\\\\\\\\\\'s one of the most famous AI\\\\\\\\nresearchers of all time, he modified with his research\\\\\\\\nteam at the time, I believe they were AT&T Bell Labs, they\\\\\\\\nmodified that NIST handwritten digit dataset to create the\\\\\\\\nMNIST, modified NIST, handwritten dataset. So I don\\\\\\\\\\'t\\\\\\\\nknow, it\\\\\\\\\\'s a bit of an aside, but that MNIST dataset is\\\\\\\\nprobably familiar to anyone who\\\\\\\\\\'s done any kind of deep\\\\\\\\nlearning at all. And so yeah, so that same organization,\\\\\\\\nNIST, has been around for a long time in the US I don\\\\\\\\\\'t\\\\\\\\nknow how many decades.\\\\\\\\n    07:58 But has been trying to set up frameworks for all different\\\\\\\\nkinds of industries in science and technology, and has\\\\\\\\nnow created this AI risk management framework, which\\\\\\\\nagain, I\\\\\\\\\\'ll have a link to that in the show notes alongside\\\\\\\\nthe AI Bill of Rights. A third framework, I guess, you can\\\\\\\\ncorrect me if I\\\\\\\\\\'m not using the right word there, that you\\\\\\\\nbrought up in your talk that also seems really helpful\\\\\\\\nhere is something called the MITRE ATLAS.\\\\\\\\n    08:26 So I\\\\\\\\\\'ve been trying to, as you\\\\\\\\\\'ve been speaking, dig up\\\\\\\\nwhat MITRE stands for, M-I-T-R-E. It doesn\\\\\\\\\\'t seem like it\\\\\\\\nstands for anything. Can you tell us a bit about MITRE\\\\\\\\nand the MITRE ATLAS and then maybe you can weave\\\\\\\\ntogether these three different things; the AI Bill of Rights,\\\\\\\\nthe NIST AI regulatory framework, as well as MITRE\\\\\\\\nATLAS. And tell us how we can integrate these three\\\\\\\\nframeworks together in order to have a good sense of how\\\\\\\\nto move forward with the AI systems that we built.\\\\\\\\nGina: 08:58 So MITRE is a not-for-profit organization. I worked for\\\\\\\\nthem for 10 years, and they support the federal\\\\\\\\ngovernment across all the federal government agencies to\\\\\\\\nhelp them solve some of the most pressing challenges. So\\\\\\\\nMITRE operates federally funded research and\\\\\\\\ndevelopment centers in support of the federal government\\\\\\\\nto solve problems for a safer world, essentially is what\\\\\\\\nMITRE does. And while at MITRE, I supported multiple\\\\\\\\nShow Notes: http://www.superdatascience.com/802 7\\\\\\\\nagencies; Department of Homeland Security, Social\\\\\\\\nSecurity Administration, Veterans Affairs, Department of\\\\\\\\nDefense, in some of the challenges that they were facing\\\\\\\\nat the time.\\\\\\\\n    09:45 Societal challenges to include when the economy was\\\\\\\\ndoing some downward slides and banks were failing, part\\\\\\\\nof some of the work that I did was at the FDIC, that was\\\\\\\\nwith Booz Allen. But MITRE was involved in other aspects\\\\\\\\nof that as well, to really understand the failures and to\\\\\\\\nfigure out the mitigation strategies to ensure that society\\\\\\\\ndidn\\\\\\\\\\'t feel those impacts as broadly and as strongly.\\\\\\\\n10:24 And MITRE created the ATLAS threat model introduction,\\\\\\\\nthreat model. It\\\\\\\\\\'s this comprehensive coverage of AIspecific adversary tactics techniques that includes realworld observation and reporting. It talks about\\\\\\\\naccessibility and usability of AI alignment with existing\\\\\\\\ncybersecurity frameworks in terms of from an AI\\\\\\\\nperspective. And that community engagement\\\\\\\\ncontribution and the educational resources and training.\\\\\\\\n10:58 So they\\\\\\\\\\'re developing a detailed taxonomy of tactics, of\\\\\\\\ntechniques, of procedures specific to AI systems that\\\\\\\\ncover the entire lifecycle from data collection to model\\\\\\\\ndevelopment and deployment and maintenance. Where\\\\\\\\nthey establish those mechanisms for continuously\\\\\\\\ngathering and updating threat intelligence based on realworld cybersecurity incidents involving AI so that the\\\\\\\\nknowledge base remains current and relevant. So that\\\\\\\\\\'s\\\\\\\\nwhat MITRE is doing it with their MITRE ATLAS\\\\\\\\nframework. And the framework integrates their existing\\\\\\\\nMITRE attack for enterprise framework that shows that\\\\\\\\nthey bring in that consistency and interoperability across\\\\\\\\ncybersecurity efforts as it pertains to AI systems. And\\\\\\\\nthat\\\\\\\\\\'s MITRE ATLAS threat model.\\\\\\\\nShow Notes: http://www.superdatascience.com/802 8\\\\\\\\nJon: 12:01 Terrifically useful context there from Gina. In my next\\\\\\\\nclip, Alex Andorra and I discuss Bayesian statistics,\\\\\\\\nnamely why being able to crunch larger and larger data\\\\\\\\nsets has helped us to use a powerful modeling technique\\\\\\\\nthat was originally devised centuries ago.\\\\\\\\n12:15 In addition to the podcast, also, I mentioned this at the\\\\\\\\noutset, I said that you\\\\\\\\\\'re co-founder and principal data\\\\\\\\nscientist of the popular Bayesian stats modeling platform,\\\\\\\\nPyMC. So like many things in data science, it\\\\\\\\\\'s uppercase\\\\\\\\nP, lowercase Y, for Python. What\\\\\\\\\\'s the MC? PyMC, one\\\\\\\\nword, M and the C are capitalized.\\\\\\\\nAlex: 12:38 So it\\\\\\\\\\'s very confusing because it stands for Python and\\\\\\\\nthen MC is Monte Carlo. So I understand, but why Monte\\\\\\\\nCarlo? It\\\\\\\\\\'s because it comes from Markov chain Monte\\\\\\\\nCarlo. So actually, it should be PyMCMC or PyMC\\\\\\\\nsquared, which is what I\\\\\\\\\\'m saying since the beginning.\\\\\\\\nBut anyways, yeah, it\\\\\\\\\\'s actually PyMC squared. So for\\\\\\\\nMarkov chain Monte Carlo and Markov chain Monte Carlo\\\\\\\\nis one of the main ways... All the algorithms now, new\\\\\\\\nones, but the blockbuster algorithm to run Bayesian\\\\\\\\nmodels is to use MCMC.\\\\\\\\nJon: 13:21 So in the same way that stochastic gradient descent is\\\\\\\\nlike the defacto standard for finding your model weights\\\\\\\\nin machine learning, Markov chain Monte Carlo is the\\\\\\\\nstandard way of doing it with the Bayesian network?\\\\\\\\nAlex: 13:36 Yeah. Yeah, yeah. And so now there are newer versions,\\\\\\\\nmore efficient versions. That\\\\\\\\\\'s basically the name of the\\\\\\\\ngame, making the algorithm more and more efficient. But\\\\\\\\nthe first algorithm dates back... I think it was actually\\\\\\\\ninvented during the project Manhattan. So during World\\\\\\\\nWar II.\\\\\\\\nJon: 13:57 Theme of the day.\\\\\\\\nShow Notes: http://www.superdatascience.com/802 9\\\\\\\\nAlex: 13:58 Yeah. And lots of physicists actually, statistical physics is\\\\\\\\na field that\\\\\\\\\\'s contributed a lot to MCMC. And so yeah,\\\\\\\\nphysicists who came to the field of statistics and trying to\\\\\\\\nmake the algorithms more efficient for their models. So\\\\\\\\nthey have contributed a lot. The field of physics has\\\\\\\\ncontributed a lot of big names and people to great leaps\\\\\\\\ninto the realm of more efficient algorithms. And so, I don\\\\\\\\\\'t\\\\\\\\nknow who your audience is, but that may sound boring.\\\\\\\\n14:37 Yeah, the algorithm, it\\\\\\\\\\'s like the workhorse, but it\\\\\\\\\\'s\\\\\\\\nextremely powerful. And that\\\\\\\\\\'s also one of the main\\\\\\\\nreasons why Bayesian statistics are increasing in\\\\\\\\npopularity lately, because I\\\\\\\\\\'m going to argue that it\\\\\\\\\\'s\\\\\\\\nalways been the best framework to do statistics, to do\\\\\\\\nscience. But it was hard to do with pen and paper\\\\\\\\nbecause the problem is that you have a huge, nasty\\\\\\\\nintegral on the numerator, on the denominator, sorry.\\\\\\\\nAnd this integral is not computable by pen and paper. So\\\\\\\\nfor a long, long time, Bayesian statistics combined two\\\\\\\\nfeatures like campaigns, PR campaigns. Bayesian\\\\\\\\nstatistics was relegated to the margins because it was just\\\\\\\\nsuper hard to do.\\\\\\\\n15:31 And so for other problems, other than very trivial ones, it\\\\\\\\nwas not very applicable. But now with the advent of\\\\\\\\npersonal computing, you have these incredible\\\\\\\\nalgorithms. So now most of the time, it\\\\\\\\\\'s HMC, Hamilton\\\\\\\\nand Monte Carlo. That\\\\\\\\\\'s what we use under the hood with\\\\\\\\nPyMC. But if you stand, if you use [inaudible 00:15:54] ,\\\\\\\\nit\\\\\\\\\\'s the same. And thanks to these algorithms, now we\\\\\\\\ncan make extremely powerful models because we can\\\\\\\\napproximate the [inaudible 00:16:03] distributions thanks\\\\\\\\nto, well, computer\\\\\\\\\\'s computing power. A computer is very\\\\\\\\ngood at computing. I think that\\\\\\\\\\'s why it\\\\\\\\\\'s called that.\\\\\\\\nJon: 16:15 Yes. And so that reminds me of deep learning. It\\\\\\\\\\'s a\\\\\\\\nsimilar kind of thing where the applications we have\\\\\\\\ntoday, like your ChatGPT or whatever your favorite large\\\\\\\\nShow Notes: http://www.superdatascience.com/802 10\\\\\\\\nlanguage model is, these amazing. Video generation like\\\\\\\\nSora, all of this is happening thanks to deep learning,\\\\\\\\nwhich is an approach we\\\\\\\\\\'ve had since the \\\\\\\\\\'50s. Certainly\\\\\\\\nnot as old as Bayesian statistics, but similarly, it has\\\\\\\\nbeen able to take off with much larger data sets and\\\\\\\\nmuch more compute.\\\\\\\\nAlex: 16:46 Yeah, yeah. Yeah, yeah, very good point. And I think\\\\\\\\nthat\\\\\\\\\\'s even more the point in deep learning for sure,\\\\\\\\nbecause Bayesian stats doesn\\\\\\\\\\'t need the scale, but the\\\\\\\\nway we\\\\\\\\\\'re doing deep learning for now, definitely need the\\\\\\\\nscale.\\\\\\\\nJon: 16:58 Yeah, yeah. Scale of data.\\\\\\\\nAlex: 17:00 Yeah, yeah, exactly. Yeah, sorry, yeah, the scale, because\\\\\\\\nour two scales, data and computing. Yeah. You\\\\\\\\\\'re right.\\\\\\\\nJon: 17:05 And for model parameters. So that has actually... I mean,\\\\\\\\ntying back to something you said near the beginning of\\\\\\\\nthis episode, is that actually one of the advantages of\\\\\\\\nBayesian statistics is that you can do it with very few\\\\\\\\ndata. Maybe fewer data than with a frequentist approach\\\\\\\\nor a machine learning approach, because you can bake in\\\\\\\\nyour prior assumptions. And those prior assumptions\\\\\\\\ngive some kind of structure, some kind of framework for\\\\\\\\nyour data to make an impact.\\\\\\\\nAlex: 17:32 Yeah. Yeah, completely.\\\\\\\\nJon: 17:34 And in keeping with the theme of returning to the past to\\\\\\\\nfind golden opportunities, I speak to Dr. Nathan Lambert\\\\\\\\nabout historical influences on contemporary\\\\\\\\nmethodologies. I also managed to sneak in a question\\\\\\\\nabout reinforcement learning from human feedback.\\\\\\\\nNathan is a research scientist for the Allen Institute for\\\\\\\\nAI, and previously built out the RLHF team at Hugging\\\\\\\\nFace. So there was no better person to ask about the lack\\\\\\\\nShow Notes: http://www.superdatascience.com/802 11\\\\\\\\nof robustness in RLHF and how that could impact the\\\\\\\\nfuture development and deployment of AI systems.\\\\\\\\n18:02 Another really cool thing that you\\\\\\\\\\'ve done related to RLHF\\\\\\\\nis you have traced it back to ancient philosophy and\\\\\\\\nmodern economics. So mentioning Aristotle and von\\\\\\\\nNeumann-Morganstern utility theorem, for example. I\\\\\\\\ndon\\\\\\\\\\'t really know what the VNM utility theorem is, but\\\\\\\\nhow do these historical foundations influence current\\\\\\\\nmethodologies and what can modern AI research learn\\\\\\\\nfrom these early theories?\\\\\\\\nNathan: 18:30 Yeah. So this is a fun paper with a few colleagues that I\\\\\\\\nstarted working with at Berkeley, and now we\\\\\\\\\\'re kind of\\\\\\\\nspread out. This is all based on the fact that RL is very\\\\\\\\ndeep field multidisciplinary history, where it goes way\\\\\\\\nback. And then the notion of preference is a very vague\\\\\\\\nthing in economics. And it\\\\\\\\\\'s like the von NeumannMorganstern theory is a foundational thing that\\\\\\\\nessentially it\\\\\\\\\\'s like you can express either all behaviors or\\\\\\\\nall goals as probability and expected value distributions,\\\\\\\\nwhich essentially lets you do expected value math over\\\\\\\\npreferences.\\\\\\\\n19:10 And then it led to a bunch of debates on whether or not\\\\\\\\npreferences actually exist and are tractable in any of\\\\\\\\nthese things, or if they\\\\\\\\\\'re actually measurable or not due\\\\\\\\nto the preference shift over time based on context. So\\\\\\\\nthese are the kinds of things that we take and it\\\\\\\\\\'s ask a\\\\\\\\nlot of questions on how this impacts the modern RLHF\\\\\\\\nprocess. It\\\\\\\\\\'s things like is the final model\\\\\\\\\\'s preferences,\\\\\\\\nwhich is like we\\\\\\\\\\'re mapping onto very human terms, is\\\\\\\\nthat actually based more on the the base model, which is\\\\\\\\nscraped from the internet than the human preferences\\\\\\\\nthat they get from somewhere like Scale AI.\\\\\\\\n19:46 So it\\\\\\\\\\'s like if it\\\\\\\\\\'s based more on the internet crawling than\\\\\\\\nthis million dollar dataset they\\\\\\\\\\'re getting from Scale AI,\\\\\\\\nShow Notes: http://www.superdatascience.com/802 12\\\\\\\\nit\\\\\\\\\\'s kind of confusing to the marketing where we\\\\\\\\\\'re saying\\\\\\\\nwe\\\\\\\\\\'re learning a preference model, but it might not\\\\\\\\nactually do that much. Is other things like OpenAI now\\\\\\\\nhas a ton of user data and it\\\\\\\\\\'s like what does the\\\\\\\\neconomics literature say about generating data for\\\\\\\\ntraining that comes from a user context or a professional\\\\\\\\ncontext where someone is paid to do it and they\\\\\\\\\\'re paid to\\\\\\\\nact in a certain way? And how does all of this mix? So it\\\\\\\\\\'s\\\\\\\\nreally just a super long list of questions of why we should\\\\\\\\nlook at other social sciences if we\\\\\\\\\\'re making grand claims\\\\\\\\nabout human preferences and all of these things.\\\\\\\\nJon: 20:26 Nice. Well, fascinating. Tons to dig into there for our\\\\\\\\nlisteners. Final topic that I planned related to RLHF, I\\\\\\\\\\'m\\\\\\\\nsure it\\\\\\\\\\'ll come up again organically in the conversation,\\\\\\\\nbut you\\\\\\\\\\'ve mentioned that RLHF is not even robust to\\\\\\\\nfine-tuning. And so removing the safety layer from models\\\\\\\\nlike GPT-4 and Llama 2 can break down the notion of\\\\\\\\nsafety. Can you elaborate on the implications of this\\\\\\\\nfragility for the future development and deployment of AI\\\\\\\\nsystems?\\\\\\\\nNathan: 20:59 Yeah, so this is a specific line of research. So there\\\\\\\\\\'s a few\\\\\\\\npapers that showed that if you take a model like Zephyr\\\\\\\\nor Tulu that we were mentioning, if they have safety in\\\\\\\\nthe dataset, if you then go and fine-tune it again on some\\\\\\\\ndifferent tasks, you\\\\\\\\\\'ll do some of the behaviors that are\\\\\\\\n\\\\\"ingrained\\\\\" in the model. I honestly think this is a little\\\\\\\\nbit more clickbaity than actually worrisome because it\\\\\\\\\\'s\\\\\\\\nreally not surprising given that if you just look at the\\\\\\\\namount of compute applied at fine-tuning, we pre-trained\\\\\\\\nthese models for trillions of tokens. And then we apply a\\\\\\\\ncouple billion tokens of compute at fine-tuning.\\\\\\\\n21:36 And it\\\\\\\\\\'s like we\\\\\\\\\\'re not changing the weights of the model\\\\\\\\nsubstantially. We\\\\\\\\\\'re doing a slight nudge, and it makes\\\\\\\\nsense that a slight nudge could be undone at the same\\\\\\\\nway. But if you were to take this to some of the bigger\\\\\\\\nShow Notes: http://www.superdatascience.com/802 13\\\\\\\\nlabs, what you hear is that safety is not just a single\\\\\\\\nartifact thing. Safety is much more about a complete\\\\\\\\nsystem than a model. So open weight models being\\\\\\\\nunsafe or unsafe, I don\\\\\\\\\\'t consider to be that big of a deal.\\\\\\\\nIt\\\\\\\\\\'s like if you were to apply them to a free endpoint that\\\\\\\\neveryone on the internet could talk to, then I don\\\\\\\\\\'t want\\\\\\\\nmy model saying good things about Hitler and all these\\\\\\\\nobvious things.\\\\\\\\n22:09 But if it\\\\\\\\\\'s a research artifact that you need to spin up\\\\\\\\nGPUs to use yourself, and it\\\\\\\\\\'s a little bit more... I\\\\\\\\\\'m more\\\\\\\\nopen to having these diversity of models exist. But if you\\\\\\\\nask [inaudible 00:22:22] or somebody, it\\\\\\\\\\'s like, \\\\\"What\\\\\\\\nhappens... How do you get safety into your model?\\\\\" And\\\\\\\\nit\\\\\\\\\\'s like, it\\\\\\\\\\'s not just RLHF. You need to have safety at the\\\\\\\\npre-training, any preference model you trained. And then\\\\\\\\nall of these models have a safety filter on the output. So\\\\\\\\nChatGPT, it reads all the text generated from the base\\\\\\\\nmodel, and then there\\\\\\\\\\'s a go, no go where it will rephrase\\\\\\\\nthe text if it gets a no-go signal, which is like their content\\\\\\\\nmoderation API.\\\\\\\\n22:45 So it\\\\\\\\\\'s kind of a double. It\\\\\\\\\\'s the type of thing where\\\\\\\\nresearchers need to market their work, but it\\\\\\\\\\'s not as big\\\\\\\\nof a detail as I think it is. It\\\\\\\\\\'s like, okay, I think it has\\\\\\\\ninteresting business downstream things with liability. So\\\\\\\\nit\\\\\\\\\\'s just like if you want to fine-tune a Llama model, you\\\\\\\\nnormally do that on your own hardware, but OpenAI has\\\\\\\\na fine-tuning API. And if they claim their model is safe,\\\\\\\\nbut any fine-tuning on their API that they then host\\\\\\\\nmakes it unsafe, that seems like more of a business\\\\\\\\nproblem. Which is like, oh, it\\\\\\\\\\'s a nice way that open\\\\\\\\necosystem might be better off because it breaks the\\\\\\\\nliability chain. But we\\\\\\\\\\'ll see this research continue to\\\\\\\\nevolve. It\\\\\\\\\\'s so early in all of these things for a year in.\\\\\\\\nJon: 23:31 All right. That\\\\\\\\\\'s it for today\\\\\\\\\\'s In Case You Missed It\\\\\\\\nepisode, to be sure not to miss any of our exciting\\\\\\\\nShow Notes: http://www.superdatascience.com/802 14\\\\\\\\nupcoming episodes. Be sure to subscribe to this podcast\\\\\\\\nif you haven\\\\\\\\\\'t already. But most importantly, I hope you\\\\\\\\\\'ll\\\\\\\\njust keep on listening. Until next time, keep on rocking it\\\\\\\\nout there. And I\\\\\\\\\\'m looking forward to enjoying another\\\\\\\\nround of Super Data Science Podcast with you very soon.\\'\"\\n      ]\\n     },\\n     \"execution_count\": 20,\\n     \"metadata\": {},\\n     \"output_type\": \"execute_result\"\\n    }\\n   ],\\n   \"source\": [\\n    \"docs = retriever.invoke(q1)\\\\n\",\\n    \"docs[0].page_content\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"## Similarity Searach With Score\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 21,\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"data\": {\\n      \"text/plain\": [\\n       \"[(Document(metadata={\\'source\\': \\'4. Embedding/super_DS.txt\\'}, page_content=\\'Show Notes: http://www.superdatascience.com/802 1\\\\\\\\nSDS PODCAST\\\\\\\\nEPISODE 802:\\\\\\\\nIN CASE YOU MISSED\\\\\\\\nIT IN JUNE 2024\\\\\\\\n    Show Notes: http://www.superdatascience.com/802 2\\\\\\\\nJon: 00:02 This is episode number 802, our In Case You Missed it in\\\\\\\\nJune episode.\\\\\\\\n    00:19 Welcome back to the Super Data Science Podcast. I\\\\\\\\\\'m\\\\\\\\nyour host, Jon Krohn. This is an In Case You Missed It\\\\\\\\nepisode that highlights the best parts of conversations we\\\\\\\\nhad on the show in the last month. This first clip you\\\\\\\\\\'ll\\\\\\\\nhear is from my interview with Dr. Jason Yosinski, one of\\\\\\\\nmy all-time favorite AI researchers. We had a great\\\\\\\\nconversation about making your AI and ML models\\\\\\\\nattractive to customers.\\\\\\\\n    00:40 In this clip, I got him to speak from his experience as\\\\\\\\nCEO of the climate technology startup he founded,\\\\\\\\nWindscape AI. This is a great case study if you\\\\\\\\\\'re\\\\\\\\nplanning to launch your own AI models commercially.\\\\\\\\n00:51 I\\\\\\\\\\'m sure that kind of engineering mindset is applicable to\\\\\\\\na lot of our listeners, and it seems like your approach is\\\\\\\\nworking. So EDP, a large Portuguese utility company,\\\\\\\\nrecently selected Windscape as one of nine startups for its\\\\\\\\nrenewable innovation program in Singapore to accelerate\\\\\\\\nthe global energy transition. What opportunities do you\\\\\\\\nsee emerging from Windscape AI\\\\\\\\\\'s participation in this\\\\\\\\nprogram?\\\\\\\\n    Jason: 01:16 Yeah. Well, thanks for mentioning that. We did apply for\\\\\\\\nthis program. We were selected. EDP is a huge utility. I\\\\\\\\nbelieve they\\\\\\\\\\'re the fourth-largest wind owner in the world.\\\\\\\\nSo they own tons and tons of turbines. They generate a\\\\\\\\nlot of wind energy. When I met with folks from EDP, I\\\\\\\\nfound them to be a very forward-looking organization.\\\\\\\\nSometimes you get a big company and they\\\\\\\\\\'re impossibly\\\\\\\\nslow or something, but these folks are really pushing the\\\\\\\\nboundaries, all the boundaries they can, which I thought\\\\\\\\nwas super cool.\\\\\\\\n    Show Notes: http://www.superdatascience.com/802 3\\\\\\\\n01:50 What we hope to get out of it and where that collaboration\\\\\\\\nmight go is to pilot our technology, start working with\\\\\\\\nthem, see how it works on their wind farms around the\\\\\\\\nworld. And then if it does work really well, hopefully we\\\\\\\\nroll out more broadly and we can also maybe use that as\\\\\\\\na demo for new potential customers.\\\\\\\\n    Jon: 02:08 Very cool. So it sounds like EDP is forward-looking. But\\\\\\\\nin general, do you counter resistance or hurdles as you\\\\\\\\ntry to come to energy utilities and say, \\\\\"Hey, you could be\\\\\\\\nusing AI like Windscape\\\\\\\\\\'s to be improving the efficiency of\\\\\\\\nyour systems.\\\\\" Do you encounter resistance or hurdles,\\\\\\\\nor is it relatively straightforward to convince people that\\\\\\\\nyou\\\\\\\\\\'re doing something valuable?\\\\\\\\n    Jason: 02:31 I wouldn\\\\\\\\\\'t say it\\\\\\\\\\'s straightforward. No. Convincing people\\\\\\\\nthat what you\\\\\\\\\\'re doing is valuable is maybe always hard. I\\\\\\\\nwould say saying the words AI or machine learning\\\\\\\\ndoesn\\\\\\\\\\'t immediately open all the doors. It can open some\\\\\\\\ndoors. Some of these companies realize that AI might be\\\\\\\\nrevolutionizing things that happen internally, and they\\\\\\\\\\'re\\\\\\\\nnot quite sure how yet, but maybe we should talk to these\\\\\\\\nrandos from Windscape and see what they think.\\\\\\\\n02:59 It does open some doors, but not all. Just as probably\\\\\\\\nwithin any industry, there are some organizations that\\\\\\\\nare very forward-looking and others early adopters of any\\\\\\\\ntechnology and others that are slower, that are later\\\\\\\\nadopters. They literally, some have told us, \\\\\"We don\\\\\\\\\\'t care\\\\\\\\nwhat you\\\\\\\\\\'re [inaudible 00:03:17], just show us when four\\\\\\\\nother companies are using it and then we\\\\\\\\\\'ll consider\\\\\\\\nusing it because how we work,\\\\\" which is potentially an\\\\\\\\nefficient choice from their perspective.\\\\\\\\n    03:27 There\\\\\\\\\\'s also small energy companies and large energy\\\\\\\\ncompanies, and there\\\\\\\\\\'s a spectrum there of how you sell\\\\\\\\nto these companies and how you get adoption and so on.\\\\\\\\nSo yeah, and convincing everyone, it can be hard. You\\\\\\\\nShow Notes: http://www.superdatascience.com/802 4\\\\\\\\nhave to convince people that your technology will work,\\\\\\\\nthat it won\\\\\\\\\\'t be a huge headache to adopt. The people in\\\\\\\\nthe field need to buy into it. It can\\\\\\\\\\'t ruin their workflow or\\\\\\\\nsomething. It has to be possible to actually integrate. So\\\\\\\\nsome of these systems run software that\\\\\\\\\\'s hard to work\\\\\\\\nwith and simply integrating can be difficult at times. So I\\\\\\\\ndon\\\\\\\\\\'t know, there\\\\\\\\\\'s a lot of factors probably as in any\\\\\\\\nindustry.\\\\\\\\n    Jon: 04:10 Yeah, it makes so much sense. And hopefully I\\\\\\\\\\'m not\\\\\\\\ngoing too deep here, and if I am asking a question that\\\\\\\\nwould give away some kind of IP, just feel free to not\\\\\\\\nanswer this. But it seems to me like in a situation like\\\\\\\\nyours, where you are providing software to hardware\\\\\\\\ncompanies, say the turbine manufacturers, you are not,\\\\\\\\nat least in the immediate term, planning on building, say\\\\\\\\nyour own turbines, your own wind farms.\\\\\\\\n    04:37 You are a software company. You need to be partnering\\\\\\\\nwith turbine manufacturers, with wind farm operators.\\\\\\\\nHow does that work? Are people... I guess maybe your\\\\\\\\nresponse is going to be similar, where there\\\\\\\\\\'s a range of\\\\\\\\nresponses where some turbine manufacturers are\\\\\\\\nrelatively early adopters. They see the potential. They say,\\\\\\\\n\\\\\"Wow, Jason\\\\\\\\\\'s done a lot of amazing research in the past.\\\\\\\\nHe seems like the kind of person we should be working\\\\\\\\nwith to accelerate our roadmap.\\\\\" And then other folks are\\\\\\\\njust like, \\\\\"Yeah, we\\\\\\\\\\'ve got our own team,\\\\\" or I don\\\\\\\\\\'t know.\\\\\\\\nHow does it look for you? Yeah.\\\\\\\\n    Jason: 05:09 What we started this whole endeavor, what we imagined\\\\\\\\nwould happen is we would first build products that we\\\\\\\\nwould sell to people that own the turbines. Why do they\\\\\\\\nwant them? Because our product would help them make\\\\\\\\nmore money starting next month. We help them make\\\\\\\\nmore money. They like our product, we roll out, they tell\\\\\\\\ntheir friends. We deploy to more and more farms, more\\\\\\\\nand more companies. As we start to increase our market\\\\\\\\nShow Notes: http://www.superdatascience.com/802 5\\\\\\\\npenetration in the industry, then much later, turbine\\\\\\\\nmanufacturers would notice and they would say, \\\\\"Hey,\\\\\\\\neveryone\\\\\\\\\\'s using these Windscape people. Maybe we\\\\\\\\nshould talk to them and consider integrating their thing\\\\\\\\noff the factory floor rather than an as aftermarket add-on\\\\\\\\non.\\\\\"\\\\\\\\n    05:48 That\\\\\\\\\\'s still the process we\\\\\\\\\\'re following, although we\\\\\\\\\\'ve\\\\\\\\nbeen surprised that some OEMs are interested in chatting\\\\\\\\nearly. I think they just want to have on their radar what\\\\\\\\\\'s\\\\\\\\ngoing on in the world. And if there\\\\\\\\\\'s any promising\\\\\\\\ntechnology, they want to be there first. So I guess we\\\\\\\\\\'re\\\\\\\\nalready having some of those conversations too.\\\\\\\\nJon: 06:05 And now, we move from offers that tech companies can\\\\\\\\nrefuse to regulations that startups have a duty to follow.\\\\\\\\nIn this clip with the systems engineering and AI\\\\\\\\nregulation guru, Dr. Gina Guillaume-Joseph, she lays out\\\\\\\\nthe evolving regulatory field for AI, which can be difficult\\\\\\\\nto navigate even if you\\\\\\\\\\'ve got the best of intentions.\\\\\\\\nSpecifically, Gina and I talk about the AI Bill of Rights,\\\\\\\\nthe NIST AI regulatory framework, and her work on the\\\\\\\\nMITRE ATLAS.\\\\\\\\n    06:32 Explain for us... You mentioned there, so there\\\\\\\\\\'s the NIST\\\\\\\\nAI risk management framework. So NIST is the National\\\\\\\\nInstitutes of Science and Technology, that may be familiar\\\\\\\\nas an acronym. The NIST thing is something for those of\\\\\\\\nus who have done any deep learning to kind of Hello\\\\\\\\nworld deep learning example involves this handwritten\\\\\\\\ndata set of digits. So it\\\\\\\\\\'s 60,000 handwritten digits done\\\\\\\\nby, if I remember correctly, US postal workers, as well as\\\\\\\\nelementary school students. And so it\\\\\\\\\\'s just each image is\\\\\\\\na different digit. So it\\\\\\\\\\'s some of them are zero, some are\\\\\\\\none, some are two, some are threes, all the way up to\\\\\\\\nnine. And this handwritten dataset was curated initially, I\\\\\\\\nguess in the \\\\\\\\\\'90s, maybe even in the \\\\\\\\\\'80s by NIST.\\\\\\\\nShow Notes: http://www.superdatascience.com/802 6\\\\\\\\n    07:24 And then Yann Le Cun, who\\\\\\\\\\'s one of the most famous AI\\\\\\\\nresearchers of all time, he modified with his research\\\\\\\\nteam at the time, I believe they were AT&T Bell Labs, they\\\\\\\\nmodified that NIST handwritten digit dataset to create the\\\\\\\\nMNIST, modified NIST, handwritten dataset. So I don\\\\\\\\\\'t\\\\\\\\nknow, it\\\\\\\\\\'s a bit of an aside, but that MNIST dataset is\\\\\\\\nprobably familiar to anyone who\\\\\\\\\\'s done any kind of deep\\\\\\\\nlearning at all. And so yeah, so that same organization,\\\\\\\\nNIST, has been around for a long time in the US I don\\\\\\\\\\'t\\\\\\\\nknow how many decades.\\\\\\\\n    07:58 But has been trying to set up frameworks for all different\\\\\\\\nkinds of industries in science and technology, and has\\\\\\\\nnow created this AI risk management framework, which\\\\\\\\nagain, I\\\\\\\\\\'ll have a link to that in the show notes alongside\\\\\\\\nthe AI Bill of Rights. A third framework, I guess, you can\\\\\\\\ncorrect me if I\\\\\\\\\\'m not using the right word there, that you\\\\\\\\nbrought up in your talk that also seems really helpful\\\\\\\\nhere is something called the MITRE ATLAS.\\\\\\\\n    08:26 So I\\\\\\\\\\'ve been trying to, as you\\\\\\\\\\'ve been speaking, dig up\\\\\\\\nwhat MITRE stands for, M-I-T-R-E. It doesn\\\\\\\\\\'t seem like it\\\\\\\\nstands for anything. Can you tell us a bit about MITRE\\\\\\\\nand the MITRE ATLAS and then maybe you can weave\\\\\\\\ntogether these three different things; the AI Bill of Rights,\\\\\\\\nthe NIST AI regulatory framework, as well as MITRE\\\\\\\\nATLAS. And tell us how we can integrate these three\\\\\\\\nframeworks together in order to have a good sense of how\\\\\\\\nto move forward with the AI systems that we built.\\\\\\\\nGina: 08:58 So MITRE is a not-for-profit organization. I worked for\\\\\\\\nthem for 10 years, and they support the federal\\\\\\\\ngovernment across all the federal government agencies to\\\\\\\\nhelp them solve some of the most pressing challenges. So\\\\\\\\nMITRE operates federally funded research and\\\\\\\\ndevelopment centers in support of the federal government\\\\\\\\nto solve problems for a safer world, essentially is what\\\\\\\\nMITRE does. And while at MITRE, I supported multiple\\\\\\\\nShow Notes: http://www.superdatascience.com/802 7\\\\\\\\nagencies; Department of Homeland Security, Social\\\\\\\\nSecurity Administration, Veterans Affairs, Department of\\\\\\\\nDefense, in some of the challenges that they were facing\\\\\\\\nat the time.\\\\\\\\n    09:45 Societal challenges to include when the economy was\\\\\\\\ndoing some downward slides and banks were failing, part\\\\\\\\nof some of the work that I did was at the FDIC, that was\\\\\\\\nwith Booz Allen. But MITRE was involved in other aspects\\\\\\\\nof that as well, to really understand the failures and to\\\\\\\\nfigure out the mitigation strategies to ensure that society\\\\\\\\ndidn\\\\\\\\\\'t feel those impacts as broadly and as strongly.\\\\\\\\n10:24 And MITRE created the ATLAS threat model introduction,\\\\\\\\nthreat model. It\\\\\\\\\\'s this comprehensive coverage of AIspecific adversary tactics techniques that includes realworld observation and reporting. It talks about\\\\\\\\naccessibility and usability of AI alignment with existing\\\\\\\\ncybersecurity frameworks in terms of from an AI\\\\\\\\nperspective. And that community engagement\\\\\\\\ncontribution and the educational resources and training.\\\\\\\\n10:58 So they\\\\\\\\\\'re developing a detailed taxonomy of tactics, of\\\\\\\\ntechniques, of procedures specific to AI systems that\\\\\\\\ncover the entire lifecycle from data collection to model\\\\\\\\ndevelopment and deployment and maintenance. Where\\\\\\\\nthey establish those mechanisms for continuously\\\\\\\\ngathering and updating threat intelligence based on realworld cybersecurity incidents involving AI so that the\\\\\\\\nknowledge base remains current and relevant. So that\\\\\\\\\\'s\\\\\\\\nwhat MITRE is doing it with their MITRE ATLAS\\\\\\\\nframework. And the framework integrates their existing\\\\\\\\nMITRE attack for enterprise framework that shows that\\\\\\\\nthey bring in that consistency and interoperability across\\\\\\\\ncybersecurity efforts as it pertains to AI systems. And\\\\\\\\nthat\\\\\\\\\\'s MITRE ATLAS threat model.\\\\\\\\nShow Notes: http://www.superdatascience.com/802 8\\\\\\\\nJon: 12:01 Terrifically useful context there from Gina. In my next\\\\\\\\nclip, Alex Andorra and I discuss Bayesian statistics,\\\\\\\\nnamely why being able to crunch larger and larger data\\\\\\\\nsets has helped us to use a powerful modeling technique\\\\\\\\nthat was originally devised centuries ago.\\\\\\\\n12:15 In addition to the podcast, also, I mentioned this at the\\\\\\\\noutset, I said that you\\\\\\\\\\'re co-founder and principal data\\\\\\\\nscientist of the popular Bayesian stats modeling platform,\\\\\\\\nPyMC. So like many things in data science, it\\\\\\\\\\'s uppercase\\\\\\\\nP, lowercase Y, for Python. What\\\\\\\\\\'s the MC? PyMC, one\\\\\\\\nword, M and the C are capitalized.\\\\\\\\nAlex: 12:38 So it\\\\\\\\\\'s very confusing because it stands for Python and\\\\\\\\nthen MC is Monte Carlo. So I understand, but why Monte\\\\\\\\nCarlo? It\\\\\\\\\\'s because it comes from Markov chain Monte\\\\\\\\nCarlo. So actually, it should be PyMCMC or PyMC\\\\\\\\nsquared, which is what I\\\\\\\\\\'m saying since the beginning.\\\\\\\\nBut anyways, yeah, it\\\\\\\\\\'s actually PyMC squared. So for\\\\\\\\nMarkov chain Monte Carlo and Markov chain Monte Carlo\\\\\\\\nis one of the main ways... All the algorithms now, new\\\\\\\\nones, but the blockbuster algorithm to run Bayesian\\\\\\\\nmodels is to use MCMC.\\\\\\\\nJon: 13:21 So in the same way that stochastic gradient descent is\\\\\\\\nlike the defacto standard for finding your model weights\\\\\\\\nin machine learning, Markov chain Monte Carlo is the\\\\\\\\nstandard way of doing it with the Bayesian network?\\\\\\\\nAlex: 13:36 Yeah. Yeah, yeah. And so now there are newer versions,\\\\\\\\nmore efficient versions. That\\\\\\\\\\'s basically the name of the\\\\\\\\ngame, making the algorithm more and more efficient. But\\\\\\\\nthe first algorithm dates back... I think it was actually\\\\\\\\ninvented during the project Manhattan. So during World\\\\\\\\nWar II.\\\\\\\\nJon: 13:57 Theme of the day.\\\\\\\\nShow Notes: http://www.superdatascience.com/802 9\\\\\\\\nAlex: 13:58 Yeah. And lots of physicists actually, statistical physics is\\\\\\\\na field that\\\\\\\\\\'s contributed a lot to MCMC. And so yeah,\\\\\\\\nphysicists who came to the field of statistics and trying to\\\\\\\\nmake the algorithms more efficient for their models. So\\\\\\\\nthey have contributed a lot. The field of physics has\\\\\\\\ncontributed a lot of big names and people to great leaps\\\\\\\\ninto the realm of more efficient algorithms. And so, I don\\\\\\\\\\'t\\\\\\\\nknow who your audience is, but that may sound boring.\\\\\\\\n14:37 Yeah, the algorithm, it\\\\\\\\\\'s like the workhorse, but it\\\\\\\\\\'s\\\\\\\\nextremely powerful. And that\\\\\\\\\\'s also one of the main\\\\\\\\nreasons why Bayesian statistics are increasing in\\\\\\\\npopularity lately, because I\\\\\\\\\\'m going to argue that it\\\\\\\\\\'s\\\\\\\\nalways been the best framework to do statistics, to do\\\\\\\\nscience. But it was hard to do with pen and paper\\\\\\\\nbecause the problem is that you have a huge, nasty\\\\\\\\nintegral on the numerator, on the denominator, sorry.\\\\\\\\nAnd this integral is not computable by pen and paper. So\\\\\\\\nfor a long, long time, Bayesian statistics combined two\\\\\\\\nfeatures like campaigns, PR campaigns. Bayesian\\\\\\\\nstatistics was relegated to the margins because it was just\\\\\\\\nsuper hard to do.\\\\\\\\n15:31 And so for other problems, other than very trivial ones, it\\\\\\\\nwas not very applicable. But now with the advent of\\\\\\\\npersonal computing, you have these incredible\\\\\\\\nalgorithms. So now most of the time, it\\\\\\\\\\'s HMC, Hamilton\\\\\\\\nand Monte Carlo. That\\\\\\\\\\'s what we use under the hood with\\\\\\\\nPyMC. But if you stand, if you use [inaudible 00:15:54] ,\\\\\\\\nit\\\\\\\\\\'s the same. And thanks to these algorithms, now we\\\\\\\\ncan make extremely powerful models because we can\\\\\\\\napproximate the [inaudible 00:16:03] distributions thanks\\\\\\\\nto, well, computer\\\\\\\\\\'s computing power. A computer is very\\\\\\\\ngood at computing. I think that\\\\\\\\\\'s why it\\\\\\\\\\'s called that.\\\\\\\\nJon: 16:15 Yes. And so that reminds me of deep learning. It\\\\\\\\\\'s a\\\\\\\\nsimilar kind of thing where the applications we have\\\\\\\\ntoday, like your ChatGPT or whatever your favorite large\\\\\\\\nShow Notes: http://www.superdatascience.com/802 10\\\\\\\\nlanguage model is, these amazing. Video generation like\\\\\\\\nSora, all of this is happening thanks to deep learning,\\\\\\\\nwhich is an approach we\\\\\\\\\\'ve had since the \\\\\\\\\\'50s. Certainly\\\\\\\\nnot as old as Bayesian statistics, but similarly, it has\\\\\\\\nbeen able to take off with much larger data sets and\\\\\\\\nmuch more compute.\\\\\\\\nAlex: 16:46 Yeah, yeah. Yeah, yeah, very good point. And I think\\\\\\\\nthat\\\\\\\\\\'s even more the point in deep learning for sure,\\\\\\\\nbecause Bayesian stats doesn\\\\\\\\\\'t need the scale, but the\\\\\\\\nway we\\\\\\\\\\'re doing deep learning for now, definitely need the\\\\\\\\nscale.\\\\\\\\nJon: 16:58 Yeah, yeah. Scale of data.\\\\\\\\nAlex: 17:00 Yeah, yeah, exactly. Yeah, sorry, yeah, the scale, because\\\\\\\\nour two scales, data and computing. Yeah. You\\\\\\\\\\'re right.\\\\\\\\nJon: 17:05 And for model parameters. So that has actually... I mean,\\\\\\\\ntying back to something you said near the beginning of\\\\\\\\nthis episode, is that actually one of the advantages of\\\\\\\\nBayesian statistics is that you can do it with very few\\\\\\\\ndata. Maybe fewer data than with a frequentist approach\\\\\\\\nor a machine learning approach, because you can bake in\\\\\\\\nyour prior assumptions. And those prior assumptions\\\\\\\\ngive some kind of structure, some kind of framework for\\\\\\\\nyour data to make an impact.\\\\\\\\nAlex: 17:32 Yeah. Yeah, completely.\\\\\\\\nJon: 17:34 And in keeping with the theme of returning to the past to\\\\\\\\nfind golden opportunities, I speak to Dr. Nathan Lambert\\\\\\\\nabout historical influences on contemporary\\\\\\\\nmethodologies. I also managed to sneak in a question\\\\\\\\nabout reinforcement learning from human feedback.\\\\\\\\nNathan is a research scientist for the Allen Institute for\\\\\\\\nAI, and previously built out the RLHF team at Hugging\\\\\\\\nFace. So there was no better person to ask about the lack\\\\\\\\nShow Notes: http://www.superdatascience.com/802 11\\\\\\\\nof robustness in RLHF and how that could impact the\\\\\\\\nfuture development and deployment of AI systems.\\\\\\\\n18:02 Another really cool thing that you\\\\\\\\\\'ve done related to RLHF\\\\\\\\nis you have traced it back to ancient philosophy and\\\\\\\\nmodern economics. So mentioning Aristotle and von\\\\\\\\nNeumann-Morganstern utility theorem, for example. I\\\\\\\\ndon\\\\\\\\\\'t really know what the VNM utility theorem is, but\\\\\\\\nhow do these historical foundations influence current\\\\\\\\nmethodologies and what can modern AI research learn\\\\\\\\nfrom these early theories?\\\\\\\\nNathan: 18:30 Yeah. So this is a fun paper with a few colleagues that I\\\\\\\\nstarted working with at Berkeley, and now we\\\\\\\\\\'re kind of\\\\\\\\nspread out. This is all based on the fact that RL is very\\\\\\\\ndeep field multidisciplinary history, where it goes way\\\\\\\\nback. And then the notion of preference is a very vague\\\\\\\\nthing in economics. And it\\\\\\\\\\'s like the von NeumannMorganstern theory is a foundational thing that\\\\\\\\nessentially it\\\\\\\\\\'s like you can express either all behaviors or\\\\\\\\nall goals as probability and expected value distributions,\\\\\\\\nwhich essentially lets you do expected value math over\\\\\\\\npreferences.\\\\\\\\n19:10 And then it led to a bunch of debates on whether or not\\\\\\\\npreferences actually exist and are tractable in any of\\\\\\\\nthese things, or if they\\\\\\\\\\'re actually measurable or not due\\\\\\\\nto the preference shift over time based on context. So\\\\\\\\nthese are the kinds of things that we take and it\\\\\\\\\\'s ask a\\\\\\\\nlot of questions on how this impacts the modern RLHF\\\\\\\\nprocess. It\\\\\\\\\\'s things like is the final model\\\\\\\\\\'s preferences,\\\\\\\\nwhich is like we\\\\\\\\\\'re mapping onto very human terms, is\\\\\\\\nthat actually based more on the the base model, which is\\\\\\\\nscraped from the internet than the human preferences\\\\\\\\nthat they get from somewhere like Scale AI.\\\\\\\\n19:46 So it\\\\\\\\\\'s like if it\\\\\\\\\\'s based more on the internet crawling than\\\\\\\\nthis million dollar dataset they\\\\\\\\\\'re getting from Scale AI,\\\\\\\\nShow Notes: http://www.superdatascience.com/802 12\\\\\\\\nit\\\\\\\\\\'s kind of confusing to the marketing where we\\\\\\\\\\'re saying\\\\\\\\nwe\\\\\\\\\\'re learning a preference model, but it might not\\\\\\\\nactually do that much. Is other things like OpenAI now\\\\\\\\nhas a ton of user data and it\\\\\\\\\\'s like what does the\\\\\\\\neconomics literature say about generating data for\\\\\\\\ntraining that comes from a user context or a professional\\\\\\\\ncontext where someone is paid to do it and they\\\\\\\\\\'re paid to\\\\\\\\nact in a certain way? And how does all of this mix? So it\\\\\\\\\\'s\\\\\\\\nreally just a super long list of questions of why we should\\\\\\\\nlook at other social sciences if we\\\\\\\\\\'re making grand claims\\\\\\\\nabout human preferences and all of these things.\\\\\\\\nJon: 20:26 Nice. Well, fascinating. Tons to dig into there for our\\\\\\\\nlisteners. Final topic that I planned related to RLHF, I\\\\\\\\\\'m\\\\\\\\nsure it\\\\\\\\\\'ll come up again organically in the conversation,\\\\\\\\nbut you\\\\\\\\\\'ve mentioned that RLHF is not even robust to\\\\\\\\nfine-tuning. And so removing the safety layer from models\\\\\\\\nlike GPT-4 and Llama 2 can break down the notion of\\\\\\\\nsafety. Can you elaborate on the implications of this\\\\\\\\nfragility for the future development and deployment of AI\\\\\\\\nsystems?\\\\\\\\nNathan: 20:59 Yeah, so this is a specific line of research. So there\\\\\\\\\\'s a few\\\\\\\\npapers that showed that if you take a model like Zephyr\\\\\\\\nor Tulu that we were mentioning, if they have safety in\\\\\\\\nthe dataset, if you then go and fine-tune it again on some\\\\\\\\ndifferent tasks, you\\\\\\\\\\'ll do some of the behaviors that are\\\\\\\\n\\\\\"ingrained\\\\\" in the model. I honestly think this is a little\\\\\\\\nbit more clickbaity than actually worrisome because it\\\\\\\\\\'s\\\\\\\\nreally not surprising given that if you just look at the\\\\\\\\namount of compute applied at fine-tuning, we pre-trained\\\\\\\\nthese models for trillions of tokens. And then we apply a\\\\\\\\ncouple billion tokens of compute at fine-tuning.\\\\\\\\n21:36 And it\\\\\\\\\\'s like we\\\\\\\\\\'re not changing the weights of the model\\\\\\\\nsubstantially. We\\\\\\\\\\'re doing a slight nudge, and it makes\\\\\\\\nsense that a slight nudge could be undone at the same\\\\\\\\nway. But if you were to take this to some of the bigger\\\\\\\\nShow Notes: http://www.superdatascience.com/802 13\\\\\\\\nlabs, what you hear is that safety is not just a single\\\\\\\\nartifact thing. Safety is much more about a complete\\\\\\\\nsystem than a model. So open weight models being\\\\\\\\nunsafe or unsafe, I don\\\\\\\\\\'t consider to be that big of a deal.\\\\\\\\nIt\\\\\\\\\\'s like if you were to apply them to a free endpoint that\\\\\\\\neveryone on the internet could talk to, then I don\\\\\\\\\\'t want\\\\\\\\nmy model saying good things about Hitler and all these\\\\\\\\nobvious things.\\\\\\\\n22:09 But if it\\\\\\\\\\'s a research artifact that you need to spin up\\\\\\\\nGPUs to use yourself, and it\\\\\\\\\\'s a little bit more... I\\\\\\\\\\'m more\\\\\\\\nopen to having these diversity of models exist. But if you\\\\\\\\nask [inaudible 00:22:22] or somebody, it\\\\\\\\\\'s like, \\\\\"What\\\\\\\\nhappens... How do you get safety into your model?\\\\\" And\\\\\\\\nit\\\\\\\\\\'s like, it\\\\\\\\\\'s not just RLHF. You need to have safety at the\\\\\\\\npre-training, any preference model you trained. And then\\\\\\\\nall of these models have a safety filter on the output. So\\\\\\\\nChatGPT, it reads all the text generated from the base\\\\\\\\nmodel, and then there\\\\\\\\\\'s a go, no go where it will rephrase\\\\\\\\nthe text if it gets a no-go signal, which is like their content\\\\\\\\nmoderation API.\\\\\\\\n22:45 So it\\\\\\\\\\'s kind of a double. It\\\\\\\\\\'s the type of thing where\\\\\\\\nresearchers need to market their work, but it\\\\\\\\\\'s not as big\\\\\\\\nof a detail as I think it is. It\\\\\\\\\\'s like, okay, I think it has\\\\\\\\ninteresting business downstream things with liability. So\\\\\\\\nit\\\\\\\\\\'s just like if you want to fine-tune a Llama model, you\\\\\\\\nnormally do that on your own hardware, but OpenAI has\\\\\\\\na fine-tuning API. And if they claim their model is safe,\\\\\\\\nbut any fine-tuning on their API that they then host\\\\\\\\nmakes it unsafe, that seems like more of a business\\\\\\\\nproblem. Which is like, oh, it\\\\\\\\\\'s a nice way that open\\\\\\\\necosystem might be better off because it breaks the\\\\\\\\nliability chain. But we\\\\\\\\\\'ll see this research continue to\\\\\\\\nevolve. It\\\\\\\\\\'s so early in all of these things for a year in.\\\\\\\\nJon: 23:31 All right. That\\\\\\\\\\'s it for today\\\\\\\\\\'s In Case You Missed It\\\\\\\\nepisode, to be sure not to miss any of our exciting\\\\\\\\nShow Notes: http://www.superdatascience.com/802 14\\\\\\\\nupcoming episodes. Be sure to subscribe to this podcast\\\\\\\\nif you haven\\\\\\\\\\'t already. But most importantly, I hope you\\\\\\\\\\'ll\\\\\\\\njust keep on listening. Until next time, keep on rocking it\\\\\\\\nout there. And I\\\\\\\\\\'m looking forward to enjoying another\\\\\\\\nround of Super Data Science Podcast with you very soon.\\'),\\\\n\",\\n       \"  7497.7583)]\"\\n      ]\\n     },\\n     \"execution_count\": 21,\\n     \"metadata\": {},\\n     \"output_type\": \"execute_result\"\\n    }\\n   ],\\n   \"source\": [\\n    \"docs_and_score = db.similarity_search_with_score(q1)\\\\n\",\\n    \"docs_and_score\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 22,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"embedding_vector = ollama_embeddings.embed_query(q1)\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 25,\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"data\": {\\n      \"text/plain\": [\\n       \"3584\"\\n      ]\\n     },\\n     \"execution_count\": 25,\\n     \"metadata\": {},\\n     \"output_type\": \"execute_result\"\\n    }\\n   ],\\n   \"source\": [\\n    \"len(embedding_vector)\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 24,\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"data\": {\\n      \"text/plain\": [\\n       \"[-0.8230404853820801,\\\\n\",\\n       \" -1.8964414596557617,\\\\n\",\\n       \" -0.14863909780979156,\\\\n\",\\n       \" -0.6310588121414185,\\\\n\",\\n       \" -3.0927000045776367]\"\\n      ]\\n     },\\n     \"execution_count\": 24,\\n     \"metadata\": {},\\n     \"output_type\": \"execute_result\"\\n    }\\n   ],\\n   \"source\": [\\n    \"embedding_vector[:5]\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 27,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"docs_score = db.similarity_search_by_vector(embedding_vector)\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 28,\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"data\": {\\n      \"text/plain\": [\\n       \"[Document(metadata={\\'source\\': \\'4. Embedding/super_DS.txt\\'}, page_content=\\'Show Notes: http://www.superdatascience.com/802 1\\\\\\\\nSDS PODCAST\\\\\\\\nEPISODE 802:\\\\\\\\nIN CASE YOU MISSED\\\\\\\\nIT IN JUNE 2024\\\\\\\\n    Show Notes: http://www.superdatascience.com/802 2\\\\\\\\nJon: 00:02 This is episode number 802, our In Case You Missed it in\\\\\\\\nJune episode.\\\\\\\\n    00:19 Welcome back to the Super Data Science Podcast. I\\\\\\\\\\'m\\\\\\\\nyour host, Jon Krohn. This is an In Case You Missed It\\\\\\\\nepisode that highlights the best parts of conversations we\\\\\\\\nhad on the show in the last month. This first clip you\\\\\\\\\\'ll\\\\\\\\nhear is from my interview with Dr. Jason Yosinski, one of\\\\\\\\nmy all-time favorite AI researchers. We had a great\\\\\\\\nconversation about making your AI and ML models\\\\\\\\nattractive to customers.\\\\\\\\n    00:40 In this clip, I got him to speak from his experience as\\\\\\\\nCEO of the climate technology startup he founded,\\\\\\\\nWindscape AI. This is a great case study if you\\\\\\\\\\'re\\\\\\\\nplanning to launch your own AI models commercially.\\\\\\\\n00:51 I\\\\\\\\\\'m sure that kind of engineering mindset is applicable to\\\\\\\\na lot of our listeners, and it seems like your approach is\\\\\\\\nworking. So EDP, a large Portuguese utility company,\\\\\\\\nrecently selected Windscape as one of nine startups for its\\\\\\\\nrenewable innovation program in Singapore to accelerate\\\\\\\\nthe global energy transition. What opportunities do you\\\\\\\\nsee emerging from Windscape AI\\\\\\\\\\'s participation in this\\\\\\\\nprogram?\\\\\\\\n    Jason: 01:16 Yeah. Well, thanks for mentioning that. We did apply for\\\\\\\\nthis program. We were selected. EDP is a huge utility. I\\\\\\\\nbelieve they\\\\\\\\\\'re the fourth-largest wind owner in the world.\\\\\\\\nSo they own tons and tons of turbines. They generate a\\\\\\\\nlot of wind energy. When I met with folks from EDP, I\\\\\\\\nfound them to be a very forward-looking organization.\\\\\\\\nSometimes you get a big company and they\\\\\\\\\\'re impossibly\\\\\\\\nslow or something, but these folks are really pushing the\\\\\\\\nboundaries, all the boundaries they can, which I thought\\\\\\\\nwas super cool.\\\\\\\\n    Show Notes: http://www.superdatascience.com/802 3\\\\\\\\n01:50 What we hope to get out of it and where that collaboration\\\\\\\\nmight go is to pilot our technology, start working with\\\\\\\\nthem, see how it works on their wind farms around the\\\\\\\\nworld. And then if it does work really well, hopefully we\\\\\\\\nroll out more broadly and we can also maybe use that as\\\\\\\\na demo for new potential customers.\\\\\\\\n    Jon: 02:08 Very cool. So it sounds like EDP is forward-looking. But\\\\\\\\nin general, do you counter resistance or hurdles as you\\\\\\\\ntry to come to energy utilities and say, \\\\\"Hey, you could be\\\\\\\\nusing AI like Windscape\\\\\\\\\\'s to be improving the efficiency of\\\\\\\\nyour systems.\\\\\" Do you encounter resistance or hurdles,\\\\\\\\nor is it relatively straightforward to convince people that\\\\\\\\nyou\\\\\\\\\\'re doing something valuable?\\\\\\\\n    Jason: 02:31 I wouldn\\\\\\\\\\'t say it\\\\\\\\\\'s straightforward. No. Convincing people\\\\\\\\nthat what you\\\\\\\\\\'re doing is valuable is maybe always hard. I\\\\\\\\nwould say saying the words AI or machine learning\\\\\\\\ndoesn\\\\\\\\\\'t immediately open all the doors. It can open some\\\\\\\\ndoors. Some of these companies realize that AI might be\\\\\\\\nrevolutionizing things that happen internally, and they\\\\\\\\\\'re\\\\\\\\nnot quite sure how yet, but maybe we should talk to these\\\\\\\\nrandos from Windscape and see what they think.\\\\\\\\n02:59 It does open some doors, but not all. Just as probably\\\\\\\\nwithin any industry, there are some organizations that\\\\\\\\nare very forward-looking and others early adopters of any\\\\\\\\ntechnology and others that are slower, that are later\\\\\\\\nadopters. They literally, some have told us, \\\\\"We don\\\\\\\\\\'t care\\\\\\\\nwhat you\\\\\\\\\\'re [inaudible 00:03:17], just show us when four\\\\\\\\nother companies are using it and then we\\\\\\\\\\'ll consider\\\\\\\\nusing it because how we work,\\\\\" which is potentially an\\\\\\\\nefficient choice from their perspective.\\\\\\\\n    03:27 There\\\\\\\\\\'s also small energy companies and large energy\\\\\\\\ncompanies, and there\\\\\\\\\\'s a spectrum there of how you sell\\\\\\\\nto these companies and how you get adoption and so on.\\\\\\\\nSo yeah, and convincing everyone, it can be hard. You\\\\\\\\nShow Notes: http://www.superdatascience.com/802 4\\\\\\\\nhave to convince people that your technology will work,\\\\\\\\nthat it won\\\\\\\\\\'t be a huge headache to adopt. The people in\\\\\\\\nthe field need to buy into it. It can\\\\\\\\\\'t ruin their workflow or\\\\\\\\nsomething. It has to be possible to actually integrate. So\\\\\\\\nsome of these systems run software that\\\\\\\\\\'s hard to work\\\\\\\\nwith and simply integrating can be difficult at times. So I\\\\\\\\ndon\\\\\\\\\\'t know, there\\\\\\\\\\'s a lot of factors probably as in any\\\\\\\\nindustry.\\\\\\\\n    Jon: 04:10 Yeah, it makes so much sense. And hopefully I\\\\\\\\\\'m not\\\\\\\\ngoing too deep here, and if I am asking a question that\\\\\\\\nwould give away some kind of IP, just feel free to not\\\\\\\\nanswer this. But it seems to me like in a situation like\\\\\\\\nyours, where you are providing software to hardware\\\\\\\\ncompanies, say the turbine manufacturers, you are not,\\\\\\\\nat least in the immediate term, planning on building, say\\\\\\\\nyour own turbines, your own wind farms.\\\\\\\\n    04:37 You are a software company. You need to be partnering\\\\\\\\nwith turbine manufacturers, with wind farm operators.\\\\\\\\nHow does that work? Are people... I guess maybe your\\\\\\\\nresponse is going to be similar, where there\\\\\\\\\\'s a range of\\\\\\\\nresponses where some turbine manufacturers are\\\\\\\\nrelatively early adopters. They see the potential. They say,\\\\\\\\n\\\\\"Wow, Jason\\\\\\\\\\'s done a lot of amazing research in the past.\\\\\\\\nHe seems like the kind of person we should be working\\\\\\\\nwith to accelerate our roadmap.\\\\\" And then other folks are\\\\\\\\njust like, \\\\\"Yeah, we\\\\\\\\\\'ve got our own team,\\\\\" or I don\\\\\\\\\\'t know.\\\\\\\\nHow does it look for you? Yeah.\\\\\\\\n    Jason: 05:09 What we started this whole endeavor, what we imagined\\\\\\\\nwould happen is we would first build products that we\\\\\\\\nwould sell to people that own the turbines. Why do they\\\\\\\\nwant them? Because our product would help them make\\\\\\\\nmore money starting next month. We help them make\\\\\\\\nmore money. They like our product, we roll out, they tell\\\\\\\\ntheir friends. We deploy to more and more farms, more\\\\\\\\nand more companies. As we start to increase our market\\\\\\\\nShow Notes: http://www.superdatascience.com/802 5\\\\\\\\npenetration in the industry, then much later, turbine\\\\\\\\nmanufacturers would notice and they would say, \\\\\"Hey,\\\\\\\\neveryone\\\\\\\\\\'s using these Windscape people. Maybe we\\\\\\\\nshould talk to them and consider integrating their thing\\\\\\\\noff the factory floor rather than an as aftermarket add-on\\\\\\\\non.\\\\\"\\\\\\\\n    05:48 That\\\\\\\\\\'s still the process we\\\\\\\\\\'re following, although we\\\\\\\\\\'ve\\\\\\\\nbeen surprised that some OEMs are interested in chatting\\\\\\\\nearly. I think they just want to have on their radar what\\\\\\\\\\'s\\\\\\\\ngoing on in the world. And if there\\\\\\\\\\'s any promising\\\\\\\\ntechnology, they want to be there first. So I guess we\\\\\\\\\\'re\\\\\\\\nalready having some of those conversations too.\\\\\\\\nJon: 06:05 And now, we move from offers that tech companies can\\\\\\\\nrefuse to regulations that startups have a duty to follow.\\\\\\\\nIn this clip with the systems engineering and AI\\\\\\\\nregulation guru, Dr. Gina Guillaume-Joseph, she lays out\\\\\\\\nthe evolving regulatory field for AI, which can be difficult\\\\\\\\nto navigate even if you\\\\\\\\\\'ve got the best of intentions.\\\\\\\\nSpecifically, Gina and I talk about the AI Bill of Rights,\\\\\\\\nthe NIST AI regulatory framework, and her work on the\\\\\\\\nMITRE ATLAS.\\\\\\\\n    06:32 Explain for us... You mentioned there, so there\\\\\\\\\\'s the NIST\\\\\\\\nAI risk management framework. So NIST is the National\\\\\\\\nInstitutes of Science and Technology, that may be familiar\\\\\\\\nas an acronym. The NIST thing is something for those of\\\\\\\\nus who have done any deep learning to kind of Hello\\\\\\\\nworld deep learning example involves this handwritten\\\\\\\\ndata set of digits. So it\\\\\\\\\\'s 60,000 handwritten digits done\\\\\\\\nby, if I remember correctly, US postal workers, as well as\\\\\\\\nelementary school students. And so it\\\\\\\\\\'s just each image is\\\\\\\\na different digit. So it\\\\\\\\\\'s some of them are zero, some are\\\\\\\\none, some are two, some are threes, all the way up to\\\\\\\\nnine. And this handwritten dataset was curated initially, I\\\\\\\\nguess in the \\\\\\\\\\'90s, maybe even in the \\\\\\\\\\'80s by NIST.\\\\\\\\nShow Notes: http://www.superdatascience.com/802 6\\\\\\\\n    07:24 And then Yann Le Cun, who\\\\\\\\\\'s one of the most famous AI\\\\\\\\nresearchers of all time, he modified with his research\\\\\\\\nteam at the time, I believe they were AT&T Bell Labs, they\\\\\\\\nmodified that NIST handwritten digit dataset to create the\\\\\\\\nMNIST, modified NIST, handwritten dataset. So I don\\\\\\\\\\'t\\\\\\\\nknow, it\\\\\\\\\\'s a bit of an aside, but that MNIST dataset is\\\\\\\\nprobably familiar to anyone who\\\\\\\\\\'s done any kind of deep\\\\\\\\nlearning at all. And so yeah, so that same organization,\\\\\\\\nNIST, has been around for a long time in the US I don\\\\\\\\\\'t\\\\\\\\nknow how many decades.\\\\\\\\n    07:58 But has been trying to set up frameworks for all different\\\\\\\\nkinds of industries in science and technology, and has\\\\\\\\nnow created this AI risk management framework, which\\\\\\\\nagain, I\\\\\\\\\\'ll have a link to that in the show notes alongside\\\\\\\\nthe AI Bill of Rights. A third framework, I guess, you can\\\\\\\\ncorrect me if I\\\\\\\\\\'m not using the right word there, that you\\\\\\\\nbrought up in your talk that also seems really helpful\\\\\\\\nhere is something called the MITRE ATLAS.\\\\\\\\n    08:26 So I\\\\\\\\\\'ve been trying to, as you\\\\\\\\\\'ve been speaking, dig up\\\\\\\\nwhat MITRE stands for, M-I-T-R-E. It doesn\\\\\\\\\\'t seem like it\\\\\\\\nstands for anything. Can you tell us a bit about MITRE\\\\\\\\nand the MITRE ATLAS and then maybe you can weave\\\\\\\\ntogether these three different things; the AI Bill of Rights,\\\\\\\\nthe NIST AI regulatory framework, as well as MITRE\\\\\\\\nATLAS. And tell us how we can integrate these three\\\\\\\\nframeworks together in order to have a good sense of how\\\\\\\\nto move forward with the AI systems that we built.\\\\\\\\nGina: 08:58 So MITRE is a not-for-profit organization. I worked for\\\\\\\\nthem for 10 years, and they support the federal\\\\\\\\ngovernment across all the federal government agencies to\\\\\\\\nhelp them solve some of the most pressing challenges. So\\\\\\\\nMITRE operates federally funded research and\\\\\\\\ndevelopment centers in support of the federal government\\\\\\\\nto solve problems for a safer world, essentially is what\\\\\\\\nMITRE does. And while at MITRE, I supported multiple\\\\\\\\nShow Notes: http://www.superdatascience.com/802 7\\\\\\\\nagencies; Department of Homeland Security, Social\\\\\\\\nSecurity Administration, Veterans Affairs, Department of\\\\\\\\nDefense, in some of the challenges that they were facing\\\\\\\\nat the time.\\\\\\\\n    09:45 Societal challenges to include when the economy was\\\\\\\\ndoing some downward slides and banks were failing, part\\\\\\\\nof some of the work that I did was at the FDIC, that was\\\\\\\\nwith Booz Allen. But MITRE was involved in other aspects\\\\\\\\nof that as well, to really understand the failures and to\\\\\\\\nfigure out the mitigation strategies to ensure that society\\\\\\\\ndidn\\\\\\\\\\'t feel those impacts as broadly and as strongly.\\\\\\\\n10:24 And MITRE created the ATLAS threat model introduction,\\\\\\\\nthreat model. It\\\\\\\\\\'s this comprehensive coverage of AIspecific adversary tactics techniques that includes realworld observation and reporting. It talks about\\\\\\\\naccessibility and usability of AI alignment with existing\\\\\\\\ncybersecurity frameworks in terms of from an AI\\\\\\\\nperspective. And that community engagement\\\\\\\\ncontribution and the educational resources and training.\\\\\\\\n10:58 So they\\\\\\\\\\'re developing a detailed taxonomy of tactics, of\\\\\\\\ntechniques, of procedures specific to AI systems that\\\\\\\\ncover the entire lifecycle from data collection to model\\\\\\\\ndevelopment and deployment and maintenance. Where\\\\\\\\nthey establish those mechanisms for continuously\\\\\\\\ngathering and updating threat intelligence based on realworld cybersecurity incidents involving AI so that the\\\\\\\\nknowledge base remains current and relevant. So that\\\\\\\\\\'s\\\\\\\\nwhat MITRE is doing it with their MITRE ATLAS\\\\\\\\nframework. And the framework integrates their existing\\\\\\\\nMITRE attack for enterprise framework that shows that\\\\\\\\nthey bring in that consistency and interoperability across\\\\\\\\ncybersecurity efforts as it pertains to AI systems. And\\\\\\\\nthat\\\\\\\\\\'s MITRE ATLAS threat model.\\\\\\\\nShow Notes: http://www.superdatascience.com/802 8\\\\\\\\nJon: 12:01 Terrifically useful context there from Gina. In my next\\\\\\\\nclip, Alex Andorra and I discuss Bayesian statistics,\\\\\\\\nnamely why being able to crunch larger and larger data\\\\\\\\nsets has helped us to use a powerful modeling technique\\\\\\\\nthat was originally devised centuries ago.\\\\\\\\n12:15 In addition to the podcast, also, I mentioned this at the\\\\\\\\noutset, I said that you\\\\\\\\\\'re co-founder and principal data\\\\\\\\nscientist of the popular Bayesian stats modeling platform,\\\\\\\\nPyMC. So like many things in data science, it\\\\\\\\\\'s uppercase\\\\\\\\nP, lowercase Y, for Python. What\\\\\\\\\\'s the MC? PyMC, one\\\\\\\\nword, M and the C are capitalized.\\\\\\\\nAlex: 12:38 So it\\\\\\\\\\'s very confusing because it stands for Python and\\\\\\\\nthen MC is Monte Carlo. So I understand, but why Monte\\\\\\\\nCarlo? It\\\\\\\\\\'s because it comes from Markov chain Monte\\\\\\\\nCarlo. So actually, it should be PyMCMC or PyMC\\\\\\\\nsquared, which is what I\\\\\\\\\\'m saying since the beginning.\\\\\\\\nBut anyways, yeah, it\\\\\\\\\\'s actually PyMC squared. So for\\\\\\\\nMarkov chain Monte Carlo and Markov chain Monte Carlo\\\\\\\\nis one of the main ways... All the algorithms now, new\\\\\\\\nones, but the blockbuster algorithm to run Bayesian\\\\\\\\nmodels is to use MCMC.\\\\\\\\nJon: 13:21 So in the same way that stochastic gradient descent is\\\\\\\\nlike the defacto standard for finding your model weights\\\\\\\\nin machine learning, Markov chain Monte Carlo is the\\\\\\\\nstandard way of doing it with the Bayesian network?\\\\\\\\nAlex: 13:36 Yeah. Yeah, yeah. And so now there are newer versions,\\\\\\\\nmore efficient versions. That\\\\\\\\\\'s basically the name of the\\\\\\\\ngame, making the algorithm more and more efficient. But\\\\\\\\nthe first algorithm dates back... I think it was actually\\\\\\\\ninvented during the project Manhattan. So during World\\\\\\\\nWar II.\\\\\\\\nJon: 13:57 Theme of the day.\\\\\\\\nShow Notes: http://www.superdatascience.com/802 9\\\\\\\\nAlex: 13:58 Yeah. And lots of physicists actually, statistical physics is\\\\\\\\na field that\\\\\\\\\\'s contributed a lot to MCMC. And so yeah,\\\\\\\\nphysicists who came to the field of statistics and trying to\\\\\\\\nmake the algorithms more efficient for their models. So\\\\\\\\nthey have contributed a lot. The field of physics has\\\\\\\\ncontributed a lot of big names and people to great leaps\\\\\\\\ninto the realm of more efficient algorithms. And so, I don\\\\\\\\\\'t\\\\\\\\nknow who your audience is, but that may sound boring.\\\\\\\\n14:37 Yeah, the algorithm, it\\\\\\\\\\'s like the workhorse, but it\\\\\\\\\\'s\\\\\\\\nextremely powerful. And that\\\\\\\\\\'s also one of the main\\\\\\\\nreasons why Bayesian statistics are increasing in\\\\\\\\npopularity lately, because I\\\\\\\\\\'m going to argue that it\\\\\\\\\\'s\\\\\\\\nalways been the best framework to do statistics, to do\\\\\\\\nscience. But it was hard to do with pen and paper\\\\\\\\nbecause the problem is that you have a huge, nasty\\\\\\\\nintegral on the numerator, on the denominator, sorry.\\\\\\\\nAnd this integral is not computable by pen and paper. So\\\\\\\\nfor a long, long time, Bayesian statistics combined two\\\\\\\\nfeatures like campaigns, PR campaigns. Bayesian\\\\\\\\nstatistics was relegated to the margins because it was just\\\\\\\\nsuper hard to do.\\\\\\\\n15:31 And so for other problems, other than very trivial ones, it\\\\\\\\nwas not very applicable. But now with the advent of\\\\\\\\npersonal computing, you have these incredible\\\\\\\\nalgorithms. So now most of the time, it\\\\\\\\\\'s HMC, Hamilton\\\\\\\\nand Monte Carlo. That\\\\\\\\\\'s what we use under the hood with\\\\\\\\nPyMC. But if you stand, if you use [inaudible 00:15:54] ,\\\\\\\\nit\\\\\\\\\\'s the same. And thanks to these algorithms, now we\\\\\\\\ncan make extremely powerful models because we can\\\\\\\\napproximate the [inaudible 00:16:03] distributions thanks\\\\\\\\nto, well, computer\\\\\\\\\\'s computing power. A computer is very\\\\\\\\ngood at computing. I think that\\\\\\\\\\'s why it\\\\\\\\\\'s called that.\\\\\\\\nJon: 16:15 Yes. And so that reminds me of deep learning. It\\\\\\\\\\'s a\\\\\\\\nsimilar kind of thing where the applications we have\\\\\\\\ntoday, like your ChatGPT or whatever your favorite large\\\\\\\\nShow Notes: http://www.superdatascience.com/802 10\\\\\\\\nlanguage model is, these amazing. Video generation like\\\\\\\\nSora, all of this is happening thanks to deep learning,\\\\\\\\nwhich is an approach we\\\\\\\\\\'ve had since the \\\\\\\\\\'50s. Certainly\\\\\\\\nnot as old as Bayesian statistics, but similarly, it has\\\\\\\\nbeen able to take off with much larger data sets and\\\\\\\\nmuch more compute.\\\\\\\\nAlex: 16:46 Yeah, yeah. Yeah, yeah, very good point. And I think\\\\\\\\nthat\\\\\\\\\\'s even more the point in deep learning for sure,\\\\\\\\nbecause Bayesian stats doesn\\\\\\\\\\'t need the scale, but the\\\\\\\\nway we\\\\\\\\\\'re doing deep learning for now, definitely need the\\\\\\\\nscale.\\\\\\\\nJon: 16:58 Yeah, yeah. Scale of data.\\\\\\\\nAlex: 17:00 Yeah, yeah, exactly. Yeah, sorry, yeah, the scale, because\\\\\\\\nour two scales, data and computing. Yeah. You\\\\\\\\\\'re right.\\\\\\\\nJon: 17:05 And for model parameters. So that has actually... I mean,\\\\\\\\ntying back to something you said near the beginning of\\\\\\\\nthis episode, is that actually one of the advantages of\\\\\\\\nBayesian statistics is that you can do it with very few\\\\\\\\ndata. Maybe fewer data than with a frequentist approach\\\\\\\\nor a machine learning approach, because you can bake in\\\\\\\\nyour prior assumptions. And those prior assumptions\\\\\\\\ngive some kind of structure, some kind of framework for\\\\\\\\nyour data to make an impact.\\\\\\\\nAlex: 17:32 Yeah. Yeah, completely.\\\\\\\\nJon: 17:34 And in keeping with the theme of returning to the past to\\\\\\\\nfind golden opportunities, I speak to Dr. Nathan Lambert\\\\\\\\nabout historical influences on contemporary\\\\\\\\nmethodologies. I also managed to sneak in a question\\\\\\\\nabout reinforcement learning from human feedback.\\\\\\\\nNathan is a research scientist for the Allen Institute for\\\\\\\\nAI, and previously built out the RLHF team at Hugging\\\\\\\\nFace. So there was no better person to ask about the lack\\\\\\\\nShow Notes: http://www.superdatascience.com/802 11\\\\\\\\nof robustness in RLHF and how that could impact the\\\\\\\\nfuture development and deployment of AI systems.\\\\\\\\n18:02 Another really cool thing that you\\\\\\\\\\'ve done related to RLHF\\\\\\\\nis you have traced it back to ancient philosophy and\\\\\\\\nmodern economics. So mentioning Aristotle and von\\\\\\\\nNeumann-Morganstern utility theorem, for example. I\\\\\\\\ndon\\\\\\\\\\'t really know what the VNM utility theorem is, but\\\\\\\\nhow do these historical foundations influence current\\\\\\\\nmethodologies and what can modern AI research learn\\\\\\\\nfrom these early theories?\\\\\\\\nNathan: 18:30 Yeah. So this is a fun paper with a few colleagues that I\\\\\\\\nstarted working with at Berkeley, and now we\\\\\\\\\\'re kind of\\\\\\\\nspread out. This is all based on the fact that RL is very\\\\\\\\ndeep field multidisciplinary history, where it goes way\\\\\\\\nback. And then the notion of preference is a very vague\\\\\\\\nthing in economics. And it\\\\\\\\\\'s like the von NeumannMorganstern theory is a foundational thing that\\\\\\\\nessentially it\\\\\\\\\\'s like you can express either all behaviors or\\\\\\\\nall goals as probability and expected value distributions,\\\\\\\\nwhich essentially lets you do expected value math over\\\\\\\\npreferences.\\\\\\\\n19:10 And then it led to a bunch of debates on whether or not\\\\\\\\npreferences actually exist and are tractable in any of\\\\\\\\nthese things, or if they\\\\\\\\\\'re actually measurable or not due\\\\\\\\nto the preference shift over time based on context. So\\\\\\\\nthese are the kinds of things that we take and it\\\\\\\\\\'s ask a\\\\\\\\nlot of questions on how this impacts the modern RLHF\\\\\\\\nprocess. It\\\\\\\\\\'s things like is the final model\\\\\\\\\\'s preferences,\\\\\\\\nwhich is like we\\\\\\\\\\'re mapping onto very human terms, is\\\\\\\\nthat actually based more on the the base model, which is\\\\\\\\nscraped from the internet than the human preferences\\\\\\\\nthat they get from somewhere like Scale AI.\\\\\\\\n19:46 So it\\\\\\\\\\'s like if it\\\\\\\\\\'s based more on the internet crawling than\\\\\\\\nthis million dollar dataset they\\\\\\\\\\'re getting from Scale AI,\\\\\\\\nShow Notes: http://www.superdatascience.com/802 12\\\\\\\\nit\\\\\\\\\\'s kind of confusing to the marketing where we\\\\\\\\\\'re saying\\\\\\\\nwe\\\\\\\\\\'re learning a preference model, but it might not\\\\\\\\nactually do that much. Is other things like OpenAI now\\\\\\\\nhas a ton of user data and it\\\\\\\\\\'s like what does the\\\\\\\\neconomics literature say about generating data for\\\\\\\\ntraining that comes from a user context or a professional\\\\\\\\ncontext where someone is paid to do it and they\\\\\\\\\\'re paid to\\\\\\\\nact in a certain way? And how does all of this mix? So it\\\\\\\\\\'s\\\\\\\\nreally just a super long list of questions of why we should\\\\\\\\nlook at other social sciences if we\\\\\\\\\\'re making grand claims\\\\\\\\nabout human preferences and all of these things.\\\\\\\\nJon: 20:26 Nice. Well, fascinating. Tons to dig into there for our\\\\\\\\nlisteners. Final topic that I planned related to RLHF, I\\\\\\\\\\'m\\\\\\\\nsure it\\\\\\\\\\'ll come up again organically in the conversation,\\\\\\\\nbut you\\\\\\\\\\'ve mentioned that RLHF is not even robust to\\\\\\\\nfine-tuning. And so removing the safety layer from models\\\\\\\\nlike GPT-4 and Llama 2 can break down the notion of\\\\\\\\nsafety. Can you elaborate on the implications of this\\\\\\\\nfragility for the future development and deployment of AI\\\\\\\\nsystems?\\\\\\\\nNathan: 20:59 Yeah, so this is a specific line of research. So there\\\\\\\\\\'s a few\\\\\\\\npapers that showed that if you take a model like Zephyr\\\\\\\\nor Tulu that we were mentioning, if they have safety in\\\\\\\\nthe dataset, if you then go and fine-tune it again on some\\\\\\\\ndifferent tasks, you\\\\\\\\\\'ll do some of the behaviors that are\\\\\\\\n\\\\\"ingrained\\\\\" in the model. I honestly think this is a little\\\\\\\\nbit more clickbaity than actually worrisome because it\\\\\\\\\\'s\\\\\\\\nreally not surprising given that if you just look at the\\\\\\\\namount of compute applied at fine-tuning, we pre-trained\\\\\\\\nthese models for trillions of tokens. And then we apply a\\\\\\\\ncouple billion tokens of compute at fine-tuning.\\\\\\\\n21:36 And it\\\\\\\\\\'s like we\\\\\\\\\\'re not changing the weights of the model\\\\\\\\nsubstantially. We\\\\\\\\\\'re doing a slight nudge, and it makes\\\\\\\\nsense that a slight nudge could be undone at the same\\\\\\\\nway. But if you were to take this to some of the bigger\\\\\\\\nShow Notes: http://www.superdatascience.com/802 13\\\\\\\\nlabs, what you hear is that safety is not just a single\\\\\\\\nartifact thing. Safety is much more about a complete\\\\\\\\nsystem than a model. So open weight models being\\\\\\\\nunsafe or unsafe, I don\\\\\\\\\\'t consider to be that big of a deal.\\\\\\\\nIt\\\\\\\\\\'s like if you were to apply them to a free endpoint that\\\\\\\\neveryone on the internet could talk to, then I don\\\\\\\\\\'t want\\\\\\\\nmy model saying good things about Hitler and all these\\\\\\\\nobvious things.\\\\\\\\n22:09 But if it\\\\\\\\\\'s a research artifact that you need to spin up\\\\\\\\nGPUs to use yourself, and it\\\\\\\\\\'s a little bit more... I\\\\\\\\\\'m more\\\\\\\\nopen to having these diversity of models exist. But if you\\\\\\\\nask [inaudible 00:22:22] or somebody, it\\\\\\\\\\'s like, \\\\\"What\\\\\\\\nhappens... How do you get safety into your model?\\\\\" And\\\\\\\\nit\\\\\\\\\\'s like, it\\\\\\\\\\'s not just RLHF. You need to have safety at the\\\\\\\\npre-training, any preference model you trained. And then\\\\\\\\nall of these models have a safety filter on the output. So\\\\\\\\nChatGPT, it reads all the text generated from the base\\\\\\\\nmodel, and then there\\\\\\\\\\'s a go, no go where it will rephrase\\\\\\\\nthe text if it gets a no-go signal, which is like their content\\\\\\\\nmoderation API.\\\\\\\\n22:45 So it\\\\\\\\\\'s kind of a double. It\\\\\\\\\\'s the type of thing where\\\\\\\\nresearchers need to market their work, but it\\\\\\\\\\'s not as big\\\\\\\\nof a detail as I think it is. It\\\\\\\\\\'s like, okay, I think it has\\\\\\\\ninteresting business downstream things with liability. So\\\\\\\\nit\\\\\\\\\\'s just like if you want to fine-tune a Llama model, you\\\\\\\\nnormally do that on your own hardware, but OpenAI has\\\\\\\\na fine-tuning API. And if they claim their model is safe,\\\\\\\\nbut any fine-tuning on their API that they then host\\\\\\\\nmakes it unsafe, that seems like more of a business\\\\\\\\nproblem. Which is like, oh, it\\\\\\\\\\'s a nice way that open\\\\\\\\necosystem might be better off because it breaks the\\\\\\\\nliability chain. But we\\\\\\\\\\'ll see this research continue to\\\\\\\\nevolve. It\\\\\\\\\\'s so early in all of these things for a year in.\\\\\\\\nJon: 23:31 All right. That\\\\\\\\\\'s it for today\\\\\\\\\\'s In Case You Missed It\\\\\\\\nepisode, to be sure not to miss any of our exciting\\\\\\\\nShow Notes: http://www.superdatascience.com/802 14\\\\\\\\nupcoming episodes. Be sure to subscribe to this podcast\\\\\\\\nif you haven\\\\\\\\\\'t already. But most importantly, I hope you\\\\\\\\\\'ll\\\\\\\\njust keep on listening. Until next time, keep on rocking it\\\\\\\\nout there. And I\\\\\\\\\\'m looking forward to enjoying another\\\\\\\\nround of Super Data Science Podcast with you very soon.\\')]\"\\n      ]\\n     },\\n     \"execution_count\": 28,\\n     \"metadata\": {},\\n     \"output_type\": \"execute_result\"\\n    }\\n   ],\\n   \"source\": [\\n    \"docs_score\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"## Saving and Loading\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 30,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"db.save_local(\\\\\"faiss_index\\\\\")\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 33,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"new_db = FAISS.load_local(\\\\\"faiss_index\\\\\", ollama_embeddings,allow_dangerous_deserialization=True)\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 34,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"docs = new_db.similarity_search(q1)\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 35,\\n   \"metadata\": {},\\n   \"outputs\": [\\n    {\\n     \"data\": {\\n      \"text/plain\": [\\n       \"[Document(metadata={\\'source\\': \\'4. Embedding/super_DS.txt\\'}, page_content=\\'Show Notes: http://www.superdatascience.com/802 1\\\\\\\\nSDS PODCAST\\\\\\\\nEPISODE 802:\\\\\\\\nIN CASE YOU MISSED\\\\\\\\nIT IN JUNE 2024\\\\\\\\n    Show Notes: http://www.superdatascience.com/802 2\\\\\\\\nJon: 00:02 This is episode number 802, our In Case You Missed it in\\\\\\\\nJune episode.\\\\\\\\n    00:19 Welcome back to the Super Data Science Podcast. I\\\\\\\\\\'m\\\\\\\\nyour host, Jon Krohn. This is an In Case You Missed It\\\\\\\\nepisode that highlights the best parts of conversations we\\\\\\\\nhad on the show in the last month. This first clip you\\\\\\\\\\'ll\\\\\\\\nhear is from my interview with Dr. Jason Yosinski, one of\\\\\\\\nmy all-time favorite AI researchers. We had a great\\\\\\\\nconversation about making your AI and ML models\\\\\\\\nattractive to customers.\\\\\\\\n    00:40 In this clip, I got him to speak from his experience as\\\\\\\\nCEO of the climate technology startup he founded,\\\\\\\\nWindscape AI. This is a great case study if you\\\\\\\\\\'re\\\\\\\\nplanning to launch your own AI models commercially.\\\\\\\\n00:51 I\\\\\\\\\\'m sure that kind of engineering mindset is applicable to\\\\\\\\na lot of our listeners, and it seems like your approach is\\\\\\\\nworking. So EDP, a large Portuguese utility company,\\\\\\\\nrecently selected Windscape as one of nine startups for its\\\\\\\\nrenewable innovation program in Singapore to accelerate\\\\\\\\nthe global energy transition. What opportunities do you\\\\\\\\nsee emerging from Windscape AI\\\\\\\\\\'s participation in this\\\\\\\\nprogram?\\\\\\\\n    Jason: 01:16 Yeah. Well, thanks for mentioning that. We did apply for\\\\\\\\nthis program. We were selected. EDP is a huge utility. I\\\\\\\\nbelieve they\\\\\\\\\\'re the fourth-largest wind owner in the world.\\\\\\\\nSo they own tons and tons of turbines. They generate a\\\\\\\\nlot of wind energy. When I met with folks from EDP, I\\\\\\\\nfound them to be a very forward-looking organization.\\\\\\\\nSometimes you get a big company and they\\\\\\\\\\'re impossibly\\\\\\\\nslow or something, but these folks are really pushing the\\\\\\\\nboundaries, all the boundaries they can, which I thought\\\\\\\\nwas super cool.\\\\\\\\n    Show Notes: http://www.superdatascience.com/802 3\\\\\\\\n01:50 What we hope to get out of it and where that collaboration\\\\\\\\nmight go is to pilot our technology, start working with\\\\\\\\nthem, see how it works on their wind farms around the\\\\\\\\nworld. And then if it does work really well, hopefully we\\\\\\\\nroll out more broadly and we can also maybe use that as\\\\\\\\na demo for new potential customers.\\\\\\\\n    Jon: 02:08 Very cool. So it sounds like EDP is forward-looking. But\\\\\\\\nin general, do you counter resistance or hurdles as you\\\\\\\\ntry to come to energy utilities and say, \\\\\"Hey, you could be\\\\\\\\nusing AI like Windscape\\\\\\\\\\'s to be improving the efficiency of\\\\\\\\nyour systems.\\\\\" Do you encounter resistance or hurdles,\\\\\\\\nor is it relatively straightforward to convince people that\\\\\\\\nyou\\\\\\\\\\'re doing something valuable?\\\\\\\\n    Jason: 02:31 I wouldn\\\\\\\\\\'t say it\\\\\\\\\\'s straightforward. No. Convincing people\\\\\\\\nthat what you\\\\\\\\\\'re doing is valuable is maybe always hard. I\\\\\\\\nwould say saying the words AI or machine learning\\\\\\\\ndoesn\\\\\\\\\\'t immediately open all the doors. It can open some\\\\\\\\ndoors. Some of these companies realize that AI might be\\\\\\\\nrevolutionizing things that happen internally, and they\\\\\\\\\\'re\\\\\\\\nnot quite sure how yet, but maybe we should talk to these\\\\\\\\nrandos from Windscape and see what they think.\\\\\\\\n02:59 It does open some doors, but not all. Just as probably\\\\\\\\nwithin any industry, there are some organizations that\\\\\\\\nare very forward-looking and others early adopters of any\\\\\\\\ntechnology and others that are slower, that are later\\\\\\\\nadopters. They literally, some have told us, \\\\\"We don\\\\\\\\\\'t care\\\\\\\\nwhat you\\\\\\\\\\'re [inaudible 00:03:17], just show us when four\\\\\\\\nother companies are using it and then we\\\\\\\\\\'ll consider\\\\\\\\nusing it because how we work,\\\\\" which is potentially an\\\\\\\\nefficient choice from their perspective.\\\\\\\\n    03:27 There\\\\\\\\\\'s also small energy companies and large energy\\\\\\\\ncompanies, and there\\\\\\\\\\'s a spectrum there of how you sell\\\\\\\\nto these companies and how you get adoption and so on.\\\\\\\\nSo yeah, and convincing everyone, it can be hard. You\\\\\\\\nShow Notes: http://www.superdatascience.com/802 4\\\\\\\\nhave to convince people that your technology will work,\\\\\\\\nthat it won\\\\\\\\\\'t be a huge headache to adopt. The people in\\\\\\\\nthe field need to buy into it. It can\\\\\\\\\\'t ruin their workflow or\\\\\\\\nsomething. It has to be possible to actually integrate. So\\\\\\\\nsome of these systems run software that\\\\\\\\\\'s hard to work\\\\\\\\nwith and simply integrating can be difficult at times. So I\\\\\\\\ndon\\\\\\\\\\'t know, there\\\\\\\\\\'s a lot of factors probably as in any\\\\\\\\nindustry.\\\\\\\\n    Jon: 04:10 Yeah, it makes so much sense. And hopefully I\\\\\\\\\\'m not\\\\\\\\ngoing too deep here, and if I am asking a question that\\\\\\\\nwould give away some kind of IP, just feel free to not\\\\\\\\nanswer this. But it seems to me like in a situation like\\\\\\\\nyours, where you are providing software to hardware\\\\\\\\ncompanies, say the turbine manufacturers, you are not,\\\\\\\\nat least in the immediate term, planning on building, say\\\\\\\\nyour own turbines, your own wind farms.\\\\\\\\n    04:37 You are a software company. You need to be partnering\\\\\\\\nwith turbine manufacturers, with wind farm operators.\\\\\\\\nHow does that work? Are people... I guess maybe your\\\\\\\\nresponse is going to be similar, where there\\\\\\\\\\'s a range of\\\\\\\\nresponses where some turbine manufacturers are\\\\\\\\nrelatively early adopters. They see the potential. They say,\\\\\\\\n\\\\\"Wow, Jason\\\\\\\\\\'s done a lot of amazing research in the past.\\\\\\\\nHe seems like the kind of person we should be working\\\\\\\\nwith to accelerate our roadmap.\\\\\" And then other folks are\\\\\\\\njust like, \\\\\"Yeah, we\\\\\\\\\\'ve got our own team,\\\\\" or I don\\\\\\\\\\'t know.\\\\\\\\nHow does it look for you? Yeah.\\\\\\\\n    Jason: 05:09 What we started this whole endeavor, what we imagined\\\\\\\\nwould happen is we would first build products that we\\\\\\\\nwould sell to people that own the turbines. Why do they\\\\\\\\nwant them? Because our product would help them make\\\\\\\\nmore money starting next month. We help them make\\\\\\\\nmore money. They like our product, we roll out, they tell\\\\\\\\ntheir friends. We deploy to more and more farms, more\\\\\\\\nand more companies. As we start to increase our market\\\\\\\\nShow Notes: http://www.superdatascience.com/802 5\\\\\\\\npenetration in the industry, then much later, turbine\\\\\\\\nmanufacturers would notice and they would say, \\\\\"Hey,\\\\\\\\neveryone\\\\\\\\\\'s using these Windscape people. Maybe we\\\\\\\\nshould talk to them and consider integrating their thing\\\\\\\\noff the factory floor rather than an as aftermarket add-on\\\\\\\\non.\\\\\"\\\\\\\\n    05:48 That\\\\\\\\\\'s still the process we\\\\\\\\\\'re following, although we\\\\\\\\\\'ve\\\\\\\\nbeen surprised that some OEMs are interested in chatting\\\\\\\\nearly. I think they just want to have on their radar what\\\\\\\\\\'s\\\\\\\\ngoing on in the world. And if there\\\\\\\\\\'s any promising\\\\\\\\ntechnology, they want to be there first. So I guess we\\\\\\\\\\'re\\\\\\\\nalready having some of those conversations too.\\\\\\\\nJon: 06:05 And now, we move from offers that tech companies can\\\\\\\\nrefuse to regulations that startups have a duty to follow.\\\\\\\\nIn this clip with the systems engineering and AI\\\\\\\\nregulation guru, Dr. Gina Guillaume-Joseph, she lays out\\\\\\\\nthe evolving regulatory field for AI, which can be difficult\\\\\\\\nto navigate even if you\\\\\\\\\\'ve got the best of intentions.\\\\\\\\nSpecifically, Gina and I talk about the AI Bill of Rights,\\\\\\\\nthe NIST AI regulatory framework, and her work on the\\\\\\\\nMITRE ATLAS.\\\\\\\\n    06:32 Explain for us... You mentioned there, so there\\\\\\\\\\'s the NIST\\\\\\\\nAI risk management framework. So NIST is the National\\\\\\\\nInstitutes of Science and Technology, that may be familiar\\\\\\\\nas an acronym. The NIST thing is something for those of\\\\\\\\nus who have done any deep learning to kind of Hello\\\\\\\\nworld deep learning example involves this handwritten\\\\\\\\ndata set of digits. So it\\\\\\\\\\'s 60,000 handwritten digits done\\\\\\\\nby, if I remember correctly, US postal workers, as well as\\\\\\\\nelementary school students. And so it\\\\\\\\\\'s just each image is\\\\\\\\na different digit. So it\\\\\\\\\\'s some of them are zero, some are\\\\\\\\none, some are two, some are threes, all the way up to\\\\\\\\nnine. And this handwritten dataset was curated initially, I\\\\\\\\nguess in the \\\\\\\\\\'90s, maybe even in the \\\\\\\\\\'80s by NIST.\\\\\\\\nShow Notes: http://www.superdatascience.com/802 6\\\\\\\\n    07:24 And then Yann Le Cun, who\\\\\\\\\\'s one of the most famous AI\\\\\\\\nresearchers of all time, he modified with his research\\\\\\\\nteam at the time, I believe they were AT&T Bell Labs, they\\\\\\\\nmodified that NIST handwritten digit dataset to create the\\\\\\\\nMNIST, modified NIST, handwritten dataset. So I don\\\\\\\\\\'t\\\\\\\\nknow, it\\\\\\\\\\'s a bit of an aside, but that MNIST dataset is\\\\\\\\nprobably familiar to anyone who\\\\\\\\\\'s done any kind of deep\\\\\\\\nlearning at all. And so yeah, so that same organization,\\\\\\\\nNIST, has been around for a long time in the US I don\\\\\\\\\\'t\\\\\\\\nknow how many decades.\\\\\\\\n    07:58 But has been trying to set up frameworks for all different\\\\\\\\nkinds of industries in science and technology, and has\\\\\\\\nnow created this AI risk management framework, which\\\\\\\\nagain, I\\\\\\\\\\'ll have a link to that in the show notes alongside\\\\\\\\nthe AI Bill of Rights. A third framework, I guess, you can\\\\\\\\ncorrect me if I\\\\\\\\\\'m not using the right word there, that you\\\\\\\\nbrought up in your talk that also seems really helpful\\\\\\\\nhere is something called the MITRE ATLAS.\\\\\\\\n    08:26 So I\\\\\\\\\\'ve been trying to, as you\\\\\\\\\\'ve been speaking, dig up\\\\\\\\nwhat MITRE stands for, M-I-T-R-E. It doesn\\\\\\\\\\'t seem like it\\\\\\\\nstands for anything. Can you tell us a bit about MITRE\\\\\\\\nand the MITRE ATLAS and then maybe you can weave\\\\\\\\ntogether these three different things; the AI Bill of Rights,\\\\\\\\nthe NIST AI regulatory framework, as well as MITRE\\\\\\\\nATLAS. And tell us how we can integrate these three\\\\\\\\nframeworks together in order to have a good sense of how\\\\\\\\nto move forward with the AI systems that we built.\\\\\\\\nGina: 08:58 So MITRE is a not-for-profit organization. I worked for\\\\\\\\nthem for 10 years, and they support the federal\\\\\\\\ngovernment across all the federal government agencies to\\\\\\\\nhelp them solve some of the most pressing challenges. So\\\\\\\\nMITRE operates federally funded research and\\\\\\\\ndevelopment centers in support of the federal government\\\\\\\\nto solve problems for a safer world, essentially is what\\\\\\\\nMITRE does. And while at MITRE, I supported multiple\\\\\\\\nShow Notes: http://www.superdatascience.com/802 7\\\\\\\\nagencies; Department of Homeland Security, Social\\\\\\\\nSecurity Administration, Veterans Affairs, Department of\\\\\\\\nDefense, in some of the challenges that they were facing\\\\\\\\nat the time.\\\\\\\\n    09:45 Societal challenges to include when the economy was\\\\\\\\ndoing some downward slides and banks were failing, part\\\\\\\\nof some of the work that I did was at the FDIC, that was\\\\\\\\nwith Booz Allen. But MITRE was involved in other aspects\\\\\\\\nof that as well, to really understand the failures and to\\\\\\\\nfigure out the mitigation strategies to ensure that society\\\\\\\\ndidn\\\\\\\\\\'t feel those impacts as broadly and as strongly.\\\\\\\\n10:24 And MITRE created the ATLAS threat model introduction,\\\\\\\\nthreat model. It\\\\\\\\\\'s this comprehensive coverage of AIspecific adversary tactics techniques that includes realworld observation and reporting. It talks about\\\\\\\\naccessibility and usability of AI alignment with existing\\\\\\\\ncybersecurity frameworks in terms of from an AI\\\\\\\\nperspective. And that community engagement\\\\\\\\ncontribution and the educational resources and training.\\\\\\\\n10:58 So they\\\\\\\\\\'re developing a detailed taxonomy of tactics, of\\\\\\\\ntechniques, of procedures specific to AI systems that\\\\\\\\ncover the entire lifecycle from data collection to model\\\\\\\\ndevelopment and deployment and maintenance. Where\\\\\\\\nthey establish those mechanisms for continuously\\\\\\\\ngathering and updating threat intelligence based on realworld cybersecurity incidents involving AI so that the\\\\\\\\nknowledge base remains current and relevant. So that\\\\\\\\\\'s\\\\\\\\nwhat MITRE is doing it with their MITRE ATLAS\\\\\\\\nframework. And the framework integrates their existing\\\\\\\\nMITRE attack for enterprise framework that shows that\\\\\\\\nthey bring in that consistency and interoperability across\\\\\\\\ncybersecurity efforts as it pertains to AI systems. And\\\\\\\\nthat\\\\\\\\\\'s MITRE ATLAS threat model.\\\\\\\\nShow Notes: http://www.superdatascience.com/802 8\\\\\\\\nJon: 12:01 Terrifically useful context there from Gina. In my next\\\\\\\\nclip, Alex Andorra and I discuss Bayesian statistics,\\\\\\\\nnamely why being able to crunch larger and larger data\\\\\\\\nsets has helped us to use a powerful modeling technique\\\\\\\\nthat was originally devised centuries ago.\\\\\\\\n12:15 In addition to the podcast, also, I mentioned this at the\\\\\\\\noutset, I said that you\\\\\\\\\\'re co-founder and principal data\\\\\\\\nscientist of the popular Bayesian stats modeling platform,\\\\\\\\nPyMC. So like many things in data science, it\\\\\\\\\\'s uppercase\\\\\\\\nP, lowercase Y, for Python. What\\\\\\\\\\'s the MC? PyMC, one\\\\\\\\nword, M and the C are capitalized.\\\\\\\\nAlex: 12:38 So it\\\\\\\\\\'s very confusing because it stands for Python and\\\\\\\\nthen MC is Monte Carlo. So I understand, but why Monte\\\\\\\\nCarlo? It\\\\\\\\\\'s because it comes from Markov chain Monte\\\\\\\\nCarlo. So actually, it should be PyMCMC or PyMC\\\\\\\\nsquared, which is what I\\\\\\\\\\'m saying since the beginning.\\\\\\\\nBut anyways, yeah, it\\\\\\\\\\'s actually PyMC squared. So for\\\\\\\\nMarkov chain Monte Carlo and Markov chain Monte Carlo\\\\\\\\nis one of the main ways... All the algorithms now, new\\\\\\\\nones, but the blockbuster algorithm to run Bayesian\\\\\\\\nmodels is to use MCMC.\\\\\\\\nJon: 13:21 So in the same way that stochastic gradient descent is\\\\\\\\nlike the defacto standard for finding your model weights\\\\\\\\nin machine learning, Markov chain Monte Carlo is the\\\\\\\\nstandard way of doing it with the Bayesian network?\\\\\\\\nAlex: 13:36 Yeah. Yeah, yeah. And so now there are newer versions,\\\\\\\\nmore efficient versions. That\\\\\\\\\\'s basically the name of the\\\\\\\\ngame, making the algorithm more and more efficient. But\\\\\\\\nthe first algorithm dates back... I think it was actually\\\\\\\\ninvented during the project Manhattan. So during World\\\\\\\\nWar II.\\\\\\\\nJon: 13:57 Theme of the day.\\\\\\\\nShow Notes: http://www.superdatascience.com/802 9\\\\\\\\nAlex: 13:58 Yeah. And lots of physicists actually, statistical physics is\\\\\\\\na field that\\\\\\\\\\'s contributed a lot to MCMC. And so yeah,\\\\\\\\nphysicists who came to the field of statistics and trying to\\\\\\\\nmake the algorithms more efficient for their models. So\\\\\\\\nthey have contributed a lot. The field of physics has\\\\\\\\ncontributed a lot of big names and people to great leaps\\\\\\\\ninto the realm of more efficient algorithms. And so, I don\\\\\\\\\\'t\\\\\\\\nknow who your audience is, but that may sound boring.\\\\\\\\n14:37 Yeah, the algorithm, it\\\\\\\\\\'s like the workhorse, but it\\\\\\\\\\'s\\\\\\\\nextremely powerful. And that\\\\\\\\\\'s also one of the main\\\\\\\\nreasons why Bayesian statistics are increasing in\\\\\\\\npopularity lately, because I\\\\\\\\\\'m going to argue that it\\\\\\\\\\'s\\\\\\\\nalways been the best framework to do statistics, to do\\\\\\\\nscience. But it was hard to do with pen and paper\\\\\\\\nbecause the problem is that you have a huge, nasty\\\\\\\\nintegral on the numerator, on the denominator, sorry.\\\\\\\\nAnd this integral is not computable by pen and paper. So\\\\\\\\nfor a long, long time, Bayesian statistics combined two\\\\\\\\nfeatures like campaigns, PR campaigns. Bayesian\\\\\\\\nstatistics was relegated to the margins because it was just\\\\\\\\nsuper hard to do.\\\\\\\\n15:31 And so for other problems, other than very trivial ones, it\\\\\\\\nwas not very applicable. But now with the advent of\\\\\\\\npersonal computing, you have these incredible\\\\\\\\nalgorithms. So now most of the time, it\\\\\\\\\\'s HMC, Hamilton\\\\\\\\nand Monte Carlo. That\\\\\\\\\\'s what we use under the hood with\\\\\\\\nPyMC. But if you stand, if you use [inaudible 00:15:54] ,\\\\\\\\nit\\\\\\\\\\'s the same. And thanks to these algorithms, now we\\\\\\\\ncan make extremely powerful models because we can\\\\\\\\napproximate the [inaudible 00:16:03] distributions thanks\\\\\\\\nto, well, computer\\\\\\\\\\'s computing power. A computer is very\\\\\\\\ngood at computing. I think that\\\\\\\\\\'s why it\\\\\\\\\\'s called that.\\\\\\\\nJon: 16:15 Yes. And so that reminds me of deep learning. It\\\\\\\\\\'s a\\\\\\\\nsimilar kind of thing where the applications we have\\\\\\\\ntoday, like your ChatGPT or whatever your favorite large\\\\\\\\nShow Notes: http://www.superdatascience.com/802 10\\\\\\\\nlanguage model is, these amazing. Video generation like\\\\\\\\nSora, all of this is happening thanks to deep learning,\\\\\\\\nwhich is an approach we\\\\\\\\\\'ve had since the \\\\\\\\\\'50s. Certainly\\\\\\\\nnot as old as Bayesian statistics, but similarly, it has\\\\\\\\nbeen able to take off with much larger data sets and\\\\\\\\nmuch more compute.\\\\\\\\nAlex: 16:46 Yeah, yeah. Yeah, yeah, very good point. And I think\\\\\\\\nthat\\\\\\\\\\'s even more the point in deep learning for sure,\\\\\\\\nbecause Bayesian stats doesn\\\\\\\\\\'t need the scale, but the\\\\\\\\nway we\\\\\\\\\\'re doing deep learning for now, definitely need the\\\\\\\\nscale.\\\\\\\\nJon: 16:58 Yeah, yeah. Scale of data.\\\\\\\\nAlex: 17:00 Yeah, yeah, exactly. Yeah, sorry, yeah, the scale, because\\\\\\\\nour two scales, data and computing. Yeah. You\\\\\\\\\\'re right.\\\\\\\\nJon: 17:05 And for model parameters. So that has actually... I mean,\\\\\\\\ntying back to something you said near the beginning of\\\\\\\\nthis episode, is that actually one of the advantages of\\\\\\\\nBayesian statistics is that you can do it with very few\\\\\\\\ndata. Maybe fewer data than with a frequentist approach\\\\\\\\nor a machine learning approach, because you can bake in\\\\\\\\nyour prior assumptions. And those prior assumptions\\\\\\\\ngive some kind of structure, some kind of framework for\\\\\\\\nyour data to make an impact.\\\\\\\\nAlex: 17:32 Yeah. Yeah, completely.\\\\\\\\nJon: 17:34 And in keeping with the theme of returning to the past to\\\\\\\\nfind golden opportunities, I speak to Dr. Nathan Lambert\\\\\\\\nabout historical influences on contemporary\\\\\\\\nmethodologies. I also managed to sneak in a question\\\\\\\\nabout reinforcement learning from human feedback.\\\\\\\\nNathan is a research scientist for the Allen Institute for\\\\\\\\nAI, and previously built out the RLHF team at Hugging\\\\\\\\nFace. So there was no better person to ask about the lack\\\\\\\\nShow Notes: http://www.superdatascience.com/802 11\\\\\\\\nof robustness in RLHF and how that could impact the\\\\\\\\nfuture development and deployment of AI systems.\\\\\\\\n18:02 Another really cool thing that you\\\\\\\\\\'ve done related to RLHF\\\\\\\\nis you have traced it back to ancient philosophy and\\\\\\\\nmodern economics. So mentioning Aristotle and von\\\\\\\\nNeumann-Morganstern utility theorem, for example. I\\\\\\\\ndon\\\\\\\\\\'t really know what the VNM utility theorem is, but\\\\\\\\nhow do these historical foundations influence current\\\\\\\\nmethodologies and what can modern AI research learn\\\\\\\\nfrom these early theories?\\\\\\\\nNathan: 18:30 Yeah. So this is a fun paper with a few colleagues that I\\\\\\\\nstarted working with at Berkeley, and now we\\\\\\\\\\'re kind of\\\\\\\\nspread out. This is all based on the fact that RL is very\\\\\\\\ndeep field multidisciplinary history, where it goes way\\\\\\\\nback. And then the notion of preference is a very vague\\\\\\\\nthing in economics. And it\\\\\\\\\\'s like the von NeumannMorganstern theory is a foundational thing that\\\\\\\\nessentially it\\\\\\\\\\'s like you can express either all behaviors or\\\\\\\\nall goals as probability and expected value distributions,\\\\\\\\nwhich essentially lets you do expected value math over\\\\\\\\npreferences.\\\\\\\\n19:10 And then it led to a bunch of debates on whether or not\\\\\\\\npreferences actually exist and are tractable in any of\\\\\\\\nthese things, or if they\\\\\\\\\\'re actually measurable or not due\\\\\\\\nto the preference shift over time based on context. So\\\\\\\\nthese are the kinds of things that we take and it\\\\\\\\\\'s ask a\\\\\\\\nlot of questions on how this impacts the modern RLHF\\\\\\\\nprocess. It\\\\\\\\\\'s things like is the final model\\\\\\\\\\'s preferences,\\\\\\\\nwhich is like we\\\\\\\\\\'re mapping onto very human terms, is\\\\\\\\nthat actually based more on the the base model, which is\\\\\\\\nscraped from the internet than the human preferences\\\\\\\\nthat they get from somewhere like Scale AI.\\\\\\\\n19:46 So it\\\\\\\\\\'s like if it\\\\\\\\\\'s based more on the internet crawling than\\\\\\\\nthis million dollar dataset they\\\\\\\\\\'re getting from Scale AI,\\\\\\\\nShow Notes: http://www.superdatascience.com/802 12\\\\\\\\nit\\\\\\\\\\'s kind of confusing to the marketing where we\\\\\\\\\\'re saying\\\\\\\\nwe\\\\\\\\\\'re learning a preference model, but it might not\\\\\\\\nactually do that much. Is other things like OpenAI now\\\\\\\\nhas a ton of user data and it\\\\\\\\\\'s like what does the\\\\\\\\neconomics literature say about generating data for\\\\\\\\ntraining that comes from a user context or a professional\\\\\\\\ncontext where someone is paid to do it and they\\\\\\\\\\'re paid to\\\\\\\\nact in a certain way? And how does all of this mix? So it\\\\\\\\\\'s\\\\\\\\nreally just a super long list of questions of why we should\\\\\\\\nlook at other social sciences if we\\\\\\\\\\'re making grand claims\\\\\\\\nabout human preferences and all of these things.\\\\\\\\nJon: 20:26 Nice. Well, fascinating. Tons to dig into there for our\\\\\\\\nlisteners. Final topic that I planned related to RLHF, I\\\\\\\\\\'m\\\\\\\\nsure it\\\\\\\\\\'ll come up again organically in the conversation,\\\\\\\\nbut you\\\\\\\\\\'ve mentioned that RLHF is not even robust to\\\\\\\\nfine-tuning. And so removing the safety layer from models\\\\\\\\nlike GPT-4 and Llama 2 can break down the notion of\\\\\\\\nsafety. Can you elaborate on the implications of this\\\\\\\\nfragility for the future development and deployment of AI\\\\\\\\nsystems?\\\\\\\\nNathan: 20:59 Yeah, so this is a specific line of research. So there\\\\\\\\\\'s a few\\\\\\\\npapers that showed that if you take a model like Zephyr\\\\\\\\nor Tulu that we were mentioning, if they have safety in\\\\\\\\nthe dataset, if you then go and fine-tune it again on some\\\\\\\\ndifferent tasks, you\\\\\\\\\\'ll do some of the behaviors that are\\\\\\\\n\\\\\"ingrained\\\\\" in the model. I honestly think this is a little\\\\\\\\nbit more clickbaity than actually worrisome because it\\\\\\\\\\'s\\\\\\\\nreally not surprising given that if you just look at the\\\\\\\\namount of compute applied at fine-tuning, we pre-trained\\\\\\\\nthese models for trillions of tokens. And then we apply a\\\\\\\\ncouple billion tokens of compute at fine-tuning.\\\\\\\\n21:36 And it\\\\\\\\\\'s like we\\\\\\\\\\'re not changing the weights of the model\\\\\\\\nsubstantially. We\\\\\\\\\\'re doing a slight nudge, and it makes\\\\\\\\nsense that a slight nudge could be undone at the same\\\\\\\\nway. But if you were to take this to some of the bigger\\\\\\\\nShow Notes: http://www.superdatascience.com/802 13\\\\\\\\nlabs, what you hear is that safety is not just a single\\\\\\\\nartifact thing. Safety is much more about a complete\\\\\\\\nsystem than a model. So open weight models being\\\\\\\\nunsafe or unsafe, I don\\\\\\\\\\'t consider to be that big of a deal.\\\\\\\\nIt\\\\\\\\\\'s like if you were to apply them to a free endpoint that\\\\\\\\neveryone on the internet could talk to, then I don\\\\\\\\\\'t want\\\\\\\\nmy model saying good things about Hitler and all these\\\\\\\\nobvious things.\\\\\\\\n22:09 But if it\\\\\\\\\\'s a research artifact that you need to spin up\\\\\\\\nGPUs to use yourself, and it\\\\\\\\\\'s a little bit more... I\\\\\\\\\\'m more\\\\\\\\nopen to having these diversity of models exist. But if you\\\\\\\\nask [inaudible 00:22:22] or somebody, it\\\\\\\\\\'s like, \\\\\"What\\\\\\\\nhappens... How do you get safety into your model?\\\\\" And\\\\\\\\nit\\\\\\\\\\'s like, it\\\\\\\\\\'s not just RLHF. You need to have safety at the\\\\\\\\npre-training, any preference model you trained. And then\\\\\\\\nall of these models have a safety filter on the output. So\\\\\\\\nChatGPT, it reads all the text generated from the base\\\\\\\\nmodel, and then there\\\\\\\\\\'s a go, no go where it will rephrase\\\\\\\\nthe text if it gets a no-go signal, which is like their content\\\\\\\\nmoderation API.\\\\\\\\n22:45 So it\\\\\\\\\\'s kind of a double. It\\\\\\\\\\'s the type of thing where\\\\\\\\nresearchers need to market their work, but it\\\\\\\\\\'s not as big\\\\\\\\nof a detail as I think it is. It\\\\\\\\\\'s like, okay, I think it has\\\\\\\\ninteresting business downstream things with liability. So\\\\\\\\nit\\\\\\\\\\'s just like if you want to fine-tune a Llama model, you\\\\\\\\nnormally do that on your own hardware, but OpenAI has\\\\\\\\na fine-tuning API. And if they claim their model is safe,\\\\\\\\nbut any fine-tuning on their API that they then host\\\\\\\\nmakes it unsafe, that seems like more of a business\\\\\\\\nproblem. Which is like, oh, it\\\\\\\\\\'s a nice way that open\\\\\\\\necosystem might be better off because it breaks the\\\\\\\\nliability chain. But we\\\\\\\\\\'ll see this research continue to\\\\\\\\nevolve. It\\\\\\\\\\'s so early in all of these things for a year in.\\\\\\\\nJon: 23:31 All right. That\\\\\\\\\\'s it for today\\\\\\\\\\'s In Case You Missed It\\\\\\\\nepisode, to be sure not to miss any of our exciting\\\\\\\\nShow Notes: http://www.superdatascience.com/802 14\\\\\\\\nupcoming episodes. Be sure to subscribe to this podcast\\\\\\\\nif you haven\\\\\\\\\\'t already. But most importantly, I hope you\\\\\\\\\\'ll\\\\\\\\njust keep on listening. Until next time, keep on rocking it\\\\\\\\nout there. And I\\\\\\\\\\'m looking forward to enjoying another\\\\\\\\nround of Super Data Science Podcast with you very soon.\\')]\"\\n      ]\\n     },\\n     \"execution_count\": 35,\\n     \"metadata\": {},\\n     \"output_type\": \"execute_result\"\\n    }\\n   ],\\n   \"source\": [\\n    \"docs\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"markdown\",\\n   \"metadata\": {},\\n   \"source\": [\\n    \"## Chroma DB\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": 37,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"# building sample vectorDB\\\\n\",\\n    \"\\\\n\",\\n    \"from langchain_chroma import Chroma\\\\n\",\\n    \"from langchain_community.document_loaders import TextLoader\\\\n\",\\n    \"from langchain_community.embeddings import OllamaEmbeddings\\\\n\",\\n    \"from langchain.text_splitter import RecursiveCharacterTextSplitter\"\\n   ]\\n  },\\n  {\\n   \"cell_type\": \"code\",\\n   \"execution_count\": null,\\n   \"metadata\": {},\\n   \"outputs\": [],\\n   \"source\": [\\n    \"loader = TextLoader(\\\\\"5. VectorStores/vectorStores.ipynb\\\\\")\\\\n\",\\n    \"data \"\\n   ]\\n  }\\n ],\\n \"metadata\": {\\n  \"language_info\": {\\n   \"name\": \"python\"\\n  }\\n },\\n \"nbformat\": 4,\\n \"nbformat_minor\": 2\\n}\\n')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = TextLoader(\"5. VectorStores/vectorStores.ipynb\")\n",
    "data = loader.load()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorDB = Chroma.from_documents(documents=splits, embedding=ollama_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Query it\n",
    "\n",
    "q2 = \"How do you get safety into your model?\"\n",
    "docs = vectorDB.similarity_search(q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving in local\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=splits, embedding=ollama_embeddings, persist_directory=\"./chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from disk\n",
    "\n",
    "db2 = Chroma(persist_directory=\"./chroma_db\", embedding_function=ollama_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = db2.similarity_search(q2)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similary Search with Score\n",
    "\n",
    "docs = vectorDB.similarity_search_with_score(q2)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retriever \n",
    "\n",
    "retriever_chroma = vectorDB.retriever()\n",
    "retriever_chroma.invoke(q2)[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
